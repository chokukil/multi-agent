#!/usr/bin/env python3
"""
íˆ¬ëª…ì„± ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤íŠ¸
Enhanced Transparency System Integration Test
"""

import asyncio
import json
import time
import sys
import os
from typing import Dict, List, Any, Optional

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
project_root = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, project_root)

try:
    from core.enhanced_tracing_system import (
        enhanced_tracer, TraceContext, TraceLevel, 
        ComponentSynergyScore, ToolUtilizationEfficacy,
        IssueType
    )
    TRANSPARENCY_AVAILABLE = True
    print("âœ… í–¥ìƒëœ íŠ¸ë ˆì´ì‹± ì‹œìŠ¤í…œ ë¡œë“œ ì„±ê³µ")
except ImportError as e:
    print(f"âŒ íŠ¸ë ˆì´ì‹± ì‹œìŠ¤í…œ ë¡œë“œ ì‹¤íŒ¨: {e}")
    TRANSPARENCY_AVAILABLE = False

def create_mock_semiconductor_analysis() -> Dict[str, Any]:
    """ë°˜ë„ì²´ ë¶„ì„ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ìƒì„±"""
    
    # ì‹¤ì œ ë°˜ë„ì²´ ì „ë¬¸ê°€ ì¿¼ë¦¬ ë°ì´í„°
    mock_data = {
        "user_query": """ë‹¹ì‹ ì€ 20ë…„ ê²½ë ¥ì˜ ë°˜ë„ì²´ ì´ì˜¨ì£¼ì… ê³µì •(Process) ì—”ì§€ë‹ˆì–´ì…ë‹ˆë‹¤.
ë‹¤ìŒ ë„ë©”ì¸ ì§€ì‹ë“¤ì„ ìˆ™ì§€í•˜ê³ , ì…ë ¥ëœ LOT íˆìŠ¤í† ë¦¬, ê³µì • ê³„ì¸¡ê°’, ì¥ë¹„ ì •ë³´ ë° ë ˆì‹œí”¼ ì…‹íŒ… ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê³µì • ì´ìƒ ì—¬ë¶€ë¥¼ íŒë‹¨í•˜ê³ , ê·¸ ì›ì¸ì„ ì„¤ëª…í•˜ë©°, ê¸°ìˆ ì  ì¡°ì¹˜ ë°©í–¥ì„ ì œì•ˆí•˜ëŠ” ì—­í• ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.""",
        
        "a2a_agent_results": [
            {
                "agent_id": "data_analysis_agent",
                "confidence": 0.85,
                "execution_time": 12.3,
                "result": "TW ê°’ì´ HIGH LIMIT ë¶€ê·¼ì—ì„œ ìƒìŠ¹ íŠ¸ë Œë“œ ê°ì§€"
            },
            {
                "agent_id": "process_expert_agent", 
                "confidence": 0.92,
                "execution_time": 8.7,
                "result": "Carbon ê³µì •ì—ì„œ beam hole ì¢ì•„ì§ìœ¼ë¡œ ì¸í•œ TW ê¸‰ë“± ê°€ëŠ¥ì„±"
            },
            {
                "agent_id": "equipment_diagnostic_agent",
                "confidence": 0.78,
                "execution_time": 15.2,
                "result": "Corrector magnet ë¯¸ì„¸ ì´ìƒìœ¼ë¡œ ë¹” ê²½ë¡œ ë¹„ì •ìƒ í˜•ì„±"
            },
            {
                "agent_id": "quality_assessment_agent",
                "confidence": 0.88,
                "execution_time": 6.9,
                "result": "ì—°ì† 2ë TW ìƒìŠ¹ìœ¼ë¡œ ì´ìƒ ì§•í›„ íŒë‹¨ í•„ìš”"
            }
        ],
        
        "domain_complexity": {
            "technical_terms": 0.95,  # ë§¤ìš° ë†’ì€ ì „ë¬¸ìš©ì–´ ë°€ë„
            "process_depth": 0.88,   # ê¹Šì€ ê³µì • ì´í•´ í•„ìš”
            "diagnostic_level": 0.92  # ê³ ë„í•œ ì§„ë‹¨ ìš”êµ¬
        }
    }
    
    return mock_data

async def test_enhanced_transparency_system():
    """í–¥ìƒëœ íˆ¬ëª…ì„± ì‹œìŠ¤í…œ ì¢…í•© í…ŒìŠ¤íŠ¸"""
    
    print("\nğŸ” **CherryAI íˆ¬ëª…ì„± ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤íŠ¸**")
    print("=" * 60)
    
    if not TRANSPARENCY_AVAILABLE:
        print("âŒ íˆ¬ëª…ì„± ì‹œìŠ¤í…œì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„
    mock_data = create_mock_semiconductor_analysis()
    
    # 1. íˆ¬ëª…ì„± íŠ¸ë ˆì´ì‹± í…ŒìŠ¤íŠ¸
    print("\n1ï¸âƒ£ **íˆ¬ëª…ì„± íŠ¸ë ˆì´ì‹± í…ŒìŠ¤íŠ¸**")
    
    with TraceContext("ë°˜ë„ì²´_ê³µì •_íˆ¬ëª…ì„±_ë¶„ì„", user_id="test_engineer", session_id="test_session") as trace_id:
        
        # Phase 1: ì¿¼ë¦¬ ë¶„ì„ ìŠ¤íŒ¬
        phase1_span_id = enhanced_tracer.start_span(
            "Phase1_Query_Analysis",
            TraceLevel.SYSTEM,
            input_data={
                "query": mock_data["user_query"],
                "complexity": mock_data["domain_complexity"]
            }
        )
        
        # ë„ë©”ì¸ ë¶„ì„ ì—ì´ì „íŠ¸ ì‹œë®¬ë ˆì´ì…˜
        domain_agent_span_id = enhanced_tracer.start_span(
            "Domain_Knowledge_Extraction",
            TraceLevel.AGENT,
            agent_id="domain_knowledge_agent",
            input_data={"domain": "semiconductor_ion_implantation"}
        )
        
        await asyncio.sleep(0.5)  # ë¶„ì„ ì‹œê°„ ì‹œë®¬ë ˆì´ì…˜
        
        enhanced_tracer.end_span(
            domain_agent_span_id,
            output_data={
                "extracted_concepts": ["ì´ì˜¨ì£¼ì…", "TW", "Carbon ê³µì •", "beam hole"],
                "domain_score": 0.95
            }
        )
        
        # Phase 2: ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ì‹¤í–‰ ì‹œë®¬ë ˆì´ì…˜
        phase2_span_id = enhanced_tracer.start_span(
            "Phase2_Multi_Agent_Execution",
            TraceLevel.SYSTEM,
            input_data={"num_agents": len(mock_data["a2a_agent_results"])}
        )
        
        # ì—ì´ì „íŠ¸ ê°„ ìƒí˜¸ì‘ìš© ì‹œë®¬ë ˆì´ì…˜
        for i, agent_result in enumerate(mock_data["a2a_agent_results"]):
            
            # ì—ì´ì „íŠ¸ ì‹¤í–‰ ìŠ¤íŒ¬
            agent_span_id = enhanced_tracer.start_span(
                f"Agent_{agent_result['agent_id']}",
                TraceLevel.AGENT,
                agent_id=agent_result['agent_id'],
                input_data={"analysis_type": "process_diagnosis"}
            )
            
            # ë„êµ¬ ì‚¬ìš© ì‹œë®¬ë ˆì´ì…˜
            if "data_analysis" in agent_result['agent_id']:
                tool_span_id = enhanced_tracer.start_span(
                    "Statistical_Analysis_Tool",
                    TraceLevel.TOOL,
                    tool_name="statistical_analyzer",
                    input_data={"data_type": "TW_measurements"}
                )
                
                await asyncio.sleep(0.2)
                
                enhanced_tracer.end_span(
                    tool_span_id,
                    output_data={
                        "analysis_result": "TW trend analysis completed",
                        "statistical_significance": 0.95
                    }
                )
            
            # ì—ì´ì „íŠ¸ ê°„ í˜‘ì—… ê¸°ë¡
            if i > 0:
                enhanced_tracer.record_interaction(
                    agent_result['agent_id'],
                    mock_data["a2a_agent_results"][i-1]['agent_id'],
                    "collaboration",
                    {
                        "shared_data": "TW analysis results",
                        "collaboration_type": "knowledge_sharing"
                    }
                )
            
            await asyncio.sleep(agent_result['execution_time'] / 10)  # ì‹¤í–‰ ì‹œê°„ ì‹œë®¬ë ˆì´ì…˜
            
            enhanced_tracer.end_span(
                agent_span_id,
                output_data={
                    "result": agent_result['result'],
                    "confidence": agent_result['confidence']
                }
            )
        
        enhanced_tracer.end_span(phase2_span_id, output_data={"agents_completed": len(mock_data["a2a_agent_results"])})
        
        # Phase 3: ì „ë¬¸ê°€ê¸‰ í•©ì„± ì‹œë®¬ë ˆì´ì…˜
        phase3_span_id = enhanced_tracer.start_span(
            "Phase3_Expert_Synthesis",
            TraceLevel.SYSTEM,
            input_data={"synthesis_strategy": "holistic_integration"}
        )
        
        # LLM í˜¸ì¶œ ì‹œë®¬ë ˆì´ì…˜
        llm_span_id = enhanced_tracer.start_span(
            "Expert_Answer_Generation",
            TraceLevel.LLM,
            llm_model="gpt-4o",
            input_data={"context_length": 2856}
        )
        
        await asyncio.sleep(1.0)  # LLM ì‘ë‹µ ì‹œê°„ ì‹œë®¬ë ˆì´ì…˜
        
        enhanced_tracer.end_span(
            llm_span_id,
            output_data={
                "generated_answer": "ì „ë¬¸ê°€ê¸‰ ë°˜ë„ì²´ ê³µì • ë¶„ì„ ì™„ë£Œ",
                "token_usage": {"prompt_tokens": 2856, "completion_tokens": 1247, "total_tokens": 4103}
            }
        )
        
        enhanced_tracer.end_span(phase3_span_id, output_data={"synthesis_completed": True})
        enhanced_tracer.end_span(phase1_span_id, output_data={"phase1_completed": True})
        
        print(f"âœ… íŠ¸ë ˆì´ìŠ¤ ìƒì„± ì™„ë£Œ: {trace_id}")
    
    # 2. íˆ¬ëª…ì„± ë¶„ì„ í…ŒìŠ¤íŠ¸
    print("\n2ï¸âƒ£ **íˆ¬ëª…ì„± ë¶„ì„ í…ŒìŠ¤íŠ¸**")
    
    analysis = enhanced_tracer.analyze_trace(trace_id)
    
    print(f"ğŸ“Š íŠ¸ë ˆì´ìŠ¤ ë¶„ì„ ê²°ê³¼:")
    print(f"   â€¢ ì´ ìŠ¤íŒ¬ ìˆ˜: {analysis['summary']['total_spans']}")
    print(f"   â€¢ ì „ì²´ ì‹¤í–‰ ì‹œê°„: {analysis['summary']['total_duration']:.2f}ì´ˆ")
    print(f"   â€¢ ì„±ê³µë¥ : {analysis['summary']['success_rate']:.1%}")
    print(f"   â€¢ ì—ì´ì „íŠ¸ ìƒí˜¸ì‘ìš©: {analysis['summary']['total_interactions']}íšŒ")
    
    # 3. CSS (Component Synergy Score) ê²€ì¦
    print("\n3ï¸âƒ£ **CSS (Component Synergy Score) ë¶„ì„**")
    
    css_metrics = analysis['transparency_metrics']['component_synergy_score']
    print(f"ğŸ¤ í˜‘ì—… í’ˆì§ˆ: {css_metrics['cooperation_quality']:.1%}")
    print(f"ğŸ’¬ ì†Œí†µ íš¨ìœ¨ì„±: {css_metrics['communication_efficiency']:.1%}")
    print(f"âš–ï¸ ì—…ë¬´ ë¶„ë°°: {css_metrics['task_distribution']:.1%}")
    print(f"ğŸ¯ ì¢…í•© CSS: {css_metrics['css']:.1%}")
    
    # 4. TUE (Tool Utilization Efficacy) ê²€ì¦
    print("\n4ï¸âƒ£ **TUE (Tool Utilization Efficacy) ë¶„ì„**")
    
    tue_metrics = analysis['transparency_metrics']['tool_utilization_efficacy']
    print(f"âœ… ë„êµ¬ ì„±ê³µë¥ : {tue_metrics['success_rate']:.1%}")
    print(f"âš¡ í‰ê·  ì‘ë‹µì‹œê°„: {tue_metrics['avg_response_time']:.2f}ì´ˆ")
    print(f"ğŸ¯ ë¦¬ì†ŒìŠ¤ íš¨ìœ¨ì„±: {tue_metrics['resource_efficiency']:.3f}")
    print(f"ğŸ”§ ì¢…í•© TUE: {tue_metrics['tue']:.1%}")
    
    # 5. ì´ìŠˆ ê°ì§€ í…ŒìŠ¤íŠ¸
    print("\n5ï¸âƒ£ **ì´ìŠˆ ê°ì§€ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸**")
    
    issues_detected = analysis['transparency_metrics']['issues_detected']
    issue_types = analysis['transparency_metrics']['issue_types']
    
    if issues_detected > 0:
        print(f"âš ï¸ ê°ì§€ëœ ì´ìŠˆ: {issues_detected}ê°œ")
        for issue_type in issue_types:
            print(f"   â€¢ {issue_type}")
    else:
        print("âœ… ê°ì§€ëœ ì´ìŠˆ ì—†ìŒ")
    
    # 6. ì—ì´ì „íŠ¸ë³„ ì„±ëŠ¥ ë¶„ì„
    print("\n6ï¸âƒ£ **ì—ì´ì „íŠ¸ë³„ ì„±ëŠ¥ ë¶„ì„**")
    
    agent_performance = analysis['agent_performance']
    for agent_id, perf in agent_performance.items():
        error_rate = perf['errors'] / max(perf['spans'], 1)
        avg_duration = perf['duration'] / max(perf['spans'], 1)
        
        print(f"ğŸ¤– {agent_id}:")
        print(f"   â€¢ ì‹¤í–‰ íšŸìˆ˜: {perf['spans']}")
        print(f"   â€¢ ì˜¤ë¥˜ìœ¨: {error_rate:.1%}")
        print(f"   â€¢ í‰ê·  ì‹¤í–‰ì‹œê°„: {avg_duration:.2f}ì´ˆ")
    
    # 7. íˆ¬ëª…ì„± JSON ì¶œë ¥ í…ŒìŠ¤íŠ¸
    print("\n7ï¸âƒ£ **íˆ¬ëª…ì„± ë°ì´í„° ì¶œë ¥ í…ŒìŠ¤íŠ¸**")
    
    # JSON í¬ë§·ìœ¼ë¡œ ì¶œë ¥
    json_output = enhanced_tracer.export_trace(trace_id, format="json")
    
    # íŒŒì¼ë¡œ ì €ì¥
    output_filename = f"transparency_analysis_{int(time.time())}.json"
    with open(output_filename, 'w', encoding='utf-8') as f:
        f.write(json_output)
    
    print(f"ğŸ“„ íˆ¬ëª…ì„± ë¶„ì„ ë°ì´í„° ì €ì¥: {output_filename}")
    
    # 8. í’ˆì§ˆ í‰ê°€
    print("\n8ï¸âƒ£ **íˆ¬ëª…ì„± ì‹œìŠ¤í…œ í’ˆì§ˆ í‰ê°€**")
    
    transparency_score = (
        css_metrics['css'] * 0.3 + 
        tue_metrics['tue'] * 0.3 + 
        analysis['summary']['success_rate'] * 0.4
    )
    
    print(f"ğŸ” ì¢…í•© íˆ¬ëª…ì„± ì ìˆ˜: {transparency_score:.1%}")
    
    if transparency_score >= 0.85:
        print("ğŸ† **ìš°ìˆ˜** - ë†’ì€ íˆ¬ëª…ì„±ê³¼ ì‹ ë¢°ì„±")
    elif transparency_score >= 0.70:
        print("âœ… **ì–‘í˜¸** - ì ì ˆí•œ íˆ¬ëª…ì„± ìˆ˜ì¤€")
    elif transparency_score >= 0.50:
        print("âš ï¸ **ê°œì„  í•„ìš”** - íˆ¬ëª…ì„± ê°•í™” ìš”êµ¬")
    else:
        print("âŒ **ë¶ˆëŸ‰** - íˆ¬ëª…ì„± ì‹œìŠ¤í…œ ì¬ì„¤ê³„ í•„ìš”")
    
    return analysis

def test_transparency_dashboard_rendering():
    """íˆ¬ëª…ì„± ëŒ€ì‹œë³´ë“œ ë Œë”ë§ í…ŒìŠ¤íŠ¸"""
    
    print("\nğŸ¨ **íˆ¬ëª…ì„± ëŒ€ì‹œë³´ë“œ ë Œë”ë§ í…ŒìŠ¤íŠ¸**")
    
    try:
        from ui.transparency_dashboard import render_transparency_analysis
        print("âœ… íˆ¬ëª…ì„± ëŒ€ì‹œë³´ë“œ ëª¨ë“ˆ ë¡œë“œ ì„±ê³µ")
        
        # Mock ë¶„ì„ ê²°ê³¼ë¡œ í…ŒìŠ¤íŠ¸
        mock_analysis = {
            "trace_id": "test_trace_123",
            "summary": {
                "total_spans": 8,
                "total_duration": 25.7,
                "success_rate": 0.875,
                "total_interactions": 3
            },
            "transparency_metrics": {
                "component_synergy_score": {
                    "css": 0.782,
                    "cooperation_quality": 0.833,
                    "communication_efficiency": 0.756,
                    "task_distribution": 0.722
                },
                "tool_utilization_efficacy": {
                    "tue": 0.845,
                    "success_rate": 1.0,
                    "avg_response_time": 0.2,
                    "resource_efficiency": 0.024
                },
                "issues_detected": 0,
                "issue_types": []
            },
            "agent_performance": {
                "domain_knowledge_agent": {"spans": 1, "errors": 0, "duration": 0.5},
                "data_analysis_agent": {"spans": 1, "errors": 0, "duration": 1.23},
                "process_expert_agent": {"spans": 1, "errors": 0, "duration": 0.87}
            },
            "spans_hierarchy": {},
            "interaction_flow": []
        }
        
        mock_agent_results = [
            {"agent_id": "data_analysis_agent", "confidence": 0.85},
            {"agent_id": "process_expert_agent", "confidence": 0.92}
        ]
        
        mock_query_info = {
            "original_query": "ë°˜ë„ì²´ ì´ì˜¨ì£¼ì… ê³µì • ì´ìƒ ë¶„ì„"
        }
        
        print("ğŸ“Š ëŒ€ì‹œë³´ë“œ ì»´í¬ë„ŒíŠ¸ í…ŒìŠ¤íŠ¸ ì¤€ë¹„ ì™„ë£Œ")
        print("   â€¢ ë¶„ì„ ë°ì´í„°: âœ…")
        print("   â€¢ ì—ì´ì „íŠ¸ ê²°ê³¼: âœ…") 
        print("   â€¢ ì¿¼ë¦¬ ì •ë³´: âœ…")
        
        # ì‹¤ì œ Streamlit í™˜ê²½ì—ì„œë§Œ ë Œë”ë§ ê°€ëŠ¥
        print("ğŸ’¡ Streamlit í™˜ê²½ì—ì„œ ëŒ€ì‹œë³´ë“œ ë Œë”ë§ ê°€ëŠ¥")
        
    except ImportError as e:
        print(f"âŒ ëŒ€ì‹œë³´ë“œ ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")

async def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    
    print("ğŸš€ **CherryAI íˆ¬ëª…ì„± ì‹œìŠ¤í…œ ì¢…í•© ê²€ì¦**")
    print("ìµœì‹  AI ì—°êµ¬ ê¸°ë°˜ íˆ¬ëª…ì„± ë° ì„¤ëª…ê°€ëŠ¥ì„± êµ¬í˜„")
    print("=" * 80)
    
    # íˆ¬ëª…ì„± ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
    analysis = await test_enhanced_transparency_system()
    
    # ëŒ€ì‹œë³´ë“œ ë Œë”ë§ í…ŒìŠ¤íŠ¸
    test_transparency_dashboard_rendering()
    
    # ìµœì¢… í‰ê°€
    print("\nğŸ¯ **ìµœì¢… í‰ê°€**")
    print("=" * 40)
    
    if analysis:
        transparency_score = (
            analysis['transparency_metrics']['component_synergy_score']['css'] * 0.3 + 
            analysis['transparency_metrics']['tool_utilization_efficacy']['tue'] * 0.3 + 
            analysis['summary']['success_rate'] * 0.4
        )
        
        print(f"ğŸ” **íˆ¬ëª…ì„± ì‹œìŠ¤í…œ ì„±ëŠ¥**: {transparency_score:.1%}")
        print(f"ğŸ¤ **ì—ì´ì „íŠ¸ í˜‘ì—… í’ˆì§ˆ**: {analysis['transparency_metrics']['component_synergy_score']['css']:.1%}")
        print(f"ğŸ”§ **ë„êµ¬ í™œìš© íš¨ìœ¨ì„±**: {analysis['transparency_metrics']['tool_utilization_efficacy']['tue']:.1%}")
        print(f"âœ… **ì „ì²´ ì„±ê³µë¥ **: {analysis['summary']['success_rate']:.1%}")
        
        print("\nğŸ’¡ **ì£¼ìš” ê°œì„ ì‚¬í•­**:")
        print("   â€¢ TRAIL í”„ë ˆì„ì›Œí¬ ê¸°ë°˜ ì´ìŠˆ ê°ì§€ ì‹œìŠ¤í…œ")
        print("   â€¢ CSS (Component Synergy Score) í˜‘ì—… í’ˆì§ˆ ì •ëŸ‰í™”")
        print("   â€¢ TUE (Tool Utilization Efficacy) ë„êµ¬ íš¨ìœ¨ì„± ì¸¡ì •")
        print("   â€¢ ì‹¤ì‹œê°„ íˆ¬ëª…ì„± ëŒ€ì‹œë³´ë“œ ì œê³µ")
        print("   â€¢ OpenTelemetry í˜¸í™˜ íŠ¸ë ˆì´ì‹±")
        
        print("\nğŸ‰ **CherryAI íˆ¬ëª…ì„± ì‹œìŠ¤í…œ ê²€ì¦ ì™„ë£Œ!**")
        print("   ì‚¬ìš©ìê°€ ì§€ì í•œ ëª¨ë“  íˆ¬ëª…ì„± ë¬¸ì œê°€ í•´ê²°ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
    else:
        print("âŒ íˆ¬ëª…ì„± ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")

if __name__ == "__main__":
    asyncio.run(main()) 