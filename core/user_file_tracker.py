#!/usr/bin/env python3
"""
ğŸ” User File Tracking System for CherryAI

A2A SDK 0.2.9 ì¤€ìˆ˜ ì‚¬ìš©ì íŒŒì¼ ì¶”ì  ë° ê´€ë¦¬ ì‹œìŠ¤í…œ
SessionDataManagerì™€ ì—°ë™í•˜ì—¬ ì—…ë¡œë“œëœ íŒŒì¼ì„ A2A ì—ì´ì „íŠ¸ê°€ ì •í™•íˆ ì‚¬ìš©í•˜ë„ë¡ í•¨
"""

import os
import json
import shutil
import logging
import pandas as pd
from datetime import datetime, timedelta
from pathlib import Path
from typing import Optional, Dict, Any, List, Tuple
from dataclasses import dataclass, asdict

logger = logging.getLogger(__name__)

@dataclass
class UserFileInfo:
    """ì‚¬ìš©ì ì—…ë¡œë“œ íŒŒì¼ ì •ë³´"""
    file_id: str
    original_name: str
    session_id: str
    uploaded_at: datetime
    file_size: int
    file_type: str
    data_shape: Tuple[int, int]
    is_active: bool = True
    user_context: Optional[str] = None
    file_paths: Dict[str, str] = None  # ì—¬ëŸ¬ ê²½ë¡œì— ì €ì¥ëœ íŒŒì¼ ì •ë³´
    
    def __post_init__(self):
        if self.file_paths is None:
            self.file_paths = {}

@dataclass
class FileSelectionRequest:
    """íŒŒì¼ ì„ íƒ ìš”ì²­ ì •ë³´"""
    user_request: str
    session_id: str
    agent_name: str
    requested_at: datetime
    context: Dict[str, Any] = None

class UserFileTracker:
    """
    ì‚¬ìš©ì íŒŒì¼ ì¶”ì  ë° ê´€ë¦¬ ì‹œìŠ¤í…œ
    
    A2A SDK 0.2.9 í˜¸í™˜ íŒŒì¼ ì¶”ì  ì‹œìŠ¤í…œìœ¼ë¡œ ë‹¤ìŒ ê¸°ëŠ¥ ì œê³µ:
    - ì—…ë¡œë“œëœ íŒŒì¼ì˜ ì „ì²´ ìƒëª…ì£¼ê¸° ì¶”ì 
    - ì„¸ì…˜ë³„ íŒŒì¼ ê´€ë¦¬
    - A2A ì—ì´ì „íŠ¸ìš© íŒŒì¼ ì„ íƒ ìµœì í™”
    - SessionDataManagerì™€ì˜ ì™„ë²½í•œ ì—°ë™
    """
    
    def __init__(self):
        # ê²½ë¡œ ì„¤ì •
        self.session_data_path = Path("ai_ds_team/data")
        self.shared_data_path = Path("a2a_ds_servers/artifacts/data/shared_dataframes")
        self.metadata_path = Path("core/file_tracking_metadata")
        
        # ê²½ë¡œ ìƒì„±
        self.session_data_path.mkdir(parents=True, exist_ok=True)
        self.shared_data_path.mkdir(parents=True, exist_ok=True)
        self.metadata_path.mkdir(parents=True, exist_ok=True)
        
        # ë‚´ë¶€ ìƒíƒœ
        self.tracked_files: Dict[str, UserFileInfo] = {}
        self.session_files: Dict[str, List[str]] = {}  # session_id -> file_ids
        self.current_session_id: Optional[str] = None
        
        # ê¸°ì¡´ ë©”íƒ€ë°ì´í„° ë¡œë“œ
        self._load_existing_metadata()
        
        logger.info("UserFileTracker initialized with A2A SDK 0.2.9 compatibility")
    
    def register_uploaded_file(self, 
                             file_id: str,
                             original_name: str,
                             session_id: str,
                             data: pd.DataFrame,
                             user_context: Optional[str] = None) -> bool:
        """
        ì‚¬ìš©ì ì—…ë¡œë“œ íŒŒì¼ ë“±ë¡
        
        Args:
            file_id: íŒŒì¼ ê³ ìœ  ID (ë³´í†µ ì›ë³¸ íŒŒì¼ëª…)
            original_name: ì›ë³¸ íŒŒì¼ëª…
            session_id: ì„¸ì…˜ ID
            data: íŒë‹¤ìŠ¤ ë°ì´í„°í”„ë ˆì„
            user_context: ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ ì •ë³´
            
        Returns:
            bool: ë“±ë¡ ì„±ê³µ ì—¬ë¶€
        """
        try:
            # íŒŒì¼ ì •ë³´ ìƒì„±
            file_info = UserFileInfo(
                file_id=file_id,
                original_name=original_name,
                session_id=session_id,
                uploaded_at=datetime.now(),
                file_size=int(data.memory_usage(deep=True).sum()),
                file_type=Path(original_name).suffix.lower(),
                data_shape=data.shape,
                user_context=user_context
            )
            
            # 1. ì„¸ì…˜ ê²½ë¡œì— ì €ì¥ (SessionDataManager í˜¸í™˜)
            session_dir = self.session_data_path / session_id
            session_dir.mkdir(exist_ok=True)
            session_file_path = session_dir / original_name
            self._save_dataframe(data, session_file_path)
            file_info.file_paths['session'] = str(session_file_path)
            
            # 2. ê³µìœ  ê²½ë¡œì— ì €ì¥ (A2A ì—ì´ì „íŠ¸ í˜¸í™˜)
            shared_file_path = self.shared_data_path / f"{session_id}_{original_name}"
            self._save_dataframe(data, shared_file_path)
            file_info.file_paths['shared'] = str(shared_file_path)
            
            # 3. ë©”íƒ€ë°ì´í„°ì— ì»¨í…ìŠ¤íŠ¸ ì €ì¥
            context_file = session_dir / "file_context.json"
            context_data = {
                "file_id": file_id,
                "original_name": original_name,
                "uploaded_at": file_info.uploaded_at.isoformat(),
                "user_context": user_context,
                "data_shape": data.shape,
                "shared_file_path": str(shared_file_path)
            }
            
            with open(context_file, 'w', encoding='utf-8') as f:
                json.dump(context_data, f, ensure_ascii=False, indent=2)
            
            # 4. ì¶”ì  ì •ë³´ ì—…ë°ì´íŠ¸
            self.tracked_files[file_id] = file_info
            
            if session_id not in self.session_files:
                self.session_files[session_id] = []
            self.session_files[session_id].append(file_id)
            
            # 5. í˜„ì¬ ì„¸ì…˜ìœ¼ë¡œ ì„¤ì •
            self.current_session_id = session_id
            
            # 6. ë©”íƒ€ë°ì´í„° ì €ì¥
            self._save_metadata()
            
            logger.info(f"âœ… File registered: {file_id} in session {session_id}")
            logger.info(f"   - Session path: {session_file_path}")
            logger.info(f"   - Shared path: {shared_file_path}")
            logger.info(f"   - Data shape: {data.shape}")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ Failed to register file {file_id}: {e}")
            return False
    
    def get_file_for_a2a_request(self, 
                                user_request: str,
                                session_id: Optional[str] = None,
                                agent_name: Optional[str] = None) -> Tuple[Optional[str], str]:
        """
        A2A ìš”ì²­ì— ëŒ€í•œ ìµœì  íŒŒì¼ ì„ íƒ
        
        Args:
            user_request: ì‚¬ìš©ì ìš”ì²­ í…ìŠ¤íŠ¸
            session_id: ì„¸ì…˜ ID (ì—†ìœ¼ë©´ í˜„ì¬ ì„¸ì…˜)
            agent_name: ìš”ì²­í•œ ì—ì´ì „íŠ¸ëª…
            
        Returns:
            Tuple[íŒŒì¼ê²½ë¡œ, ì„ íƒì´ìœ ]: ì„ íƒëœ íŒŒì¼ ê²½ë¡œì™€ ì„ íƒ ì´ìœ 
        """
        if session_id is None:
            session_id = self.current_session_id
        
        if not session_id or session_id not in self.session_files:
            return None, "ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ"
        
        session_file_ids = self.session_files[session_id]
        if not session_file_ids:
            return None, "ì„¸ì…˜ì— ì—…ë¡œë“œëœ íŒŒì¼ì´ ì—†ìŒ"
        
        # ìš”ì²­ ë¶„ì„ ë° íŒŒì¼ ì„ íƒ
        selection_request = FileSelectionRequest(
            user_request=user_request,
            session_id=session_id,
            agent_name=agent_name or "unknown",
            requested_at=datetime.now(),
            context={"source": "a2a_request"}
        )
        
        selected_file_id, reason = self._smart_file_selection(selection_request, session_file_ids)
        
        if selected_file_id:
            file_info = self.tracked_files[selected_file_id]
            # A2A ì—ì´ì „íŠ¸ê°€ ì ‘ê·¼ ê°€ëŠ¥í•œ ê³µìœ  ê²½ë¡œ ë°˜í™˜
            shared_path = file_info.file_paths.get('shared')
            if shared_path and os.path.exists(shared_path):
                logger.info(f"ğŸ¯ Selected file for A2A: {shared_path} ({reason})")
                return shared_path, reason
            else:
                # ê³µìœ  ê²½ë¡œê°€ ì—†ìœ¼ë©´ ì„¸ì…˜ ê²½ë¡œ ë°˜í™˜
                session_path = file_info.file_paths.get('session')
                if session_path and os.path.exists(session_path):
                    logger.info(f"ğŸ¯ Selected file for A2A: {session_path} ({reason})")
                    return session_path, reason
        
        return None, "ì„ íƒëœ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ"
    
    def _smart_file_selection(self, 
                             request: FileSelectionRequest,
                             available_file_ids: List[str]) -> Tuple[Optional[str], str]:
        """ìŠ¤ë§ˆíŠ¸ íŒŒì¼ ì„ íƒ ë¡œì§"""
        
        # 1ìˆœìœ„: ì‚¬ìš©ìê°€ ëª…ì‹œì ìœ¼ë¡œ íŒŒì¼ëª… ì–¸ê¸‰
        mentioned_file = self._extract_mentioned_filename(request.user_request)
        if mentioned_file:
            for file_id in available_file_ids:
                file_info = self.tracked_files[file_id]
                if (mentioned_file.lower() in file_info.original_name.lower() or
                    mentioned_file.lower() in file_id.lower()):
                    return file_id, f"ì‚¬ìš©ì ì–¸ê¸‰ íŒŒì¼: '{mentioned_file}'"
        
        # 2ìˆœìœ„: ë„ë©”ì¸ë³„ ìµœì í™” (ë°˜ë„ì²´, ê¸ˆìœµ, ì˜ë£Œ ë“±)
        domain_file = self._find_domain_optimized_file(request.user_request, available_file_ids)
        if domain_file:
            return domain_file, "ë„ë©”ì¸ ìµœì í™” ì„ íƒ"
        
        # 3ìˆœìœ„: í™œì„± íŒŒì¼ (ê°€ì¥ ìµœê·¼ ì—…ë¡œë“œ)
        active_files = [fid for fid in available_file_ids 
                       if self.tracked_files[fid].is_active]
        if active_files:
            latest_file = max(active_files, 
                            key=lambda fid: self.tracked_files[fid].uploaded_at)
            return latest_file, "ê°€ì¥ ìµœê·¼ ì—…ë¡œë“œ íŒŒì¼"
        
        # 4ìˆœìœ„: ì²« ë²ˆì§¸ ì‚¬ìš© ê°€ëŠ¥ íŒŒì¼
        if available_file_ids:
            return available_file_ids[0], "ì²« ë²ˆì§¸ ì‚¬ìš© ê°€ëŠ¥ íŒŒì¼"
        
        return None, "ì‚¬ìš© ê°€ëŠ¥í•œ íŒŒì¼ ì—†ìŒ"
    
    def _extract_mentioned_filename(self, user_request: str) -> Optional[str]:
        """ì‚¬ìš©ì ìš”ì²­ì—ì„œ ì–¸ê¸‰ëœ íŒŒì¼ëª… ì¶”ì¶œ"""
        import re
        
        # íŒŒì¼ í™•ì¥ìê°€ í¬í•¨ëœ íŒ¨í„´ (ìš°ì„ ìˆœìœ„ ìˆœì„œ)
        patterns = [
            r'([a-zA-Z0-9_\-]+\.(?:csv|xlsx|xls|json|pkl))',  # í™•ì¥ì í¬í•¨ íŒŒì¼ëª… ìµœìš°ì„ 
            r'([a-zA-Z0-9_\-]*ion_implant[a-zA-Z0-9_\-]*)',  # ion_implant í¬í•¨
            r'([a-zA-Z0-9_\-]*titanic[a-zA-Z0-9_\-]*)',      # titanic í¬í•¨
            r'([a-zA-Z0-9_\-]+_dataset[a-zA-Z0-9_\-]*)',     # _dataset í¬í•¨ (ë” êµ¬ì²´ì )
            r'([a-zA-Z0-9_\-]+dataset[a-zA-Z0-9_\-]*)',      # dataset í¬í•¨
            r'([a-zA-Z0-9_\-]+_data[a-zA-Z0-9_\-]*)'         # _data í¬í•¨
        ]
        
        # ê°€ì¥ ê¸´ ë§¤ì¹˜ë¥¼ ì°¾ê¸° ìœ„í•´ ëª¨ë“  íŒ¨í„´ í™•ì¸
        all_matches = []
        
        for pattern in patterns:
            matches = re.findall(pattern, user_request, re.IGNORECASE)
            for match in matches:
                all_matches.append(match)
        
        if all_matches:
            # ê°€ì¥ ê¸´ ë§¤ì¹˜ ë°˜í™˜ (ë” êµ¬ì²´ì ì¸ ê²ƒì„ ì„ í˜¸)
            return max(all_matches, key=len)
        
        return None
    
    def _find_domain_optimized_file(self, user_request: str, file_ids: List[str]) -> Optional[str]:
        """ë„ë©”ì¸ ê¸°ë°˜ ìµœì í™” íŒŒì¼ ì„ íƒ"""
        user_request_lower = user_request.lower()
        
        # ë„ë©”ì¸ë³„ í‚¤ì›Œë“œ ë§¤í•‘
        domain_keywords = {
            'semiconductor': ['ë°˜ë„ì²´', 'ion', 'implant', 'wafer', 'fab', 'process'],
            'finance': ['financial', 'ê¸ˆìœµ', 'bank', 'stock', 'investment'],
            'medical': ['medical', 'ì˜ë£Œ', 'patient', 'clinical', 'health'],
            'retail': ['sales', 'íŒë§¤', 'customer', 'product', 'marketing']
        }
        
        # ì‚¬ìš©ì ìš”ì²­ì—ì„œ ë„ë©”ì¸ ê°ì§€
        detected_domain = None
        for domain, keywords in domain_keywords.items():
            if any(keyword in user_request_lower for keyword in keywords):
                detected_domain = domain
                break
        
        if detected_domain:
            # í•´ë‹¹ ë„ë©”ì¸ì— ë§ëŠ” íŒŒì¼ ê²€ìƒ‰
            domain_files = []
            for file_id in file_ids:
                file_info = self.tracked_files[file_id]
                file_name_lower = file_info.original_name.lower()
                
                if detected_domain == 'semiconductor' and 'ion' in file_name_lower:
                    domain_files.append(file_id)
                elif detected_domain == 'finance' and any(kw in file_name_lower for kw in ['financial', 'bank', 'stock']):
                    domain_files.append(file_id)
                # ì¶”ê°€ ë„ë©”ì¸ ë§¤ì¹­ ë¡œì§...
            
            if domain_files:
                # ê°€ì¥ ìµœê·¼ ë„ë©”ì¸ íŒŒì¼ ë°˜í™˜
                return max(domain_files, 
                         key=lambda fid: self.tracked_files[fid].uploaded_at)
        
        return None
    
    def _save_dataframe(self, df: pd.DataFrame, file_path: Path):
        """ë°ì´í„°í”„ë ˆì„ì„ ì ì ˆí•œ í˜•ì‹ìœ¼ë¡œ ì €ì¥"""
        file_extension = file_path.suffix.lower()
        
        if file_extension == '.csv':
            df.to_csv(file_path, index=False)
        elif file_extension in ['.xlsx', '.xls']:
            df.to_excel(file_path, index=False)
        elif file_extension == '.pkl':
            df.to_pickle(file_path)
        elif file_extension == '.json':
            df.to_json(file_path, orient='records', indent=2)
        else:
            # ê¸°ë³¸ê°’: CSVë¡œ ì €ì¥
            df.to_csv(file_path.with_suffix('.csv'), index=False)
    
    def _load_existing_metadata(self):
        """ê¸°ì¡´ ë©”íƒ€ë°ì´í„° ë¡œë“œ"""
        metadata_file = self.metadata_path / "file_tracking.json"
        
        if metadata_file.exists():
            try:
                with open(metadata_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                # UserFileInfo ê°ì²´ ë³µì›
                for file_id, file_data in data.get('tracked_files', {}).items():
                    # datetime ë³µì›
                    file_data['uploaded_at'] = datetime.fromisoformat(file_data['uploaded_at'])
                    
                    # tuple ë³µì›
                    file_data['data_shape'] = tuple(file_data['data_shape'])
                    
                    self.tracked_files[file_id] = UserFileInfo(**file_data)
                
                self.session_files = data.get('session_files', {})
                self.current_session_id = data.get('current_session_id')
                
                logger.info(f"Loaded {len(self.tracked_files)} tracked files")
                
            except Exception as e:
                logger.warning(f"Failed to load file tracking metadata: {e}")
    
    def _save_metadata(self):
        """ë©”íƒ€ë°ì´í„° ì €ì¥"""
        metadata_file = self.metadata_path / "file_tracking.json"
        
        try:
            # ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜
            tracked_files_data = {}
            for file_id, file_info in self.tracked_files.items():
                file_data = asdict(file_info)
                file_data['uploaded_at'] = file_info.uploaded_at.isoformat()
                tracked_files_data[file_id] = file_data
            
            data = {
                'tracked_files': tracked_files_data,
                'session_files': self.session_files,
                'current_session_id': self.current_session_id,
                'last_updated': datetime.now().isoformat()
            }
            
            with open(metadata_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
                
        except Exception as e:
            logger.error(f"Failed to save file tracking metadata: {e}")
    
    def get_session_files_info(self, session_id: Optional[str] = None) -> List[Dict[str, Any]]:
        """ì„¸ì…˜ì˜ íŒŒì¼ ì •ë³´ ë°˜í™˜"""
        if session_id is None:
            session_id = self.current_session_id
        
        if not session_id or session_id not in self.session_files:
            return []
        
        files_info = []
        for file_id in self.session_files[session_id]:
            if file_id in self.tracked_files:
                file_info = self.tracked_files[file_id]
                files_info.append({
                    'file_id': file_info.file_id,
                    'original_name': file_info.original_name,
                    'uploaded_at': file_info.uploaded_at,
                    'file_size': file_info.file_size,
                    'data_shape': file_info.data_shape,
                    'is_active': file_info.is_active,
                    'shared_path': file_info.file_paths.get('shared'),
                    'session_path': file_info.file_paths.get('session')
                })
        
        return files_info
    
    def cleanup_old_files(self, hours_threshold: int = 48):
        """ì˜¤ë˜ëœ íŒŒì¼ ì •ë¦¬"""
        current_time = datetime.now()
        files_to_remove = []
        
        for file_id, file_info in self.tracked_files.items():
            age = current_time - file_info.uploaded_at
            if age.total_seconds() / 3600 > hours_threshold:
                files_to_remove.append(file_id)
        
        for file_id in files_to_remove:
            try:
                file_info = self.tracked_files[file_id]
                
                # íŒŒì¼ ì‚­ì œ
                for path in file_info.file_paths.values():
                    if os.path.exists(path):
                        os.remove(path)
                
                # ë©”íƒ€ë°ì´í„°ì—ì„œ ì œê±°
                del self.tracked_files[file_id]
                
                # ì„¸ì…˜ì—ì„œ ì œê±°
                for session_id, file_ids in self.session_files.items():
                    if file_id in file_ids:
                        file_ids.remove(file_id)
                
                logger.info(f"ğŸ—‘ï¸ Cleaned up old file: {file_id}")
                
            except Exception as e:
                logger.error(f"Failed to cleanup file {file_id}: {e}")
        
        if files_to_remove:
            self._save_metadata()

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
_user_file_tracker = None

def get_user_file_tracker() -> UserFileTracker:
    """ì „ì—­ UserFileTracker ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _user_file_tracker
    if _user_file_tracker is None:
        _user_file_tracker = UserFileTracker()
    return _user_file_tracker 