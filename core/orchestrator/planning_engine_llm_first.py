"""
Planning Engine - 100% LLM First ÏßÄÎä•Ìòï Î∂ÑÏÑù Í≥ÑÌöç ÏàòÎ¶Ω
Î™®Îì† ÏùòÏÇ¨Í≤∞Ï†ïÏùÑ LLMÏù¥ Îã¥ÎãπÌïòÎäî ÏàúÏàò ÎèôÏ†Å ÏãúÏä§ÌÖú

Features:
- 100% LLM Í∏∞Î∞ò ÏÇ¨Ïö©Ïûê ÏùòÎèÑ Î∂ÑÏÑù
- LLM Í∏∞Î∞ò ÎèôÏ†Å ÏóêÏù¥Ï†ÑÌä∏ ÏÑ†ÌÉù Î∞è Ïö∞ÏÑ†ÏàúÏúÑ ÏÑ§Ï†ï
- LLM Í∏∞Î∞ò Ïã§Ìñâ ÏàúÏÑú ÏµúÏ†ÅÌôî
- ÌïòÎìúÏΩîÎî© Ï†úÎ°ú ÏïÑÌÇ§ÌÖçÏ≤ò
"""

import logging
from datetime import timedelta
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass
import json
import asyncio

from config.agents_config import AgentConfig

logger = logging.getLogger(__name__)

@dataclass
class UserIntent:
    """ÏÇ¨Ïö©Ïûê ÏùòÎèÑ Î∂ÑÏÑù Í≤∞Í≥º"""
    primary_goal: str  # Ï£ºÏöî Î™©Ìëú
    data_type: str  # Îç∞Ïù¥ÌÑ∞ Ïú†Ìòï
    analysis_type: List[str]  # Î∂ÑÏÑù Ï¢ÖÎ•ò
    complexity_level: str  # Î≥µÏû°ÎèÑ (low, medium, high)
    domain: Optional[str]  # ÎèÑÎ©îÏù∏ (semiconductor, finance, etc.)
    required_capabilities: List[str]  # ÌïÑÏöîÌïú Îä•Î†•
    priority: int  # Ïö∞ÏÑ†ÏàúÏúÑ (1-5)

@dataclass
class AgentSelection:
    """ÏóêÏù¥Ï†ÑÌä∏ ÏÑ†ÌÉù Í≤∞Í≥º"""
    agent_id: str
    confidence: float  # ÏÑ†ÌÉù Ïã†Î¢∞ÎèÑ (0-1)
    reasoning: str  # ÏÑ†ÌÉù Ïù¥Ïú†
    expected_contribution: str  # ÏòàÏÉÅ Í∏∞Ïó¨ÎèÑ

@dataclass
class ExecutionSequence:
    """Ïã§Ìñâ ÏàúÏÑú Í≥ÑÌöç"""
    sequence: List[Dict[str, Any]]
    total_steps: int
    estimated_time: timedelta
    parallelizable_steps: List[int]  # Î≥ëÎ†¨ Ïã§Ìñâ Í∞ÄÎä•Ìïú Îã®Í≥Ñ

class PlanningEngineLLMFirst:
    """100% LLM First ÏßÄÎä•Ìòï Î∂ÑÏÑù Í≥ÑÌöç ÏàòÎ¶Ω"""
    
    def __init__(self):
        """ÏàúÏàò LLM Í∏∞Î∞ò Ï¥àÍ∏∞Ìôî"""
        self.llm_client = None  # LLM ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏Îäî ÌïÑÏöîÏãú Ï¥àÍ∏∞Ìôî
        logger.info("üöÄ PlanningEngineLLMFirst Ï¥àÍ∏∞Ìôî - 100% LLM First ÏïÑÌÇ§ÌÖçÏ≤ò")
    
    async def analyze_user_intent(self, query: str, data_context: Dict = None) -> UserIntent:
        """LLM Í∏∞Î∞ò ÏÇ¨Ïö©Ïûê ÏùòÎèÑ Î∂ÑÏÑù"""
        from core.universal_engine.llm_factory import LLMFactory
        
        if not self.llm_client:
            self.llm_client = LLMFactory.create_llm()
        
        prompt = f"""
        Analyze the user's intent from the following query:
        
        Query: "{query}"
        Data Context: {json.dumps(data_context, indent=2) if data_context else "None"}
        
        Extract and analyze:
        1. Primary goal of the query
        2. Type of data being analyzed
        3. Types of analysis requested (list all)
        4. Complexity level (low/medium/high)
        5. Domain (if specific domain is mentioned)
        6. Required capabilities to fulfill this request
        7. Priority level (1-5, where 5 is highest)
        
        Respond in JSON format:
        {{
            "primary_goal": "specific goal description",
            "data_type": "type of data",
            "analysis_types": ["type1", "type2", ...],
            "complexity_level": "low|medium|high",
            "domain": "domain name or null",
            "required_capabilities": ["capability1", "capability2", ...],
            "priority": 1-5
        }}
        """
        
        try:
            response = await asyncio.to_thread(self.llm_client.invoke, prompt)
            response_text = response.content if hasattr(response, 'content') else str(response)
            
            # JSON ÌååÏã±
            try:
                data = json.loads(response_text)
            except json.JSONDecodeError:
                # JSON Ï∂îÏ∂ú ÏãúÎèÑ
                import re
                json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
                if json_match:
                    data = json.loads(json_match.group())
                else:
                    raise ValueError("LLM response is not valid JSON")
            
            return UserIntent(
                primary_goal=data.get('primary_goal', 'General analysis'),
                data_type=data.get('data_type', 'unknown'),
                analysis_type=data.get('analysis_types', []),
                complexity_level=data.get('complexity_level', 'medium'),
                domain=data.get('domain'),
                required_capabilities=data.get('required_capabilities', []),
                priority=data.get('priority', 3)
            )
            
        except Exception as e:
            logger.error(f"ÏÇ¨Ïö©Ïûê ÏùòÎèÑ Î∂ÑÏÑù Ïã§Ìå®: {e}")
            # Ìè¥Î∞± ÏùëÎãµ
            return UserIntent(
                primary_goal="Analyze the provided data",
                data_type="general",
                analysis_type=["general_analysis"],
                complexity_level="medium",
                domain=None,
                required_capabilities=["data_analysis"],
                priority=3
            )
    
    async def select_agents(self, intent: UserIntent, available_agents: List[AgentConfig]) -> List[AgentSelection]:
        """LLM Í∏∞Î∞ò ÎèôÏ†Å ÏóêÏù¥Ï†ÑÌä∏ ÏÑ†ÌÉù"""
        from core.universal_engine.llm_factory import LLMFactory
        
        if not self.llm_client:
            self.llm_client = LLMFactory.create_llm()
        
        # ÏóêÏù¥Ï†ÑÌä∏ Ï†ïÎ≥¥ Ï§ÄÎπÑ
        agents_info = []
        for agent in available_agents:
            agents_info.append({
                "id": agent.id,
                "name": agent.name,
                "description": agent.description,
                "capabilities": agent.capabilities,
                "required_inputs": agent.required_inputs,
                "supported_outputs": agent.supported_outputs
            })
        
        prompt = f"""
        Based on the user intent analysis, select the most appropriate agents for the task.
        
        User Intent:
        - Primary Goal: {intent.primary_goal}
        - Data Type: {intent.data_type}
        - Analysis Types: {intent.analysis_type}
        - Domain: {intent.domain}
        - Required Capabilities: {intent.required_capabilities}
        - Complexity: {intent.complexity_level}
        
        Available Agents:
        {json.dumps(agents_info, indent=2)}
        
        Select agents that best match the requirements. For each selected agent, provide:
        1. Agent ID
        2. Confidence score (0.0-1.0)
        3. Reasoning for selection
        4. Expected contribution to the goal
        
        Respond in JSON format:
        {{
            "selected_agents": [
                {{
                    "agent_id": "agent_id",
                    "confidence": 0.0-1.0,
                    "reasoning": "why this agent was selected",
                    "expected_contribution": "what this agent will contribute"
                }},
                ...
            ]
        }}
        """
        
        try:
            response = await asyncio.to_thread(self.llm_client.invoke, prompt)
            response_text = response.content if hasattr(response, 'content') else str(response)
            
            # JSON ÌååÏã±
            try:
                data = json.loads(response_text)
            except json.JSONDecodeError:
                # JSON Ï∂îÏ∂ú ÏãúÎèÑ
                import re
                json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
                if json_match:
                    data = json.loads(json_match.group())
                else:
                    raise ValueError("LLM response is not valid JSON")
            
            selections = []
            for agent_data in data.get('selected_agents', []):
                selections.append(AgentSelection(
                    agent_id=agent_data['agent_id'],
                    confidence=float(agent_data['confidence']),
                    reasoning=agent_data['reasoning'],
                    expected_contribution=agent_data['expected_contribution']
                ))
            
            return selections
            
        except Exception as e:
            logger.error(f"ÏóêÏù¥Ï†ÑÌä∏ ÏÑ†ÌÉù Ïã§Ìå®: {e}")
            # Ìè¥Î∞±: Ï≤´ Î≤àÏß∏ ÏóêÏù¥Ï†ÑÌä∏ ÏÑ†ÌÉù
            if available_agents:
                return [AgentSelection(
                    agent_id=available_agents[0].id,
                    confidence=0.5,
                    reasoning="Fallback selection",
                    expected_contribution="General analysis"
                )]
            return []
    
    async def create_execution_plan(self, intent: UserIntent, selected_agents: List[AgentSelection]) -> ExecutionSequence:
        """LLM Í∏∞Î∞ò Ïã§Ìñâ Í≥ÑÌöç ÏàòÎ¶Ω"""
        from core.universal_engine.llm_factory import LLMFactory
        
        if not self.llm_client:
            self.llm_client = LLMFactory.create_llm()
        
        prompt = f"""
        Create an execution plan for the selected agents.
        
        User Intent:
        - Primary Goal: {intent.primary_goal}
        - Complexity: {intent.complexity_level}
        
        Selected Agents:
        {json.dumps([{
            'agent_id': agent.agent_id,
            'confidence': agent.confidence,
            'expected_contribution': agent.expected_contribution
        } for agent in selected_agents], indent=2)}
        
        Create an execution sequence that:
        1. Orders agents for optimal results
        2. Identifies which steps can run in parallel
        3. Estimates time for each step
        4. Calculates total execution time
        
        Consider:
        - Data dependencies (data must be loaded before analysis)
        - Logical flow (exploration before advanced analysis)
        - Parallel execution opportunities
        
        Respond in JSON format:
        {{
            "sequence": [
                {{
                    "step": 1,
                    "agent_id": "agent_id",
                    "task": "specific task description",
                    "estimated_time_seconds": 30,
                    "dependencies": []
                }},
                ...
            ],
            "parallelizable_steps": [2, 3],  // steps that can run in parallel
            "total_estimated_seconds": 180
        }}
        """
        
        try:
            response = await asyncio.to_thread(self.llm_client.invoke, prompt)
            response_text = response.content if hasattr(response, 'content') else str(response)
            
            # JSON ÌååÏã±
            try:
                data = json.loads(response_text)
            except json.JSONDecodeError:
                # JSON Ï∂îÏ∂ú ÏãúÎèÑ
                import re
                json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
                if json_match:
                    data = json.loads(json_match.group())
                else:
                    raise ValueError("LLM response is not valid JSON")
            
            sequence = data.get('sequence', [])
            parallelizable = data.get('parallelizable_steps', [])
            total_seconds = data.get('total_estimated_seconds', 180)
            
            return ExecutionSequence(
                sequence=sequence,
                total_steps=len(sequence),
                estimated_time=timedelta(seconds=total_seconds),
                parallelizable_steps=parallelizable
            )
            
        except Exception as e:
            logger.error(f"Ïã§Ìñâ Í≥ÑÌöç ÏàòÎ¶Ω Ïã§Ìå®: {e}")
            # Ìè¥Î∞±: ÏàúÏ∞® Ïã§Ìñâ
            sequence = []
            for i, agent in enumerate(selected_agents):
                sequence.append({
                    'step': i + 1,
                    'agent_id': agent.agent_id,
                    'task': f"Execute {agent.agent_id}",
                    'estimated_time_seconds': 60,
                    'dependencies': [i] if i > 0 else []
                })
            
            return ExecutionSequence(
                sequence=sequence,
                total_steps=len(sequence),
                estimated_time=timedelta(seconds=60 * len(sequence)),
                parallelizable_steps=[]
            )
    
    async def create_analysis_plan(self, query: str, data_context: Dict = None) -> Tuple[ExecutionSequence, List[AgentSelection], UserIntent]:
        """ÌÜµÌï© Î∂ÑÏÑù Í≥ÑÌöç ÏàòÎ¶Ω - 100% LLM First"""
        logger.info(f"üß† LLM First Î∂ÑÏÑù Í≥ÑÌöç ÏàòÎ¶Ω: {query[:100]}...")
        
        # 1. ÏÇ¨Ïö©Ïûê ÏùòÎèÑ Î∂ÑÏÑù
        intent = await self.analyze_user_intent(query, data_context)
        logger.info(f"üìã ÏùòÎèÑ Î∂ÑÏÑù ÏôÑÎ£å: {intent.primary_goal}")
        
        # 2. ÏÇ¨Ïö© Í∞ÄÎä•Ìïú ÏóêÏù¥Ï†ÑÌä∏ Í∞ÄÏ†∏Ïò§Í∏∞
        available_agents = AgentConfig.get_all_agents()
        
        # 3. ÏóêÏù¥Ï†ÑÌä∏ ÏÑ†ÌÉù
        selected_agents = await self.select_agents(intent, available_agents)
        logger.info(f"ü§ñ {len(selected_agents)}Í∞ú ÏóêÏù¥Ï†ÑÌä∏ ÏÑ†ÌÉùÎê®")
        
        # 4. Ïã§Ìñâ Í≥ÑÌöç ÏàòÎ¶Ω
        execution_plan = await self.create_execution_plan(intent, selected_agents)
        logger.info(f"üìä Ïã§Ìñâ Í≥ÑÌöç ÏàòÎ¶Ω ÏôÑÎ£å: {execution_plan.total_steps}Îã®Í≥Ñ, ÏòàÏÉÅ ÏãúÍ∞Ñ: {execution_plan.estimated_time}")
        
        return execution_plan, selected_agents, intent