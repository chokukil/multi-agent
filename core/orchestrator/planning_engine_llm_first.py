"""
Planning Engine - 100% LLM First ì§€ëŠ¥í˜• ë¶„ì„ ê³„íš ìˆ˜ë¦½
ëª¨ë“  ì˜ì‚¬ê²°ì •ì„ LLMì´ ë‹´ë‹¹í•˜ëŠ” ìˆœìˆ˜ ë™ì  ì‹œìŠ¤í…œ

Features:
- 100% LLM ê¸°ë°˜ ì‚¬ìš©ì ì˜ë„ ë¶„ì„
- LLM ê¸°ë°˜ ë™ì  ì—ì´ì „íŠ¸ ì„ íƒ ë° ìš°ì„ ìˆœìœ„ ì„¤ì •
- LLM ê¸°ë°˜ ì‹¤í–‰ ìˆœì„œ ìµœì í™”
- í•˜ë“œì½”ë”© ì œë¡œ ì•„í‚¤í…ì²˜
"""

import logging
from datetime import timedelta
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass
import json
import asyncio

from config.agents_config import AgentConfig

logger = logging.getLogger(__name__)

@dataclass
class UserIntent:
    """ì‚¬ìš©ì ì˜ë„ ë¶„ì„ ê²°ê³¼"""
    primary_goal: str  # ì£¼ìš” ëª©í‘œ
    data_type: str  # ë°ì´í„° ìœ í˜•
    analysis_type: List[str]  # ë¶„ì„ ì¢…ë¥˜
    complexity_level: str  # ë³µì¡ë„ (low, medium, high)
    domain: Optional[str]  # ë„ë©”ì¸ (semiconductor, finance, etc.)
    required_capabilities: List[str]  # í•„ìš”í•œ ëŠ¥ë ¥
    priority: int  # ìš°ì„ ìˆœìœ„ (1-5)

@dataclass
class AgentSelection:
    """ì—ì´ì „íŠ¸ ì„ íƒ ê²°ê³¼"""
    agent_id: str
    confidence: float  # ì„ íƒ ì‹ ë¢°ë„ (0-1)
    reasoning: str  # ì„ íƒ ì´ìœ 
    expected_contribution: str  # ì˜ˆìƒ ê¸°ì—¬ë„

@dataclass
class ExecutionSequence:
    """ì‹¤í–‰ ìˆœì„œ ê³„íš"""
    sequence: List[Dict[str, Any]]
    total_steps: int
    estimated_time: timedelta
    parallelizable_steps: List[int]  # ë³‘ë ¬ ì‹¤í–‰ ê°€ëŠ¥í•œ ë‹¨ê³„

class PlanningEngineLLMFirst:
    """100% LLM First ì§€ëŠ¥í˜• ë¶„ì„ ê³„íš ìˆ˜ë¦½"""
    
    def __init__(self):
        """ìˆœìˆ˜ LLM ê¸°ë°˜ ì´ˆê¸°í™”"""
        self.llm_client = None  # LLM í´ë¼ì´ì–¸íŠ¸ëŠ” í•„ìš”ì‹œ ì´ˆê¸°í™”
        logger.info("ğŸš€ PlanningEngineLLMFirst ì´ˆê¸°í™” - 100% LLM First ì•„í‚¤í…ì²˜")
    
    async def analyze_user_intent(self, query: str, data_context: Dict = None) -> UserIntent:
        """LLM ê¸°ë°˜ ì‚¬ìš©ì ì˜ë„ ë¶„ì„"""
        from core.universal_engine.llm_factory import LLMFactory
        
        if not self.llm_client:
            self.llm_client = LLMFactory.create_llm()
        
        prompt = f"""
        Analyze the user's intent from the following query:
        
        Query: "{query}"
        Data Context: {json.dumps(data_context, indent=2) if data_context else "None"}
        
        Extract and analyze:
        1. Primary goal of the query
        2. Type of data being analyzed
        3. Types of analysis requested (list all)
        4. Complexity level (low/medium/high)
        5. Domain (if specific domain is mentioned)
        6. Required capabilities to fulfill this request
        7. Priority level (1-5, where 5 is highest)
        
        Respond in JSON format:
        {{
            "primary_goal": "specific goal description",
            "data_type": "type of data",
            "analysis_types": ["type1", "type2", ...],
            "complexity_level": "low|medium|high",
            "domain": "domain name or null",
            "required_capabilities": ["capability1", "capability2", ...],
            "priority": 1-5
        }}
        """
        
        try:
            response = await asyncio.to_thread(self.llm_client.invoke, prompt)
            response_text = response.content if hasattr(response, 'content') else str(response)
            
            # JSON íŒŒì‹±
            try:
                data = json.loads(response_text)
            except json.JSONDecodeError:
                # JSON ì¶”ì¶œ ì‹œë„
                import re
                json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
                if json_match:
                    data = json.loads(json_match.group())
                else:
                    raise ValueError("LLM response is not valid JSON")
            
            return UserIntent(
                primary_goal=data.get('primary_goal', 'General analysis'),
                data_type=data.get('data_type', 'unknown'),
                analysis_type=data.get('analysis_types', []),
                complexity_level=data.get('complexity_level', 'medium'),
                domain=data.get('domain'),
                required_capabilities=data.get('required_capabilities', []),
                priority=data.get('priority', 3)
            )
            
        except Exception as e:
            logger.error(f"ì‚¬ìš©ì ì˜ë„ ë¶„ì„ ì‹¤íŒ¨: {e}")
            # í´ë°± ì‘ë‹µ
            return UserIntent(
                primary_goal="Analyze the provided data",
                data_type="general",
                analysis_type=["general_analysis"],
                complexity_level="medium",
                domain=None,
                required_capabilities=["data_analysis"],
                priority=3
            )
    
    async def select_agents(self, intent: UserIntent, available_agents: List[AgentConfig]) -> List[AgentSelection]:
        """LLM ê¸°ë°˜ ë™ì  ì—ì´ì „íŠ¸ ì„ íƒ"""
        from core.universal_engine.llm_factory import LLMFactory
        
        if not self.llm_client:
            self.llm_client = LLMFactory.create_llm()
        
        # ì—ì´ì „íŠ¸ ì •ë³´ ì¤€ë¹„
        agents_info = []
        for agent in available_agents:
            agents_info.append({
                "id": agent.id,
                "name": agent.name,
                "description": agent.description,
                "capabilities": agent.capabilities,
                "required_inputs": agent.required_inputs,
                "supported_outputs": agent.supported_outputs
            })
        
        prompt = f"""
        Based on the user intent analysis, select the most appropriate agents for the task.
        
        User Intent:
        - Primary Goal: {intent.primary_goal}
        - Data Type: {intent.data_type}
        - Analysis Types: {intent.analysis_type}
        - Domain: {intent.domain}
        - Required Capabilities: {intent.required_capabilities}
        - Complexity: {intent.complexity_level}
        
        Available Agents:
        {json.dumps(agents_info, indent=2)}
        
        Select agents that best match the requirements. For each selected agent, provide:
        1. Agent ID
        2. Confidence score (0.0-1.0)
        3. Reasoning for selection
        4. Expected contribution to the goal
        
        Respond in JSON format:
        {{
            "selected_agents": [
                {{
                    "agent_id": "agent_id",
                    "confidence": 0.0-1.0,
                    "reasoning": "why this agent was selected",
                    "expected_contribution": "what this agent will contribute"
                }},
                ...
            ]
        }}
        """
        
        try:
            response = await asyncio.to_thread(self.llm_client.invoke, prompt)
            response_text = response.content if hasattr(response, 'content') else str(response)
            
            # JSON íŒŒì‹±
            try:
                data = json.loads(response_text)
            except json.JSONDecodeError:
                # JSON ì¶”ì¶œ ì‹œë„
                import re
                json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
                if json_match:
                    data = json.loads(json_match.group())
                else:
                    raise ValueError("LLM response is not valid JSON")
            
            selections = []
            for agent_data in data.get('selected_agents', []):
                selections.append(AgentSelection(
                    agent_id=agent_data['agent_id'],
                    confidence=float(agent_data['confidence']),
                    reasoning=agent_data['reasoning'],
                    expected_contribution=agent_data['expected_contribution']
                ))
            
            return selections
            
        except Exception as e:
            logger.error(f"ì—ì´ì „íŠ¸ ì„ íƒ ì‹¤íŒ¨: {e}")
            # í´ë°±: ì²« ë²ˆì§¸ ì—ì´ì „íŠ¸ ì„ íƒ
            if available_agents:
                return [AgentSelection(
                    agent_id=available_agents[0].id,
                    confidence=0.5,
                    reasoning="Fallback selection",
                    expected_contribution="General analysis"
                )]
            return []
    
    async def create_execution_plan(self, intent: UserIntent, selected_agents: List[AgentSelection]) -> ExecutionSequence:
        """LLM ê¸°ë°˜ ì‹¤í–‰ ê³„íš ìˆ˜ë¦½"""
        from core.universal_engine.llm_factory import LLMFactory
        
        if not self.llm_client:
            self.llm_client = LLMFactory.create_llm()
        
        prompt = f"""
        Create an execution plan for the selected agents.
        
        User Intent:
        - Primary Goal: {intent.primary_goal}
        - Complexity: {intent.complexity_level}
        
        Selected Agents:
        {json.dumps([{
            'agent_id': agent.agent_id,
            'confidence': agent.confidence,
            'expected_contribution': agent.expected_contribution
        } for agent in selected_agents], indent=2)}
        
        Create an execution sequence that:
        1. Orders agents for optimal results
        2. Identifies which steps can run in parallel
        3. Estimates time for each step
        4. Calculates total execution time
        
        Consider:
        - Data dependencies (data must be loaded before analysis)
        - Logical flow (exploration before advanced analysis)
        - Parallel execution opportunities
        
        Respond in JSON format:
        {{
            "sequence": [
                {{
                    "step": 1,
                    "agent_id": "agent_id",
                    "task": "specific task description",
                    "estimated_time_seconds": 30,
                    "dependencies": []
                }},
                ...
            ],
            "parallelizable_steps": [2, 3],  // steps that can run in parallel
            "total_estimated_seconds": 180
        }}
        """
        
        try:
            response = await asyncio.to_thread(self.llm_client.invoke, prompt)
            response_text = response.content if hasattr(response, 'content') else str(response)
            
            # JSON íŒŒì‹±
            try:
                data = json.loads(response_text)
            except json.JSONDecodeError:
                # JSON ì¶”ì¶œ ì‹œë„
                import re
                json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
                if json_match:
                    data = json.loads(json_match.group())
                else:
                    raise ValueError("LLM response is not valid JSON")
            
            sequence = data.get('sequence', [])
            parallelizable = data.get('parallelizable_steps', [])
            total_seconds = data.get('total_estimated_seconds', 180)
            
            return ExecutionSequence(
                sequence=sequence,
                total_steps=len(sequence),
                estimated_time=timedelta(seconds=total_seconds),
                parallelizable_steps=parallelizable
            )
            
        except Exception as e:
            logger.error(f"ì‹¤í–‰ ê³„íš ìˆ˜ë¦½ ì‹¤íŒ¨: {e}")
            # í´ë°±: ìˆœì°¨ ì‹¤í–‰
            sequence = []
            for i, agent in enumerate(selected_agents):
                sequence.append({
                    'step': i + 1,
                    'agent_id': agent.agent_id,
                    'task': f"Execute {agent.agent_id}",
                    'estimated_time_seconds': 60,
                    'dependencies': [i] if i > 0 else []
                })
            
            return ExecutionSequence(
                sequence=sequence,
                total_steps=len(sequence),
                estimated_time=timedelta(seconds=60 * len(sequence)),
                parallelizable_steps=[]
            )
    
    async def create_analysis_plan(self, query: str, data_context: Dict = None) -> Tuple[ExecutionSequence, List[AgentSelection], UserIntent]:
        """í†µí•© ë¶„ì„ ê³„íš ìˆ˜ë¦½ - 100% LLM First"""
        logger.info(f"ğŸ§  LLM First ë¶„ì„ ê³„íš ìˆ˜ë¦½: {query[:100]}...")
        
        # 1. ì‚¬ìš©ì ì˜ë„ ë¶„ì„
        intent = await self.analyze_user_intent(query, data_context)
        logger.info(f"ğŸ“‹ ì˜ë„ ë¶„ì„ ì™„ë£Œ: {intent.primary_goal}")
        
        # 2. ì‚¬ìš© ê°€ëŠ¥í•œ ì—ì´ì „íŠ¸ ê°€ì ¸ì˜¤ê¸°
        available_agents = AgentConfig.get_all_agents()
        
        # 3. ì—ì´ì „íŠ¸ ì„ íƒ
        selected_agents = await self.select_agents(intent, available_agents)
        logger.info(f"ğŸ¤– {len(selected_agents)}ê°œ ì—ì´ì „íŠ¸ ì„ íƒë¨")
        
        # 4. ì‹¤í–‰ ê³„íš ìˆ˜ë¦½
        execution_plan = await self.create_execution_plan(intent, selected_agents)
        logger.info(f"ğŸ“Š ì‹¤í–‰ ê³„íš ìˆ˜ë¦½ ì™„ë£Œ: {execution_plan.total_steps}ë‹¨ê³„, ì˜ˆìƒ ì‹œê°„: {execution_plan.estimated_time}")
        
        return execution_plan, selected_agents, intent