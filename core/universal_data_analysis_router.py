"""
Universal Data Analysis Router

LLM ê¸°ë°˜ ë²”ìš© ë°ì´í„° ë¶„ì„ ë¼ìš°íŒ… ì‹œìŠ¤í…œ
ì‚¬ìš©ìì˜ ìì—°ì–´ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ê°€ì¥ ì í•©í•œ ì „ë¬¸ ì—ì´ì „íŠ¸ë¡œ ë¼ìš°íŒ…

Author: CherryAI Team
Date: 2024-12-30
"""

import json
import logging
import asyncio
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass
from enum import Enum
import re
from pathlib import Path

# LLM Integration
try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

# Enhanced Tracking System
try:
    from core.enhanced_langfuse_tracer import get_enhanced_tracer
    ENHANCED_TRACKING_AVAILABLE = True
except ImportError:
    ENHANCED_TRACKING_AVAILABLE = False

# UserFileTracker í†µí•©
try:
    from core.user_file_tracker import get_user_file_tracker
    from core.session_data_manager import SessionDataManager
    USER_FILE_TRACKER_AVAILABLE = True
except ImportError:
    USER_FILE_TRACKER_AVAILABLE = False

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class AnalysisType(Enum):
    """ë°ì´í„° ë¶„ì„ ìœ í˜• ë¶„ë¥˜"""
    PANDAS_AI = "pandas_ai"           # ë²”ìš© ìì—°ì–´ ë°ì´í„° ë¶„ì„
    EDA = "eda"                       # íƒìƒ‰ì  ë°ì´í„° ë¶„ì„
    VISUALIZATION = "visualization"   # ë°ì´í„° ì‹œê°í™”
    STATISTICS = "statistics"         # í†µê³„ ë¶„ì„
    MACHINE_LEARNING = "ml"           # ë¨¸ì‹ ëŸ¬ë‹
    DATA_CLEANING = "cleaning"        # ë°ì´í„° ì „ì²˜ë¦¬
    DATA_LOADING = "loading"          # ë°ì´í„° ë¡œë”©
    FEATURE_ENGINEERING = "features"  # í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§
    DATABASE = "database"             # ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬
    GENERAL = "general"               # ì¼ë°˜ ì§ˆë¬¸


@dataclass
class RouteDecision:
    """ë¼ìš°íŒ… ê²°ì • ê²°ê³¼"""
    analysis_type: AnalysisType
    confidence: float
    reasoning: str
    recommended_agent: str
    parameters: Dict[str, Any] = None
    fallback_agents: List[str] = None


@dataclass
class AgentCapability:
    """ì—ì´ì „íŠ¸ ëŠ¥ë ¥ ì •ì˜"""
    agent_name: str
    analysis_types: List[AnalysisType]
    strengths: List[str]
    limitations: List[str]
    endpoint: str
    priority: int = 5  # 1-10, 10ì´ ìµœê³  ìš°ì„ ìˆœìœ„


class UniversalDataAnalysisRouter:
    """
    ë²”ìš© ë°ì´í„° ë¶„ì„ ë¼ìš°íŒ… ì‹œìŠ¤í…œ
    
    LLMì„ í™œìš©í•˜ì—¬ ì‚¬ìš©ì ì§ˆë¬¸ì„ ë¶„ì„í•˜ê³  ìµœì ì˜ ì „ë¬¸ ì—ì´ì „íŠ¸ë¡œ ë¼ìš°íŒ…
    """
    
    def __init__(self, config: Optional[Dict] = None):
        self.config = config or {}
        self.openai_client = None
        self.enhanced_tracer = None
        self.user_file_tracker = None
        self.session_data_manager = None
        
        # ì—ì´ì „íŠ¸ ëŠ¥ë ¥ ì •ì˜
        self.agent_capabilities = self._initialize_agent_capabilities()
        
        # ë¼ìš°íŒ… íˆìŠ¤í† ë¦¬
        self.routing_history: List[Dict] = []
        
        # LLM ì´ˆê¸°í™”
        self._initialize_llm()
        
        # Enhanced Tracking ì´ˆê¸°í™”
        if ENHANCED_TRACKING_AVAILABLE:
            try:
                self.enhanced_tracer = get_enhanced_tracer()
                logger.info("âœ… Enhanced Langfuse Tracking í™œì„±í™”")
            except Exception as e:
                logger.warning(f"âš ï¸ Enhanced Tracking ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        
        # UserFileTracker ì´ˆê¸°í™”
        if USER_FILE_TRACKER_AVAILABLE:
            try:
                self.user_file_tracker = get_user_file_tracker()
                self.session_data_manager = SessionDataManager()
                logger.info("âœ… UserFileTracker í†µí•© í™œì„±í™”")
            except Exception as e:
                logger.warning(f"âš ï¸ UserFileTracker ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    def _initialize_llm(self):
        """LLM í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        if not OPENAI_AVAILABLE:
            logger.warning("âš ï¸ OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ")
            return
        
        try:
            import os
            api_key = os.getenv("OPENAI_API_KEY")
            if not api_key:
                logger.warning("âš ï¸ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
                return
            
            self.openai_client = OpenAI(api_key=api_key)
            logger.info("âœ… OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    def _initialize_agent_capabilities(self) -> Dict[str, AgentCapability]:
        """ì—ì´ì „íŠ¸ ëŠ¥ë ¥ ì •ì˜ ì´ˆê¸°í™”"""
        return {
            "pandas_ai": AgentCapability(
                agent_name="Universal Pandas-AI Agent",
                analysis_types=[
                    AnalysisType.PANDAS_AI,
                    AnalysisType.GENERAL,
                    AnalysisType.STATISTICS
                ],
                strengths=[
                    "ìì—°ì–´ ë°ì´í„° ì§ˆë¬¸ ì²˜ë¦¬",
                    "ë³µì¡í•œ ë°ì´í„° ì¡°ì‘",
                    "ì½”ë“œ ìë™ ìƒì„±",
                    "ë©€í‹°í„´ ëŒ€í™”"
                ],
                limitations=[
                    "ì‹œê°í™” í’ˆì§ˆ í•œê³„",
                    "ê³ ê¸‰ ML ì•Œê³ ë¦¬ì¦˜ ë¶€ì¡±"
                ],
                endpoint="http://localhost:8000",
                priority=8
            ),
            
            "eda": AgentCapability(
                agent_name="Enhanced EDA Tools Agent",
                analysis_types=[
                    AnalysisType.EDA,
                    AnalysisType.STATISTICS,
                    AnalysisType.VISUALIZATION
                ],
                strengths=[
                    "í¬ê´„ì  íƒìƒ‰ì  ë°ì´í„° ë¶„ì„",
                    "í†µê³„ì  ì¸ì‚¬ì´íŠ¸",
                    "ë°ì´í„° í’ˆì§ˆ ê²€ì‚¬",
                    "ìƒê´€ê´€ê³„ ë¶„ì„"
                ],
                limitations=[
                    "ììœ í˜•ì‹ ìì—°ì–´ ì²˜ë¦¬ ì œí•œ"
                ],
                endpoint="http://localhost:8001",
                priority=9
            ),
            
            "visualization": AgentCapability(
                agent_name="Data Visualization Agent",
                analysis_types=[
                    AnalysisType.VISUALIZATION
                ],
                strengths=[
                    "ê³ í’ˆì§ˆ ì‹œê°í™”",
                    "ëŒ€í™”í˜• ì°¨íŠ¸",
                    "ë‹¤ì–‘í•œ í”Œë¡¯ ìœ í˜•",
                    "ë§ì¶¤í˜• ìŠ¤íƒ€ì¼ë§"
                ],
                limitations=[
                    "ë°ì´í„° ë¶„ì„ ê¸°ëŠ¥ ì œí•œ"
                ],
                endpoint="http://localhost:8002",
                priority=7
            ),
            
            "data_cleaning": AgentCapability(
                agent_name="Data Cleaning Agent",
                analysis_types=[
                    AnalysisType.DATA_CLEANING
                ],
                strengths=[
                    "ê²°ì¸¡ê°’ ì²˜ë¦¬",
                    "ì´ìƒê°’ íƒì§€",
                    "ë°ì´í„° í‘œì¤€í™”",
                    "í’ˆì§ˆ í–¥ìƒ"
                ],
                limitations=[
                    "ë¶„ì„ ê¸°ëŠ¥ ë¶€ì¡±"
                ],
                endpoint="http://localhost:8003",
                priority=6
            ),
            
            "feature_engineering": AgentCapability(
                agent_name="Feature Engineering Agent",
                analysis_types=[
                    AnalysisType.FEATURE_ENGINEERING
                ],
                strengths=[
                    "í”¼ì²˜ ìƒì„±",
                    "ì°¨ì› ì¶•ì†Œ",
                    "í”¼ì²˜ ì„ íƒ",
                    "ë³€í™˜ ê¸°ë²•"
                ],
                limitations=[
                    "ë„ë©”ì¸ ì§€ì‹ ì˜ì¡´"
                ],
                endpoint="http://localhost:8004",
                priority=6
            ),
            
            "ml": AgentCapability(
                agent_name="Machine Learning Agent",
                analysis_types=[
                    AnalysisType.MACHINE_LEARNING
                ],
                strengths=[
                    "ML ëª¨ë¸ êµ¬ì¶•",
                    "ëª¨ë¸ í‰ê°€",
                    "í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹",
                    "ì˜ˆì¸¡ ë¶„ì„"
                ],
                limitations=[
                    "ë³µì¡í•œ ë°ì´í„° ì „ì²˜ë¦¬ ì œí•œ"
                ],
                endpoint="http://localhost:8005",
                priority=7
            )
        }
    
    async def analyze_query_intent(self, user_query: str, context: Optional[Dict] = None) -> RouteDecision:
        """
        ì‚¬ìš©ì ì§ˆë¬¸ì˜ ì˜ë„ë¥¼ ë¶„ì„í•˜ì—¬ ë¼ìš°íŒ… ê²°ì •
        
        Args:
            user_query: ì‚¬ìš©ì ì§ˆë¬¸
            context: ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ ì •ë³´
            
        Returns:
            RouteDecision: ë¼ìš°íŒ… ê²°ì • ê²°ê³¼
        """
        try:
            logger.info(f"ğŸ”„ ì§ˆë¬¸ ì˜ë„ ë¶„ì„ ì‹œì‘: {user_query[:100]}...")
            
            # Enhanced Tracking
            if self.enhanced_tracer:
                self.enhanced_tracer.log_data_operation(
                    "query_intent_analysis",
                    {"query": user_query, "context": context},
                    "Analyzing user query intent for routing"
                )
            
            # LLMì´ ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš° ê³ ê¸‰ ë¶„ì„
            if self.openai_client:
                decision = await self._llm_based_analysis(user_query, context)
            else:
                # ê·œì¹™ ê¸°ë°˜ ë¶„ì„ (í´ë°±)
                decision = self._rule_based_analysis(user_query, context)
            
            # ë¼ìš°íŒ… íˆìŠ¤í† ë¦¬ ê¸°ë¡
            self.routing_history.append({
                "timestamp": asyncio.get_event_loop().time(),
                "query": user_query,
                "decision": decision,
                "context": context
            })
            
            logger.info(f"âœ… ë¼ìš°íŒ… ê²°ì •: {decision.recommended_agent} (ì‹ ë¢°ë„: {decision.confidence:.2f})")
            return decision
            
        except Exception as e:
            logger.error(f"âŒ ì§ˆë¬¸ ì˜ë„ ë¶„ì„ ì‹¤íŒ¨: {e}")
            # í´ë°±: pandas-aië¡œ ë¼ìš°íŒ…
            return RouteDecision(
                analysis_type=AnalysisType.PANDAS_AI,
                confidence=0.3,
                reasoning=f"ë¶„ì„ ì‹¤íŒ¨ë¡œ ì¸í•œ ê¸°ë³¸ ë¼ìš°íŒ…: {str(e)}",
                recommended_agent="pandas_ai",
                fallback_agents=["eda"]
            )
    
    def _normalize_agent_name(self, agent_name: str) -> str:
        """ì—ì´ì „íŠ¸ ì´ë¦„ì„ ì •ê·œí™”í•˜ì—¬ í‚¤ ë§¤í•‘"""
        # ì—ì´ì „íŠ¸ ì´ë¦„ ë§¤í•‘ í…Œì´ë¸”
        name_mapping = {
            "Universal Pandas-AI Agent": "pandas_ai",
            "pandas_ai": "pandas_ai",
            "Enhanced EDA Tools Agent": "eda", 
            "eda": "eda",
            "Data Visualization Agent": "visualization",
            "visualization": "visualization",
            "Data Cleaning Agent": "data_cleaning",
            "data_cleaning": "data_cleaning",
            "Feature Engineering Agent": "feature_engineering",
            "feature_engineering": "feature_engineering",
            "Machine Learning Agent": "ml",
            "ml": "ml"
        }
        
        # ì •í™•í•œ ë§¤ì¹˜ ìš°ì„ 
        if agent_name in name_mapping:
            return name_mapping[agent_name]
        
        # ë¶€ë¶„ ë§¤ì¹˜ ì‹œë„
        agent_lower = agent_name.lower()
        for key, value in name_mapping.items():
            if key.lower() in agent_lower or value in agent_lower:
                return value
        
        # ë§¤ì¹˜ë˜ì§€ ì•Šìœ¼ë©´ ê¸°ë³¸ê°’
        return "pandas_ai"
    
    async def _llm_based_analysis(self, user_query: str, context: Optional[Dict] = None) -> RouteDecision:
        """LLM ê¸°ë°˜ ê³ ê¸‰ ì§ˆë¬¸ ì˜ë„ ë¶„ì„"""
        try:
            # ì—ì´ì „íŠ¸ ëŠ¥ë ¥ ìš”ì•½
            agent_summary = self._create_agent_summary()
            
            # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            system_prompt = f"""ë‹¹ì‹ ì€ ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ì´ë©°, ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ê°€ì¥ ì í•©í•œ ì „ë¬¸ ì—ì´ì „íŠ¸ë¡œ ë¼ìš°íŒ…í•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

ì‚¬ìš© ê°€ëŠ¥í•œ ì—ì´ì „íŠ¸ë“¤:
{agent_summary}

ì‚¬ìš©ì ì§ˆë¬¸ì„ ë¶„ì„í•˜ê³  ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
{{
    "analysis_type": "ë¶„ì„ ìœ í˜• (pandas_ai, eda, visualization, statistics, ml, cleaning, loading, features, database, general ì¤‘ í•˜ë‚˜)",
    "confidence": 0.0-1.0 ì‚¬ì´ì˜ ì‹ ë¢°ë„,
    "reasoning": "ë¼ìš°íŒ… ê²°ì • ì´ìœ  (í•œêµ­ì–´)",
    "recommended_agent": "ì¶”ì²œ ì—ì´ì „íŠ¸ ì´ë¦„",
    "parameters": {{"ì¶”ê°€ íŒŒë¼ë¯¸í„°ë“¤"}},
    "fallback_agents": ["ëŒ€ì•ˆ ì—ì´ì „íŠ¸ ëª©ë¡"]
}}

ë¶„ì„ ê¸°ì¤€:
1. ì§ˆë¬¸ì˜ í•µì‹¬ ì˜ë„ íŒŒì•…
2. í•„ìš”í•œ ì „ë¬¸ì„± ìˆ˜ì¤€ íŒë‹¨
3. ì—ì´ì „íŠ¸ë³„ ê°•ì ê³¼ í•œê³„ ê³ ë ¤
4. ì‹ ë¢°ë„ëŠ” ë³´ìˆ˜ì ìœ¼ë¡œ í‰ê°€"""

            user_prompt = f"""ì‚¬ìš©ì ì§ˆë¬¸: "{user_query}"

ì»¨í…ìŠ¤íŠ¸: {json.dumps(context, ensure_ascii=False, indent=2) if context else "ì—†ìŒ"}

ìœ„ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ê°€ì¥ ì í•©í•œ ì—ì´ì „íŠ¸ë¡œ ë¼ìš°íŒ…í•´ì£¼ì„¸ìš”."""

            response = self.openai_client.chat.completions.create(
                model=self.config.get("llm_model", "gpt-4o-mini"),
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.1,
                max_tokens=500
            )
            
            # ì‘ë‹µ íŒŒì‹±
            response_text = response.choices[0].message.content
            
            # JSON ì¶”ì¶œ (```json ... ``` í˜•íƒœ ì²˜ë¦¬)
            json_match = re.search(r'```json\s*(\{.*?\})\s*```', response_text, re.DOTALL)
            if json_match:
                response_text = json_match.group(1)
            
            try:
                result = json.loads(response_text)
                
                # ì—ì´ì „íŠ¸ ì´ë¦„ ì •ê·œí™”
                recommended_agent = result.get("recommended_agent", "pandas_ai")
                normalized_agent = self._normalize_agent_name(recommended_agent)
                
                return RouteDecision(
                    analysis_type=AnalysisType(result.get("analysis_type", "pandas_ai")),
                    confidence=float(result.get("confidence", 0.5)),
                    reasoning=result.get("reasoning", "LLM ë¶„ì„ ê²°ê³¼"),
                    recommended_agent=normalized_agent,
                    parameters=result.get("parameters", {}),
                    fallback_agents=result.get("fallback_agents", ["eda", "pandas_ai"])
                )
                
            except (json.JSONDecodeError, ValueError) as e:
                logger.warning(f"âš ï¸ LLM ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨, ê·œì¹™ ê¸°ë°˜ìœ¼ë¡œ í´ë°±: {e}")
                return self._rule_based_analysis(user_query, context)
            
        except Exception as e:
            logger.error(f"âŒ LLM ê¸°ë°˜ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return self._rule_based_analysis(user_query, context)
    
    def _rule_based_analysis(self, user_query: str, context: Optional[Dict] = None) -> RouteDecision:
        """ê·œì¹™ ê¸°ë°˜ ì§ˆë¬¸ ì˜ë„ ë¶„ì„ (í´ë°±)"""
        query_lower = user_query.lower()
        
        # í‚¤ì›Œë“œ ê¸°ë°˜ ë§¤ì¹­
        patterns = {
            AnalysisType.VISUALIZATION: [
                r'ê·¸ë˜í”„|ì°¨íŠ¸|í”Œë¡¯|ì‹œê°í™”|ê·¸ë¦¼|ë„í‘œ|plot|chart|graph|visualiz',
                r'íˆíŠ¸ë§µ|ì‚°ì ë„|ë§‰ëŒ€ê·¸ë˜í”„|ì„ ê·¸ë˜í”„|ìƒìê·¸ë¦¼|heatmap|scatter|bar|line|box'
            ],
            AnalysisType.EDA: [
                r'íƒìƒ‰|ë¶„í¬|ìƒê´€ê´€ê³„|ê¸°ìˆ í†µê³„|ìš”ì•½|eda|explore|distribution|correlation|summary|describe',
                r'í†µê³„|í‰ê· |ì¤‘ì•™ê°’|í‘œì¤€í¸ì°¨|ë¶„ì‚°|statistics|mean|median|std|var'
            ],
            AnalysisType.MACHINE_LEARNING: [
                r'ì˜ˆì¸¡|ëª¨ë¸|ë¶„ë¥˜|íšŒê·€|ë¨¸ì‹ ëŸ¬ë‹|ë”¥ëŸ¬ë‹|predict|model|classify|regression|ml|machine learning',
                r'í•™ìŠµ|í›ˆë ¨|ì•Œê³ ë¦¬ì¦˜|train|algorithm|fit'
            ],
            AnalysisType.DATA_CLEANING: [
                r'ì •ì œ|ì „ì²˜ë¦¬|ê²°ì¸¡|ì´ìƒê°’|ì¤‘ë³µ|ì •ë¦¬|clean|preprocess|missing|outlier|duplicate|null'
            ],
            AnalysisType.FEATURE_ENGINEERING: [
                r'í”¼ì²˜|íŠ¹ì„±|ë³€ìˆ˜|ì°¨ì›|feature|variable|dimension|encoding|scaling'
            ],
            AnalysisType.DATABASE: [
                r'sql|ì¿¼ë¦¬|ë°ì´í„°ë² ì´ìŠ¤|ì¡°ì¸|select|where|join|database|query'
            ]
        }
        
        # íŒ¨í„´ ë§¤ì¹­ ìŠ¤ì½”ì–´ ê³„ì‚°
        scores = {}
        for analysis_type, pattern_list in patterns.items():
            score = 0
            for pattern in pattern_list:
                matches = len(re.findall(pattern, query_lower))
                score += matches
            scores[analysis_type] = score
        
        # ìµœê³  ìŠ¤ì½”ì–´ ì„ íƒ
        if scores and max(scores.values()) > 0:
            best_type = max(scores, key=scores.get)
            confidence = min(0.8, scores[best_type] * 0.2)
        else:
            # ê¸°ë³¸ê°’: pandas-ai
            best_type = AnalysisType.PANDAS_AI
            confidence = 0.4
        
        # ì—ì´ì „íŠ¸ ë§¤í•‘
        agent_mapping = {
            AnalysisType.PANDAS_AI: "pandas_ai",
            AnalysisType.EDA: "eda",
            AnalysisType.VISUALIZATION: "visualization",
            AnalysisType.STATISTICS: "eda",
            AnalysisType.MACHINE_LEARNING: "ml",
            AnalysisType.DATA_CLEANING: "data_cleaning",
            AnalysisType.FEATURE_ENGINEERING: "feature_engineering",
            AnalysisType.DATABASE: "pandas_ai",
            AnalysisType.GENERAL: "pandas_ai"
        }
        
        recommended_agent = agent_mapping.get(best_type, "pandas_ai")
        
        return RouteDecision(
            analysis_type=best_type,
            confidence=confidence,
            reasoning=f"ê·œì¹™ ê¸°ë°˜ í‚¤ì›Œë“œ ë§¤ì¹­ (ìŠ¤ì½”ì–´: {scores.get(best_type, 0)})",
            recommended_agent=recommended_agent,
            parameters={},
            fallback_agents=["pandas_ai", "eda"]
        )
    
    def _create_agent_summary(self) -> str:
        """ì—ì´ì „íŠ¸ ëŠ¥ë ¥ ìš”ì•½ ìƒì„±"""
        summary_lines = []
        for agent_id, capability in self.agent_capabilities.items():
            analysis_types = [t.value for t in capability.analysis_types]
            summary_lines.append(
                f"- {capability.agent_name} ({agent_id}): "
                f"ë¶„ì„ìœ í˜•={analysis_types}, "
                f"ê°•ì ={capability.strengths[:2]}, "
                f"ìš°ì„ ìˆœìœ„={capability.priority}"
            )
        return "\n".join(summary_lines)
    
    async def route_query(self, user_query: str, session_id: Optional[str] = None, context: Optional[Dict] = None) -> Dict[str, Any]:
        """
        ì§ˆë¬¸ì„ ë¶„ì„í•˜ê³  ì ì ˆí•œ ì—ì´ì „íŠ¸ë¡œ ë¼ìš°íŒ…
        
        Args:
            user_query: ì‚¬ìš©ì ì§ˆë¬¸
            session_id: ì„¸ì…˜ ID
            context: ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸
            
        Returns:
            Dict: ë¼ìš°íŒ… ê²°ê³¼
        """
        try:
            logger.info(f"ğŸ”„ ì§ˆë¬¸ ë¼ìš°íŒ… ì‹œì‘: {user_query[:100]}...")
            
            # ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸ ìˆ˜ì§‘
            enhanced_context = await self._gather_session_context(session_id, context)
            
            # ì˜ë„ ë¶„ì„
            decision = await self.analyze_query_intent(user_query, enhanced_context)
            
            # ì—ì´ì „íŠ¸ ì •ë³´ ì¤€ë¹„
            agent_info = self.agent_capabilities.get(decision.recommended_agent)
            if not agent_info:
                logger.warning(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ì—ì´ì „íŠ¸: {decision.recommended_agent}")
                agent_info = self.agent_capabilities["pandas_ai"]  # í´ë°±
            
            result = {
                "success": True,
                "decision": {
                    "analysis_type": decision.analysis_type.value,
                    "confidence": decision.confidence,
                    "reasoning": decision.reasoning,
                    "recommended_agent": decision.recommended_agent,
                    "agent_endpoint": agent_info.endpoint,
                    "parameters": decision.parameters or {},
                    "fallback_agents": decision.fallback_agents or []
                },
                "agent_info": {
                    "name": agent_info.agent_name,
                    "strengths": agent_info.strengths,
                    "limitations": agent_info.limitations,
                    "endpoint": agent_info.endpoint,
                    "priority": agent_info.priority
                },
                "context": enhanced_context,
                "timestamp": asyncio.get_event_loop().time()
            }
            
            logger.info(f"âœ… ë¼ìš°íŒ… ì™„ë£Œ: {decision.recommended_agent}")
            return result
            
        except Exception as e:
            logger.error(f"âŒ ì§ˆë¬¸ ë¼ìš°íŒ… ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e),
                "fallback": {
                    "recommended_agent": "pandas_ai",
                    "agent_endpoint": "http://localhost:8000",
                    "reasoning": "ë¼ìš°íŒ… ì‹¤íŒ¨ë¡œ ì¸í•œ ê¸°ë³¸ ì—ì´ì „íŠ¸ ì‚¬ìš©"
                }
            }
    
    async def _gather_session_context(self, session_id: Optional[str], context: Optional[Dict]) -> Dict[str, Any]:
        """ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸ ìˆ˜ì§‘"""
        enhanced_context = context.copy() if context else {}
        
        if session_id and self.session_data_manager:
            try:
                # ì—…ë¡œë“œëœ íŒŒì¼ ì •ë³´
                uploaded_files = self.session_data_manager.get_uploaded_files(session_id)
                enhanced_context["uploaded_files"] = uploaded_files
                
                # íŒŒì¼ ìœ í˜• ë¶„ì„
                if uploaded_files and self.user_file_tracker:
                    file_analysis = []
                    for file_name in uploaded_files:
                        file_path = self.user_file_tracker.get_best_file(
                            session_id=session_id,
                            query=file_name
                        )
                        if file_path:
                            file_ext = Path(file_path).suffix.lower()
                            file_analysis.append({
                                "name": file_name,
                                "path": file_path,
                                "type": file_ext,
                                "size": Path(file_path).stat().st_size if Path(file_path).exists() else 0
                            })
                    enhanced_context["file_analysis"] = file_analysis
                
            except Exception as e:
                logger.warning(f"âš ï¸ ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        
        return enhanced_context
    
    def get_routing_statistics(self) -> Dict[str, Any]:
        """ë¼ìš°íŒ… í†µê³„ ì¡°íšŒ"""
        if not self.routing_history:
            return {"total_queries": 0, "agent_distribution": {}}
        
        total = len(self.routing_history)
        agent_counts = {}
        analysis_type_counts = {}
        confidence_sum = 0
        
        for entry in self.routing_history:
            decision = entry["decision"]
            agent = decision.recommended_agent
            analysis_type = decision.analysis_type.value
            
            agent_counts[agent] = agent_counts.get(agent, 0) + 1
            analysis_type_counts[analysis_type] = analysis_type_counts.get(analysis_type, 0) + 1
            confidence_sum += decision.confidence
        
        return {
            "total_queries": total,
            "agent_distribution": agent_counts,
            "analysis_type_distribution": analysis_type_counts,
            "average_confidence": confidence_sum / total if total > 0 else 0,
            "routing_history_size": len(self.routing_history)
        }
    
    def clear_routing_history(self):
        """ë¼ìš°íŒ… íˆìŠ¤í† ë¦¬ ì •ë¦¬"""
        self.routing_history.clear()
        logger.info("âœ… ë¼ìš°íŒ… íˆìŠ¤í† ë¦¬ ì •ë¦¬ ì™„ë£Œ")


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
_router_instance = None


def get_universal_router(config: Optional[Dict] = None) -> UniversalDataAnalysisRouter:
    """ë²”ìš© ë°ì´í„° ë¶„ì„ ë¼ìš°í„° ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _router_instance
    if _router_instance is None:
        _router_instance = UniversalDataAnalysisRouter(config)
    return _router_instance


# CLI í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
async def test_router():
    """ë¼ìš°í„° í…ŒìŠ¤íŠ¸"""
    router = get_universal_router()
    
    test_queries = [
        "ë°ì´í„°ì˜ ë¶„í¬ë¥¼ ë³´ì—¬ì£¼ì„¸ìš”",
        "ê³ ê° ë°ì´í„°ë¡œ ë§¤ì¶œ ì˜ˆì¸¡ ëª¨ë¸ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”",
        "ê²°ì¸¡ê°’ì„ ì²˜ë¦¬í•´ì£¼ì„¸ìš”",
        "ìƒê´€ê´€ê³„ë¥¼ ì‹œê°í™”í•´ì£¼ì„¸ìš”",
        "í‰ê·  ë‚˜ì´ëŠ” ì–¼ë§ˆì¸ê°€ìš”?",
    ]
    
    for query in test_queries:
        print(f"\nì§ˆë¬¸: {query}")
        result = await router.route_query(query)
        if result["success"]:
            decision = result["decision"]
            print(f"ì—ì´ì „íŠ¸: {decision['recommended_agent']}")
            print(f"ì‹ ë¢°ë„: {decision['confidence']:.2f}")
            print(f"ì´ìœ : {decision['reasoning']}")
        else:
            print(f"ì˜¤ë¥˜: {result['error']}")
    
    # í†µê³„ ì¶œë ¥
    print(f"\në¼ìš°íŒ… í†µê³„:")
    stats = router.get_routing_statistics()
    print(json.dumps(stats, ensure_ascii=False, indent=2))


if __name__ == "__main__":
    asyncio.run(test_router()) 