"""
A2A ë¸Œë¡œì»¤ ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§ ë„êµ¬
Phase 2.1: A2A í†µì‹  ìµœì í™”ë¥¼ ìœ„í•œ ì„±ëŠ¥ ë¶„ì„

ê¸°ëŠ¥:
- ë©”ì‹œì§€ ë¼ìš°íŒ… ì„±ëŠ¥ ì¸¡ì •
- ì‘ë‹µ ì‹œê°„ ë¶„ì„
- ë©”ëª¨ë¦¬ ì‚¬ìš© íŒ¨í„´ ì¶”ì 
- ë³‘ëª©ì  ì‹ë³„
- ì—°ê²° ìƒíƒœ ëª¨ë‹ˆí„°ë§
"""

import asyncio
import time
import psutil
import statistics
import json
import logging
from dataclasses import dataclass, asdict
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime, timedelta
from collections import defaultdict, deque
import httpx
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
from pathlib import Path

logger = logging.getLogger(__name__)

@dataclass
class PerformanceMetric:
    """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë°ì´í„° í´ë˜ìŠ¤"""
    timestamp: datetime
    endpoint: str
    response_time: float
    status_code: int
    memory_usage_mb: float
    cpu_usage_percent: float
    error: Optional[str] = None

@dataclass
class BottleneckAnalysis:
    """ë³‘ëª©ì  ë¶„ì„ ê²°ê³¼"""
    component: str
    severity: str  # "low", "medium", "high", "critical"
    avg_response_time: float
    max_response_time: float
    error_rate: float
    memory_pressure: float
    cpu_pressure: float
    recommendations: List[str]

@dataclass
class A2AAgentStatus:
    """A2A ì—ì´ì „íŠ¸ ìƒíƒœ"""
    name: str
    port: int
    url: str
    status: str  # "healthy", "degraded", "unhealthy", "unreachable"
    avg_response_time: float
    error_rate: float
    last_check: datetime
    agent_card_accessible: bool
    memory_usage: float
    cpu_usage: float

class A2APerformanceProfiler:
    """A2A ë¸Œë¡œì»¤ ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§ ì‹œìŠ¤í…œ"""
    
    def __init__(self, monitoring_interval: int = 5):
        self.monitoring_interval = monitoring_interval
        self.metrics_history: deque = deque(maxlen=1000)
        self.agent_statuses: Dict[str, A2AAgentStatus] = {}
        self.bottlenecks: List[BottleneckAnalysis] = []
        
        # A2A ì—ì´ì „íŠ¸ êµ¬ì„±
        self.a2a_agents = {
            "orchestrator": {"port": 8100, "url": "http://localhost:8100"},
            "data_cleaning": {"port": 8306, "url": "http://localhost:8306"},
            "data_loader": {"port": 8307, "url": "http://localhost:8307"},
            "data_visualization": {"port": 8308, "url": "http://localhost:8308"},
            "data_wrangling": {"port": 8309, "url": "http://localhost:8309"},
            "feature_engineering": {"port": 8310, "url": "http://localhost:8310"},
            "sql_database": {"port": 8311, "url": "http://localhost:8311"},
            "eda_tools": {"port": 8312, "url": "http://localhost:8312"},
            "h2o_modeling": {"port": 8313, "url": "http://localhost:8313"},
            "mlflow_tracking": {"port": 8314, "url": "http://localhost:8314"},
            "pandas_data_analyst": {"port": 8315, "url": "http://localhost:8315"}
        }
        
        # ì„±ëŠ¥ ì¶”ì ìš© íƒ€ì´ë¨¸
        self.request_timers: Dict[str, float] = {}
        self.memory_samples: deque = deque(maxlen=100)
        self.cpu_samples: deque = deque(maxlen=100)
        
        # ê²°ê³¼ ì €ì¥ ê²½ë¡œ
        self.results_dir = Path("monitoring/performance_analysis")
        self.results_dir.mkdir(parents=True, exist_ok=True)
    
    async def profile_message_routing_performance(self, test_messages: List[str], iterations: int = 10) -> Dict[str, Any]:
        """ë©”ì‹œì§€ ë¼ìš°íŒ… ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§"""
        logger.info(f"ğŸ” ë©”ì‹œì§€ ë¼ìš°íŒ… ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§ ì‹œì‘ (ë°˜ë³µ: {iterations}íšŒ)")
        
        routing_results = {}
        
        async with httpx.AsyncClient(timeout=30.0) as client:
            for agent_name, agent_config in self.a2a_agents.items():
                logger.info(f"ğŸ§ª {agent_name} ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì¤‘...")
                
                agent_metrics = []
                
                for iteration in range(iterations):
                    for message in test_messages:
                        start_time = time.time()
                        memory_before = self._get_memory_usage()
                        cpu_before = self._get_cpu_usage()
                        
                        try:
                            # A2A ë©”ì‹œì§€ ì „ì†¡
                            payload = {
                                "jsonrpc": "2.0",
                                "id": f"perf_test_{iteration}",
                                "method": "message/send",
                                "params": {
                                    "message": {
                                        "role": "user",
                                        "parts": [{"kind": "text", "text": message}],
                                        "messageId": f"perf_msg_{time.time()}"
                                    },
                                    "metadata": {}
                                }
                            }
                            
                            response = await client.post(
                                agent_config["url"],
                                json=payload,
                                headers={"Content-Type": "application/json"}
                            )
                            
                            end_time = time.time()
                            memory_after = self._get_memory_usage()
                            cpu_after = self._get_cpu_usage()
                            
                            response_time = end_time - start_time
                            memory_delta = memory_after - memory_before
                            cpu_delta = cpu_after - cpu_before
                            
                            metric = PerformanceMetric(
                                timestamp=datetime.now(),
                                endpoint=agent_config["url"],
                                response_time=response_time,
                                status_code=response.status_code,
                                memory_usage_mb=memory_delta,
                                cpu_usage_percent=cpu_delta,
                                error=None if response.status_code == 200 else f"HTTP {response.status_code}"
                            )
                            
                            agent_metrics.append(metric)
                            
                        except Exception as e:
                            end_time = time.time()
                            response_time = end_time - start_time
                            
                            error_metric = PerformanceMetric(
                                timestamp=datetime.now(),
                                endpoint=agent_config["url"],
                                response_time=response_time,
                                status_code=0,
                                memory_usage_mb=0,
                                cpu_usage_percent=0,
                                error=str(e)
                            )
                            
                            agent_metrics.append(error_metric)
                
                # ì—ì´ì „íŠ¸ë³„ ì„±ëŠ¥ ë¶„ì„
                routing_results[agent_name] = self._analyze_agent_metrics(agent_metrics)
        
        # ì „ì²´ ë¼ìš°íŒ… ì„±ëŠ¥ ë¶„ì„
        overall_analysis = self._analyze_overall_routing_performance(routing_results)
        
        # ê²°ê³¼ ì €ì¥
        await self._save_performance_results(routing_results, overall_analysis)
        
        return {
            "agent_results": routing_results,
            "overall_analysis": overall_analysis,
            "timestamp": datetime.now().isoformat()
        }
    
    def _analyze_agent_metrics(self, metrics: List[PerformanceMetric]) -> Dict[str, Any]:
        """ê°œë³„ ì—ì´ì „íŠ¸ ë©”íŠ¸ë¦­ ë¶„ì„"""
        if not metrics:
            return {"status": "no_data", "error": "No metrics available"}
        
        successful_metrics = [m for m in metrics if m.error is None]
        failed_metrics = [m for m in metrics if m.error is not None]
        
        if not successful_metrics:
            return {
                "status": "all_failed",
                "total_requests": len(metrics),
                "failed_requests": len(failed_metrics),
                "error_rate": 1.0,
                "common_errors": [m.error for m in failed_metrics[:5]]
            }
        
        response_times = [m.response_time for m in successful_metrics]
        memory_usage = [m.memory_usage_mb for m in successful_metrics]
        cpu_usage = [m.cpu_usage_percent for m in successful_metrics]
        
        analysis = {
            "status": "healthy" if len(failed_metrics) == 0 else "degraded",
            "total_requests": len(metrics),
            "successful_requests": len(successful_metrics),
            "failed_requests": len(failed_metrics),
            "error_rate": len(failed_metrics) / len(metrics),
            "response_times": {
                "avg": statistics.mean(response_times),
                "median": statistics.median(response_times),
                "min": min(response_times),
                "max": max(response_times),
                "p95": self._percentile(response_times, 95),
                "p99": self._percentile(response_times, 99)
            },
            "memory_usage": {
                "avg_delta_mb": statistics.mean(memory_usage),
                "max_delta_mb": max(memory_usage) if memory_usage else 0,
                "min_delta_mb": min(memory_usage) if memory_usage else 0
            },
            "cpu_usage": {
                "avg_delta_percent": statistics.mean(cpu_usage),
                "max_delta_percent": max(cpu_usage) if cpu_usage else 0
            }
        }
        
        # ì„±ëŠ¥ ë“±ê¸‰ í‰ê°€
        analysis["performance_grade"] = self._calculate_performance_grade(analysis)
        
        return analysis
    
    def _analyze_overall_routing_performance(self, routing_results: Dict[str, Any]) -> Dict[str, Any]:
        """ì „ì²´ ë¼ìš°íŒ… ì„±ëŠ¥ ë¶„ì„"""
        healthy_agents = []
        degraded_agents = []
        failed_agents = []
        
        total_response_times = []
        total_error_rates = []
        
        for agent_name, results in routing_results.items():
            status = results.get("status", "unknown")
            
            if status == "healthy":
                healthy_agents.append(agent_name)
            elif status == "degraded":
                degraded_agents.append(agent_name)
            else:
                failed_agents.append(agent_name)
            
            if "response_times" in results:
                total_response_times.append(results["response_times"]["avg"])
            
            if "error_rate" in results:
                total_error_rates.append(results["error_rate"])
        
        # ì „ì²´ ì‹œìŠ¤í…œ ìƒíƒœ í‰ê°€
        system_health = "healthy"
        if len(failed_agents) > 3:
            system_health = "critical"
        elif len(failed_agents) > 1 or len(degraded_agents) > 4:
            system_health = "degraded"
        elif len(degraded_agents) > 0:
            system_health = "warning"
        
        overall_analysis = {
            "system_health": system_health,
            "agent_status_summary": {
                "healthy": len(healthy_agents),
                "degraded": len(degraded_agents),
                "failed": len(failed_agents),
                "total": len(routing_results)
            },
            "healthy_agents": healthy_agents,
            "degraded_agents": degraded_agents,
            "failed_agents": failed_agents,
            "performance_summary": {
                "avg_response_time": statistics.mean(total_response_times) if total_response_times else 0,
                "avg_error_rate": statistics.mean(total_error_rates) if total_error_rates else 0,
                "fastest_agent": min(routing_results.items(), key=lambda x: x[1].get("response_times", {}).get("avg", float('inf')))[0] if total_response_times else None,
                "slowest_agent": max(routing_results.items(), key=lambda x: x[1].get("response_times", {}).get("avg", 0))[0] if total_response_times else None
            }
        }
        
        # ë³‘ëª©ì  ì‹ë³„
        bottlenecks = self._identify_bottlenecks(routing_results)
        overall_analysis["bottlenecks"] = bottlenecks
        
        # ìµœì í™” ê¶Œì¥ì‚¬í•­
        recommendations = self._generate_optimization_recommendations(overall_analysis, routing_results)
        overall_analysis["optimization_recommendations"] = recommendations
        
        return overall_analysis
    
    def _identify_bottlenecks(self, routing_results: Dict[str, Any]) -> List[BottleneckAnalysis]:
        """ë³‘ëª©ì  ì‹ë³„"""
        bottlenecks = []
        
        for agent_name, results in routing_results.items():
            if results.get("status") == "all_failed":
                bottleneck = BottleneckAnalysis(
                    component=agent_name,
                    severity="critical",
                    avg_response_time=0,
                    max_response_time=0,
                    error_rate=1.0,
                    memory_pressure=0,
                    cpu_pressure=0,
                    recommendations=[
                        f"{agent_name} ì„œë²„ê°€ ì‘ë‹µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì„œë²„ ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”.",
                        "í¬íŠ¸ ì¶©ëŒì´ë‚˜ í”„ë¡œì„¸ìŠ¤ ìƒíƒœë¥¼ ì ê²€í•˜ì„¸ìš”.",
                        "ë¡œê·¸ë¥¼ í™•ì¸í•˜ì—¬ êµ¬ì²´ì ì¸ ì˜¤ë¥˜ ì›ì¸ì„ íŒŒì•…í•˜ì„¸ìš”."
                    ]
                )
                bottlenecks.append(bottleneck)
                continue
            
            response_times = results.get("response_times", {})
            avg_response_time = response_times.get("avg", 0)
            max_response_time = response_times.get("max", 0)
            error_rate = results.get("error_rate", 0)
            
            # ì„±ëŠ¥ ì„ê³„ê°’ ê¸°ì¤€ í‰ê°€
            severity = "low"
            recommendations = []
            
            if avg_response_time > 10.0:  # 10ì´ˆ ì´ìƒ
                severity = "critical"
                recommendations.append(f"{agent_name}ì˜ í‰ê·  ì‘ë‹µì‹œê°„ì´ {avg_response_time:.2f}ì´ˆë¡œ ë§¤ìš° ëŠë¦½ë‹ˆë‹¤.")
                recommendations.append("ì½”ë“œ ìµœì í™”ë‚˜ ì¸í”„ë¼ ì—…ê·¸ë ˆì´ë“œë¥¼ ê³ ë ¤í•˜ì„¸ìš”.")
            elif avg_response_time > 5.0:  # 5ì´ˆ ì´ìƒ
                severity = "high"
                recommendations.append(f"{agent_name}ì˜ ì‘ë‹µì‹œê°„ ìµœì í™”ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            elif avg_response_time > 2.0:  # 2ì´ˆ ì´ìƒ
                severity = "medium"
                recommendations.append(f"{agent_name}ì˜ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ì„ ê°•í™”í•˜ì„¸ìš”.")
            
            if error_rate > 0.1:  # 10% ì´ìƒ
                if severity == "low":
                    severity = "high"
                recommendations.append(f"{agent_name}ì˜ ì—ëŸ¬ìœ¨ì´ {error_rate*100:.1f}%ë¡œ ë†’ìŠµë‹ˆë‹¤.")
                recommendations.append("ì—ëŸ¬ ë¡œê·¸ë¥¼ ë¶„ì„í•˜ì—¬ ê·¼ë³¸ ì›ì¸ì„ íŒŒì•…í•˜ì„¸ìš”.")
            
            if severity != "low" or recommendations:
                bottleneck = BottleneckAnalysis(
                    component=agent_name,
                    severity=severity,
                    avg_response_time=avg_response_time,
                    max_response_time=max_response_time,
                    error_rate=error_rate,
                    memory_pressure=results.get("memory_usage", {}).get("avg_delta_mb", 0),
                    cpu_pressure=results.get("cpu_usage", {}).get("avg_delta_percent", 0),
                    recommendations=recommendations
                )
                bottlenecks.append(bottleneck)
        
        return sorted(bottlenecks, key=lambda x: {"critical": 4, "high": 3, "medium": 2, "low": 1}[x.severity], reverse=True)
    
    def _generate_optimization_recommendations(self, overall_analysis: Dict[str, Any], routing_results: Dict[str, Any]) -> List[str]:
        """ìµœì í™” ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        system_health = overall_analysis["system_health"]
        failed_agents = overall_analysis["failed_agents"]
        degraded_agents = overall_analysis["degraded_agents"]
        
        # ì‹œìŠ¤í…œ ì „ì²´ ê¶Œì¥ì‚¬í•­
        if system_health == "critical":
            recommendations.append("ğŸš¨ ì‹œìŠ¤í…œì´ ìœ„í—˜í•œ ìƒíƒœì…ë‹ˆë‹¤. ì¦‰ì‹œ ì¡°ì¹˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            recommendations.append("ì‹¤íŒ¨í•œ ì—ì´ì „íŠ¸ë“¤ì„ ìš°ì„  ë³µêµ¬í•˜ì„¸ìš”: " + ", ".join(failed_agents))
        elif system_health == "degraded":
            recommendations.append("âš ï¸ ì‹œìŠ¤í…œ ì„±ëŠ¥ì´ ì €í•˜ë˜ì—ˆìŠµë‹ˆë‹¤.")
            if degraded_agents:
                recommendations.append("ì„±ëŠ¥ ì €í•˜ ì—ì´ì „íŠ¸ ìµœì í™”: " + ", ".join(degraded_agents))
        
        # ì„±ëŠ¥ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
        avg_response_time = overall_analysis["performance_summary"]["avg_response_time"]
        if avg_response_time > 3.0:
            recommendations.append(f"ì „ì²´ í‰ê·  ì‘ë‹µì‹œê°„({avg_response_time:.2f}ì´ˆ)ì´ ëª©í‘œì¹˜(3ì´ˆ)ë¥¼ ì´ˆê³¼í•©ë‹ˆë‹¤.")
            recommendations.append("ì—°ê²° í’€ í¬ê¸° ì¦ê°€ë¥¼ ê³ ë ¤í•˜ì„¸ìš”.")
            recommendations.append("íƒ€ì„ì•„ì›ƒ ì„¤ì •ì„ ì¡°ì •í•˜ì„¸ìš”.")
        
        # ì—ì´ì „íŠ¸ë³„ ì„¸ë¶€ ê¶Œì¥ì‚¬í•­
        slowest_agent = overall_analysis["performance_summary"]["slowest_agent"]
        if slowest_agent:
            slowest_time = routing_results[slowest_agent]["response_times"]["avg"]
            recommendations.append(f"ê°€ì¥ ëŠë¦° ì—ì´ì „íŠ¸ {slowest_agent}({slowest_time:.2f}ì´ˆ) ìš°ì„  ìµœì í™”")
        
        # ë©”ëª¨ë¦¬/CPU ê¶Œì¥ì‚¬í•­
        high_memory_agents = []
        high_cpu_agents = []
        
        for agent_name, results in routing_results.items():
            memory_usage = results.get("memory_usage", {}).get("avg_delta_mb", 0)
            cpu_usage = results.get("cpu_usage", {}).get("avg_delta_percent", 0)
            
            if memory_usage > 100:  # 100MB ì´ìƒ
                high_memory_agents.append(f"{agent_name}({memory_usage:.1f}MB)")
            
            if cpu_usage > 20:  # 20% ì´ìƒ
                high_cpu_agents.append(f"{agent_name}({cpu_usage:.1f}%)")
        
        if high_memory_agents:
            recommendations.append("ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ë†’ì€ ì—ì´ì „íŠ¸: " + ", ".join(high_memory_agents))
            recommendations.append("ë©”ëª¨ë¦¬ ìµœì í™” ë˜ëŠ” ì¸ìŠ¤í„´ìŠ¤ ìŠ¤ì¼€ì¼ë§ì„ ê³ ë ¤í•˜ì„¸ìš”.")
        
        if high_cpu_agents:
            recommendations.append("CPU ì‚¬ìš©ëŸ‰ì´ ë†’ì€ ì—ì´ì „íŠ¸: " + ", ".join(high_cpu_agents))
            recommendations.append("ë¹„ë™ê¸° ì²˜ë¦¬ ìµœì í™”ë¥¼ ê³ ë ¤í•˜ì„¸ìš”.")
        
        return recommendations
    
    async def continuous_monitoring(self, duration_minutes: int = 60) -> Dict[str, Any]:
        """ì§€ì†ì ì¸ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§"""
        logger.info(f"ğŸ”„ {duration_minutes}ë¶„ê°„ ì§€ì†ì ì¸ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œì‘")
        
        start_time = datetime.now()
        end_time = start_time + timedelta(minutes=duration_minutes)
        
        monitoring_data = {
            "start_time": start_time.isoformat(),
            "end_time": end_time.isoformat(),
            "samples": [],
            "alerts": []
        }
        
        while datetime.now() < end_time:
            try:
                # ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ìˆ˜ì§‘
                memory_info = psutil.virtual_memory()
                cpu_percent = psutil.cpu_percent(interval=1)
                
                # ê° ì—ì´ì „íŠ¸ ìƒíƒœ ì²´í¬
                agent_statuses = await self._check_all_agents_health()
                
                sample = {
                    "timestamp": datetime.now().isoformat(),
                    "system_memory_percent": memory_info.percent,
                    "system_cpu_percent": cpu_percent,
                    "agent_statuses": agent_statuses
                }
                
                monitoring_data["samples"].append(sample)
                
                # ì•ŒëŒ ì¡°ê±´ ì²´í¬
                alerts = self._check_performance_alerts(sample)
                monitoring_data["alerts"].extend(alerts)
                
                # ëª¨ë‹ˆí„°ë§ ê°„ê²© ëŒ€ê¸°
                await asyncio.sleep(self.monitoring_interval)
                
            except Exception as e:
                logger.error(f"ëª¨ë‹ˆí„°ë§ ì¤‘ ì˜¤ë¥˜: {e}")
                monitoring_data["alerts"].append({
                    "timestamp": datetime.now().isoformat(),
                    "type": "monitoring_error",
                    "message": str(e)
                })
        
        # ëª¨ë‹ˆí„°ë§ ê²°ê³¼ ë¶„ì„
        analysis = self._analyze_monitoring_data(monitoring_data)
        monitoring_data["analysis"] = analysis
        
        # ê²°ê³¼ ì €ì¥
        await self._save_monitoring_results(monitoring_data)
        
        return monitoring_data
    
    async def _check_all_agents_health(self) -> Dict[str, Dict[str, Any]]:
        """ëª¨ë“  ì—ì´ì „íŠ¸ì˜ í—¬ìŠ¤ ì²´í¬"""
        agent_statuses = {}
        
        async with httpx.AsyncClient(timeout=10.0) as client:
            for agent_name, agent_config in self.a2a_agents.items():
                try:
                    start_time = time.time()
                    
                    # Agent Card ì ‘ê·¼ í…ŒìŠ¤íŠ¸
                    card_response = await client.get(f"{agent_config['url']}/.well-known/agent.json")
                    card_accessible = card_response.status_code == 200
                    
                    # í—¬ìŠ¤ ì²´í¬ (ê°„ë‹¨í•œ ë©”ì‹œì§€)
                    health_payload = {
                        "jsonrpc": "2.0",
                        "id": "health_check",
                        "method": "message/send",
                        "params": {
                            "message": {
                                "role": "user",
                                "parts": [{"kind": "text", "text": "ping"}],
                                "messageId": f"health_{time.time()}"
                            },
                            "metadata": {}
                        }
                    }
                    
                    health_response = await client.post(
                        agent_config["url"],
                        json=health_payload
                    )
                    
                    response_time = time.time() - start_time
                    
                    if health_response.status_code == 200:
                        status = "healthy"
                    else:
                        status = "degraded"
                    
                    agent_statuses[agent_name] = {
                        "status": status,
                        "response_time": response_time,
                        "agent_card_accessible": card_accessible,
                        "status_code": health_response.status_code,
                        "error": None
                    }
                    
                except Exception as e:
                    agent_statuses[agent_name] = {
                        "status": "unreachable",
                        "response_time": 0,
                        "agent_card_accessible": False,
                        "status_code": 0,
                        "error": str(e)
                    }
        
        return agent_statuses
    
    def _check_performance_alerts(self, sample: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ì„±ëŠ¥ ì•ŒëŒ ì¡°ê±´ ì²´í¬"""
        alerts = []
        timestamp = sample["timestamp"]
        
        # ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ì•ŒëŒ
        if sample["system_memory_percent"] > 90:
            alerts.append({
                "timestamp": timestamp,
                "type": "system_memory_critical",
                "message": f"ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ {sample['system_memory_percent']:.1f}%ë¡œ ìœ„í—˜ ìˆ˜ì¤€ì…ë‹ˆë‹¤."
            })
        elif sample["system_memory_percent"] > 80:
            alerts.append({
                "timestamp": timestamp,
                "type": "system_memory_warning",
                "message": f"ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ {sample['system_memory_percent']:.1f}%ë¡œ ë†’ìŠµë‹ˆë‹¤."
            })
        
        if sample["system_cpu_percent"] > 90:
            alerts.append({
                "timestamp": timestamp,
                "type": "system_cpu_critical",
                "message": f"ì‹œìŠ¤í…œ CPU ì‚¬ìš©ëŸ‰ì´ {sample['system_cpu_percent']:.1f}%ë¡œ ìœ„í—˜ ìˆ˜ì¤€ì…ë‹ˆë‹¤."
            })
        
        # ì—ì´ì „íŠ¸ë³„ ì•ŒëŒ
        for agent_name, agent_status in sample["agent_statuses"].items():
            if agent_status["status"] == "unreachable":
                alerts.append({
                    "timestamp": timestamp,
                    "type": "agent_unreachable",
                    "message": f"ì—ì´ì „íŠ¸ {agent_name}ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                    "agent": agent_name
                })
            elif agent_status["response_time"] > 10.0:
                alerts.append({
                    "timestamp": timestamp,
                    "type": "agent_slow_response",
                    "message": f"ì—ì´ì „íŠ¸ {agent_name}ì˜ ì‘ë‹µì‹œê°„ì´ {agent_status['response_time']:.2f}ì´ˆë¡œ ëŠë¦½ë‹ˆë‹¤.",
                    "agent": agent_name
                })
        
        return alerts
    
    def _analyze_monitoring_data(self, monitoring_data: Dict[str, Any]) -> Dict[str, Any]:
        """ëª¨ë‹ˆí„°ë§ ë°ì´í„° ë¶„ì„"""
        samples = monitoring_data["samples"]
        
        if not samples:
            return {"error": "No monitoring data available"}
        
        # ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ í†µê³„
        memory_usage = [s["system_memory_percent"] for s in samples]
        cpu_usage = [s["system_cpu_percent"] for s in samples]
        
        # ì—ì´ì „íŠ¸ ê°€ìš©ì„± ë¶„ì„
        agent_availability = defaultdict(list)
        agent_response_times = defaultdict(list)
        
        for sample in samples:
            for agent_name, status in sample["agent_statuses"].items():
                agent_availability[agent_name].append(status["status"] == "healthy")
                if status["response_time"] > 0:
                    agent_response_times[agent_name].append(status["response_time"])
        
        analysis = {
            "monitoring_duration_minutes": len(samples) * self.monitoring_interval / 60,
            "total_samples": len(samples),
            "system_resources": {
                "memory": {
                    "avg_percent": statistics.mean(memory_usage),
                    "max_percent": max(memory_usage),
                    "min_percent": min(memory_usage)
                },
                "cpu": {
                    "avg_percent": statistics.mean(cpu_usage),
                    "max_percent": max(cpu_usage),
                    "min_percent": min(cpu_usage)
                }
            },
            "agent_availability": {
                agent: {
                    "uptime_percent": sum(statuses) / len(statuses) * 100,
                    "total_checks": len(statuses),
                    "healthy_checks": sum(statuses)
                }
                for agent, statuses in agent_availability.items()
            },
            "agent_performance": {
                agent: {
                    "avg_response_time": statistics.mean(times),
                    "max_response_time": max(times),
                    "min_response_time": min(times)
                }
                for agent, times in agent_response_times.items() if times
            },
            "alerts_summary": {
                "total_alerts": len(monitoring_data["alerts"]),
                "alert_types": list(set(alert["type"] for alert in monitoring_data["alerts"]))
            }
        }
        
        return analysis
    
    async def generate_performance_visualization(self, results: Dict[str, Any]) -> str:
        """ì„±ëŠ¥ ë¶„ì„ ê²°ê³¼ ì‹œê°í™”"""
        logger.info("ğŸ“Š ì„±ëŠ¥ ë¶„ì„ ê²°ê³¼ ì‹œê°í™” ìƒì„± ì¤‘...")
        
        # ì‹œê°í™” ì„¤ì •
        plt.style.use('seaborn-v0_8')
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('A2A ë¸Œë¡œì»¤ ì„±ëŠ¥ ë¶„ì„ ê²°ê³¼', fontsize=16, fontweight='bold')
        
        # 1. ì—ì´ì „íŠ¸ë³„ ì‘ë‹µì‹œê°„ ë¹„êµ
        agent_names = []
        avg_response_times = []
        error_rates = []
        
        for agent_name, result in results["agent_results"].items():
            if result.get("status") in ["healthy", "degraded"]:
                agent_names.append(agent_name.replace("_", "\n"))
                avg_response_times.append(result["response_times"]["avg"])
                error_rates.append(result["error_rate"] * 100)
        
        if agent_names:
            axes[0, 0].bar(agent_names, avg_response_times, color='skyblue', alpha=0.7)
            axes[0, 0].set_title('ì—ì´ì „íŠ¸ë³„ í‰ê·  ì‘ë‹µì‹œê°„', fontweight='bold')
            axes[0, 0].set_ylabel('ì‘ë‹µì‹œê°„ (ì´ˆ)')
            axes[0, 0].tick_params(axis='x', rotation=45)
            
            # ëª©í‘œ ì‘ë‹µì‹œê°„ ë¼ì¸ ì¶”ê°€
            axes[0, 0].axhline(y=3.0, color='red', linestyle='--', label='ëª©í‘œ (3ì´ˆ)')
            axes[0, 0].legend()
        
        # 2. ì—ì´ì „íŠ¸ë³„ ì—ëŸ¬ìœ¨
        if agent_names:
            bars = axes[0, 1].bar(agent_names, error_rates, color='lightcoral', alpha=0.7)
            axes[0, 1].set_title('ì—ì´ì „íŠ¸ë³„ ì—ëŸ¬ìœ¨', fontweight='bold')
            axes[0, 1].set_ylabel('ì—ëŸ¬ìœ¨ (%)')
            axes[0, 1].tick_params(axis='x', rotation=45)
            
            # 10% ì´ìƒ ì—ëŸ¬ìœ¨ ê°•ì¡°
            for i, (bar, rate) in enumerate(zip(bars, error_rates)):
                if rate > 10:
                    bar.set_color('red')
        
        # 3. ì‹œìŠ¤í…œ ìƒíƒœ ìš”ì•½
        status_summary = results["overall_analysis"]["agent_status_summary"]
        status_labels = list(status_summary.keys())
        status_values = list(status_summary.values())
        colors = ['green', 'orange', 'red', 'blue']
        
        axes[1, 0].pie(status_values, labels=status_labels, colors=colors[:len(status_labels)], 
                      autopct='%1.1f%%', startangle=90)
        axes[1, 0].set_title('ì—ì´ì „íŠ¸ ìƒíƒœ ë¶„í¬', fontweight='bold')
        
        # 4. ë³‘ëª©ì  ì‹¬ê°ë„
        bottlenecks = results["overall_analysis"].get("bottlenecks", [])
        if bottlenecks:
            severity_count = defaultdict(int)
            for bottleneck in bottlenecks:
                severity_count[bottleneck.severity] += 1
            
            severity_labels = list(severity_count.keys())
            severity_values = list(severity_count.values())
            severity_colors = {'critical': 'red', 'high': 'orange', 'medium': 'yellow', 'low': 'green'}
            bar_colors = [severity_colors.get(label, 'gray') for label in severity_labels]
            
            axes[1, 1].bar(severity_labels, severity_values, color=bar_colors, alpha=0.7)
            axes[1, 1].set_title('ë³‘ëª©ì  ì‹¬ê°ë„ ë¶„í¬', fontweight='bold')
            axes[1, 1].set_ylabel('ê°œìˆ˜')
        else:
            axes[1, 1].text(0.5, 0.5, 'ë³‘ëª©ì  ì—†ìŒ', ha='center', va='center', 
                           transform=axes[1, 1].transAxes, fontsize=14)
            axes[1, 1].set_title('ë³‘ëª©ì  ì‹¬ê°ë„ ë¶„í¬', fontweight='bold')
        
        plt.tight_layout()
        
        # ì €ì¥
        chart_path = self.results_dir / f"performance_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
        plt.savefig(chart_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        logger.info(f"ğŸ“Š ì„±ëŠ¥ ë¶„ì„ ì°¨íŠ¸ ì €ì¥: {chart_path}")
        return str(chart_path)
    
    async def _save_performance_results(self, routing_results: Dict[str, Any], overall_analysis: Dict[str, Any]):
        """ì„±ëŠ¥ ë¶„ì„ ê²°ê³¼ ì €ì¥"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # JSON ê²°ê³¼ ì €ì¥
        results_data = {
            "timestamp": datetime.now().isoformat(),
            "routing_results": routing_results,
            "overall_analysis": overall_analysis
        }
        
        json_path = self.results_dir / f"performance_results_{timestamp}.json"
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(results_data, f, indent=2, ensure_ascii=False, default=str)
        
        logger.info(f"ğŸ’¾ ì„±ëŠ¥ ë¶„ì„ ê²°ê³¼ ì €ì¥: {json_path}")
    
    async def _save_monitoring_results(self, monitoring_data: Dict[str, Any]):
        """ëª¨ë‹ˆí„°ë§ ê²°ê³¼ ì €ì¥"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        json_path = self.results_dir / f"monitoring_results_{timestamp}.json"
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(monitoring_data, f, indent=2, ensure_ascii=False, default=str)
        
        logger.info(f"ğŸ’¾ ëª¨ë‹ˆí„°ë§ ê²°ê³¼ ì €ì¥: {json_path}")
    
    def _get_memory_usage(self) -> float:
        """í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (MB)"""
        return psutil.virtual_memory().used / 1024 / 1024
    
    def _get_cpu_usage(self) -> float:
        """í˜„ì¬ CPU ì‚¬ìš©ë¥  (%)"""
        return psutil.cpu_percent()
    
    def _percentile(self, data: List[float], percentile: float) -> float:
        """ë°±ë¶„ìœ„ìˆ˜ ê³„ì‚°"""
        if not data:
            return 0
        sorted_data = sorted(data)
        index = int(len(sorted_data) * percentile / 100)
        return sorted_data[min(index, len(sorted_data) - 1)]
    
    def _calculate_performance_grade(self, analysis: Dict[str, Any]) -> str:
        """ì„±ëŠ¥ ë“±ê¸‰ ê³„ì‚°"""
        error_rate = analysis.get("error_rate", 0)
        avg_response_time = analysis.get("response_times", {}).get("avg", 0)
        
        if error_rate > 0.2 or avg_response_time > 10:
            return "F"
        elif error_rate > 0.1 or avg_response_time > 5:
            return "D"
        elif error_rate > 0.05 or avg_response_time > 3:
            return "C"
        elif error_rate > 0.01 or avg_response_time > 1.5:
            return "B"
        else:
            return "A"


# ì‚¬ìš© ì˜ˆì‹œ ë° í…ŒìŠ¤íŠ¸
async def main():
    """ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§ ì‹¤í–‰ ì˜ˆì‹œ"""
    profiler = A2APerformanceProfiler()
    
    # í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€ë“¤
    test_messages = [
        "Hello",
        "ë°ì´í„°ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”",
        "ì‹œê°í™”ë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”",
        "ìš”ì•½ í†µê³„ë¥¼ ê³„ì‚°í•´ì£¼ì„¸ìš”"
    ]
    
    # ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§ ì‹¤í–‰
    results = await profiler.profile_message_routing_performance(test_messages, iterations=5)
    
    # ê²°ê³¼ ì¶œë ¥
    print("ğŸ” A2A ë¸Œë¡œì»¤ ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§ ê²°ê³¼:")
    print(f"ì‹œìŠ¤í…œ ìƒíƒœ: {results['overall_analysis']['system_health']}")
    print(f"í‰ê·  ì‘ë‹µì‹œê°„: {results['overall_analysis']['performance_summary']['avg_response_time']:.2f}ì´ˆ")
    
    # ì‹œê°í™” ìƒì„±
    chart_path = await profiler.generate_performance_visualization(results)
    print(f"ğŸ“Š ì„±ëŠ¥ ì°¨íŠ¸: {chart_path}")

if __name__ == "__main__":
    asyncio.run(main()) 