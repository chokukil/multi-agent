#!/usr/bin/env python3
"""
ğŸ’ CherryAI ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìë™ ìˆ˜ì§‘ ì‹œìŠ¤í…œ
Phase 1.5: í¬ê´„ì  ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë° ë¶„ì„

Features:
- ì‘ë‹µì‹œê°„ íŠ¸ë˜í‚¹ (A2A + MCP)
- ë©”ëª¨ë¦¬/CPU ì‚¬ìš©ë¥  ëª¨ë‹ˆí„°ë§
- ì—ëŸ¬ìœ¨ ë° ì„±ê³µë¥  ì¶”ì 
- íˆìŠ¤í† ë¦¬ ë°ì´í„° ê´€ë¦¬
- ì„±ëŠ¥ íŠ¸ë Œë“œ ë¶„ì„
- ì•Œë¦¼ ë° ì„ê³„ê°’ ê´€ë¦¬

Author: CherryAI Team
Date: 2025-07-13
"""

import asyncio
import time
import logging
import psutil
import requests
import json
import sqlite3
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, field, asdict
from enum import Enum
from pathlib import Path
import statistics
import threading
from concurrent.futures import ThreadPoolExecutor

from .mcp_config_manager import get_mcp_config_manager
from .mcp_server_manager import get_server_manager

logger = logging.getLogger(__name__)

class MetricType(Enum):
    """ë©”íŠ¸ë¦­ íƒ€ì…"""
    RESPONSE_TIME = "response_time"
    CPU_USAGE = "cpu_usage"
    MEMORY_USAGE = "memory_usage"
    ERROR_RATE = "error_rate"
    SUCCESS_RATE = "success_rate"
    CONNECTION_COUNT = "connection_count"
    UPTIME = "uptime"

class AlertLevel(Enum):
    """ì•Œë¦¼ ë ˆë²¨"""
    INFO = "info"
    WARNING = "warning"
    ERROR = "error"
    CRITICAL = "critical"

@dataclass
class MetricRecord:
    """ë©”íŠ¸ë¦­ ë ˆì½”ë“œ"""
    server_id: str
    server_type: str  # "a2a" or "mcp"
    metric_type: MetricType
    value: float
    timestamp: datetime
    metadata: Dict[str, Any] = field(default_factory=dict)

@dataclass
class PerformanceAlert:
    """ì„±ëŠ¥ ì•Œë¦¼"""
    server_id: str
    metric_type: MetricType
    level: AlertLevel
    current_value: float
    threshold: float
    message: str
    timestamp: datetime
    resolved: bool = False

@dataclass
class PerformanceThreshold:
    """ì„±ëŠ¥ ì„ê³„ê°’"""
    metric_type: MetricType
    warning_threshold: float
    error_threshold: float
    critical_threshold: float
    unit: str = ""

@dataclass
class ServerPerformanceSummary:
    """ì„œë²„ ì„±ëŠ¥ ìš”ì•½"""
    server_id: str
    server_type: str
    last_update: datetime
    
    # ì‘ë‹µì‹œê°„ (ms)
    avg_response_time: float = 0.0
    max_response_time: float = 0.0
    min_response_time: float = 0.0
    
    # ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ë¥  (%)
    avg_cpu_usage: float = 0.0
    max_cpu_usage: float = 0.0
    avg_memory_usage: float = 0.0
    max_memory_usage: float = 0.0
    
    # ì‹ ë¢°ì„±
    success_rate: float = 100.0
    error_rate: float = 0.0
    uptime_hours: float = 0.0
    
    # ì—°ê²°
    active_connections: int = 0
    total_requests: int = 0
    
    # ì•Œë¦¼
    active_alerts: List[PerformanceAlert] = field(default_factory=list)

class PerformanceMetricsCollector:
    """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìë™ ìˆ˜ì§‘ ì‹œìŠ¤í…œ"""
    
    def __init__(self, db_path: str = "logs/performance_metrics.db"):
        self.db_path = Path(db_path)
        self.db_path.parent.mkdir(parents=True, exist_ok=True)
        
        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.config_manager = get_mcp_config_manager()
        self.server_manager = get_server_manager()
        
        # ìˆ˜ì§‘ ì„¤ì •
        self.collection_interval = 30  # 30ì´ˆë§ˆë‹¤ ìˆ˜ì§‘
        self.history_retention_days = 30
        self.is_collecting = False
        
        # ì„±ëŠ¥ ì„ê³„ê°’ ì„¤ì •
        self.thresholds = self._init_performance_thresholds()
        
        # ë°ì´í„° ì €ì¥ì†Œ
        self.metrics_cache: List[MetricRecord] = []
        self.performance_summaries: Dict[str, ServerPerformanceSummary] = {}
        self.active_alerts: List[PerformanceAlert] = []
        
        # A2A ì—ì´ì „íŠ¸ í¬íŠ¸ ì„¤ì •
        self.a2a_ports = {
            8100: "Orchestrator",
            8306: "Data Preprocessor", 
            8307: "Data Validator",
            8308: "EDA Analyst", 
            8309: "Feature Engineer",
            8310: "ML Modeler",
            8311: "Model Evaluator",
            8312: "Visualization Generator",
            8313: "Report Generator",
            8314: "MLflow Tracker",
            8315: "Pandas Analyst"
        }
        
        # ìŠ¤ë ˆë“œ í’€
        self.executor = ThreadPoolExecutor(max_workers=5)
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
        self._init_database()
        
        logger.info("Performance Metrics Collector ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _init_database(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                # ë©”íŠ¸ë¦­ í…Œì´ë¸”
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS metrics (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        server_id TEXT NOT NULL,
                        server_type TEXT NOT NULL,
                        metric_type TEXT NOT NULL,
                        value REAL NOT NULL,
                        timestamp DATETIME NOT NULL,
                        metadata TEXT
                    )
                """)
                
                # ì•Œë¦¼ í…Œì´ë¸”
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS alerts (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        server_id TEXT NOT NULL,
                        metric_type TEXT NOT NULL,
                        level TEXT NOT NULL,
                        current_value REAL NOT NULL,
                        threshold REAL NOT NULL,
                        message TEXT NOT NULL,
                        timestamp DATETIME NOT NULL,
                        resolved BOOLEAN DEFAULT FALSE
                    )
                """)
                
                # ì¸ë±ìŠ¤ ìƒì„±
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_metrics_server_time ON metrics(server_id, timestamp)")
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_alerts_server_time ON alerts(server_id, timestamp)")
                
                conn.commit()
                logger.info("ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
                
        except Exception as e:
            logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    def _init_performance_thresholds(self) -> Dict[MetricType, PerformanceThreshold]:
        """ì„±ëŠ¥ ì„ê³„ê°’ ì´ˆê¸°í™”"""
        return {
            MetricType.RESPONSE_TIME: PerformanceThreshold(
                metric_type=MetricType.RESPONSE_TIME,
                warning_threshold=1000.0,    # 1ì´ˆ
                error_threshold=3000.0,      # 3ì´ˆ
                critical_threshold=5000.0,   # 5ì´ˆ
                unit="ms"
            ),
            MetricType.CPU_USAGE: PerformanceThreshold(
                metric_type=MetricType.CPU_USAGE,
                warning_threshold=70.0,      # 70%
                error_threshold=85.0,        # 85%
                critical_threshold=95.0,     # 95%
                unit="%"
            ),
            MetricType.MEMORY_USAGE: PerformanceThreshold(
                metric_type=MetricType.MEMORY_USAGE,
                warning_threshold=70.0,      # 70%
                error_threshold=85.0,        # 85%
                critical_threshold=95.0,     # 95%
                unit="%"
            ),
            MetricType.ERROR_RATE: PerformanceThreshold(
                metric_type=MetricType.ERROR_RATE,
                warning_threshold=5.0,       # 5%
                error_threshold=10.0,        # 10%
                critical_threshold=20.0,     # 20%
                unit="%"
            )
        }
    
    async def start_collection(self):
        """ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹œì‘"""
        if self.is_collecting:
            logger.warning("ë©”íŠ¸ë¦­ ìˆ˜ì§‘ì´ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤")
            return
        
        self.is_collecting = True
        logger.info("ğŸ” ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìë™ ìˆ˜ì§‘ ì‹œì‘")
        
        try:
            while self.is_collecting:
                start_time = time.time()
                
                # A2A ë° MCP ë©”íŠ¸ë¦­ ìˆ˜ì§‘
                await self._collect_all_metrics()
                
                # ì„±ëŠ¥ ìš”ì•½ ì—…ë°ì´íŠ¸
                await self._update_performance_summaries()
                
                # ì•Œë¦¼ í™•ì¸
                await self._check_alerts()
                
                # ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
                await self._save_metrics_to_db()
                
                # ì˜¤ë˜ëœ ë°ì´í„° ì •ë¦¬
                await self._cleanup_old_data()
                
                # ìˆ˜ì§‘ ì‹œê°„ ê³„ì‚° ë° ëŒ€ê¸°
                collection_time = time.time() - start_time
                sleep_time = max(0, self.collection_interval - collection_time)
                
                logger.debug(f"ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì™„ë£Œ (ì†Œìš”ì‹œê°„: {collection_time:.2f}ì´ˆ, ëŒ€ê¸°: {sleep_time:.2f}ì´ˆ)")
                await asyncio.sleep(sleep_time)
                
        except Exception as e:
            logger.error(f"ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}")
        finally:
            self.is_collecting = False
            logger.info("ğŸ›‘ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì¤‘ì§€")
    
    async def _collect_all_metrics(self):
        """ëª¨ë“  ì„œë²„ì˜ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        try:
            # A2A ì—ì´ì „íŠ¸ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
            a2a_tasks = [
                self._collect_a2a_metrics(port, name) 
                for port, name in self.a2a_ports.items()
            ]
            
            # MCP ì„œë²„ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
            enabled_servers = self.config_manager.get_enabled_servers()
            mcp_tasks = [
                self._collect_mcp_metrics(server_id, server_def) 
                for server_id, server_def in enabled_servers.items()
            ]
            
            # ë³‘ë ¬ ì‹¤í–‰
            all_tasks = a2a_tasks + mcp_tasks
            await asyncio.gather(*all_tasks, return_exceptions=True)
            
        except Exception as e:
            logger.error(f"ì „ì²´ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}")
    
    async def _collect_a2a_metrics(self, port: int, name: str):
        """A2A ì—ì´ì „íŠ¸ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        server_id = f"a2a_{port}"
        timestamp = datetime.now()
        
        try:
            # ì‘ë‹µì‹œê°„ ì¸¡ì •
            start_time = time.time()
            try:
                response = requests.get(
                    f"http://localhost:{port}/.well-known/agent.json",
                    timeout=5
                )
                response_time = (time.time() - start_time) * 1000  # ms
                success = response.status_code == 200
            except requests.exceptions.RequestException as e:
                response_time = 5000  # íƒ€ì„ì•„ì›ƒìœ¼ë¡œ ê°€ì •
                success = False
            
            # ì‘ë‹µì‹œê°„ ë©”íŠ¸ë¦­ ì €ì¥
            self._add_metric(MetricRecord(
                server_id=server_id,
                server_type="a2a",
                metric_type=MetricType.RESPONSE_TIME,
                value=response_time,
                timestamp=timestamp,
                metadata={"port": port, "name": name, "success": success}
            ))
            
            # ì„±ê³µë¥  ë©”íŠ¸ë¦­ ì €ì¥
            success_rate = 100.0 if success else 0.0
            self._add_metric(MetricRecord(
                server_id=server_id,
                server_type="a2a",
                metric_type=MetricType.SUCCESS_RATE,
                value=success_rate,
                timestamp=timestamp,
                metadata={"port": port, "name": name}
            ))
            
            # í¬íŠ¸ì—ì„œ ì‹¤í–‰ ì¤‘ì¸ í”„ë¡œì„¸ìŠ¤ ì°¾ê¸° (ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ë¥ )
            try:
                import subprocess
                result = subprocess.run(['lsof', '-ti', f':{port}'], 
                                      capture_output=True, text=True, timeout=3)
                if result.returncode == 0 and result.stdout.strip():
                    pid = int(result.stdout.strip().split('\n')[0])
                    process = psutil.Process(pid)
                    
                    # CPU ì‚¬ìš©ë¥ 
                    cpu_percent = process.cpu_percent()
                    self._add_metric(MetricRecord(
                        server_id=server_id,
                        server_type="a2a",
                        metric_type=MetricType.CPU_USAGE,
                        value=cpu_percent,
                        timestamp=timestamp,
                        metadata={"pid": pid, "port": port}
                    ))
                    
                    # ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ 
                    memory_info = process.memory_info()
                    memory_mb = memory_info.rss / 1024 / 1024
                    self._add_metric(MetricRecord(
                        server_id=server_id,
                        server_type="a2a",
                        metric_type=MetricType.MEMORY_USAGE,
                        value=memory_mb,
                        timestamp=timestamp,
                        metadata={"pid": pid, "port": port, "unit": "MB"}
                    ))
                    
                    # ì—°ê²° ìˆ˜
                    connections = len(process.connections())
                    self._add_metric(MetricRecord(
                        server_id=server_id,
                        server_type="a2a",
                        metric_type=MetricType.CONNECTION_COUNT,
                        value=connections,
                        timestamp=timestamp,
                        metadata={"pid": pid, "port": port}
                    ))
                    
            except Exception as e:
                logger.debug(f"A2A í”„ë¡œì„¸ìŠ¤ ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨ (í¬íŠ¸ {port}): {e}")
            
        except Exception as e:
            logger.error(f"A2A ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹¤íŒ¨ (í¬íŠ¸ {port}): {e}")
    
    async def _collect_mcp_metrics(self, server_id: str, server_def):
        """MCP ì„œë²„ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        timestamp = datetime.now()
        
        try:
            # ì„œë²„ ì„±ëŠ¥ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            performance = await self.server_manager.get_server_performance(server_id)
            
            if performance.get("status") == "running" and "metrics" in performance:
                metrics = performance["metrics"]
                
                # CPU ì‚¬ìš©ë¥ 
                if "cpu_percent" in metrics:
                    self._add_metric(MetricRecord(
                        server_id=server_id,
                        server_type="mcp",
                        metric_type=MetricType.CPU_USAGE,
                        value=metrics["cpu_percent"],
                        timestamp=timestamp,
                        metadata={"mcp_type": server_def.server_type.value}
                    ))
                
                # ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ 
                if "memory_mb" in metrics:
                    self._add_metric(MetricRecord(
                        server_id=server_id,
                        server_type="mcp",
                        metric_type=MetricType.MEMORY_USAGE,
                        value=metrics["memory_mb"],
                        timestamp=timestamp,
                        metadata={"mcp_type": server_def.server_type.value, "unit": "MB"}
                    ))
                
                # ì—°ê²° ìˆ˜
                if "connections" in metrics:
                    self._add_metric(MetricRecord(
                        server_id=server_id,
                        server_type="mcp",
                        metric_type=MetricType.CONNECTION_COUNT,
                        value=metrics["connections"],
                        timestamp=timestamp,
                        metadata={"mcp_type": server_def.server_type.value}
                    ))
                
                # ì—…íƒ€ì„
                if "uptime_seconds" in metrics:
                    uptime_hours = metrics["uptime_seconds"] / 3600
                    self._add_metric(MetricRecord(
                        server_id=server_id,
                        server_type="mcp",
                        metric_type=MetricType.UPTIME,
                        value=uptime_hours,
                        timestamp=timestamp,
                        metadata={"mcp_type": server_def.server_type.value, "unit": "hours"}
                    ))
            
            # MCP ì—°ê²° í…ŒìŠ¤íŠ¸ (ì‘ë‹µì‹œê°„)
            start_time = time.time()
            try:
                if server_def.server_type.value == "sse" and server_def.url:
                    response = requests.get(server_def.url, timeout=5)
                    response_time = (time.time() - start_time) * 1000
                    success = response.status_code == 200
                elif server_def.server_type.value == "stdio":
                    # STDIOëŠ” í”„ë¡œì„¸ìŠ¤ ìƒíƒœë¡œ íŒë‹¨
                    response_time = 50  # ê¸°ë³¸ê°’
                    success = performance.get("status") == "running"
                else:
                    response_time = 0
                    success = False
                
                # ì‘ë‹µì‹œê°„ ë©”íŠ¸ë¦­
                self._add_metric(MetricRecord(
                    server_id=server_id,
                    server_type="mcp",
                    metric_type=MetricType.RESPONSE_TIME,
                    value=response_time,
                    timestamp=timestamp,
                    metadata={"mcp_type": server_def.server_type.value, "success": success}
                ))
                
                # ì„±ê³µë¥  ë©”íŠ¸ë¦­
                success_rate = 100.0 if success else 0.0
                self._add_metric(MetricRecord(
                    server_id=server_id,
                    server_type="mcp",
                    metric_type=MetricType.SUCCESS_RATE,
                    value=success_rate,
                    timestamp=timestamp,
                    metadata={"mcp_type": server_def.server_type.value}
                ))
                
            except Exception as e:
                logger.debug(f"MCP ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ {server_id}: {e}")
            
        except Exception as e:
            logger.error(f"MCP ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹¤íŒ¨ {server_id}: {e}")
    
    def _add_metric(self, metric: MetricRecord):
        """ë©”íŠ¸ë¦­ ì¶”ê°€ (ìºì‹œ)"""
        self.metrics_cache.append(metric)
        
        # ìºì‹œ í¬ê¸° ì œí•œ (ë©”ëª¨ë¦¬ ë³´í˜¸)
        if len(self.metrics_cache) > 10000:
            self.metrics_cache = self.metrics_cache[-5000:]  # ìµœê·¼ 5000ê°œë§Œ ìœ ì§€
    
    async def _update_performance_summaries(self):
        """ì„±ëŠ¥ ìš”ì•½ ì—…ë°ì´íŠ¸"""
        try:
            # ì„œë²„ë³„ë¡œ ê·¸ë£¹í™”
            server_metrics = {}
            for metric in self.metrics_cache[-1000:]:  # ìµœê·¼ 1000ê°œ ë©”íŠ¸ë¦­ë§Œ ì‚¬ìš©
                if metric.server_id not in server_metrics:
                    server_metrics[metric.server_id] = []
                server_metrics[metric.server_id].append(metric)
            
            # ê° ì„œë²„ì˜ ì„±ëŠ¥ ìš”ì•½ ê³„ì‚°
            for server_id, metrics in server_metrics.items():
                summary = self._calculate_server_summary(server_id, metrics)
                self.performance_summaries[server_id] = summary
                
        except Exception as e:
            logger.error(f"ì„±ëŠ¥ ìš”ì•½ ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜: {e}")
    
    def _calculate_server_summary(self, server_id: str, metrics: List[MetricRecord]) -> ServerPerformanceSummary:
        """ì„œë²„ ì„±ëŠ¥ ìš”ì•½ ê³„ì‚°"""
        if not metrics:
            return ServerPerformanceSummary(
                server_id=server_id,
                server_type="unknown",
                last_update=datetime.now()
            )
        
        # ë©”íŠ¸ë¦­ íƒ€ì…ë³„ ë¶„ë¥˜
        response_times = [m.value for m in metrics if m.metric_type == MetricType.RESPONSE_TIME]
        cpu_usage = [m.value for m in metrics if m.metric_type == MetricType.CPU_USAGE]
        memory_usage = [m.value for m in metrics if m.metric_type == MetricType.MEMORY_USAGE]
        success_rates = [m.value for m in metrics if m.metric_type == MetricType.SUCCESS_RATE]
        connections = [m.value for m in metrics if m.metric_type == MetricType.CONNECTION_COUNT]
        
        # ì„œë²„ íƒ€ì… ê²°ì •
        server_type = metrics[0].server_type
        
        summary = ServerPerformanceSummary(
            server_id=server_id,
            server_type=server_type,
            last_update=datetime.now()
        )
        
        # ì‘ë‹µì‹œê°„ í†µê³„
        if response_times:
            summary.avg_response_time = statistics.mean(response_times)
            summary.max_response_time = max(response_times)
            summary.min_response_time = min(response_times)
        
        # CPU ì‚¬ìš©ë¥  í†µê³„
        if cpu_usage:
            summary.avg_cpu_usage = statistics.mean(cpu_usage)
            summary.max_cpu_usage = max(cpu_usage)
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  í†µê³„
        if memory_usage:
            summary.avg_memory_usage = statistics.mean(memory_usage)
            summary.max_memory_usage = max(memory_usage)
        
        # ì„±ê³µë¥ 
        if success_rates:
            summary.success_rate = statistics.mean(success_rates)
            summary.error_rate = 100.0 - summary.success_rate
        
        # ì—°ê²° ìˆ˜
        if connections:
            summary.active_connections = int(statistics.mean(connections))
        
        summary.total_requests = len([m for m in metrics if m.metric_type == MetricType.RESPONSE_TIME])
        
        return summary
    
    async def _check_alerts(self):
        """ì•Œë¦¼ í™•ì¸ ë° ìƒì„±"""
        try:
            new_alerts = []
            
            for server_id, summary in self.performance_summaries.items():
                # ì‘ë‹µì‹œê°„ ì•Œë¦¼
                if summary.avg_response_time > 0:
                    alert = self._check_threshold_alert(
                        server_id, MetricType.RESPONSE_TIME, summary.avg_response_time
                    )
                    if alert:
                        new_alerts.append(alert)
                
                # CPU ì‚¬ìš©ë¥  ì•Œë¦¼
                if summary.avg_cpu_usage > 0:
                    alert = self._check_threshold_alert(
                        server_id, MetricType.CPU_USAGE, summary.avg_cpu_usage
                    )
                    if alert:
                        new_alerts.append(alert)
                
                # ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ì•Œë¦¼ (MB -> % ë³€í™˜ ê°€ì •)
                if summary.avg_memory_usage > 0:
                    memory_percent = min(summary.avg_memory_usage / 10, 100)  # ê°„ë‹¨í•œ ë³€í™˜
                    alert = self._check_threshold_alert(
                        server_id, MetricType.MEMORY_USAGE, memory_percent
                    )
                    if alert:
                        new_alerts.append(alert)
                
                # ì—ëŸ¬ìœ¨ ì•Œë¦¼
                if summary.error_rate > 0:
                    alert = self._check_threshold_alert(
                        server_id, MetricType.ERROR_RATE, summary.error_rate
                    )
                    if alert:
                        new_alerts.append(alert)
            
            # ìƒˆ ì•Œë¦¼ ì¶”ê°€
            self.active_alerts.extend(new_alerts)
            
            # ì•Œë¦¼ ë¡œê·¸
            for alert in new_alerts:
                logger.warning(f"ğŸš¨ ì„±ëŠ¥ ì•Œë¦¼: {alert.message}")
                
        except Exception as e:
            logger.error(f"ì•Œë¦¼ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
    
    def _check_threshold_alert(self, server_id: str, metric_type: MetricType, value: float) -> Optional[PerformanceAlert]:
        """ì„ê³„ê°’ ì•Œë¦¼ í™•ì¸"""
        if metric_type not in self.thresholds:
            return None
        
        threshold = self.thresholds[metric_type]
        
        # ì„ê³„ê°’ í™•ì¸
        level = None
        threshold_value = 0
        
        if value >= threshold.critical_threshold:
            level = AlertLevel.CRITICAL
            threshold_value = threshold.critical_threshold
        elif value >= threshold.error_threshold:
            level = AlertLevel.ERROR
            threshold_value = threshold.error_threshold
        elif value >= threshold.warning_threshold:
            level = AlertLevel.WARNING
            threshold_value = threshold.warning_threshold
        
        if level:
            # ì¤‘ë³µ ì•Œë¦¼ ë°©ì§€ (ê°™ì€ ì„œë²„, ê°™ì€ ë©”íŠ¸ë¦­ì˜ í™œì„± ì•Œë¦¼ í™•ì¸)
            existing_alert = next(
                (a for a in self.active_alerts 
                 if a.server_id == server_id and a.metric_type == metric_type and not a.resolved),
                None
            )
            
            if not existing_alert:
                return PerformanceAlert(
                    server_id=server_id,
                    metric_type=metric_type,
                    level=level,
                    current_value=value,
                    threshold=threshold_value,
                    message=f"{server_id} {metric_type.value} {level.value}: {value:.2f}{threshold.unit} (ì„ê³„ê°’: {threshold_value}{threshold.unit})",
                    timestamp=datetime.now()
                )
        
        return None
    
    async def _save_metrics_to_db(self):
        """ë©”íŠ¸ë¦­ì„ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
        if not self.metrics_cache:
            return
        
        try:
            def save_metrics():
                with sqlite3.connect(self.db_path) as conn:
                    cursor = conn.cursor()
                    
                    # ë©”íŠ¸ë¦­ ì €ì¥
                    for metric in self.metrics_cache:
                        cursor.execute("""
                            INSERT INTO metrics (server_id, server_type, metric_type, value, timestamp, metadata)
                            VALUES (?, ?, ?, ?, ?, ?)
                        """, (
                            metric.server_id,
                            metric.server_type,
                            metric.metric_type.value,
                            metric.value,
                            metric.timestamp,
                            json.dumps(metric.metadata)
                        ))
                    
                    # ì•Œë¦¼ ì €ì¥
                    for alert in self.active_alerts:
                        if not hasattr(alert, '_saved'):
                            cursor.execute("""
                                INSERT INTO alerts (server_id, metric_type, level, current_value, threshold, message, timestamp, resolved)
                                VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                            """, (
                                alert.server_id,
                                alert.metric_type.value,
                                alert.level.value,
                                alert.current_value,
                                alert.threshold,
                                alert.message,
                                alert.timestamp,
                                alert.resolved
                            ))
                            alert._saved = True
                    
                    conn.commit()
            
            # ìŠ¤ë ˆë“œ í’€ì—ì„œ ì‹¤í–‰
            await asyncio.get_event_loop().run_in_executor(self.executor, save_metrics)
            
            # ìºì‹œ í´ë¦¬ì–´
            self.metrics_cache.clear()
            
        except Exception as e:
            logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
    
    async def _cleanup_old_data(self):
        """ì˜¤ë˜ëœ ë°ì´í„° ì •ë¦¬"""
        try:
            cutoff_date = datetime.now() - timedelta(days=self.history_retention_days)
            
            def cleanup():
                with sqlite3.connect(self.db_path) as conn:
                    cursor = conn.cursor()
                    
                    # ì˜¤ë˜ëœ ë©”íŠ¸ë¦­ ì‚­ì œ
                    cursor.execute("DELETE FROM metrics WHERE timestamp < ?", (cutoff_date,))
                    
                    # í•´ê²°ëœ ì˜¤ë˜ëœ ì•Œë¦¼ ì‚­ì œ
                    old_alert_date = datetime.now() - timedelta(days=7)
                    cursor.execute("DELETE FROM alerts WHERE timestamp < ? AND resolved = TRUE", (old_alert_date,))
                    
                    conn.commit()
            
            await asyncio.get_event_loop().run_in_executor(self.executor, cleanup)
            
        except Exception as e:
            logger.error(f"ë°ì´í„° ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
    
    async def stop_collection(self):
        """ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì¤‘ì§€"""
        self.is_collecting = False
        
        # ë‚¨ì€ ë©”íŠ¸ë¦­ ì €ì¥
        if self.metrics_cache:
            await self._save_metrics_to_db()
        
        # ìŠ¤ë ˆë“œ í’€ ì¢…ë£Œ
        self.executor.shutdown(wait=True)
        
        logger.info("ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì¤‘ì§€ ì™„ë£Œ")
    
    def get_server_summary(self, server_id: str) -> Optional[ServerPerformanceSummary]:
        """ì„œë²„ ì„±ëŠ¥ ìš”ì•½ ì¡°íšŒ"""
        return self.performance_summaries.get(server_id)
    
    def get_all_summaries(self) -> Dict[str, ServerPerformanceSummary]:
        """ëª¨ë“  ì„œë²„ ì„±ëŠ¥ ìš”ì•½ ì¡°íšŒ"""
        return self.performance_summaries.copy()
    
    def get_active_alerts(self) -> List[PerformanceAlert]:
        """í™œì„± ì•Œë¦¼ ì¡°íšŒ"""
        return [alert for alert in self.active_alerts if not alert.resolved]
    
    def resolve_alert(self, alert_id: int):
        """ì•Œë¦¼ í•´ê²° ì²˜ë¦¬"""
        if alert_id < len(self.active_alerts):
            self.active_alerts[alert_id].resolved = True
            logger.info(f"ì•Œë¦¼ í•´ê²°ë¨: {self.active_alerts[alert_id].message}")

# ì „ì—­ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸° ì¸ìŠ¤í„´ìŠ¤
_metrics_collector = None

def get_metrics_collector() -> PerformanceMetricsCollector:
    """ì „ì—­ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸° ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _metrics_collector
    if _metrics_collector is None:
        _metrics_collector = PerformanceMetricsCollector()
    return _metrics_collector 