"""
ë©”íƒ€ ëŸ¬ë‹ ì‹œìŠ¤í…œ (Meta Learning System)
Phase 3.3: ë¶„ì„ ê²½í—˜ í•™ìŠµ ë° ì§€ì†ì  ê°œì„ 

í•µì‹¬ ê¸°ëŠ¥:
- ë¶„ì„ íŒ¨í„´ í•™ìŠµ ë° ì¶•ì 
- ì„±ê³µ/ì‹¤íŒ¨ ì‚¬ë¡€ ë¶„ë¥˜ ë° í•™ìŠµ
- ìë™ ì „ëµ ê°œì„  ë° ìµœì í™”
- ì‚¬ìš©ì í”¼ë“œë°± í†µí•© í•™ìŠµ
- ì ì‘í˜• ë¶„ì„ íŒŒë¼ë¯¸í„° ì¡°ì •
- ë„ë©”ì¸ë³„ ì§€ì‹ ì¶•ì 
"""

import asyncio
import json
import logging
import pickle
import statistics
import numpy as np
import pandas as pd
from dataclasses import dataclass, field, asdict
from typing import Dict, List, Any, Optional, Tuple, Set
from datetime import datetime, timedelta
from collections import defaultdict, deque
from enum import Enum
from pathlib import Path
import sqlite3
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
from sklearn.metrics.pairwise import cosine_similarity

logger = logging.getLogger(__name__)

class AnalysisOutcome(Enum):
    """ë¶„ì„ ê²°ê³¼ í‰ê°€"""
    EXCELLENT = "excellent"     # ë§¤ìš° ì„±ê³µì 
    GOOD = "good"              # ì„±ê³µì 
    ACCEPTABLE = "acceptable"   # ë³´í†µ
    POOR = "poor"              # ë¯¸í¡
    FAILED = "failed"          # ì‹¤íŒ¨

class LearningType(Enum):
    """í•™ìŠµ ìœ í˜•"""
    PATTERN_RECOGNITION = "pattern_recognition"
    STRATEGY_OPTIMIZATION = "strategy_optimization"
    PARAMETER_TUNING = "parameter_tuning"
    FEEDBACK_INTEGRATION = "feedback_integration"
    DOMAIN_ADAPTATION = "domain_adaptation"

@dataclass
class AnalysisExperience:
    """ë¶„ì„ ê²½í—˜ ë°ì´í„°"""
    id: str
    timestamp: datetime
    data_profile: Dict[str, Any]
    strategy_used: Dict[str, Any]
    outcome: AnalysisOutcome
    user_feedback: Dict[str, Any]
    performance_metrics: Dict[str, float]
    insights_quality: float
    execution_time: float
    context: str
    domain_tags: List[str] = field(default_factory=list)
    lessons_learned: List[str] = field(default_factory=list)

@dataclass
class LearningRule:
    """í•™ìŠµ ê·œì¹™"""
    id: str
    rule_type: LearningType
    condition: Dict[str, Any]
    action: Dict[str, Any]
    confidence: float
    success_count: int
    failure_count: int
    last_updated: datetime
    domain_applicability: List[str] = field(default_factory=list)

@dataclass
class MetaKnowledge:
    """ë©”íƒ€ ì§€ì‹"""
    data_patterns: Dict[str, Any]
    successful_strategies: Dict[str, List[Dict[str, Any]]]
    common_pitfalls: List[Dict[str, Any]]
    optimal_parameters: Dict[str, Dict[str, Any]]
    domain_insights: Dict[str, Dict[str, Any]]
    adaptation_rules: List[LearningRule]

class ExperienceDatabase:
    """ê²½í—˜ ë°ì´í„°ë² ì´ìŠ¤"""
    
    def __init__(self, db_path: str = "core/meta_learning/experience.db"):
        self.db_path = db_path
        Path(db_path).parent.mkdir(parents=True, exist_ok=True)
        self._initialize_database()
    
    def _initialize_database(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            
            # ê²½í—˜ í…Œì´ë¸”
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS experiences (
                    id TEXT PRIMARY KEY,
                    timestamp DATETIME,
                    data_profile TEXT,
                    strategy_used TEXT,
                    outcome TEXT,
                    user_feedback TEXT,
                    performance_metrics TEXT,
                    insights_quality REAL,
                    execution_time REAL,
                    context TEXT,
                    domain_tags TEXT,
                    lessons_learned TEXT
                )
            """)
            
            # í•™ìŠµ ê·œì¹™ í…Œì´ë¸”
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS learning_rules (
                    id TEXT PRIMARY KEY,
                    rule_type TEXT,
                    condition TEXT,
                    action TEXT,
                    confidence REAL,
                    success_count INTEGER,
                    failure_count INTEGER,
                    last_updated DATETIME,
                    domain_applicability TEXT
                )
            """)
            
            # ì„±ëŠ¥ ë©”íŠ¸ë¦­ í…Œì´ë¸”
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS performance_tracking (
                    timestamp DATETIME,
                    metric_name TEXT,
                    metric_value REAL,
                    context TEXT,
                    PRIMARY KEY (timestamp, metric_name, context)
                )
            """)
            
            conn.commit()
    
    def store_experience(self, experience: AnalysisExperience):
        """ê²½í—˜ ì €ì¥"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            
            cursor.execute("""
                INSERT OR REPLACE INTO experiences 
                (id, timestamp, data_profile, strategy_used, outcome, user_feedback,
                 performance_metrics, insights_quality, execution_time, context,
                 domain_tags, lessons_learned)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                experience.id,
                experience.timestamp,
                json.dumps(experience.data_profile),
                json.dumps(experience.strategy_used),
                experience.outcome.value,
                json.dumps(experience.user_feedback),
                json.dumps(experience.performance_metrics),
                experience.insights_quality,
                experience.execution_time,
                experience.context,
                json.dumps(experience.domain_tags),
                json.dumps(experience.lessons_learned)
            ))
            
            conn.commit()
    
    def get_experiences(self, 
                       outcome_filter: Optional[List[AnalysisOutcome]] = None,
                       domain_filter: Optional[List[str]] = None,
                       limit: int = 1000) -> List[AnalysisExperience]:
        """ê²½í—˜ ì¡°íšŒ"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            
            query = "SELECT * FROM experiences"
            params = []
            conditions = []
            
            if outcome_filter:
                outcome_values = [outcome.value for outcome in outcome_filter]
                conditions.append(f"outcome IN ({','.join(['?'] * len(outcome_values))})")
                params.extend(outcome_values)
            
            if conditions:
                query += " WHERE " + " AND ".join(conditions)
            
            query += " ORDER BY timestamp DESC LIMIT ?"
            params.append(limit)
            
            cursor.execute(query, params)
            rows = cursor.fetchall()
            
            experiences = []
            for row in rows:
                experience = AnalysisExperience(
                    id=row[0],
                    timestamp=datetime.fromisoformat(row[1]),
                    data_profile=json.loads(row[2]),
                    strategy_used=json.loads(row[3]),
                    outcome=AnalysisOutcome(row[4]),
                    user_feedback=json.loads(row[5]),
                    performance_metrics=json.loads(row[6]),
                    insights_quality=row[7],
                    execution_time=row[8],
                    context=row[9],
                    domain_tags=json.loads(row[10]),
                    lessons_learned=json.loads(row[11])
                )
                experiences.append(experience)
            
            return experiences
    
    def store_learning_rule(self, rule: LearningRule):
        """í•™ìŠµ ê·œì¹™ ì €ì¥"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            
            cursor.execute("""
                INSERT OR REPLACE INTO learning_rules 
                (id, rule_type, condition, action, confidence, success_count,
                 failure_count, last_updated, domain_applicability)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                rule.id,
                rule.rule_type.value,
                json.dumps(rule.condition),
                json.dumps(rule.action),
                rule.confidence,
                rule.success_count,
                rule.failure_count,
                rule.last_updated,
                json.dumps(rule.domain_applicability)
            ))
            
            conn.commit()
    
    def get_learning_rules(self, rule_type: Optional[LearningType] = None) -> List[LearningRule]:
        """í•™ìŠµ ê·œì¹™ ì¡°íšŒ"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            
            if rule_type:
                cursor.execute("SELECT * FROM learning_rules WHERE rule_type = ?", (rule_type.value,))
            else:
                cursor.execute("SELECT * FROM learning_rules")
            
            rows = cursor.fetchall()
            
            rules = []
            for row in rows:
                rule = LearningRule(
                    id=row[0],
                    rule_type=LearningType(row[1]),
                    condition=json.loads(row[2]),
                    action=json.loads(row[3]),
                    confidence=row[4],
                    success_count=row[5],
                    failure_count=row[6],
                    last_updated=datetime.fromisoformat(row[7]),
                    domain_applicability=json.loads(row[8])
                )
                rules.append(rule)
            
            return rules

class PatternLearner:
    """íŒ¨í„´ í•™ìŠµê¸°"""
    
    def __init__(self):
        self.vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')
        self.clusterer = KMeans(n_clusters=10, random_state=42)
        self.pattern_cache = {}
        
    def learn_data_patterns(self, experiences: List[AnalysisExperience]) -> Dict[str, Any]:
        """ë°ì´í„° íŒ¨í„´ í•™ìŠµ"""
        logger.info(f"ğŸ“Š ë°ì´í„° íŒ¨í„´ í•™ìŠµ ì‹œì‘: {len(experiences)}ê°œ ê²½í—˜")
        
        patterns = {
            "size_patterns": self._learn_size_patterns(experiences),
            "type_patterns": self._learn_type_patterns(experiences),
            "quality_patterns": self._learn_quality_patterns(experiences),
            "complexity_patterns": self._learn_complexity_patterns(experiences)
        }
        
        return patterns
    
    def _learn_size_patterns(self, experiences: List[AnalysisExperience]) -> Dict[str, Any]:
        """ë°ì´í„° í¬ê¸° íŒ¨í„´ í•™ìŠµ"""
        size_outcomes = defaultdict(list)
        
        for exp in experiences:
            data_profile = exp.data_profile
            if 'shape' in data_profile:
                rows, cols = data_profile['shape']
                size_category = self._categorize_size(rows, cols)
                size_outcomes[size_category].append(exp.outcome.value)
        
        # í¬ê¸°ë³„ ì„±ê³µ íŒ¨í„´ ë¶„ì„
        size_success_rates = {}
        for size_cat, outcomes in size_outcomes.items():
            success_count = sum(1 for outcome in outcomes if outcome in ['excellent', 'good'])
            success_rate = success_count / len(outcomes) if outcomes else 0
            size_success_rates[size_cat] = success_rate
        
        return {
            "size_success_rates": size_success_rates,
            "optimal_sizes": [cat for cat, rate in size_success_rates.items() if rate > 0.7],
            "challenging_sizes": [cat for cat, rate in size_success_rates.items() if rate < 0.3]
        }
    
    def _categorize_size(self, rows: int, cols: int) -> str:
        """ë°ì´í„° í¬ê¸° ë¶„ë¥˜"""
        if rows < 1000 and cols < 10:
            return "small"
        elif rows < 10000 and cols < 50:
            return "medium"
        elif rows < 100000 and cols < 100:
            return "large"
        else:
            return "very_large"
    
    def _learn_type_patterns(self, experiences: List[AnalysisExperience]) -> Dict[str, Any]:
        """ë°ì´í„° íƒ€ì… íŒ¨í„´ í•™ìŠµ"""
        type_outcomes = defaultdict(list)
        
        for exp in experiences:
            data_profile = exp.data_profile
            if 'data_characteristics' in data_profile:
                characteristics = data_profile['data_characteristics']
                char_signature = "_".join(sorted(characteristics))
                type_outcomes[char_signature].append(exp.outcome.value)
        
        # íƒ€ì…ë³„ ì„±ê³µ íŒ¨í„´
        type_success_rates = {}
        for char_sig, outcomes in type_outcomes.items():
            success_count = sum(1 for outcome in outcomes if outcome in ['excellent', 'good'])
            success_rate = success_count / len(outcomes) if outcomes else 0
            type_success_rates[char_sig] = success_rate
        
        return {
            "type_success_rates": type_success_rates,
            "preferred_types": [t for t, rate in type_success_rates.items() if rate > 0.6],
            "difficult_types": [t for t, rate in type_success_rates.items() if rate < 0.4]
        }
    
    def _learn_quality_patterns(self, experiences: List[AnalysisExperience]) -> Dict[str, Any]:
        """ë°ì´í„° í’ˆì§ˆ íŒ¨í„´ í•™ìŠµ"""
        quality_bins = [(0.0, 0.3), (0.3, 0.6), (0.6, 0.8), (0.8, 1.0)]
        quality_outcomes = {f"{low}-{high}": [] for low, high in quality_bins}
        
        for exp in experiences:
            data_profile = exp.data_profile
            quality_score = data_profile.get('quality_score', 0.5)
            
            for low, high in quality_bins:
                if low <= quality_score < high:
                    quality_outcomes[f"{low}-{high}"].append(exp.outcome.value)
                    break
        
        # í’ˆì§ˆë³„ ì„±ê³µ íŒ¨í„´
        quality_success_rates = {}
        for quality_range, outcomes in quality_outcomes.items():
            if outcomes:
                success_count = sum(1 for outcome in outcomes if outcome in ['excellent', 'good'])
                success_rate = success_count / len(outcomes)
                quality_success_rates[quality_range] = success_rate
        
        return {
            "quality_success_rates": quality_success_rates,
            "quality_threshold": 0.6  # ê²½í—˜ì  ì„ê³„ê°’
        }
    
    def _learn_complexity_patterns(self, experiences: List[AnalysisExperience]) -> Dict[str, Any]:
        """ë³µì¡ë„ íŒ¨í„´ í•™ìŠµ"""
        complexity_outcomes = defaultdict(list)
        
        for exp in experiences:
            data_profile = exp.data_profile
            complexity = data_profile.get('complexity_level', 'medium')
            complexity_outcomes[complexity].append(exp.outcome.value)
        
        complexity_success_rates = {}
        for complexity, outcomes in complexity_outcomes.items():
            success_count = sum(1 for outcome in outcomes if outcome in ['excellent', 'good'])
            success_rate = success_count / len(outcomes) if outcomes else 0
            complexity_success_rates[complexity] = success_rate
        
        return {
            "complexity_success_rates": complexity_success_rates,
            "manageable_complexity": [c for c, rate in complexity_success_rates.items() if rate > 0.5]
        }

class StrategyOptimizer:
    """ì „ëµ ìµœì í™”ê¸°"""
    
    def __init__(self):
        self.strategy_performance = defaultdict(list)
        self.parameter_optimization = {}
        
    def optimize_strategies(self, experiences: List[AnalysisExperience]) -> Dict[str, Any]:
        """ì „ëµ ìµœì í™”"""
        logger.info(f"ğŸ¯ ì „ëµ ìµœì í™” ì‹œì‘: {len(experiences)}ê°œ ê²½í—˜ ë¶„ì„")
        
        optimization_results = {
            "strategy_rankings": self._rank_strategies(experiences),
            "context_strategies": self._optimize_context_strategies(experiences),
            "parameter_recommendations": self._optimize_parameters(experiences),
            "hybrid_strategies": self._discover_hybrid_strategies(experiences)
        }
        
        return optimization_results
    
    def _rank_strategies(self, experiences: List[AnalysisExperience]) -> Dict[str, Any]:
        """ì „ëµ ìˆœìœ„ ë§¤ê¸°ê¸°"""
        strategy_performance = defaultdict(list)
        
        for exp in experiences:
            strategy = exp.strategy_used.get('context', 'unknown')
            
            # ì„±ëŠ¥ ì ìˆ˜ ê³„ì‚° (ê²°ê³¼ + í’ˆì§ˆ + ì‹¤í–‰ì‹œê°„)
            outcome_score = self._outcome_to_score(exp.outcome)
            quality_score = exp.insights_quality
            time_penalty = max(0, 1 - (exp.execution_time / 300))  # 5ë¶„ ê¸°ì¤€
            
            overall_score = (outcome_score * 0.5 + quality_score * 0.3 + time_penalty * 0.2)
            strategy_performance[strategy].append(overall_score)
        
        # ì „ëµë³„ í‰ê·  ì„±ëŠ¥
        strategy_rankings = {}
        for strategy, scores in strategy_performance.items():
            avg_score = statistics.mean(scores)
            confidence = 1 / (1 + statistics.stdev(scores)) if len(scores) > 1 else 0.5
            strategy_rankings[strategy] = {
                "avg_score": avg_score,
                "confidence": confidence,
                "sample_size": len(scores)
            }
        
        # ìˆœìœ„ë³„ ì •ë ¬
        sorted_strategies = sorted(strategy_rankings.items(), 
                                 key=lambda x: x[1]['avg_score'], reverse=True)
        
        return {
            "rankings": dict(sorted_strategies),
            "top_strategies": [s[0] for s in sorted_strategies[:3]],
            "strategies_to_avoid": [s[0] for s in sorted_strategies[-2:] if s[1]['avg_score'] < 0.3]
        }
    
    def _outcome_to_score(self, outcome: AnalysisOutcome) -> float:
        """ê²°ê³¼ë¥¼ ì ìˆ˜ë¡œ ë³€í™˜"""
        score_mapping = {
            AnalysisOutcome.EXCELLENT: 1.0,
            AnalysisOutcome.GOOD: 0.8,
            AnalysisOutcome.ACCEPTABLE: 0.6,
            AnalysisOutcome.POOR: 0.3,
            AnalysisOutcome.FAILED: 0.0
        }
        return score_mapping.get(outcome, 0.5)
    
    def _optimize_context_strategies(self, experiences: List[AnalysisExperience]) -> Dict[str, Any]:
        """ì»¨í…ìŠ¤íŠ¸ë³„ ì „ëµ ìµœì í™”"""
        context_strategies = defaultdict(lambda: defaultdict(list))
        
        # ì»¨í…ìŠ¤íŠ¸ë³„ ì „ëµ ì„±ëŠ¥ ë¶„ì„
        for exp in experiences:
            context = exp.context
            strategy = exp.strategy_used.get('context', 'unknown')
            score = self._outcome_to_score(exp.outcome)
            
            context_strategies[context][strategy].append(score)
        
        # ì»¨í…ìŠ¤íŠ¸ë³„ ìµœì  ì „ëµ ì„ ì •
        optimal_strategies = {}
        for context, strategies in context_strategies.items():
            strategy_scores = {}
            for strategy, scores in strategies.items():
                strategy_scores[strategy] = statistics.mean(scores)
            
            if strategy_scores:
                best_strategy = max(strategy_scores.items(), key=lambda x: x[1])
                optimal_strategies[context] = {
                    "strategy": best_strategy[0],
                    "score": best_strategy[1],
                    "alternatives": sorted(strategy_scores.items(), 
                                        key=lambda x: x[1], reverse=True)[1:3]
                }
        
        return optimal_strategies
    
    def _optimize_parameters(self, experiences: List[AnalysisExperience]) -> Dict[str, Any]:
        """íŒŒë¼ë¯¸í„° ìµœì í™”"""
        parameter_performance = defaultdict(lambda: defaultdict(list))
        
        for exp in experiences:
            strategy = exp.strategy_used
            score = self._outcome_to_score(exp.outcome)
            
            # ì „ëµì˜ íŒŒë¼ë¯¸í„° ë¶„ì„
            if 'adaptive_parameters' in strategy:
                params = strategy['adaptive_parameters']
                for param_name, param_value in params.items():
                    parameter_performance[param_name][str(param_value)].append(score)
        
        # íŒŒë¼ë¯¸í„°ë³„ ìµœì ê°’ ì°¾ê¸°
        optimal_parameters = {}
        for param_name, value_scores in parameter_performance.items():
            if value_scores:
                avg_scores = {value: statistics.mean(scores) 
                            for value, scores in value_scores.items()}
                best_value = max(avg_scores.items(), key=lambda x: x[1])
                optimal_parameters[param_name] = {
                    "optimal_value": best_value[0],
                    "score": best_value[1],
                    "alternatives": sorted(avg_scores.items(), 
                                        key=lambda x: x[1], reverse=True)[1:3]
                }
        
        return optimal_parameters
    
    def _discover_hybrid_strategies(self, experiences: List[AnalysisExperience]) -> Dict[str, Any]:
        """í•˜ì´ë¸Œë¦¬ë“œ ì „ëµ ë°œê²¬"""
        # ì„±ê³µì ì¸ ê²½í—˜ë“¤ì˜ ê³µí†µ íŒ¨í„´ ì°¾ê¸°
        successful_experiences = [exp for exp in experiences 
                                if exp.outcome in [AnalysisOutcome.EXCELLENT, AnalysisOutcome.GOOD]]
        
        if len(successful_experiences) < 5:
            return {"hybrid_strategies": [], "confidence": 0.0}
        
        # ì„±ê³µì ì¸ ì „ëµì˜ ì¡°í•© íŒ¨í„´ ë¶„ì„
        strategy_combinations = defaultdict(int)
        
        for exp in successful_experiences:
            strategy = exp.strategy_used
            techniques = strategy.get('techniques', [])
            steps = strategy.get('priority_steps', [])
            
            # ê¸°ë²•ê³¼ ë‹¨ê³„ì˜ ì¡°í•© íŒ¨í„´
            combo_key = "_".join(sorted(techniques[:3])) + "|" + "_".join(sorted(steps[:3]))
            strategy_combinations[combo_key] += 1
        
        # ë¹ˆë„ìˆ˜ ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ ì „ëµ ì œì•ˆ
        common_combinations = sorted(strategy_combinations.items(), 
                                   key=lambda x: x[1], reverse=True)[:3]
        
        hybrid_strategies = []
        for combo, frequency in common_combinations:
            techniques_part, steps_part = combo.split("|")
            hybrid_strategies.append({
                "techniques": techniques_part.split("_"),
                "steps": steps_part.split("_"),
                "frequency": frequency,
                "confidence": frequency / len(successful_experiences)
            })
        
        return {
            "hybrid_strategies": hybrid_strategies,
            "discovery_confidence": 0.7 if hybrid_strategies else 0.0
        }

class FeedbackIntegrator:
    """í”¼ë“œë°± í†µí•©ê¸°"""
    
    def __init__(self):
        self.feedback_weights = {
            "user_satisfaction": 0.4,
            "insight_relevance": 0.3,
            "actionability": 0.2,
            "novelty": 0.1
        }
        
    def integrate_feedback(self, experiences: List[AnalysisExperience]) -> Dict[str, Any]:
        """í”¼ë“œë°± í†µí•© í•™ìŠµ"""
        logger.info(f"ğŸ“ í”¼ë“œë°± í†µí•© í•™ìŠµ: {len(experiences)}ê°œ ê²½í—˜")
        
        feedback_analysis = {
            "satisfaction_patterns": self._analyze_satisfaction_patterns(experiences),
            "improvement_suggestions": self._extract_improvement_suggestions(experiences),
            "quality_correlations": self._analyze_quality_correlations(experiences),
            "user_preferences": self._learn_user_preferences(experiences)
        }
        
        return feedback_analysis
    
    def _analyze_satisfaction_patterns(self, experiences: List[AnalysisExperience]) -> Dict[str, Any]:
        """ë§Œì¡±ë„ íŒ¨í„´ ë¶„ì„"""
        satisfaction_data = []
        
        for exp in experiences:
            feedback = exp.user_feedback
            if 'satisfaction_score' in feedback:
                satisfaction_data.append({
                    'satisfaction': feedback['satisfaction_score'],
                    'strategy': exp.strategy_used.get('context', 'unknown'),
                    'quality': exp.insights_quality,
                    'time': exp.execution_time
                })
        
        if not satisfaction_data:
            return {"patterns": [], "insights": ["í”¼ë“œë°± ë°ì´í„° ë¶€ì¡±"]}
        
        # ë§Œì¡±ë„ ì˜í–¥ ìš”ì¸ ë¶„ì„
        high_satisfaction = [d for d in satisfaction_data if d['satisfaction'] > 0.8]
        low_satisfaction = [d for d in satisfaction_data if d['satisfaction'] < 0.4]
        
        patterns = []
        
        if high_satisfaction:
            common_strategies = set(d['strategy'] for d in high_satisfaction)
            avg_quality = statistics.mean(d['quality'] for d in high_satisfaction)
            avg_time = statistics.mean(d['time'] for d in high_satisfaction)
            
            patterns.append({
                "type": "high_satisfaction",
                "strategies": list(common_strategies),
                "avg_quality": avg_quality,
                "avg_time": avg_time,
                "count": len(high_satisfaction)
            })
        
        if low_satisfaction:
            problem_strategies = set(d['strategy'] for d in low_satisfaction)
            patterns.append({
                "type": "low_satisfaction",
                "strategies": list(problem_strategies),
                "count": len(low_satisfaction)
            })
        
        return {
            "patterns": patterns,
            "insights": self._generate_satisfaction_insights(patterns)
        }
    
    def _generate_satisfaction_insights(self, patterns: List[Dict[str, Any]]) -> List[str]:
        """ë§Œì¡±ë„ ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        insights = []
        
        for pattern in patterns:
            if pattern["type"] == "high_satisfaction":
                insights.append(f"ê³ ë§Œì¡± ì „ëµ: {', '.join(pattern['strategies'][:3])}")
                insights.append(f"ê³ ë§Œì¡± í’ˆì§ˆ í‰ê· : {pattern['avg_quality']:.2f}")
            elif pattern["type"] == "low_satisfaction":
                insights.append(f"ê°œì„  í•„ìš” ì „ëµ: {', '.join(pattern['strategies'][:3])}")
        
        return insights
    
    def _extract_improvement_suggestions(self, experiences: List[AnalysisExperience]) -> List[str]:
        """ê°œì„  ì œì•ˆ ì¶”ì¶œ"""
        suggestions = []
        
        for exp in experiences:
            feedback = exp.user_feedback
            if 'suggestions' in feedback and feedback['suggestions']:
                suggestions.extend(feedback['suggestions'])
        
        # ë¹ˆë„ìˆ˜ ê¸°ë°˜ ì¤‘ìš” ì œì•ˆ ì¶”ì¶œ
        suggestion_counts = defaultdict(int)
        for suggestion in suggestions:
            suggestion_counts[suggestion] += 1
        
        top_suggestions = sorted(suggestion_counts.items(), 
                               key=lambda x: x[1], reverse=True)[:5]
        
        return [suggestion for suggestion, count in top_suggestions]
    
    def _analyze_quality_correlations(self, experiences: List[AnalysisExperience]) -> Dict[str, Any]:
        """í’ˆì§ˆ ìƒê´€ê´€ê³„ ë¶„ì„"""
        correlations = {}
        
        quality_scores = []
        satisfaction_scores = []
        execution_times = []
        
        for exp in experiences:
            if 'satisfaction_score' in exp.user_feedback:
                quality_scores.append(exp.insights_quality)
                satisfaction_scores.append(exp.user_feedback['satisfaction_score'])
                execution_times.append(exp.execution_time)
        
        if len(quality_scores) > 3:
            # ê°„ë‹¨í•œ ìƒê´€ê´€ê³„ ê³„ì‚°
            quality_satisfaction_corr = np.corrcoef(quality_scores, satisfaction_scores)[0, 1]
            quality_time_corr = np.corrcoef(quality_scores, execution_times)[0, 1]
            
            correlations = {
                "quality_satisfaction": quality_satisfaction_corr,
                "quality_time": quality_time_corr,
                "insights": [
                    f"í’ˆì§ˆ-ë§Œì¡±ë„ ìƒê´€ê´€ê³„: {quality_satisfaction_corr:.3f}",
                    f"í’ˆì§ˆ-ì‹¤í–‰ì‹œê°„ ìƒê´€ê´€ê³„: {quality_time_corr:.3f}"
                ]
            }
        
        return correlations
    
    def _learn_user_preferences(self, experiences: List[AnalysisExperience]) -> Dict[str, Any]:
        """ì‚¬ìš©ì ì„ í˜¸ë„ í•™ìŠµ"""
        preferences = {
            "preferred_analysis_depth": "medium",
            "preferred_visualization_types": [],
            "preferred_insight_format": "detailed",
            "time_tolerance": 180  # 3ë¶„ ê¸°ë³¸ê°’
        }
        
        # í”¼ë“œë°±ì—ì„œ ì„ í˜¸ë„ íŒ¨í„´ ì¶”ì¶œ
        depth_preferences = []
        time_tolerances = []
        
        for exp in experiences:
            feedback = exp.user_feedback
            
            if 'preferred_depth' in feedback:
                depth_preferences.append(feedback['preferred_depth'])
                
            if 'time_acceptable' in feedback and feedback['time_acceptable']:
                time_tolerances.append(exp.execution_time)
        
        if depth_preferences:
            preferences["preferred_analysis_depth"] = max(set(depth_preferences), 
                                                        key=depth_preferences.count)
        
        if time_tolerances:
            preferences["time_tolerance"] = statistics.median(time_tolerances)
        
        return preferences

class MetaLearningSystem:
    """ë©”íƒ€ ëŸ¬ë‹ ì‹œìŠ¤í…œ (í†µí•©)"""
    
    def __init__(self):
        self.db = ExperienceDatabase()
        self.pattern_learner = PatternLearner()
        self.strategy_optimizer = StrategyOptimizer()
        self.feedback_integrator = FeedbackIntegrator()
        
        # ë©”íƒ€ ì§€ì‹ ì €ì¥ì†Œ
        self.meta_knowledge = MetaKnowledge(
            data_patterns={},
            successful_strategies={},
            common_pitfalls=[],
            optimal_parameters={},
            domain_insights={},
            adaptation_rules=[]
        )
        
        # í•™ìŠµ ì„¤ì •
        self.learning_interval = timedelta(hours=24)  # 24ì‹œê°„ë§ˆë‹¤ í•™ìŠµ
        self.min_experiences_for_learning = 10
        self.confidence_threshold = 0.7
        
        # ê²°ê³¼ ì €ì¥ ê²½ë¡œ
        self.knowledge_path = Path("core/meta_learning/meta_knowledge.pkl")
        self.knowledge_path.parent.mkdir(parents=True, exist_ok=True)
        
        # ê¸°ì¡´ ì§€ì‹ ë¡œë“œ
        self._load_meta_knowledge()
    
    async def record_analysis_experience(self, 
                                       data_profile: Dict[str, Any],
                                       strategy_used: Dict[str, Any],
                                       outcome: AnalysisOutcome,
                                       user_feedback: Dict[str, Any],
                                       performance_metrics: Dict[str, float],
                                       insights_quality: float,
                                       execution_time: float,
                                       context: str = "") -> str:
        """ë¶„ì„ ê²½í—˜ ê¸°ë¡"""
        
        experience_id = f"exp_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{hash(str(data_profile))}"
        
        experience = AnalysisExperience(
            id=experience_id,
            timestamp=datetime.now(),
            data_profile=data_profile,
            strategy_used=strategy_used,
            outcome=outcome,
            user_feedback=user_feedback,
            performance_metrics=performance_metrics,
            insights_quality=insights_quality,
            execution_time=execution_time,
            context=context,
            domain_tags=self._extract_domain_tags(data_profile, context),
            lessons_learned=self._extract_lessons_learned(outcome, user_feedback)
        )
        
        # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
        self.db.store_experience(experience)
        
        logger.info(f"ğŸ“ ë¶„ì„ ê²½í—˜ ê¸°ë¡: {experience_id} (ê²°ê³¼: {outcome.value})")
        
        # ì¦‰ì‹œ í•™ìŠµ íŠ¸ë¦¬ê±° (ë¹„ë™ê¸°)
        asyncio.create_task(self._trigger_learning_if_needed())
        
        return experience_id
    
    async def _trigger_learning_if_needed(self):
        """í•„ìš”ì‹œ í•™ìŠµ íŠ¸ë¦¬ê±°"""
        recent_experiences = self.db.get_experiences(limit=self.min_experiences_for_learning + 1)
        
        if len(recent_experiences) >= self.min_experiences_for_learning:
            await self.learn_from_experiences()
    
    async def learn_from_experiences(self) -> Dict[str, Any]:
        """ê²½í—˜ìœ¼ë¡œë¶€í„° í•™ìŠµ"""
        logger.info("ğŸ§  ë©”íƒ€ ëŸ¬ë‹ ì‹œì‘...")
        
        # ìµœê·¼ ê²½í—˜ ìˆ˜ì§‘
        experiences = self.db.get_experiences(limit=1000)
        
        if len(experiences) < self.min_experiences_for_learning:
            logger.warning(f"í•™ìŠµì„ ìœ„í•œ ê²½í—˜ ë¶€ì¡±: {len(experiences)}/{self.min_experiences_for_learning}")
            return {"status": "insufficient_data"}
        
        learning_results = {}
        
        # 1. íŒ¨í„´ í•™ìŠµ
        try:
            data_patterns = self.pattern_learner.learn_data_patterns(experiences)
            self.meta_knowledge.data_patterns.update(data_patterns)
            learning_results["pattern_learning"] = data_patterns
            logger.info("âœ… íŒ¨í„´ í•™ìŠµ ì™„ë£Œ")
        except Exception as e:
            logger.error(f"íŒ¨í„´ í•™ìŠµ ì‹¤íŒ¨: {e}")
            learning_results["pattern_learning"] = {"error": str(e)}
        
        # 2. ì „ëµ ìµœì í™”
        try:
            strategy_optimization = self.strategy_optimizer.optimize_strategies(experiences)
            self.meta_knowledge.successful_strategies.update(strategy_optimization)
            learning_results["strategy_optimization"] = strategy_optimization
            logger.info("âœ… ì „ëµ ìµœì í™” ì™„ë£Œ")
        except Exception as e:
            logger.error(f"ì „ëµ ìµœì í™” ì‹¤íŒ¨: {e}")
            learning_results["strategy_optimization"] = {"error": str(e)}
        
        # 3. í”¼ë“œë°± í†µí•©
        try:
            feedback_analysis = self.feedback_integrator.integrate_feedback(experiences)
            learning_results["feedback_integration"] = feedback_analysis
            logger.info("âœ… í”¼ë“œë°± í†µí•© ì™„ë£Œ")
        except Exception as e:
            logger.error(f"í”¼ë“œë°± í†µí•© ì‹¤íŒ¨: {e}")
            learning_results["feedback_integration"] = {"error": str(e)}
        
        # 4. í•™ìŠµ ê·œì¹™ ìƒì„±
        new_rules = await self._generate_learning_rules(experiences, learning_results)
        for rule in new_rules:
            self.db.store_learning_rule(rule)
        learning_results["new_rules"] = len(new_rules)
        
        # 5. ë©”íƒ€ ì§€ì‹ ì €ì¥
        self._save_meta_knowledge()
        
        learning_results["learning_timestamp"] = datetime.now().isoformat()
        learning_results["experiences_processed"] = len(experiences)
        
        logger.info(f"ğŸ¯ ë©”íƒ€ ëŸ¬ë‹ ì™„ë£Œ: {len(experiences)}ê°œ ê²½í—˜ ì²˜ë¦¬, {len(new_rules)}ê°œ ìƒˆ ê·œì¹™ ìƒì„±")
        
        return learning_results
    
    async def _generate_learning_rules(self, experiences: List[AnalysisExperience], 
                                     learning_results: Dict[str, Any]) -> List[LearningRule]:
        """í•™ìŠµ ê·œì¹™ ìƒì„±"""
        rules = []
        
        # íŒ¨í„´ ê¸°ë°˜ ê·œì¹™
        if "pattern_learning" in learning_results:
            patterns = learning_results["pattern_learning"]
            
            # í¬ê¸° ê¸°ë°˜ ê·œì¹™
            if "size_patterns" in patterns:
                size_patterns = patterns["size_patterns"]
                for size_cat in size_patterns.get("optimal_sizes", []):
                    rule = LearningRule(
                        id=f"size_rule_{size_cat}_{datetime.now().strftime('%Y%m%d')}",
                        rule_type=LearningType.PATTERN_RECOGNITION,
                        condition={"size_category": size_cat},
                        action={"recommend": "apply_standard_strategy"},
                        confidence=0.8,
                        success_count=0,
                        failure_count=0,
                        last_updated=datetime.now()
                    )
                    rules.append(rule)
        
        # ì „ëµ ê¸°ë°˜ ê·œì¹™
        if "strategy_optimization" in learning_results:
            strategy_opt = learning_results["strategy_optimization"]
            
            if "top_strategies" in strategy_opt:
                for strategy in strategy_opt["top_strategies"][:2]:  # ìƒìœ„ 2ê°œ
                    rule = LearningRule(
                        id=f"strategy_rule_{strategy}_{datetime.now().strftime('%Y%m%d')}",
                        rule_type=LearningType.STRATEGY_OPTIMIZATION,
                        condition={"general_analysis": True},
                        action={"prefer_strategy": strategy},
                        confidence=0.7,
                        success_count=0,
                        failure_count=0,
                        last_updated=datetime.now()
                    )
                    rules.append(rule)
        
        return rules
    
    def get_recommendations(self, data_profile: Dict[str, Any], 
                          context: str = "") -> Dict[str, Any]:
        """ë©”íƒ€ ì§€ì‹ ê¸°ë°˜ ì¶”ì²œ"""
        recommendations = {
            "strategy_recommendations": [],
            "parameter_suggestions": {},
            "warnings": [],
            "confidence": 0.5
        }
        
        # ë°ì´í„° íŒ¨í„´ ê¸°ë°˜ ì¶”ì²œ
        if self.meta_knowledge.data_patterns:
            pattern_recs = self._get_pattern_recommendations(data_profile)
            recommendations["strategy_recommendations"].extend(pattern_recs)
        
        # ì„±ê³µ ì „ëµ ê¸°ë°˜ ì¶”ì²œ
        if self.meta_knowledge.successful_strategies:
            strategy_recs = self._get_strategy_recommendations(data_profile, context)
            recommendations["strategy_recommendations"].extend(strategy_recs)
        
        # í•™ìŠµ ê·œì¹™ ì ìš©
        rule_recs = self._apply_learning_rules(data_profile, context)
        recommendations.update(rule_recs)
        
        # ì¶”ì²œ ì‹ ë¢°ë„ ê³„ì‚°
        recommendations["confidence"] = self._calculate_recommendation_confidence(
            data_profile, recommendations
        )
        
        return recommendations
    
    def _get_pattern_recommendations(self, data_profile: Dict[str, Any]) -> List[str]:
        """íŒ¨í„´ ê¸°ë°˜ ì¶”ì²œ"""
        recommendations = []
        
        patterns = self.meta_knowledge.data_patterns
        
        # í¬ê¸° íŒ¨í„´ ì²´í¬
        if 'shape' in data_profile and 'size_patterns' in patterns:
            rows, cols = data_profile['shape']
            size_category = self.pattern_learner._categorize_size(rows, cols)
            
            size_patterns = patterns['size_patterns']
            if size_category in size_patterns.get('challenging_sizes', []):
                recommendations.append(f"ì£¼ì˜: {size_category} í¬ê¸° ë°ì´í„°ëŠ” ë¶„ì„ì´ ì–´ë ¤ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤")
            elif size_category in size_patterns.get('optimal_sizes', []):
                recommendations.append(f"ì ì ˆí•œ í¬ê¸°: {size_category} ë°ì´í„°ë¡œ ì¢‹ì€ ê²°ê³¼ê°€ ì˜ˆìƒë©ë‹ˆë‹¤")
        
        return recommendations
    
    def _get_strategy_recommendations(self, data_profile: Dict[str, Any], context: str) -> List[str]:
        """ì „ëµ ê¸°ë°˜ ì¶”ì²œ"""
        recommendations = []
        
        strategies = self.meta_knowledge.successful_strategies
        
        if 'strategy_rankings' in strategies:
            rankings = strategies['strategy_rankings']
            if 'top_strategies' in rankings:
                top_strategy = rankings['top_strategies'][0] if rankings['top_strategies'] else None
                if top_strategy:
                    recommendations.append(f"ì¶”ì²œ ì „ëµ: {top_strategy} (ë†’ì€ ì„±ê³µë¥ )")
        
        return recommendations
    
    def _apply_learning_rules(self, data_profile: Dict[str, Any], context: str) -> Dict[str, Any]:
        """í•™ìŠµ ê·œì¹™ ì ìš©"""
        applicable_rules = self.db.get_learning_rules()
        
        applied_recommendations = {
            "rule_based_suggestions": [],
            "parameter_adjustments": {}
        }
        
        for rule in applicable_rules:
            if self._rule_applies(rule, data_profile, context):
                if rule.confidence > self.confidence_threshold:
                    if rule.rule_type == LearningType.STRATEGY_OPTIMIZATION:
                        action = rule.action
                        if 'prefer_strategy' in action:
                            applied_recommendations["rule_based_suggestions"].append(
                                f"ê·œì¹™ ê¸°ë°˜ ì¶”ì²œ: {action['prefer_strategy']} ì „ëµ ì‚¬ìš©"
                            )
                    elif rule.rule_type == LearningType.PARAMETER_TUNING:
                        applied_recommendations["parameter_adjustments"].update(rule.action)
        
        return applied_recommendations
    
    def _rule_applies(self, rule: LearningRule, data_profile: Dict[str, Any], context: str) -> bool:
        """ê·œì¹™ ì ìš© ê°€ëŠ¥ì„± í™•ì¸"""
        condition = rule.condition
        
        # ê°„ë‹¨í•œ ì¡°ê±´ ë§¤ì¹­
        if 'size_category' in condition:
            if 'shape' in data_profile:
                rows, cols = data_profile['shape']
                size_category = self.pattern_learner._categorize_size(rows, cols)
                return size_category == condition['size_category']
        
        if 'general_analysis' in condition:
            return condition['general_analysis']
        
        return False
    
    def _calculate_recommendation_confidence(self, data_profile: Dict[str, Any], 
                                          recommendations: Dict[str, Any]) -> float:
        """ì¶”ì²œ ì‹ ë¢°ë„ ê³„ì‚°"""
        confidence_factors = []
        
        # ë©”íƒ€ ì§€ì‹ í’ë¶€ë„
        knowledge_richness = len(self.meta_knowledge.data_patterns) * 0.1
        confidence_factors.append(min(1.0, knowledge_richness))
        
        # ì¶”ì²œ ìˆ˜ëŸ‰
        rec_count = len(recommendations.get("strategy_recommendations", []))
        rec_factor = min(1.0, rec_count * 0.2)
        confidence_factors.append(rec_factor)
        
        # ë°ì´í„° í”„ë¡œíŒŒì¼ ì™„ì„±ë„
        profile_completeness = len(data_profile) * 0.1
        confidence_factors.append(min(1.0, profile_completeness))
        
        return statistics.mean(confidence_factors) if confidence_factors else 0.5
    
    def _extract_domain_tags(self, data_profile: Dict[str, Any], context: str) -> List[str]:
        """ë„ë©”ì¸ íƒœê·¸ ì¶”ì¶œ"""
        tags = []
        
        # ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ íƒœê·¸
        if context:
            tags.append(context.lower())
        
        # ë°ì´í„° íŠ¹ì„± ê¸°ë°˜ íƒœê·¸
        if 'data_characteristics' in data_profile:
            tags.extend(data_profile['data_characteristics'])
        
        # í¬ê¸° ê¸°ë°˜ íƒœê·¸
        if 'shape' in data_profile:
            rows, cols = data_profile['shape']
            size_tag = self.pattern_learner._categorize_size(rows, cols)
            tags.append(size_tag)
        
        return list(set(tags))  # ì¤‘ë³µ ì œê±°
    
    def _extract_lessons_learned(self, outcome: AnalysisOutcome, 
                               user_feedback: Dict[str, Any]) -> List[str]:
        """êµí›ˆ ì¶”ì¶œ"""
        lessons = []
        
        if outcome == AnalysisOutcome.FAILED:
            lessons.append("ë¶„ì„ ì‹¤íŒ¨ ì‚¬ë¡€ - ì „ëµ ì¬ê²€í†  í•„ìš”")
        elif outcome == AnalysisOutcome.EXCELLENT:
            lessons.append("ì„±ê³µì ì¸ ë¶„ì„ ì‚¬ë¡€ - ì „ëµ ì¬ì‚¬ìš© ê¶Œì¥")
        
        if 'suggestions' in user_feedback:
            lessons.extend(user_feedback['suggestions'])
        
        return lessons
    
    def _load_meta_knowledge(self):
        """ë©”íƒ€ ì§€ì‹ ë¡œë“œ"""
        if self.knowledge_path.exists():
            try:
                with open(self.knowledge_path, 'rb') as f:
                    self.meta_knowledge = pickle.load(f)
                logger.info("ğŸ“š ê¸°ì¡´ ë©”íƒ€ ì§€ì‹ ë¡œë“œ ì™„ë£Œ")
            except Exception as e:
                logger.warning(f"ë©”íƒ€ ì§€ì‹ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    def _save_meta_knowledge(self):
        """ë©”íƒ€ ì§€ì‹ ì €ì¥"""
        try:
            with open(self.knowledge_path, 'wb') as f:
                pickle.dump(self.meta_knowledge, f)
            logger.info("ğŸ’¾ ë©”íƒ€ ì§€ì‹ ì €ì¥ ì™„ë£Œ")
        except Exception as e:
            logger.error(f"ë©”íƒ€ ì§€ì‹ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def get_learning_status(self) -> Dict[str, Any]:
        """í•™ìŠµ ìƒíƒœ ë°˜í™˜"""
        experiences = self.db.get_experiences(limit=100)
        recent_experiences = [exp for exp in experiences 
                            if (datetime.now() - exp.timestamp).days < 7]
        
        return {
            "total_experiences": len(experiences),
            "recent_experiences": len(recent_experiences),
            "knowledge_areas": len(self.meta_knowledge.data_patterns),
            "learning_rules": len(self.db.get_learning_rules()),
            "last_learning": datetime.now().isoformat(),  # ì‹¤ì œë¡œëŠ” ë§ˆì§€ë§‰ í•™ìŠµ ì‹œì 
            "confidence_level": 0.7  # í˜„ì¬ ì‹œìŠ¤í…œ ì‹ ë¢°ë„
        }


# ì‚¬ìš© ì˜ˆì‹œ ë° í…ŒìŠ¤íŠ¸
async def test_meta_learning_system():
    """ë©”íƒ€ ëŸ¬ë‹ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
    meta_system = MetaLearningSystem()
    
    # í…ŒìŠ¤íŠ¸ ê²½í—˜ ê¸°ë¡
    test_data_profile = {
        "shape": (1000, 20),
        "data_characteristics": ["numerical", "mixed"],
        "quality_score": 0.8,
        "complexity_level": "medium"
    }
    
    test_strategy = {
        "context": "exploration",
        "techniques": ["descriptive_statistics", "correlation_analysis"],
        "priority_steps": ["data_overview", "pattern_discovery"]
    }
    
    test_feedback = {
        "satisfaction_score": 0.9,
        "suggestions": ["ë” ìƒì„¸í•œ ì‹œê°í™” í•„ìš”"]
    }
    
    # ê²½í—˜ ê¸°ë¡
    experience_id = await meta_system.record_analysis_experience(
        data_profile=test_data_profile,
        strategy_used=test_strategy,
        outcome=AnalysisOutcome.GOOD,
        user_feedback=test_feedback,
        performance_metrics={"accuracy": 0.85},
        insights_quality=0.8,
        execution_time=120.0,
        context="business_analytics"
    )
    
    print(f"ğŸ“ ê²½í—˜ ê¸°ë¡ë¨: {experience_id}")
    
    # ì¶”ì²œ ë°›ê¸°
    recommendations = meta_system.get_recommendations(test_data_profile, "business_analytics")
    
    print(f"\nğŸ’¡ ë©”íƒ€ ëŸ¬ë‹ ì¶”ì²œ:")
    for rec in recommendations["strategy_recommendations"]:
        print(f"   â€¢ {rec}")
    
    print(f"   ì‹ ë¢°ë„: {recommendations['confidence']:.2f}")
    
    # í•™ìŠµ ìƒíƒœ í™•ì¸
    status = meta_system.get_learning_status()
    print(f"\nğŸ“Š í•™ìŠµ ìƒíƒœ: {status['total_experiences']}ê°œ ê²½í—˜, {status['learning_rules']}ê°œ ê·œì¹™")

if __name__ == "__main__":
    asyncio.run(test_meta_learning_system()) 