"""
Intelligent Result Interpretation and Recommendation System

ì§€ëŠ¥í˜• ê²°ê³¼ í•´ì„ ë° ì¶”ì²œ ì‹œìŠ¤í…œ
- ë‹¤ì–‘í•œ ì—ì´ì „íŠ¸ ê²°ê³¼ í†µí•© ë¶„ì„
- ì§€ëŠ¥í˜• ì¸ì‚¬ì´íŠ¸ ìƒì„±
- ì‹¤í–‰ ê°€ëŠ¥í•œ ì¶”ì²œì‚¬í•­ ì œê³µ
- ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ
- ë„ë©”ì¸ë³„ ì „ë¬¸ í•´ì„
- ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜ ì¶”ì¶œ

Author: CherryAI Team
Date: 2024-12-30
"""

import json
import logging
import re
import statistics
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional, Union, Tuple
from dataclasses import dataclass, asdict
from enum import Enum
import warnings
warnings.filterwarnings('ignore')

# Optional imports for enhanced functionality
try:
    import pandas as pd
    import numpy as np
    PANDAS_AVAILABLE = True
except ImportError:
    PANDAS_AVAILABLE = False

try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

# Our imports
try:
    from core.enhanced_langfuse_tracer import get_enhanced_tracer
    from core.auto_data_profiler import DataProfile, DataQuality
    from core.advanced_code_tracker import CodeExecution, ExecutionResult
    CORE_SYSTEMS_AVAILABLE = True
except ImportError:
    CORE_SYSTEMS_AVAILABLE = False

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class InsightType(Enum):
    """ì¸ì‚¬ì´íŠ¸ ìœ í˜•"""
    DESCRIPTIVE = "descriptive"         # ê¸°ìˆ  í†µê³„ ì¸ì‚¬ì´íŠ¸
    DIAGNOSTIC = "diagnostic"           # ì›ì¸ ë¶„ì„ ì¸ì‚¬ì´íŠ¸
    PREDICTIVE = "predictive"           # ì˜ˆì¸¡ì  ì¸ì‚¬ì´íŠ¸
    PRESCRIPTIVE = "prescriptive"       # ì²˜ë°©ì  ì¸ì‚¬ì´íŠ¸
    COMPARATIVE = "comparative"         # ë¹„êµ ë¶„ì„ ì¸ì‚¬ì´íŠ¸
    TREND = "trend"                     # íŠ¸ë Œë“œ ë¶„ì„ ì¸ì‚¬ì´íŠ¸
    ANOMALY = "anomaly"                 # ì´ìƒ íƒì§€ ì¸ì‚¬ì´íŠ¸
    CORRELATION = "correlation"         # ìƒê´€ê´€ê³„ ì¸ì‚¬ì´íŠ¸


class RecommendationType(Enum):
    """ì¶”ì²œì‚¬í•­ ìœ í˜•"""
    DATA_QUALITY = "data_quality"       # ë°ì´í„° í’ˆì§ˆ ê°œì„ 
    ANALYSIS = "analysis"               # ì¶”ê°€ ë¶„ì„
    VISUALIZATION = "visualization"     # ì‹œê°í™” ê°œì„ 
    MODELING = "modeling"               # ëª¨ë¸ë§ ì œì•ˆ
    BUSINESS_ACTION = "business_action" # ë¹„ì¦ˆë‹ˆìŠ¤ ì•¡ì…˜
    TECHNICAL = "technical"             # ê¸°ìˆ ì  ê°œì„ 
    EXPLORATION = "exploration"         # íƒìƒ‰ì  ë¶„ì„
    VALIDATION = "validation"           # ê²€ì¦ í•„ìš”


class Priority(Enum):
    """ìš°ì„ ìˆœìœ„"""
    CRITICAL = "critical"    # ì¦‰ì‹œ ì¡°ì¹˜ í•„ìš”
    HIGH = "high"           # ë†’ì€ ìš°ì„ ìˆœìœ„
    MEDIUM = "medium"       # ë³´í†µ ìš°ì„ ìˆœìœ„
    LOW = "low"             # ë‚®ì€ ìš°ì„ ìˆœìœ„
    INFO = "info"           # ì •ë³´ì„±


@dataclass
class Insight:
    """ì¸ì‚¬ì´íŠ¸ ì •ë³´"""
    insight_id: str
    insight_type: InsightType
    title: str
    description: str
    evidence: List[str]
    confidence: float  # 0.0 ~ 1.0
    impact_score: float  # 0.0 ~ 1.0
    
    # ë©”íƒ€ë°ì´í„°
    data_sources: List[str] = None
    related_metrics: Dict[str, Any] = None
    generated_at: str = None
    
    # ë¹„ì¦ˆë‹ˆìŠ¤ ì»¨í…ìŠ¤íŠ¸
    business_implications: List[str] = None
    affected_stakeholders: List[str] = None


@dataclass
class Recommendation:
    """ì¶”ì²œì‚¬í•­ ì •ë³´"""
    recommendation_id: str
    recommendation_type: RecommendationType
    priority: Priority
    title: str
    description: str
    rationale: str
    
    # ì‹¤í–‰ ì •ë³´
    action_steps: List[str] = None
    estimated_effort: str = None  # "Low", "Medium", "High"
    expected_impact: str = None   # "Low", "Medium", "High"
    timeline: str = None          # "Immediate", "Short-term", "Long-term"
    
    # ë¦¬ì†ŒìŠ¤ ì •ë³´
    required_skills: List[str] = None
    required_tools: List[str] = None
    prerequisites: List[str] = None
    
    # ë©”íŠ¸ë¦­
    success_metrics: List[str] = None
    risk_factors: List[str] = None


@dataclass
class InterpretationResult:
    """í•´ì„ ê²°ê³¼"""
    session_id: str
    analysis_summary: str
    
    # í•µì‹¬ ê²°ê³¼
    key_findings: List[str]
    insights: List[Insight]
    recommendations: List[Recommendation]
    
    # ë‹¤ìŒ ë‹¨ê³„
    next_steps: List[str]
    alternative_approaches: List[str] = None
    
    # ë©”íƒ€ë°ì´í„°
    confidence_score: float = 0.0
    interpretation_timestamp: str = None
    data_sources_analyzed: List[str] = None
    
    # ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜
    business_value: str = None
    roi_potential: str = None


class DomainExpert:
    """ë„ë©”ì¸ë³„ ì „ë¬¸ í•´ì„ê¸°"""
    
    @staticmethod
    def interpret_statistical_results(results: Dict[str, Any]) -> List[Insight]:
        """í†µê³„ ë¶„ì„ ê²°ê³¼ í•´ì„"""
        insights = []
        
        # ê¸°ìˆ  í†µê³„ í•´ì„
        if "mean" in results and "std" in results:
            mean_val = results["mean"]
            std_val = results["std"]
            cv = std_val / mean_val if mean_val != 0 else float('inf')
            
            if cv < 0.1:
                insights.append(Insight(
                    insight_id="low_variability",
                    insight_type=InsightType.DESCRIPTIVE,
                    title="ë‚®ì€ ë³€ë™ì„± íƒì§€",
                    description=f"ë°ì´í„°ì˜ ë³€ë™ê³„ìˆ˜ê°€ {cv:.2%}ë¡œ ë§¤ìš° ë‚®ì•„ ì¼ê´€ëœ íŒ¨í„´ì„ ë³´ì…ë‹ˆë‹¤.",
                    evidence=[f"í‰ê· : {mean_val:.2f}, í‘œì¤€í¸ì°¨: {std_val:.2f}"],
                    confidence=0.9,
                    impact_score=0.6,
                    business_implications=["ì˜ˆì¸¡ ê°€ëŠ¥í•œ íŒ¨í„´", "ì•ˆì •ì ì¸ í”„ë¡œì„¸ìŠ¤"]
                ))
            elif cv > 0.5:
                insights.append(Insight(
                    insight_id="high_variability",
                    insight_type=InsightType.DIAGNOSTIC,
                    title="ë†’ì€ ë³€ë™ì„± ë°œê²¬",
                    description=f"ë°ì´í„°ì˜ ë³€ë™ê³„ìˆ˜ê°€ {cv:.2%}ë¡œ ë†’ì•„ ë¶ˆì•ˆì •í•œ íŒ¨í„´ì„ ë³´ì…ë‹ˆë‹¤.",
                    evidence=[f"í‰ê· : {mean_val:.2f}, í‘œì¤€í¸ì°¨: {std_val:.2f}"],
                    confidence=0.9,
                    impact_score=0.8,
                    business_implications=["ë¶ˆí™•ì‹¤ì„± ì¦ê°€", "ë¦¬ìŠ¤í¬ ê´€ë¦¬ í•„ìš”"]
                ))
        
        # ìƒê´€ê´€ê³„ í•´ì„
        if "correlations" in results:
            correlations = results["correlations"]
            if isinstance(correlations, dict):
                high_corrs = [(k, v) for k, v in correlations.items() if abs(v) > 0.7]
                if high_corrs:
                    insights.append(Insight(
                        insight_id="strong_correlations",
                        insight_type=InsightType.CORRELATION,
                        title="ê°•í•œ ìƒê´€ê´€ê³„ ë°œê²¬",
                        description=f"{len(high_corrs)}ê°œì˜ ë³€ìˆ˜ ìŒì—ì„œ ê°•í•œ ìƒê´€ê´€ê³„ê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.",
                        evidence=[f"{k}: {v:.3f}" for k, v in high_corrs[:3]],
                        confidence=0.85,
                        impact_score=0.7,
                        business_implications=["ë³€ìˆ˜ ê°„ ì˜ì¡´ì„±", "ë‹¤ì¤‘ê³µì„ ì„± ê°€ëŠ¥ì„±"]
                    ))
        
        return insights
    
    @staticmethod
    def interpret_data_quality_results(profile: DataProfile) -> List[Insight]:
        """ë°ì´í„° í’ˆì§ˆ ê²°ê³¼ í•´ì„"""
        insights = []
        
        # ì „ì²´ í’ˆì§ˆ í‰ê°€
        if profile.overall_quality == DataQuality.EXCELLENT:
            insights.append(Insight(
                insight_id="excellent_quality",
                insight_type=InsightType.DESCRIPTIVE,
                title="ìš°ìˆ˜í•œ ë°ì´í„° í’ˆì§ˆ",
                description="ë°ì´í„° í’ˆì§ˆì´ ìš°ìˆ˜í•˜ì—¬ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ë¶„ì„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.",
                evidence=[f"í’ˆì§ˆ ì ìˆ˜: {profile.quality_score:.1%}"],
                confidence=0.95,
                impact_score=0.8,
                business_implications=["ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì˜ì‚¬ê²°ì •", "ë¶„ì„ ê²°ê³¼ ì‹ ë¢°ì„± ë†’ìŒ"]
            ))
        elif profile.overall_quality in [DataQuality.POOR, DataQuality.CRITICAL]:
            insights.append(Insight(
                insight_id="poor_quality",
                insight_type=InsightType.DIAGNOSTIC,
                title="ë°ì´í„° í’ˆì§ˆ ë¬¸ì œ",
                description="ë°ì´í„° í’ˆì§ˆì´ ë‚®ì•„ ë¶„ì„ ê²°ê³¼ì˜ ì‹ ë¢°ì„±ì´ ì œí•œì ì…ë‹ˆë‹¤.",
                evidence=profile.data_quality_issues[:3],
                confidence=0.9,
                impact_score=0.9,
                business_implications=["ë¶„ì„ ê²°ê³¼ ì‹ ë¢°ì„± ì €í•˜", "ë°ì´í„° ì •ì œ í•„ìš”"]
            ))
        
        # ëˆ„ë½ê°’ ë¶„ì„
        if profile.missing_percentage > 20:
            insights.append(Insight(
                insight_id="high_missing_data",
                insight_type=InsightType.DIAGNOSTIC,
                title="ë†’ì€ ëˆ„ë½ê°’ ë¹„ìœ¨",
                description=f"ì „ì²´ ë°ì´í„°ì˜ {profile.missing_percentage:.1f}%ê°€ ëˆ„ë½ë˜ì–´ ìˆìŠµë‹ˆë‹¤.",
                evidence=[f"ëˆ„ë½ê°’: {profile.total_missing:,}ê°œ"],
                confidence=0.95,
                impact_score=0.7,
                business_implications=["ë¶„ì„ ë²”ìœ„ ì œí•œ", "ë°ì´í„° ìˆ˜ì§‘ í”„ë¡œì„¸ìŠ¤ ê²€í†  í•„ìš”"]
            ))
        
        # ì¤‘ë³µ ë°ì´í„° ë¶„ì„
        if profile.duplicate_percentage > 10:
            insights.append(Insight(
                insight_id="high_duplicates",
                insight_type=InsightType.DIAGNOSTIC,
                title="ë†’ì€ ì¤‘ë³µ ë°ì´í„° ë¹„ìœ¨",
                description=f"ì „ì²´ ë°ì´í„°ì˜ {profile.duplicate_percentage:.1f}%ê°€ ì¤‘ë³µë©ë‹ˆë‹¤.",
                evidence=[f"ì¤‘ë³µ í–‰: {profile.duplicate_rows:,}ê°œ"],
                confidence=0.9,
                impact_score=0.6,
                business_implications=["ë°ì´í„° ì €ì¥ ë¹„íš¨ìœ¨", "ë¶„ì„ ê²°ê³¼ ì™œê³¡ ê°€ëŠ¥ì„±"]
            ))
        
        return insights
    
    @staticmethod
    def interpret_visualization_results(results: Dict[str, Any]) -> List[Insight]:
        """ì‹œê°í™” ê²°ê³¼ í•´ì„"""
        insights = []
        
        # ë¶„í¬ ë¶„ì„
        if "distribution_type" in results:
            dist_type = results["distribution_type"]
            if dist_type == "normal":
                insights.append(Insight(
                    insight_id="normal_distribution",
                    insight_type=InsightType.DESCRIPTIVE,
                    title="ì •ê·œë¶„í¬ íŒ¨í„´",
                    description="ë°ì´í„°ê°€ ì •ê·œë¶„í¬ë¥¼ ë”°ë¥´ëŠ” ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤.",
                    evidence=["ì •ê·œì„± ê²€ì • í†µê³¼"],
                    confidence=0.8,
                    impact_score=0.6,
                    business_implications=["í†µê³„ì  ë¶„ì„ ì ìš© ê°€ëŠ¥", "ì˜ˆì¸¡ ëª¨ë¸ ì í•©ì„± ë†’ìŒ"]
                ))
            elif dist_type == "skewed":
                insights.append(Insight(
                    insight_id="skewed_distribution",
                    insight_type=InsightType.DIAGNOSTIC,
                    title="ë¹„ëŒ€ì¹­ ë¶„í¬",
                    description="ë°ì´í„°ê°€ í•œìª½ìœ¼ë¡œ ì¹˜ìš°ì¹œ ë¶„í¬ë¥¼ ë³´ì…ë‹ˆë‹¤.",
                    evidence=["ì™œë„ ê²€ì • ê²°ê³¼"],
                    confidence=0.85,
                    impact_score=0.7,
                    business_implications=["ë³€í™˜ í•„ìš”", "ì´ìƒì¹˜ í™•ì¸ í•„ìš”"]
                ))
        
        # íŠ¸ë Œë“œ ë¶„ì„
        if "trend" in results:
            trend = results["trend"]
            if trend == "increasing":
                insights.append(Insight(
                    insight_id="positive_trend",
                    insight_type=InsightType.TREND,
                    title="ì¦ê°€ ì¶”ì„¸",
                    description="ì‹œê°„ì— ë”°ë¥¸ ì¦ê°€ ì¶”ì„¸ê°€ ê´€ì°°ë©ë‹ˆë‹¤.",
                    evidence=["ì„ í˜• íšŒê·€ ê¸°ìš¸ê¸° ì–‘ìˆ˜"],
                    confidence=0.8,
                    impact_score=0.8,
                    business_implications=["ì„±ì¥ ê¸°íšŒ", "ì§€ì† ê°€ëŠ¥ì„± ê²€í† "]
                ))
            elif trend == "decreasing":
                insights.append(Insight(
                    insight_id="negative_trend",
                    insight_type=InsightType.TREND,
                    title="ê°ì†Œ ì¶”ì„¸",
                    description="ì‹œê°„ì— ë”°ë¥¸ ê°ì†Œ ì¶”ì„¸ê°€ ê´€ì°°ë©ë‹ˆë‹¤.",
                    evidence=["ì„ í˜• íšŒê·€ ê¸°ìš¸ê¸° ìŒìˆ˜"],
                    confidence=0.8,
                    impact_score=0.9,
                    business_implications=["ì£¼ì˜ í•„ìš”", "ê°œì„  ë°©ì•ˆ ëª¨ìƒ‰"]
                ))
        
        return insights
    
    @staticmethod
    def interpret_ml_results(results: Dict[str, Any]) -> List[Insight]:
        """ë¨¸ì‹ ëŸ¬ë‹ ê²°ê³¼ í•´ì„"""
        insights = []
        
        # ëª¨ë¸ ì„±ëŠ¥ í•´ì„
        if "accuracy" in results:
            accuracy = results["accuracy"]
            if accuracy > 0.9:
                insights.append(Insight(
                    insight_id="high_accuracy",
                    insight_type=InsightType.PREDICTIVE,
                    title="ë†’ì€ ëª¨ë¸ ì •í™•ë„",
                    description=f"ëª¨ë¸ ì •í™•ë„ê°€ {accuracy:.1%}ë¡œ ë§¤ìš° ìš°ìˆ˜í•©ë‹ˆë‹¤.",
                    evidence=[f"ì •í™•ë„: {accuracy:.3f}"],
                    confidence=0.9,
                    impact_score=0.9,
                    business_implications=["ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì˜ˆì¸¡", "ìš´ì˜ í™˜ê²½ ì ìš© ê°€ëŠ¥"]
                ))
            elif accuracy < 0.7:
                insights.append(Insight(
                    insight_id="low_accuracy",
                    insight_type=InsightType.DIAGNOSTIC,
                    title="ë‚®ì€ ëª¨ë¸ ì •í™•ë„",
                    description=f"ëª¨ë¸ ì •í™•ë„ê°€ {accuracy:.1%}ë¡œ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.",
                    evidence=[f"ì •í™•ë„: {accuracy:.3f}"],
                    confidence=0.95,
                    impact_score=0.8,
                    business_implications=["ëª¨ë¸ ê°œì„  í•„ìš”", "ì¶”ê°€ ë°ì´í„° ìˆ˜ì§‘ ê³ ë ¤"]
                ))
        
        # íŠ¹ì„± ì¤‘ìš”ë„ í•´ì„
        if "feature_importance" in results:
            importance = results["feature_importance"]
            if isinstance(importance, dict):
                top_features = sorted(importance.items(), key=lambda x: x[1], reverse=True)[:3]
                insights.append(Insight(
                    insight_id="key_features",
                    insight_type=InsightType.PRESCRIPTIVE,
                    title="ì£¼ìš” íŠ¹ì„± ì‹ë³„",
                    description="ëª¨ë¸ ì˜ˆì¸¡ì— ê°€ì¥ ì¤‘ìš”í•œ íŠ¹ì„±ë“¤ì´ ì‹ë³„ë˜ì—ˆìŠµë‹ˆë‹¤.",
                    evidence=[f"{k}: {v:.3f}" for k, v in top_features],
                    confidence=0.85,
                    impact_score=0.8,
                    business_implications=["í•µì‹¬ ë³€ìˆ˜ ì§‘ì¤‘", "ë¦¬ì†ŒìŠ¤ íš¨ìœ¨ì  ë°°ë¶„"]
                ))
        
        return insights


class RecommendationEngine:
    """ì¶”ì²œ ì—”ì§„"""
    
    @staticmethod
    def generate_data_quality_recommendations(profile: DataProfile) -> List[Recommendation]:
        """ë°ì´í„° í’ˆì§ˆ ê¸°ë°˜ ì¶”ì²œì‚¬í•­"""
        recommendations = []
        
        # ëˆ„ë½ê°’ ì²˜ë¦¬ ì¶”ì²œ
        if profile.missing_percentage > 10:
            priority = Priority.HIGH if profile.missing_percentage > 30 else Priority.MEDIUM
            recommendations.append(Recommendation(
                recommendation_id="handle_missing_data",
                recommendation_type=RecommendationType.DATA_QUALITY,
                priority=priority,
                title="ëˆ„ë½ê°’ ì²˜ë¦¬",
                description="ë†’ì€ ëˆ„ë½ê°’ ë¹„ìœ¨ë¡œ ì¸í•œ ë°ì´í„° í’ˆì§ˆ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.",
                rationale=f"ì „ì²´ ë°ì´í„°ì˜ {profile.missing_percentage:.1f}%ê°€ ëˆ„ë½ë˜ì–´ ë¶„ì„ ì •í™•ë„ì— ì˜í–¥ì„ ì¤ë‹ˆë‹¤.",
                action_steps=[
                    "ëˆ„ë½ê°’ íŒ¨í„´ ë¶„ì„",
                    "ì ì ˆí•œ ëŒ€ì¹˜ ë°©ë²• ì„ íƒ (í‰ê· , ì¤‘ì•™ê°’, ëª¨ë“œ ë“±)",
                    "ëˆ„ë½ê°’ ì²˜ë¦¬ í›„ ë°ì´í„° ê²€ì¦",
                    "ì²˜ë¦¬ ì „í›„ ë¶„ì„ ê²°ê³¼ ë¹„êµ"
                ],
                estimated_effort="Medium",
                expected_impact="High",
                timeline="Short-term",
                required_skills=["ë°ì´í„° ì „ì²˜ë¦¬", "í†µê³„í•™"],
                success_metrics=["ëˆ„ë½ê°’ ë¹„ìœ¨ ê°ì†Œ", "ë°ì´í„° í’ˆì§ˆ ì ìˆ˜ í–¥ìƒ"]
            ))
        
        # ì¤‘ë³µ ë°ì´í„° ì œê±° ì¶”ì²œ
        if profile.duplicate_percentage > 5:
            recommendations.append(Recommendation(
                recommendation_id="remove_duplicates",
                recommendation_type=RecommendationType.DATA_QUALITY,
                priority=Priority.MEDIUM,
                title="ì¤‘ë³µ ë°ì´í„° ì œê±°",
                description="ì¤‘ë³µ ë°ì´í„°ë¥¼ ì œê±°í•˜ì—¬ ë¶„ì„ ì •í™•ë„ë¥¼ í–¥ìƒì‹œí‚¤ì„¸ìš”.",
                rationale=f"{profile.duplicate_percentage:.1f}%ì˜ ì¤‘ë³µ ë°ì´í„°ê°€ ë¶„ì„ ê²°ê³¼ë¥¼ ì™œê³¡í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
                action_steps=[
                    "ì¤‘ë³µ ê¸°ì¤€ ì •ì˜",
                    "ì¤‘ë³µ ë°ì´í„° ì‹ë³„ ë° ê²€í† ",
                    "ì¤‘ë³µ ì œê±° ê·œì¹™ ì ìš©",
                    "ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦"
                ],
                estimated_effort="Low",
                expected_impact="Medium",
                timeline="Immediate"
            ))
        
        # ë°ì´í„° íƒ€ì… ìµœì í™” ì¶”ì²œ
        memory_usage_mb = profile.memory_usage
        if memory_usage_mb > 100:  # 100MB ì´ìƒ
            recommendations.append(Recommendation(
                recommendation_id="optimize_data_types",
                recommendation_type=RecommendationType.TECHNICAL,
                priority=Priority.LOW,
                title="ë°ì´í„° íƒ€ì… ìµœì í™”",
                description="ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ì¤„ì´ê¸° ìœ„í•´ ë°ì´í„° íƒ€ì…ì„ ìµœì í™”í•˜ì„¸ìš”.",
                rationale=f"í˜„ì¬ {memory_usage_mb:.1f}MBì˜ ë©”ëª¨ë¦¬ë¥¼ ì‚¬ìš©í•˜ê³  ìˆì–´ ìµœì í™”ê°€ í•„ìš”í•©ë‹ˆë‹¤.",
                action_steps=[
                    "ê° ì»¬ëŸ¼ì˜ ì‹¤ì œ ë°ì´í„° ë²”ìœ„ ë¶„ì„",
                    "ì ì ˆí•œ ë°ì´í„° íƒ€ì… ì„ íƒ (int32 vs int64 ë“±)",
                    "ë²”ì£¼í˜• ë°ì´í„° category íƒ€ì… ë³€í™˜",
                    "ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¹„êµ ê²€ì¦"
                ],
                estimated_effort="Low",
                expected_impact="Medium",
                timeline="Short-term",
                required_skills=["ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§"]
            ))
        
        return recommendations
    
    @staticmethod
    def generate_analysis_recommendations(insights: List[Insight]) -> List[Recommendation]:
        """ì¸ì‚¬ì´íŠ¸ ê¸°ë°˜ ë¶„ì„ ì¶”ì²œì‚¬í•­"""
        recommendations = []
        
        # ìƒê´€ê´€ê³„ ë°œê²¬ ì‹œ ì¶”ê°€ ë¶„ì„ ì¶”ì²œ
        correlation_insights = [i for i in insights if i.insight_type == InsightType.CORRELATION]
        if correlation_insights:
            recommendations.append(Recommendation(
                recommendation_id="correlation_analysis",
                recommendation_type=RecommendationType.ANALYSIS,
                priority=Priority.MEDIUM,
                title="ìƒê´€ê´€ê³„ ì‹¬í™” ë¶„ì„",
                description="ë°œê²¬ëœ ìƒê´€ê´€ê³„ì— ëŒ€í•œ ì‹¬í™” ë¶„ì„ì„ ìˆ˜í–‰í•˜ì„¸ìš”.",
                rationale="ê°•í•œ ìƒê´€ê´€ê³„ê°€ ë°œê²¬ë˜ì–´ ì¸ê³¼ê´€ê³„ ë¶„ì„ì´ í•„ìš”í•©ë‹ˆë‹¤.",
                action_steps=[
                    "í¸ìƒê´€ê³„ìˆ˜ ê³„ì‚°",
                    "ì‹œì°¨ ìƒê´€ê´€ê³„ ë¶„ì„",
                    "ì¸ê³¼ê´€ê³„ ê²€ì • (Granger causality)",
                    "ë„ë©”ì¸ ì „ë¬¸ê°€ ê²€í† "
                ],
                estimated_effort="Medium",
                expected_impact="High",
                timeline="Short-term",
                required_skills=["í†µê³„í•™", "ë„ë©”ì¸ ì§€ì‹"]
            ))
        
        # ì´ìƒì¹˜ ë°œê²¬ ì‹œ ì¶”ì²œ
        anomaly_insights = [i for i in insights if i.insight_type == InsightType.ANOMALY]
        if anomaly_insights:
            recommendations.append(Recommendation(
                recommendation_id="anomaly_investigation",
                recommendation_type=RecommendationType.ANALYSIS,
                priority=Priority.HIGH,
                title="ì´ìƒì¹˜ ì¡°ì‚¬",
                description="ë°œê²¬ëœ ì´ìƒì¹˜ì— ëŒ€í•œ ìƒì„¸ ì¡°ì‚¬ë¥¼ ì§„í–‰í•˜ì„¸ìš”.",
                rationale="ì´ìƒì¹˜ê°€ ë°ì´í„° ì˜¤ë¥˜ì¸ì§€ ì‹¤ì œ í˜„ìƒì¸ì§€ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.",
                action_steps=[
                    "ì´ìƒì¹˜ ë°œìƒ ì›ì¸ ì¡°ì‚¬",
                    "ë°ì´í„° ìˆ˜ì§‘ ê³¼ì • ê²€í† ",
                    "ë„ë©”ì¸ ì „ë¬¸ê°€ ìƒë‹´",
                    "ì´ìƒì¹˜ ì²˜ë¦¬ ë°©ì•ˆ ê²°ì •"
                ],
                estimated_effort="High",
                expected_impact="High",
                timeline="Immediate",
                required_skills=["ë°ì´í„° ë¶„ì„", "ë„ë©”ì¸ ì§€ì‹"],
                risk_factors=["ì´ìƒì¹˜ ì˜¤íŒ ì‹œ ì •ë³´ ì†ì‹¤"]
            ))
        
        # ì˜ˆì¸¡ ëª¨ë¸ë§ ì¶”ì²œ
        predictive_insights = [i for i in insights if i.insight_type == InsightType.PREDICTIVE]
        if predictive_insights or len(insights) >= 3:
            recommendations.append(Recommendation(
                recommendation_id="predictive_modeling",
                recommendation_type=RecommendationType.MODELING,
                priority=Priority.MEDIUM,
                title="ì˜ˆì¸¡ ëª¨ë¸ êµ¬ì¶•",
                description="ìˆ˜ì§‘ëœ ì¸ì‚¬ì´íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì˜ˆì¸¡ ëª¨ë¸ì„ êµ¬ì¶•í•˜ì„¸ìš”.",
                rationale="ì¶©ë¶„í•œ ë°ì´í„°ì™€ íŒ¨í„´ì´ í™•ì¸ë˜ì–´ ì˜ˆì¸¡ ëª¨ë¸ë§ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.",
                action_steps=[
                    "ëª©í‘œ ë³€ìˆ˜ ì •ì˜",
                    "íŠ¹ì„± ì„ íƒ ë° ì—”ì§€ë‹ˆì–´ë§",
                    "ëª¨ë¸ ì•Œê³ ë¦¬ì¦˜ ì„ íƒ",
                    "ëª¨ë¸ í›ˆë ¨ ë° í‰ê°€",
                    "ëª¨ë¸ í•´ì„ ë° ê²€ì¦"
                ],
                estimated_effort="High",
                expected_impact="High",
                timeline="Long-term",
                required_skills=["ë¨¸ì‹ ëŸ¬ë‹", "í†µê³„í•™", "í”„ë¡œê·¸ë˜ë°"],
                required_tools=["Python/R", "ML ë¼ì´ë¸ŒëŸ¬ë¦¬"],
                success_metrics=["ëª¨ë¸ ì •í™•ë„", "ë¹„ì¦ˆë‹ˆìŠ¤ KPI ê°œì„ "]
            ))
        
        return recommendations
    
    @staticmethod
    def generate_visualization_recommendations(results: Dict[str, Any]) -> List[Recommendation]:
        """ì‹œê°í™” ì¶”ì²œì‚¬í•­"""
        recommendations = []
        
        # ê¸°ë³¸ ì‹œê°í™” ì¶”ì²œ
        recommendations.append(Recommendation(
            recommendation_id="comprehensive_visualization",
            recommendation_type=RecommendationType.VISUALIZATION,
            priority=Priority.MEDIUM,
            title="í¬ê´„ì  ì‹œê°í™”",
            description="ë°ì´í„°ì˜ ë‹¤ì–‘í•œ ì¸¡ë©´ì„ ë³´ì—¬ì£¼ëŠ” ì‹œê°í™”ë¥¼ ìƒì„±í•˜ì„¸ìš”.",
            rationale="ì‹œê°í™”ë¥¼ í†µí•´ ë°ì´í„° íŒ¨í„´ì„ ë” ëª…í™•í•˜ê²Œ ì´í•´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
            action_steps=[
                "ë¶„í¬ íˆìŠ¤í† ê·¸ë¨ ìƒì„±",
                "ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ ì‘ì„±",
                "ì‹œê³„ì—´ íŠ¸ë Œë“œ ì°¨íŠ¸ (ì‹œê°„ ë°ì´í„° ìˆëŠ” ê²½ìš°)",
                "ë°•ìŠ¤í”Œë¡¯ìœ¼ë¡œ ì´ìƒì¹˜ í™•ì¸",
                "ì‚°ì ë„ë¡œ ê´€ê³„ íƒìƒ‰"
            ],
            estimated_effort="Low",
            expected_impact="Medium",
            timeline="Immediate",
            required_tools=["Matplotlib", "Seaborn", "Plotly"],
            success_metrics=["ì¸ì‚¬ì´íŠ¸ ë°œê²¬ ê°œìˆ˜", "ì´í•´ê´€ê³„ì ë§Œì¡±ë„"]
        ))
        
        # ëŒ€ì‹œë³´ë“œ êµ¬ì¶• ì¶”ì²œ
        if "multiple_metrics" in results:
            recommendations.append(Recommendation(
                recommendation_id="interactive_dashboard",
                recommendation_type=RecommendationType.VISUALIZATION,
                priority=Priority.LOW,
                title="ì¸í„°ë™í‹°ë¸Œ ëŒ€ì‹œë³´ë“œ",
                description="ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ì„ ìœ„í•œ ëŒ€ì‹œë³´ë“œë¥¼ êµ¬ì¶•í•˜ì„¸ìš”.",
                rationale="ì—¬ëŸ¬ ë©”íŠ¸ë¦­ì´ ìˆì–´ í†µí•©ì ì¸ ëª¨ë‹ˆí„°ë§ì´ í•„ìš”í•©ë‹ˆë‹¤.",
                action_steps=[
                    "í•µì‹¬ KPI ì •ì˜",
                    "ëŒ€ì‹œë³´ë“œ ë ˆì´ì•„ì›ƒ ì„¤ê³„",
                    "ì¸í„°ë™í‹°ë¸Œ ê¸°ëŠ¥ êµ¬í˜„",
                    "ìë™ ì—…ë°ì´íŠ¸ ì„¤ì •",
                    "ì‚¬ìš©ì í”¼ë“œë°± ìˆ˜ì§‘"
                ],
                estimated_effort="High",
                expected_impact="High",
                timeline="Long-term",
                required_skills=["ì›¹ ê°œë°œ", "ë°ì´í„° ì‹œê°í™”"],
                required_tools=["Streamlit", "Dash", "Tableau"]
            ))
        
        return recommendations


class IntelligentResultInterpreter:
    """
    ì§€ëŠ¥í˜• ê²°ê³¼ í•´ì„ ë° ì¶”ì²œ ì‹œìŠ¤í…œ
    
    ë‹¤ì–‘í•œ ë¶„ì„ ê²°ê³¼ë¥¼ í†µí•©í•˜ì—¬ ì˜ë¯¸ ìˆëŠ” ì¸ì‚¬ì´íŠ¸ì™€ ì¶”ì²œì‚¬í•­ì„ ì œê³µ
    """
    
    def __init__(self, config: Optional[Dict] = None):
        self.config = config or {}
        self.enhanced_tracer = None
        self.openai_client = None
        
        # í•´ì„ íˆìŠ¤í† ë¦¬
        self.interpretation_history: List[InterpretationResult] = []
        
        # ë„ë©”ì¸ ì „ë¬¸ê°€ë“¤
        self.domain_expert = DomainExpert()
        self.recommendation_engine = RecommendationEngine()
        
        # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        self._initialize_systems()
        
        logger.info("ğŸ§  Intelligent Result Interpreter ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _initialize_systems(self):
        """í•µì‹¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        if CORE_SYSTEMS_AVAILABLE:
            try:
                self.enhanced_tracer = get_enhanced_tracer()
                logger.info("âœ… Enhanced tracking activated")
            except Exception as e:
                logger.warning(f"âš ï¸ Enhanced tracking initialization failed: {e}")
        
        if OPENAI_AVAILABLE:
            try:
                import os
                api_key = os.getenv("OPENAI_API_KEY")
                if api_key:
                    self.openai_client = OpenAI(api_key=api_key)
                    logger.info("âœ… OpenAI client initialized")
            except Exception as e:
                logger.warning(f"âš ï¸ OpenAI initialization failed: {e}")
    
    def interpret_results(
        self,
        session_id: str,
        results: Dict[str, Any],
        context: Optional[Dict[str, Any]] = None,
        data_profile: Optional[DataProfile] = None,
        code_executions: Optional[List[CodeExecution]] = None
    ) -> InterpretationResult:
        """ì¢…í•©ì ì¸ ê²°ê³¼ í•´ì„"""
        try:
            logger.info(f"ğŸ” ê²°ê³¼ í•´ì„ ì‹œì‘: {session_id}")
            
            # Enhanced Tracking
            if self.enhanced_tracer:
                self.enhanced_tracer.log_data_operation(
                    "result_interpretation_start",
                    {"session_id": session_id, "context": context},
                    "Starting intelligent result interpretation"
                )
            
            # ì¸ì‚¬ì´íŠ¸ ìˆ˜ì§‘
            all_insights = []
            
            # í†µê³„ ê²°ê³¼ í•´ì„
            if "statistics" in results:
                stat_insights = self.domain_expert.interpret_statistical_results(results["statistics"])
                all_insights.extend(stat_insights)
            
            # ë°ì´í„° í’ˆì§ˆ í•´ì„
            if data_profile:
                quality_insights = self.domain_expert.interpret_data_quality_results(data_profile)
                all_insights.extend(quality_insights)
            
            # ì‹œê°í™” ê²°ê³¼ í•´ì„
            if "visualization" in results:
                viz_insights = self.domain_expert.interpret_visualization_results(results["visualization"])
                all_insights.extend(viz_insights)
            
            # ë¨¸ì‹ ëŸ¬ë‹ ê²°ê³¼ í•´ì„
            if "machine_learning" in results:
                ml_insights = self.domain_expert.interpret_ml_results(results["machine_learning"])
                all_insights.extend(ml_insights)
            
            # ì½”ë“œ ì‹¤í–‰ ê²°ê³¼ í•´ì„
            if code_executions:
                code_insights = self._interpret_code_execution_results(code_executions)
                all_insights.extend(code_insights)
            
            # ì¼ë°˜ì ì¸ ê²°ê³¼ í•´ì„
            general_insights = self._interpret_general_results(results)
            all_insights.extend(general_insights)
            
            # ì¸ì‚¬ì´íŠ¸ ìš°ì„ ìˆœìœ„ ì •ë ¬
            all_insights.sort(key=lambda x: (x.impact_score * x.confidence), reverse=True)
            
            # ì¶”ì²œì‚¬í•­ ìƒì„±
            recommendations = []
            
            if data_profile:
                quality_recs = self.recommendation_engine.generate_data_quality_recommendations(data_profile)
                recommendations.extend(quality_recs)
            
            analysis_recs = self.recommendation_engine.generate_analysis_recommendations(all_insights)
            recommendations.extend(analysis_recs)
            
            viz_recs = self.recommendation_engine.generate_visualization_recommendations(results)
            recommendations.extend(viz_recs)
            
            # ì¶”ì²œì‚¬í•­ ìš°ì„ ìˆœìœ„ ì •ë ¬
            priority_order = {Priority.CRITICAL: 0, Priority.HIGH: 1, Priority.MEDIUM: 2, Priority.LOW: 3, Priority.INFO: 4}
            recommendations.sort(key=lambda x: priority_order[x.priority])
            
            # í•µì‹¬ ë°œê²¬ì‚¬í•­ ìš”ì•½
            key_findings = self._generate_key_findings(all_insights, results)
            
            # ë¶„ì„ ìš”ì•½ ìƒì„±
            analysis_summary = self._generate_analysis_summary(key_findings, all_insights, recommendations)
            
            # ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ
            next_steps = self._generate_next_steps(all_insights, recommendations)
            
            # ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚°
            confidence_score = self._calculate_overall_confidence(all_insights, results)
            
            # ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜ í‰ê°€
            business_value = self._assess_business_value(all_insights, recommendations)
            
            # í•´ì„ ê²°ê³¼ ìƒì„±
            interpretation = InterpretationResult(
                session_id=session_id,
                analysis_summary=analysis_summary,
                key_findings=key_findings,
                insights=all_insights[:10],  # ìƒìœ„ 10ê°œ
                recommendations=recommendations[:8],  # ìƒìœ„ 8ê°œ
                next_steps=next_steps,
                confidence_score=confidence_score,
                interpretation_timestamp=datetime.now().isoformat(),
                data_sources_analyzed=list(results.keys()),
                business_value=business_value
            )
            
            # íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
            self.interpretation_history.append(interpretation)
            
            # Enhanced Tracking
            if self.enhanced_tracer:
                self.enhanced_tracer.log_data_operation(
                    "result_interpretation_complete",
                    {
                        "session_id": session_id,
                        "insights_count": len(all_insights),
                        "recommendations_count": len(recommendations),
                        "confidence_score": confidence_score
                    },
                    "Result interpretation completed successfully"
                )
            
            logger.info(f"âœ… ê²°ê³¼ í•´ì„ ì™„ë£Œ: {len(all_insights)}ê°œ ì¸ì‚¬ì´íŠ¸, {len(recommendations)}ê°œ ì¶”ì²œì‚¬í•­")
            return interpretation
            
        except Exception as e:
            logger.error(f"âŒ ê²°ê³¼ í•´ì„ ì‹¤íŒ¨: {e}")
            
            # ê¸°ë³¸ í•´ì„ ê²°ê³¼ ë°˜í™˜
            return InterpretationResult(
                session_id=session_id,
                analysis_summary="ê²°ê³¼ í•´ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                key_findings=[f"í•´ì„ ì˜¤ë¥˜: {str(e)}"],
                insights=[],
                recommendations=[],
                next_steps=["ì‹œìŠ¤í…œ ìƒíƒœë¥¼ í™•ì¸í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."],
                confidence_score=0.0,
                interpretation_timestamp=datetime.now().isoformat()
            )
    
    def _interpret_code_execution_results(self, executions: List[CodeExecution]) -> List[Insight]:
        """ì½”ë“œ ì‹¤í–‰ ê²°ê³¼ í•´ì„"""
        insights = []
        
        if not executions:
            return insights
        
        # ì„±ê³µë¥  ë¶„ì„
        successful_executions = [e for e in executions if e.execution_result and e.execution_result.status.value == "success"]
        success_rate = len(successful_executions) / len(executions)
        
        if success_rate < 0.5:
            insights.append(Insight(
                insight_id="low_code_success_rate",
                insight_type=InsightType.DIAGNOSTIC,
                title="ë‚®ì€ ì½”ë“œ ì‹¤í–‰ ì„±ê³µë¥ ",
                description=f"ì½”ë“œ ì‹¤í–‰ ì„±ê³µë¥ ì´ {success_rate:.1%}ë¡œ ë‚®ìŠµë‹ˆë‹¤.",
                evidence=[f"ì´ {len(executions)}ê°œ ì¤‘ {len(successful_executions)}ê°œ ì„±ê³µ"],
                confidence=0.9,
                impact_score=0.7,
                business_implications=["ì½”ë“œ í’ˆì§ˆ ê°œì„  í•„ìš”", "ë””ë²„ê¹… í”„ë¡œì„¸ìŠ¤ ê°•í™”"]
            ))
        
        # ë³µì¡ë„ ë¶„ì„
        if executions and executions[0].code_metrics:
            complexities = [e.code_metrics.complexity_score for e in executions if e.code_metrics]
            if complexities:
                avg_complexity = statistics.mean(complexities)
                if avg_complexity > 6:
                    insights.append(Insight(
                        insight_id="high_code_complexity",
                        insight_type=InsightType.DIAGNOSTIC,
                        title="ë†’ì€ ì½”ë“œ ë³µì¡ë„",
                        description=f"í‰ê·  ì½”ë“œ ë³µì¡ë„ê°€ {avg_complexity:.1f}ë¡œ ë†’ìŠµë‹ˆë‹¤.",
                        evidence=[f"ë³µì¡ë„ ë²”ìœ„: {min(complexities):.1f} - {max(complexities):.1f}"],
                        confidence=0.8,
                        impact_score=0.6,
                        business_implications=["ìœ ì§€ë³´ìˆ˜ ì–´ë ¤ì›€", "ì½”ë“œ ë¦¬íŒ©í† ë§ í•„ìš”"]
                    ))
        
        return insights
    
    def _interpret_general_results(self, results: Dict[str, Any]) -> List[Insight]:
        """ì¼ë°˜ì ì¸ ê²°ê³¼ í•´ì„"""
        insights = []
        
        # ë°ì´í„° í¬ê¸° ë¶„ì„
        if "data_size" in results:
            size = results["data_size"]
            if isinstance(size, dict) and "rows" in size:
                rows = size["rows"]
                if rows < 100:
                    insights.append(Insight(
                        insight_id="small_dataset",
                        insight_type=InsightType.DIAGNOSTIC,
                        title="ì‘ì€ ë°ì´í„°ì…‹",
                        description=f"ë°ì´í„°ì…‹ í¬ê¸°ê°€ {rows}í–‰ìœ¼ë¡œ ì‘ìŠµë‹ˆë‹¤.",
                        evidence=[f"í–‰ ìˆ˜: {rows}"],
                        confidence=0.95,
                        impact_score=0.6,
                        business_implications=["í†µê³„ì  ìœ ì˜ì„± ì œí•œ", "ë” ë§ì€ ë°ì´í„° ìˆ˜ì§‘ í•„ìš”"]
                    ))
                elif rows > 100000:
                    insights.append(Insight(
                        insight_id="large_dataset",
                        insight_type=InsightType.DESCRIPTIVE,
                        title="ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹",
                        description=f"ë°ì´í„°ì…‹ í¬ê¸°ê°€ {rows:,}í–‰ìœ¼ë¡œ ëŒ€ìš©ëŸ‰ì…ë‹ˆë‹¤.",
                        evidence=[f"í–‰ ìˆ˜: {rows:,}"],
                        confidence=0.95,
                        impact_score=0.7,
                        business_implications=["ê³ ê¸‰ ë¶„ì„ ê¸°ë²• ì ìš© ê°€ëŠ¥", "ì²˜ë¦¬ ì„±ëŠ¥ ê³ ë ¤ í•„ìš”"]
                    ))
        
        # ì²˜ë¦¬ ì‹œê°„ ë¶„ì„
        if "processing_time" in results:
            proc_time = results["processing_time"]
            if proc_time > 60:  # 1ë¶„ ì´ìƒ
                insights.append(Insight(
                    insight_id="long_processing_time",
                    insight_type=InsightType.DIAGNOSTIC,
                    title="ê¸´ ì²˜ë¦¬ ì‹œê°„",
                    description=f"ë¶„ì„ ì²˜ë¦¬ ì‹œê°„ì´ {proc_time:.1f}ì´ˆë¡œ ê¹ë‹ˆë‹¤.",
                    evidence=[f"ì²˜ë¦¬ ì‹œê°„: {proc_time:.1f}ì´ˆ"],
                    confidence=0.9,
                    impact_score=0.5,
                    business_implications=["ì„±ëŠ¥ ìµœì í™” í•„ìš”", "ë¦¬ì†ŒìŠ¤ ì¦ì„¤ ê³ ë ¤"]
                ))
        
        return insights
    
    def _generate_key_findings(self, insights: List[Insight], results: Dict[str, Any]) -> List[str]:
        """í•µì‹¬ ë°œê²¬ì‚¬í•­ ìƒì„±"""
        findings = []
        
        # ë†’ì€ ì˜í–¥ë„ì˜ ì¸ì‚¬ì´íŠ¸ë¥¼ í•µì‹¬ ë°œê²¬ì‚¬í•­ìœ¼ë¡œ
        high_impact_insights = [i for i in insights if i.impact_score > 0.7]
        for insight in high_impact_insights[:5]:
            findings.append(f"{insight.title}: {insight.description}")
        
        # ê²°ê³¼ ê¸°ë°˜ ë°œê²¬ì‚¬í•­ ì¶”ê°€
        if "summary" in results:
            summary = results["summary"]
            if isinstance(summary, dict):
                for key, value in summary.items():
                    if isinstance(value, (int, float)):
                        findings.append(f"{key}: {value}")
        
        # ìµœì†Œ í•œ ê°œì˜ ë°œê²¬ì‚¬í•­ ë³´ì¥
        if not findings:
            findings.append("ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ìƒì„¸ ì¸ì‚¬ì´íŠ¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        
        return findings[:7]  # ìµœëŒ€ 7ê°œ
    
    def _generate_analysis_summary(
        self, 
        key_findings: List[str], 
        insights: List[Insight], 
        recommendations: List[Recommendation]
    ) -> str:
        """ë¶„ì„ ìš”ì•½ ìƒì„±"""
        summary_parts = []
        
        # í•µì‹¬ ë°œê²¬ì‚¬í•­ ìš”ì•½
        if key_findings:
            summary_parts.append(f"ì£¼ìš” ë°œê²¬ì‚¬í•­: {len(key_findings)}ê°œì˜ í•µì‹¬ ì¸ì‚¬ì´íŠ¸ê°€ ë„ì¶œë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # ì¸ì‚¬ì´íŠ¸ ìœ í˜•ë³„ ë¶„ë¥˜
        if insights:
            insight_types = {}
            for insight in insights:
                insight_type = insight.insight_type.value
                insight_types[insight_type] = insight_types.get(insight_type, 0) + 1
            
            type_summary = ", ".join([f"{k} {v}ê°œ" for k, v in insight_types.items()])
            summary_parts.append(f"ì¸ì‚¬ì´íŠ¸ êµ¬ì„±: {type_summary}")
        
        # ì¶”ì²œì‚¬í•­ ìš°ì„ ìˆœìœ„ ìš”ì•½
        if recommendations:
            priority_counts = {}
            for rec in recommendations:
                priority = rec.priority.value
                priority_counts[priority] = priority_counts.get(priority, 0) + 1
            
            high_priority = priority_counts.get("high", 0) + priority_counts.get("critical", 0)
            if high_priority > 0:
                summary_parts.append(f"ë†’ì€ ìš°ì„ ìˆœìœ„ ì•¡ì…˜ ì•„ì´í…œ: {high_priority}ê°œ")
        
        # ì‹ ë¢°ë„ ë° í’ˆì§ˆ ì–¸ê¸‰
        high_confidence_insights = [i for i in insights if i.confidence > 0.8]
        if high_confidence_insights:
            summary_parts.append(f"ë†’ì€ ì‹ ë¢°ë„ ì¸ì‚¬ì´íŠ¸: {len(high_confidence_insights)}ê°œ")
        
        return " ".join(summary_parts) if summary_parts else "ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."
    
    def _generate_next_steps(self, insights: List[Insight], recommendations: List[Recommendation]) -> List[str]:
        """ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ"""
        next_steps = []
        
        # ê¸´ê¸‰í•œ ì¶”ì²œì‚¬í•­ì„ ë‹¤ìŒ ë‹¨ê³„ë¡œ
        urgent_recs = [r for r in recommendations if r.priority in [Priority.CRITICAL, Priority.HIGH]]
        for rec in urgent_recs[:3]:
            if rec.action_steps:
                next_steps.append(f"{rec.title}: {rec.action_steps[0]}")
            else:
                next_steps.append(rec.title)
        
        # ì¶”ê°€ ë¶„ì„ ì œì•ˆ
        predictive_insights = [i for i in insights if i.insight_type == InsightType.PREDICTIVE]
        if not predictive_insights and len(insights) >= 2:
            next_steps.append("ì˜ˆì¸¡ ë¶„ì„ì„ í†µí•œ ë¯¸ë˜ íŠ¸ë Œë“œ íŒŒì•…")
        
        # ì‹œê°í™” ì œì•ˆ
        if not any("ì‹œê°í™”" in step for step in next_steps):
            next_steps.append("í•µì‹¬ ì¸ì‚¬ì´íŠ¸ë¥¼ ìœ„í•œ ì‹œê°í™” ëŒ€ì‹œë³´ë“œ êµ¬ì¶•")
        
        # ê¸°ë³¸ ë‹¤ìŒ ë‹¨ê³„
        if not next_steps:
            next_steps = [
                "ì¶”ê°€ ë°ì´í„° ìˆ˜ì§‘ ë° ê²€ì¦",
                "ê²°ê³¼ì— ëŒ€í•œ ë„ë©”ì¸ ì „ë¬¸ê°€ ê²€í† ",
                "ë¹„ì¦ˆë‹ˆìŠ¤ ì˜ì‚¬ê²°ì • ë°˜ì˜"
            ]
        
        return next_steps[:5]  # ìµœëŒ€ 5ê°œ
    
    def _calculate_overall_confidence(self, insights: List[Insight], results: Dict[str, Any]) -> float:
        """ì „ì²´ ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚°"""
        if not insights:
            return 0.5  # ê¸°ë³¸ê°’
        
        # ì¸ì‚¬ì´íŠ¸ë“¤ì˜ ê°€ì¤‘ í‰ê·  ì‹ ë¢°ë„
        weighted_confidence = sum(i.confidence * i.impact_score for i in insights)
        total_weight = sum(i.impact_score for i in insights)
        
        if total_weight == 0:
            return 0.5
        
        base_confidence = weighted_confidence / total_weight
        
        # ë°ì´í„° í’ˆì§ˆì— ë”°ë¥¸ ì¡°ì •
        data_quality_factor = 1.0
        if "data_quality_score" in results:
            quality_score = results["data_quality_score"]
            data_quality_factor = quality_score
        
        # ê²°ê³¼ ì¼ê´€ì„±ì— ë”°ë¥¸ ì¡°ì •
        consistency_factor = 1.0
        if len(insights) >= 3:
            # ì„œë¡œ ëª¨ìˆœë˜ëŠ” ì¸ì‚¬ì´íŠ¸ê°€ ìˆëŠ”ì§€ í™•ì¸ (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±)
            contradictory_count = 0
            for i, insight1 in enumerate(insights):
                for insight2 in insights[i+1:]:
                    if insight1.insight_type != insight2.insight_type:
                        if abs(insight1.impact_score - insight2.impact_score) > 0.5:
                            contradictory_count += 1
            
            if contradictory_count > 0:
                consistency_factor = max(0.7, 1.0 - (contradictory_count * 0.1))
        
        final_confidence = base_confidence * data_quality_factor * consistency_factor
        return max(0.0, min(1.0, final_confidence))
    
    def _assess_business_value(self, insights: List[Insight], recommendations: List[Recommendation]) -> str:
        """ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜ í‰ê°€"""
        # ë†’ì€ ì˜í–¥ë„ ì¸ì‚¬ì´íŠ¸ ìˆ˜
        high_impact_count = len([i for i in insights if i.impact_score > 0.7])
        
        # ì‹¤í–‰ ê°€ëŠ¥í•œ ì¶”ì²œì‚¬í•­ ìˆ˜
        actionable_recs = len([r for r in recommendations if r.action_steps])
        
        # ë¹„ì¦ˆë‹ˆìŠ¤ ì˜ë¯¸ê°€ ìˆëŠ” ì¸ì‚¬ì´íŠ¸ ìˆ˜
        business_insights = len([i for i in insights if i.business_implications])
        
        # ê°€ì¹˜ í‰ê°€
        if high_impact_count >= 3 and actionable_recs >= 2:
            return "ë†’ìŒ - ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ ê³ ì˜í–¥ ì¸ì‚¬ì´íŠ¸ ë‹¤ìˆ˜ ë°œê²¬"
        elif high_impact_count >= 2 or actionable_recs >= 3:
            return "ì¤‘ê°„ - ìœ ì˜ë¯¸í•œ ì¸ì‚¬ì´íŠ¸ì™€ ì‹¤í–‰ ë°©ì•ˆ í™•ë³´"
        elif business_insights >= 1:
            return "ë‚®ìŒ - ì¼ë¶€ ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ í™•ì¸"
        else:
            return "ì œí•œì  - ì¶”ê°€ ë¶„ì„ ë° ë°ì´í„° ìˆ˜ì§‘ í•„ìš”"
    
    def get_interpretation_history(self, session_id: Optional[str] = None, limit: int = 10) -> List[InterpretationResult]:
        """í•´ì„ íˆìŠ¤í† ë¦¬ ì¡°íšŒ"""
        if session_id:
            filtered_history = [h for h in self.interpretation_history if h.session_id == session_id]
            return filtered_history[-limit:]
        else:
            return self.interpretation_history[-limit:]
    
    def generate_comprehensive_report(self, interpretation: InterpretationResult) -> str:
        """ì¢…í•© ë³´ê³ ì„œ ìƒì„±"""
        report = f"""# ë°ì´í„° ë¶„ì„ ì¢…í•© ë³´ê³ ì„œ

**ì„¸ì…˜ ID**: {interpretation.session_id}
**ë¶„ì„ ì¼ì‹œ**: {interpretation.interpretation_timestamp}
**ì‹ ë¢°ë„ ì ìˆ˜**: {interpretation.confidence_score:.1%}

## ğŸ“Š ë¶„ì„ ìš”ì•½
{interpretation.analysis_summary}

## ğŸ” í•µì‹¬ ë°œê²¬ì‚¬í•­
{chr(10).join(f'- {finding}' for finding in interpretation.key_findings)}

## ğŸ’¡ ì£¼ìš” ì¸ì‚¬ì´íŠ¸
"""
        
        for i, insight in enumerate(interpretation.insights[:5], 1):
            report += f"""
### {i}. {insight.title}
- **ìœ í˜•**: {insight.insight_type.value}
- **ì„¤ëª…**: {insight.description}
- **ì‹ ë¢°ë„**: {insight.confidence:.1%}
- **ì˜í–¥ë„**: {insight.impact_score:.1%}
"""
            if insight.evidence:
                report += f"- **ê·¼ê±°**: {', '.join(insight.evidence[:3])}\n"
            if insight.business_implications:
                report += f"- **ë¹„ì¦ˆë‹ˆìŠ¤ ì˜ë¯¸**: {', '.join(insight.business_implications[:2])}\n"
        
        report += f"""
## ğŸ¯ ì¶”ì²œì‚¬í•­
"""
        
        for i, rec in enumerate(interpretation.recommendations[:5], 1):
            report += f"""
### {i}. {rec.title} ({rec.priority.value.upper()})
- **ì„¤ëª…**: {rec.description}
- **ì´ìœ **: {rec.rationale}
- **ì˜ˆìƒ ë…¸ë ¥**: {rec.estimated_effort or 'N/A'}
- **ì˜ˆìƒ íš¨ê³¼**: {rec.expected_impact or 'N/A'}
"""
            if rec.action_steps:
                report += f"- **ì‹¤í–‰ ë‹¨ê³„**: {', '.join(rec.action_steps[:3])}\n"
        
        report += f"""
## ğŸš€ ë‹¤ìŒ ë‹¨ê³„
{chr(10).join(f'- {step}' for step in interpretation.next_steps)}

## ğŸ’° ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜
{interpretation.business_value or 'í‰ê°€ ì¤‘'}

---
*ë³¸ ë³´ê³ ì„œëŠ” AI ê¸°ë°˜ ì§€ëŠ¥í˜• ë¶„ì„ ì‹œìŠ¤í…œì— ì˜í•´ ìë™ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.*
"""
        
        return report


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
_interpreter_instance = None


def get_intelligent_result_interpreter(config: Optional[Dict] = None) -> IntelligentResultInterpreter:
    """Intelligent Result Interpreter ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _interpreter_instance
    if _interpreter_instance is None:
        _interpreter_instance = IntelligentResultInterpreter(config)
    return _interpreter_instance


# í¸ì˜ í•¨ìˆ˜ë“¤
def interpret_analysis_results(
    session_id: str,
    results: Dict[str, Any],
    context: Optional[Dict[str, Any]] = None,
    data_profile: Optional[DataProfile] = None
) -> InterpretationResult:
    """ë¶„ì„ ê²°ê³¼ í•´ì„ í¸ì˜ í•¨ìˆ˜"""
    interpreter = get_intelligent_result_interpreter()
    return interpreter.interpret_results(session_id, results, context, data_profile)


def generate_insight_report(interpretation: InterpretationResult) -> str:
    """ì¸ì‚¬ì´íŠ¸ ë³´ê³ ì„œ ìƒì„± í¸ì˜ í•¨ìˆ˜"""
    interpreter = get_intelligent_result_interpreter()
    return interpreter.generate_comprehensive_report(interpretation)


# CLI í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
def test_intelligent_result_interpreter():
    """Intelligent Result Interpreter í…ŒìŠ¤íŠ¸"""
    print("ğŸ§  Intelligent Result Interpreter í…ŒìŠ¤íŠ¸ ì‹œì‘\n")
    
    interpreter = get_intelligent_result_interpreter()
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„
    sample_results = {
        "statistics": {
            "mean": 75.5,
            "std": 12.3,
            "correlations": {
                "var1_var2": 0.85,
                "var1_var3": 0.23,
                "var2_var3": 0.78
            }
        },
        "data_size": {
            "rows": 1500,
            "columns": 8
        },
        "processing_time": 45.2,
        "visualization": {
            "distribution_type": "normal",
            "trend": "increasing"
        }
    }
    
    # ë°ì´í„° í”„ë¡œíŒŒì¼ ì‹œë®¬ë ˆì´ì…˜
    if PANDAS_AVAILABLE:
        from core.auto_data_profiler import DataProfile, DataQuality
        sample_profile = DataProfile(
            dataset_name="Sample Dataset",
            shape=(1500, 8),
            memory_usage=12.5,
            dtypes_summary={"float64": 6, "object": 2},
            overall_quality=DataQuality.GOOD,
            quality_score=0.82,
            columns=[],
            detected_patterns=[],
            missing_percentage=8.5,
            duplicate_percentage=2.1,
            key_insights=["Good data quality", "Manageable missing values"],
            recommendations=["Handle missing values", "Consider outlier analysis"]
        )
    else:
        sample_profile = None
    
    print("ğŸ“Š ìƒ˜í”Œ ë¶„ì„ ê²°ê³¼ í•´ì„:")
    
    # ê²°ê³¼ í•´ì„ ì‹¤í–‰
    interpretation = interpreter.interpret_results(
        session_id="test_session_001",
        results=sample_results,
        context={"domain": "business_analytics", "goal": "performance_analysis"},
        data_profile=sample_profile
    )
    
    print(f"âœ… í•´ì„ ì™„ë£Œ!")
    print(f"ğŸ“ˆ ì‹ ë¢°ë„ ì ìˆ˜: {interpretation.confidence_score:.1%}")
    print(f"ğŸ” ì¸ì‚¬ì´íŠ¸ ìˆ˜: {len(interpretation.insights)}")
    print(f"ğŸ¯ ì¶”ì²œì‚¬í•­ ìˆ˜: {len(interpretation.recommendations)}")
    
    print(f"\nğŸ’¡ ì£¼ìš” ì¸ì‚¬ì´íŠ¸:")
    for i, insight in enumerate(interpretation.insights[:3], 1):
        print(f"  {i}. {insight.title}")
        print(f"     â†’ {insight.description}")
        print(f"     â†’ ì‹ ë¢°ë„: {insight.confidence:.1%}, ì˜í–¥ë„: {insight.impact_score:.1%}")
    
    print(f"\nğŸ¯ ìš°ì„ ìˆœìœ„ ì¶”ì²œì‚¬í•­:")
    for i, rec in enumerate(interpretation.recommendations[:3], 1):
        print(f"  {i}. [{rec.priority.value.upper()}] {rec.title}")
        print(f"     â†’ {rec.description}")
        if rec.action_steps:
            print(f"     â†’ ì²« ë²ˆì§¸ ë‹¨ê³„: {rec.action_steps[0]}")
    
    print(f"\nğŸš€ ë‹¤ìŒ ë‹¨ê³„:")
    for i, step in enumerate(interpretation.next_steps, 1):
        print(f"  {i}. {step}")
    
    # ë³´ê³ ì„œ ìƒì„± í…ŒìŠ¤íŠ¸
    print(f"\nğŸ“„ ì¢…í•© ë³´ê³ ì„œ ìƒì„± í…ŒìŠ¤íŠ¸:")
    report = interpreter.generate_comprehensive_report(interpretation)
    report_preview = report[:300] + "..." if len(report) > 300 else report
    print(f"ë³´ê³ ì„œ ë¯¸ë¦¬ë³´ê¸°:\n{report_preview}")
    print(f"ì „ì²´ ë³´ê³ ì„œ ê¸¸ì´: {len(report):,} ë¬¸ì")
    
    # íˆìŠ¤í† ë¦¬ í…ŒìŠ¤íŠ¸
    print(f"\nğŸ“‹ í•´ì„ íˆìŠ¤í† ë¦¬:")
    history = interpreter.get_interpretation_history(limit=3)
    for i, hist in enumerate(history, 1):
        print(f"  {i}. {hist.session_id} ({hist.interpretation_timestamp})")
        print(f"     â†’ ì¸ì‚¬ì´íŠ¸: {len(hist.insights)}ê°œ, ì¶”ì²œì‚¬í•­: {len(hist.recommendations)}ê°œ")
    
    print(f"\nâœ… Intelligent Result Interpreter í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")


if __name__ == "__main__":
    test_intelligent_result_interpreter() 