"""
Cherry AI Universal Engine UI - ë©”ì¸ UI ì»¨íŠ¸ë¡¤ëŸ¬

ìš”êµ¬ì‚¬í•­ 10.1ì— ë”°ë¥¸ êµ¬í˜„:
- ê¸°ì¡´ ChatGPT ìŠ¤íƒ€ì¼ ì¸í„°í˜ì´ìŠ¤ ìœ ì§€
- Universal Engine ìƒíƒœ ë° A2A ì—ì´ì „íŠ¸ ìˆ˜ í‘œì‹œ
- ì‚¬ì´ë“œë°”ì— Universal Engine ì œì–´íŒ êµ¬í˜„
- ì™„ì „íˆ ìƒˆë¡œìš´ LLM First ë¶„ì„ ì‹¤í–‰
"""

import streamlit as st
import asyncio
import logging
from typing import Dict, List, Any, Optional
from datetime import datetime
import json

from ..universal_query_processor import UniversalQueryProcessor
from ..a2a_integration.a2a_agent_discovery import A2AAgentDiscoverySystem
from ..a2a_integration.llm_based_agent_selector import LLMBasedAgentSelector
from ..a2a_integration.a2a_workflow_orchestrator import A2AWorkflowOrchestrator
from ..a2a_integration.a2a_communication_protocol import A2ACommunicationProtocol
from ..a2a_integration.a2a_result_integrator import A2AResultIntegrator

logger = logging.getLogger(__name__)


class CherryAIUniversalEngineUI:
    """
    Cherry AI Universal Engine UI ì»¨íŠ¸ë¡¤ëŸ¬
    - ê¸°ì¡´ Cherry AI ë¸Œëœë”© ë° ì¸í„°í˜ì´ìŠ¤ ìœ ì§€
    - Universal Engine + A2A ì—ì´ì „íŠ¸ ì™„ì „ í†µí•©
    - ChatGPT ìŠ¤íƒ€ì¼ ì‚¬ìš©ì ê²½í—˜ ì œê³µ
    """
    
    def __init__(self):
        """CherryAIUniversalEngineUI ì´ˆê¸°í™”"""
        self.universal_engine = None
        self.a2a_discovery = None
        self.agent_selector = None
        self.workflow_orchestrator = None
        self.communication_protocol = None
        self.result_integrator = None
        self.available_agents = {}
        self.initialization_complete = False
        
        # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
        self._initialize_session_state()
        logger.info("CherryAIUniversalEngineUI initialized")
    
    def _initialize_session_state(self):
        """Streamlit ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
        if 'messages' not in st.session_state:
            st.session_state.messages = []
        
        if 'universal_engine_status' not in st.session_state:
            st.session_state.universal_engine_status = "initializing"
        
        if 'available_agents' not in st.session_state:
            st.session_state.available_agents = {}
        
        if 'show_reasoning' not in st.session_state:
            st.session_state.show_reasoning = True
        
        if 'reasoning_depth' not in st.session_state:
            st.session_state.reasoning_depth = "ê¸°ë³¸"
        
        if 'expertise_level' not in st.session_state:
            st.session_state.expertise_level = "ìë™ ê°ì§€"
        
        if 'total_analyses' not in st.session_state:
            st.session_state.total_analyses = 0
        
        if 'avg_response_time' not in st.session_state:
            st.session_state.avg_response_time = 0.0
        
        if 'satisfaction_score' not in st.session_state:
            st.session_state.satisfaction_score = 0.0
        
        if 'current_data' not in st.session_state:
            st.session_state.current_data = None
        
        if 'user_profile' not in st.session_state:
            st.session_state.user_profile = {}
        
        if 'show_agent_details' not in st.session_state:
            st.session_state.show_agent_details = True
    
    async def initialize_system(self) -> bool:
        """
        Universal Engine + A2A ì‹œìŠ¤í…œ ì™„ì „ ì´ˆê¸°í™”
        
        Returns:
            ì´ˆê¸°í™” ì„±ê³µ ì—¬ë¶€
        """
        try:
            with st.spinner("ğŸ§  Universal Engine ì´ˆê¸°í™” ì¤‘..."):
                # 1. Universal Engine ì´ˆê¸°í™”
                self.universal_engine = UniversalQueryProcessor()
                
                # 2. A2A ì‹œìŠ¤í…œ ì´ˆê¸°í™”
                self.communication_protocol = A2ACommunicationProtocol()
                self.a2a_discovery = A2AAgentDiscoverySystem()
                self.agent_selector = LLMBasedAgentSelector(self.a2a_discovery)
                self.workflow_orchestrator = A2AWorkflowOrchestrator(self.communication_protocol)
                self.result_integrator = A2AResultIntegrator()
                
                # 3. A2A ì—ì´ì „íŠ¸ ë°œê²¬
                st.write("ğŸ” A2A ì—ì´ì „íŠ¸ ë°œê²¬ ì¤‘...")
                await self.a2a_discovery.start_discovery()
                self.available_agents = self.a2a_discovery.get_available_agents()
                
                # 4. ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸
                st.session_state.universal_engine_status = "active"
                st.session_state.available_agents = {
                    agent_id: {
                        'name': agent.name,
                        'port': agent.port,
                        'status': agent.status,
                        'capabilities': agent.capabilities
                    }
                    for agent_id, agent in self.available_agents.items()
                }
                
                self.initialization_complete = True
                
                st.success(f"âœ… ì´ˆê¸°í™” ì™„ë£Œ! {len(self.available_agents)}ê°œ A2A ì—ì´ì „íŠ¸ ë°œê²¬ë¨")
                return True
                
        except Exception as e:
            logger.error(f"System initialization failed: {e}")
            st.error(f"âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            st.session_state.universal_engine_status = "error"
            return False
    
    def render_header(self):
        """ğŸ’ Cherry AI ë¸Œëœë”© í—¤ë” ìœ ì§€ + Universal Engine ìƒíƒœ í‘œì‹œ"""
        col1, col2, col3, col4 = st.columns([3, 1, 1, 1])
        
        with col1:
            st.markdown("# ğŸ’ Cherry AI - LLM First Universal Engine")
            st.caption("Zero Hardcoding â€¢ Universal Adaptability â€¢ Self-Discovering")
        
        with col2:
            # Universal Engine ìƒíƒœ
            status = st.session_state.get('universal_engine_status', 'initializing')
            status_icons = {
                'initializing': 'ğŸ”„',
                'active': 'ğŸŸ¢',
                'error': 'ğŸ”´',
                'maintenance': 'ğŸŸ¡'
            }
            st.markdown(f"{status_icons.get(status, 'â“')} **Universal Engine**")
            st.caption(f"ìƒíƒœ: {status}")
        
        with col3:
            # A2A ì—ì´ì „íŠ¸ ìˆ˜
            agent_count = len(st.session_state.get('available_agents', {}))
            st.markdown(f"ğŸ¤– **A2A ì—ì´ì „íŠ¸**")
            st.caption(f"{agent_count}ê°œ í™œì„±")
        
        with col4:
            # ì„¤ì • ë²„íŠ¼
            if st.button("âš™ï¸ ì„¤ì •", key="settings_button"):
                st.session_state.show_settings = True
    
    def render_sidebar(self):
        """ğŸ”§ ì—ì´ì „íŠ¸ ìƒíƒœ ë° ì„¤ì • ì‚¬ì´ë“œë°” + Universal Engine ì œì–´"""
        with st.sidebar:
            st.header("ğŸ”§ Universal Engine ì œì–´")
            
            # ì‹œìŠ¤í…œ ì´ˆê¸°í™” ë²„íŠ¼
            if not self.initialization_complete:
                if st.button("ğŸš€ ì‹œìŠ¤í…œ ì´ˆê¸°í™”", key="init_button"):
                    asyncio.run(self.initialize_system())
            
            # ë©”íƒ€ ì¶”ë¡  ì„¤ì •
            st.subheader("ğŸ§  ë©”íƒ€ ì¶”ë¡  ì„¤ì •")
            st.session_state.show_reasoning = st.checkbox(
                "ì¶”ë¡  ê³¼ì • í‘œì‹œ", 
                value=st.session_state.get('show_reasoning', True)
            )
            
            st.session_state.reasoning_depth = st.selectbox(
                "ì¶”ë¡  ê¹Šì´", 
                ["ê¸°ë³¸", "ìƒì„¸", "ì „ë¬¸ê°€"],
                index=["ê¸°ë³¸", "ìƒì„¸", "ì „ë¬¸ê°€"].index(st.session_state.get('reasoning_depth', 'ê¸°ë³¸'))
            )
            
            # A2A Agent ìƒíƒœ
            st.subheader("ğŸ¤– A2A ì—ì´ì „íŠ¸ ìƒíƒœ")
            agents = st.session_state.get('available_agents', {})
            
            if agents:
                for agent_id, agent_info in agents.items():
                    status_icon = "ğŸŸ¢" if agent_info.get('status') == "active" else "ğŸ”´"
                    st.write(f"{status_icon} **{agent_info.get('name', 'Unknown')}**")
                    st.caption(f"í¬íŠ¸: {agent_info.get('port', 'N/A')}")
                    
                    # ì—ì´ì „íŠ¸ ìƒì„¸ ì •ë³´ (ì ‘ê¸°/í¼ì¹˜ê¸°)
                    with st.expander(f"{agent_info.get('name', 'Unknown')} ìƒì„¸ì •ë³´"):
                        st.write("**ëŠ¥ë ¥:**")
                        for capability in agent_info.get('capabilities', []):
                            st.write(f"â€¢ {capability}")
            else:
                st.info("ì‚¬ìš© ê°€ëŠ¥í•œ ì—ì´ì „íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
                if st.button("ğŸ”„ ì—ì´ì „íŠ¸ ì¬ë°œê²¬"):
                    if self.a2a_discovery:
                        asyncio.run(self.a2a_discovery.rediscover_agents())
                        st.rerun()
            
            # ì‚¬ìš©ì í”„ë¡œí•„ ì„¤ì •
            st.subheader("ğŸ‘¤ ì‚¬ìš©ì í”„ë¡œí•„")
            st.session_state.expertise_level = st.selectbox(
                "ì „ë¬¸ì„± ìˆ˜ì¤€", 
                ["ìë™ ê°ì§€", "ì´ˆë³´ì", "ì¤‘ê¸‰ì", "ì „ë¬¸ê°€"],
                index=["ìë™ ê°ì§€", "ì´ˆë³´ì", "ì¤‘ê¸‰ì", "ì „ë¬¸ê°€"].index(
                    st.session_state.get('expertise_level', 'ìë™ ê°ì§€')
                )
            )
            
            # Universal Engine í†µê³„
            st.subheader("ğŸ“Š ì—”ì§„ í†µê³„")
            st.metric("ì´ ë¶„ì„ ìˆ˜í–‰", st.session_state.get('total_analyses', 0))
            st.metric("í‰ê·  ì‘ë‹µ ì‹œê°„", f"{st.session_state.get('avg_response_time', 0):.1f}ì´ˆ")
            st.metric("ì‚¬ìš©ì ë§Œì¡±ë„", f"{st.session_state.get('satisfaction_score', 0):.1f}/5.0")
            
            # ê³ ê¸‰ ì„¤ì •
            with st.expander("ğŸ”§ ê³ ê¸‰ ì„¤ì •"):
                st.session_state.show_agent_details = st.checkbox(
                    "ì—ì´ì „íŠ¸ í˜‘ì—… ìƒì„¸ í‘œì‹œ",
                    value=st.session_state.get('show_agent_details', True)
                )
                
                # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
                if st.button("ğŸ“ˆ ì„±ëŠ¥ ë¦¬í¬íŠ¸ ë³´ê¸°"):
                    self._show_performance_report()
                
                # ì‹œìŠ¤í…œ ì¬ì‹œì‘
                if st.button("ğŸ”„ ì‹œìŠ¤í…œ ì¬ì‹œì‘"):
                    self._restart_system()
    
    def render_chat_interface(self):
        """ğŸ’¬ ChatGPT ìŠ¤íƒ€ì¼ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ ìœ ì§€ + ë©”íƒ€ ì¶”ë¡  í‘œì‹œ"""
        # ê¸°ì¡´ ì±„íŒ… ë©”ì‹œì§€ í‘œì‹œ
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.write(message["content"])
                
                # Universal Engine ë©”íƒ€ ì¶”ë¡  ê²°ê³¼ í‘œì‹œ
                if message.get("meta_reasoning") and st.session_state.get('show_reasoning', True):
                    with st.expander("ğŸ§  ë©”íƒ€ ì¶”ë¡  ê³¼ì •", expanded=False):
                        self._render_meta_reasoning(message["meta_reasoning"])
                
                # A2A Agent ê¸°ì—¬ë„ í‘œì‹œ
                if message.get("agent_contributions") and st.session_state.get('show_agent_details', True):
                    with st.expander("ğŸ¤– ì—ì´ì „íŠ¸ í˜‘ì—…", expanded=False):
                        self._render_agent_contributions(message["agent_contributions"])
        
        # ì‚¬ìš©ì ì…ë ¥
        if prompt := st.chat_input("ë¶„ì„í•˜ê³  ì‹¶ì€ ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”..."):
            # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
            st.session_state.messages.append({"role": "user", "content": prompt})
            
            with st.chat_message("user"):
                st.write(prompt)
            
            # Universal Engineìœ¼ë¡œ ë¶„ì„ ìˆ˜í–‰
            with st.chat_message("assistant"):
                asyncio.run(self._process_user_query(prompt))
    
    async def _process_user_query(self, query: str):
        """
        ì™„ì „íˆ ìƒˆë¡œìš´ LLM First ë¶„ì„ ì‹¤í–‰
        
        Args:
            query: ì‚¬ìš©ì ì¿¼ë¦¬
        """
        if not self.initialization_complete:
            st.error("ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ 'ì‹œìŠ¤í…œ ì´ˆê¸°í™”'ë¥¼ í´ë¦­í•˜ì„¸ìš”.")
            return
        
        start_time = datetime.now()
        
        try:
            # ì§„í–‰ ìƒí™© í‘œì‹œë¥¼ ìœ„í•œ í”Œë ˆì´ìŠ¤í™€ë”ë“¤
            status_placeholder = st.empty()
            progress_placeholder = st.empty()
            result_placeholder = st.empty()
            
            # 1. Universal Engineìœ¼ë¡œ ë©”íƒ€ ì¶”ë¡  ìˆ˜í–‰
            status_placeholder.info("ğŸ§  ë©”íƒ€ ì¶”ë¡  ì¤‘...")
            
            meta_analysis = await self.universal_engine.meta_reasoning_engine.analyze_request(
                query=query,
                data=st.session_state.get('current_data'),
                context=self._get_session_context()
            )
            
            if st.session_state.get('show_reasoning', True):
                with st.expander("ğŸ§  ë©”íƒ€ ì¶”ë¡  ê²°ê³¼", expanded=False):
                    self._render_meta_reasoning(meta_analysis)
            
            # 2. A2A Agent ë™ì  ì„ íƒ ë° í˜‘ì—…
            status_placeholder.info("ğŸ¤– A2A ì—ì´ì „íŠ¸ ì„ íƒ ì¤‘...")
            
            if self.available_agents:
                selection_result = await self.agent_selector.select_agents_for_query(
                    meta_analysis=meta_analysis,
                    query=query,
                    data_info=self._get_data_info(),
                    user_preferences=self._get_user_preferences()
                )
                
                # ì„ íƒëœ ì—ì´ì „íŠ¸ í‘œì‹œ
                if selection_result.selected_agents:
                    status_placeholder.success(f"âœ… {len(selection_result.selected_agents)}ê°œ ì—ì´ì „íŠ¸ ì„ íƒë¨")
                    
                    # ì—ì´ì „íŠ¸ ì„ íƒ ì •ë³´ í‘œì‹œ
                    cols = st.columns(min(len(selection_result.selected_agents), 4))
                    for i, agent in enumerate(selection_result.selected_agents):
                        with cols[i % 4]:
                            st.write(f"ğŸ¤– **{agent.name}**")
                            st.caption(f"í¬íŠ¸: {agent.port}")
                    
                    # 3. ì—ì´ì „íŠ¸ í˜‘ì—… ì‹¤í–‰ (ìŠ¤íŠ¸ë¦¬ë°)
                    status_placeholder.info("âš¡ ì—ì´ì „íŠ¸ í˜‘ì—… ì‹¤í–‰ ì¤‘...")
                    
                    progress_container = progress_placeholder.container()
                    
                    # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
                    workflow_result = None
                    async for progress_update in self.workflow_orchestrator.execute_workflow_with_streaming(
                        selection_result, query, st.session_state.get('current_data')
                    ):
                        self._update_progress_display(progress_container, progress_update)
                        
                        if progress_update.get('type') == 'workflow_completed':
                            workflow_result = progress_update.get('results')
                    
                    if workflow_result:
                        # 4. ê²°ê³¼ í†µí•© ë° ì ì‘ì  ì‘ë‹µ ìƒì„±
                        status_placeholder.info("ğŸ”„ ê²°ê³¼ í†µí•© ë° ì‘ë‹µ ìƒì„± ì¤‘...")
                        
                        # A2A ì‘ë‹µë“¤ì„ A2AResponse í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                        a2a_responses = self._convert_to_a2a_responses(workflow_result)
                        
                        # ê²°ê³¼ í†µí•©
                        integrated_result = await self.result_integrator.integrate_results(
                            responses=a2a_responses,
                            agents=selection_result.selected_agents,
                            original_query=query,
                            meta_analysis=meta_analysis
                        )
                        
                        # Universal Engineìœ¼ë¡œ ìµœì¢… ì ì‘í˜• ì‘ë‹µ ìƒì„±
                        final_response = await self.universal_engine.response_generator.generate_adaptive_response(
                            knowledge_result={'refined_result': integrated_result.consolidated_data},
                            user_profile=meta_analysis.get('user_profile', {}),
                            interaction_context=self._get_session_context()
                        )
                        
                        # ê²°ê³¼ í‘œì‹œ
                        self._display_final_response(result_placeholder, final_response, integrated_result)
                        
                        # ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸
                        self._update_session_statistics(start_time, True)
                        
                        # ë©”ì‹œì§€ ì´ë ¥ì— ì €ì¥
                        assistant_message = {
                            "role": "assistant",
                            "content": final_response.get('core_response', {}).get('summary', 'ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.'),
                            "meta_reasoning": meta_analysis,
                            "agent_contributions": integrated_result.agent_contributions,
                            "timestamp": datetime.now().isoformat()
                        }
                        st.session_state.messages.append(assistant_message)
                        
                    else:
                        st.error("ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
                
                else:
                    st.warning("ì„ íƒëœ ì—ì´ì „íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            else:
                # A2A ì—ì´ì „íŠ¸ê°€ ì—†ëŠ” ê²½ìš° Universal Engineë§Œìœ¼ë¡œ ì²˜ë¦¬
                status_placeholder.info("ğŸ§  Universal Engine ë‹¨ë… ë¶„ì„ ì¤‘...")
                
                result = await self.universal_engine.process_query(
                    query=query,
                    data=st.session_state.get('current_data'),
                    context=self._get_session_context()
                )
                
                # ê²°ê³¼ í‘œì‹œ
                if result.get('success'):
                    result_placeholder.success("âœ… ë¶„ì„ ì™„ë£Œ")
                    st.write(result.get('response', {}).get('core_response', {}).get('summary', 'ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.'))
                    
                    # ë©”ì‹œì§€ ì´ë ¥ì— ì €ì¥
                    assistant_message = {
                        "role": "assistant", 
                        "content": result.get('response', {}).get('core_response', {}).get('summary', 'ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.'),
                        "meta_reasoning": result.get('meta_analysis'),
                        "timestamp": datetime.now().isoformat()
                    }
                    st.session_state.messages.append(assistant_message)
                    
                    self._update_session_statistics(start_time, True)
                else:
                    st.error(f"ë¶„ì„ ì‹¤íŒ¨: {result.get('error', 'Unknown error')}")
                    self._update_session_statistics(start_time, False)
            
            # ìƒíƒœ í‘œì‹œ ì •ë¦¬
            status_placeholder.empty()
            progress_placeholder.empty()
            
        except Exception as e:
            logger.error(f"Error processing user query: {e}")
            st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            self._update_session_statistics(start_time, False)
    
    def _render_meta_reasoning(self, meta_analysis: Dict):
        """ë©”íƒ€ ì¶”ë¡  ê²°ê³¼ ë Œë”ë§"""
        if not meta_analysis:
            return
        
        # íƒ­ìœ¼ë¡œ 4ë‹¨ê³„ ì¶”ë¡  ê³¼ì • í‘œì‹œ
        tab1, tab2, tab3, tab4, tab5 = st.tabs([
            "ì´ˆê¸° ê´€ì°°", "ë‹¤ê°ë„ ë¶„ì„", "ìê°€ ê²€ì¦", "ì ì‘ì  ì‘ë‹µ", "í’ˆì§ˆ í‰ê°€"
        ])
        
        with tab1:
            if 'initial_analysis' in meta_analysis:
                st.json(meta_analysis['initial_analysis'])
        
        with tab2:
            if 'multi_perspective' in meta_analysis:
                st.json(meta_analysis['multi_perspective'])
        
        with tab3:
            if 'self_verification' in meta_analysis:
                st.json(meta_analysis['self_verification'])
        
        with tab4:
            if 'response_strategy' in meta_analysis:
                st.json(meta_analysis['response_strategy'])
        
        with tab5:
            if 'quality_assessment' in meta_analysis:
                st.json(meta_analysis['quality_assessment'])
    
    def _render_agent_contributions(self, agent_contributions: List):
        """ì—ì´ì „íŠ¸ ê¸°ì—¬ë„ ë Œë”ë§"""
        if not agent_contributions:
            return
        
        for contribution in agent_contributions:
            st.write(f"**{contribution.agent_name}** (ê¸°ì—¬ë„: {contribution.contribution_score:.2f})")
            
            col1, col2 = st.columns(2)
            with col1:
                st.write("**í’ˆì§ˆ ì ìˆ˜:**")
                st.write(f"â€¢ í’ˆì§ˆ: {contribution.quality_score:.2f}")
                st.write(f"â€¢ ê³ ìœ ì„±: {contribution.uniqueness_score:.2f}")
                st.write(f"â€¢ ì‹ ë¢°ì„±: {contribution.reliability_score:.2f}")
            
            with col2:
                st.write("**í•µì‹¬ ì¸ì‚¬ì´íŠ¸:**")
                for insight in contribution.key_insights[:3]:  # ìµœëŒ€ 3ê°œë§Œ í‘œì‹œ
                    st.write(f"â€¢ {insight}")
    
    def _update_progress_display(self, container, progress_update: Dict):
        """ì§„í–‰ ìƒí™© í‘œì‹œ ì—…ë°ì´íŠ¸"""
        update_type = progress_update.get('type')
        
        with container:
            if update_type == 'group_started':
                st.info(f"ê·¸ë£¹ {progress_update.get('group_index')}/{progress_update.get('total_groups')} ì‹œì‘")
                st.write(f"ì‹¤í–‰ ì—ì´ì „íŠ¸: {', '.join(progress_update.get('agents', []))}")
            
            elif update_type == 'group_progress':
                progress = progress_update.get('completed', 0) / max(progress_update.get('total', 1), 1)
                st.progress(progress)
                st.caption(f"ê·¸ë£¹ ì§„í–‰ë¥ : {progress_update.get('completed')}/{progress_update.get('total')}")
            
            elif update_type == 'overall_progress':
                st.progress(progress_update.get('progress', 0) / 100)
                st.caption(f"ì „ì²´ ì§„í–‰ë¥ : {progress_update.get('progress', 0):.1f}%")
    
    def _display_final_response(self, placeholder, final_response: Dict, integrated_result):
        """ìµœì¢… ì‘ë‹µ í‘œì‹œ"""
        with placeholder:
            st.success("âœ… ë¶„ì„ ì™„ë£Œ!")
            
            # í•µì‹¬ ì‘ë‹µ
            core_response = final_response.get('core_response', {})
            if core_response.get('summary'):
                st.write("### ğŸ“‹ ë¶„ì„ ìš”ì•½")
                st.write(core_response['summary'])
            
            # ì£¼ìš” ì¸ì‚¬ì´íŠ¸
            if core_response.get('main_insights'):
                st.write("### ğŸ’¡ ì£¼ìš” ì¸ì‚¬ì´íŠ¸")
                for insight in core_response['main_insights']:
                    st.write(f"â€¢ {insight.get('insight', '')}")
            
            # ê¶Œì¥ì‚¬í•­
            if core_response.get('recommendations'):
                st.write("### ğŸ¯ ê¶Œì¥ì‚¬í•­")
                for rec in core_response['recommendations']:
                    st.write(f"â€¢ {rec.get('action', '')}")
            
            # ì ì§„ì  ì •ë³´ ê³µê°œ ì˜µì…˜
            progressive_options = final_response.get('progressive_options', {})
            if progressive_options:
                st.write("### ğŸ” ë” ìì„¸íˆ ì•Œì•„ë³´ê¸°")
                
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    if st.button("ğŸ“Š ë” ìì„¸í•œ ë¶„ì„"):
                        st.session_state.disclosure_level = 'detailed'
                
                with col2:
                    if st.button("ğŸ”¬ ê¸°ìˆ ì  ìƒì„¸"):
                        st.session_state.disclosure_level = 'technical'
                
                with col3:
                    if st.button("ğŸ“ ê´€ë ¨ ì£¼ì œ íƒìƒ‰"):
                        st.session_state.disclosure_level = 'exploration'
    
    def _convert_to_a2a_responses(self, workflow_result: Dict) -> List:
        """ì›Œí¬í”Œë¡œìš° ê²°ê³¼ë¥¼ A2AResponse í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        from ..a2a_integration.a2a_communication_protocol import A2AResponse
        
        responses = []
        agent_results = workflow_result.get('agent_results', {})
        
        for agent_name, result_data in agent_results.items():
            response = A2AResponse(
                request_id=f"workflow_{agent_name}",
                agent_id=result_data.get('agent_id', agent_name),
                status="success",
                data=result_data.get('result', {}),
                metadata={},
                timestamp=datetime.now().isoformat(),
                execution_time=result_data.get('execution_time', 0.0)
            )
            responses.append(response)
        
        return responses
    
    def _get_session_context(self) -> Dict:
        """ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        return {
            'session_id': st.session_state.get('session_id', 'default'),
            'user_profile': st.session_state.get('user_profile', {}),
            'conversation_history': st.session_state.get('messages', [])[-5:],  # ìµœê·¼ 5ê°œ
            'settings': {
                'reasoning_depth': st.session_state.get('reasoning_depth', 'ê¸°ë³¸'),
                'expertise_level': st.session_state.get('expertise_level', 'ìë™ ê°ì§€'),
                'show_reasoning': st.session_state.get('show_reasoning', True)
            }
        }
    
    def _get_data_info(self) -> Dict:
        """í˜„ì¬ ë°ì´í„° ì •ë³´ ì¶”ì¶œ"""
        current_data = st.session_state.get('current_data')
        if current_data is None:
            return {'type': 'none', 'description': 'No data uploaded'}
        
        return {
            'type': type(current_data).__name__,
            'size': len(current_data) if hasattr(current_data, '__len__') else 'unknown',
            'description': 'User uploaded data'
        }
    
    def _get_user_preferences(self) -> Dict:
        """ì‚¬ìš©ì ì„ í˜¸ì‚¬í•­ ì¶”ì¶œ"""
        return {
            'expertise_level': st.session_state.get('expertise_level', 'ìë™ ê°ì§€'),
            'reasoning_depth': st.session_state.get('reasoning_depth', 'ê¸°ë³¸'),
            'show_agent_details': st.session_state.get('show_agent_details', True),
            'preferred_response_style': 'balanced'  # í–¥í›„ ì‚¬ìš©ì ì„¤ì •ìœ¼ë¡œ í™•ì¥ ê°€ëŠ¥
        }
    
    def _update_session_statistics(self, start_time: datetime, success: bool):
        """ì„¸ì…˜ í†µê³„ ì—…ë°ì´íŠ¸"""
        duration = (datetime.now() - start_time).total_seconds()
        
        st.session_state.total_analyses += 1
        
        # í‰ê·  ì‘ë‹µ ì‹œê°„ ì—…ë°ì´íŠ¸
        current_avg = st.session_state.get('avg_response_time', 0.0)
        total_analyses = st.session_state.get('total_analyses', 1)
        st.session_state.avg_response_time = (
            (current_avg * (total_analyses - 1) + duration) / total_analyses
        )
        
        # ì„±ê³µë¥  ê¸°ë°˜ ë§Œì¡±ë„ ì ìˆ˜ ì—…ë°ì´íŠ¸ (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±)
        if success:
            st.session_state.satisfaction_score = min(5.0, st.session_state.get('satisfaction_score', 0.0) + 0.1)
        else:
            st.session_state.satisfaction_score = max(0.0, st.session_state.get('satisfaction_score', 0.0) - 0.2)
    
    def _show_performance_report(self):
        """ì„±ëŠ¥ ë¦¬í¬íŠ¸ í‘œì‹œ"""
        st.write("### ğŸ“ˆ ì„±ëŠ¥ ë¦¬í¬íŠ¸")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.metric("ì´ ë¶„ì„ ìˆ˜", st.session_state.get('total_analyses', 0))
            st.metric("í‰ê·  ì‘ë‹µ ì‹œê°„", f"{st.session_state.get('avg_response_time', 0):.1f}ì´ˆ")
        
        with col2:
            st.metric("ì‚¬ìš©ì ë§Œì¡±ë„", f"{st.session_state.get('satisfaction_score', 0):.1f}/5.0")
            agent_count = len(st.session_state.get('available_agents', {}))
            st.metric("í™œì„± ì—ì´ì „íŠ¸", agent_count)
    
    def _restart_system(self):
        """ì‹œìŠ¤í…œ ì¬ì‹œì‘"""
        # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
        for key in list(st.session_state.keys()):
            if key.startswith(('universal_', 'available_', 'total_', 'avg_', 'satisfaction_')):
                del st.session_state[key]
        
        self.initialization_complete = False
        st.success("ì‹œìŠ¤í…œì´ ì¬ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì´ˆê¸°í™”í•´ì£¼ì„¸ìš”.")
        st.rerun()
    
    def render_enhanced_chat_interface(self):
        """
        í–¥ìƒëœ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ ë Œë”ë§
        - ë©”íƒ€ ì¶”ë¡  4ë‹¨ê³„ ê³¼ì • ì‹¤ì‹œê°„ í‘œì‹œ
        - A2A ì—ì´ì „íŠ¸ í˜‘ì—… ìƒíƒœ ì‹œê°í™”
        - ì ì§„ì  ì •ë³´ ê³µê°œ ì§€ì›
        """
        # ì±„íŒ… ì»¨í…Œì´ë„ˆ
        chat_container = st.container()
        
        with chat_container:
            # ê¸°ì¡´ ë©”ì‹œì§€ í‘œì‹œ (í–¥ìƒëœ ë²„ì „)
            for i, message in enumerate(st.session_state.messages):
                with st.chat_message(message["role"]):
                    # ê¸°ë³¸ ë©”ì‹œì§€ ë‚´ìš©
                    st.write(message["content"])
                    
                    # ë©”íƒ€ ì¶”ë¡  ê³¼ì • ì‹¤ì‹œê°„ í‘œì‹œ
                    if message.get("meta_reasoning") and st.session_state.get('show_reasoning', True):
                        self._render_enhanced_meta_reasoning(message["meta_reasoning"], f"meta_{i}")
                    
                    # A2A ì—ì´ì „íŠ¸ í˜‘ì—… ìƒíƒœ ì‹œê°í™”
                    if message.get("agent_contributions") and st.session_state.get('show_agent_details', True):
                        self._render_enhanced_agent_collaboration(message["agent_contributions"], f"agent_{i}")
                    
                    # ì ì§„ì  ì •ë³´ ê³µê°œ
                    if message["role"] == "assistant" and message.get("progressive_options"):
                        self._render_progressive_disclosure(message["progressive_options"], f"progressive_{i}")
                    
                    # ë©”ì‹œì§€ ì•¡ì…˜ ë²„íŠ¼
                    if message["role"] == "assistant":
                        self._render_message_actions(message, f"actions_{i}")
        
        # í–¥ìƒëœ ì…ë ¥ ì¸í„°í˜ì´ìŠ¤
        self._render_enhanced_input_interface()
    
    def _render_enhanced_meta_reasoning(self, meta_analysis: Dict, key_suffix: str):
        """í–¥ìƒëœ ë©”íƒ€ ì¶”ë¡  ê³¼ì • ì‹¤ì‹œê°„ í‘œì‹œ"""
        with st.expander("ğŸ§  ë©”íƒ€ ì¶”ë¡  4ë‹¨ê³„ ê³¼ì •", expanded=False):
            # ì§„í–‰ ìƒí™© í‘œì‹œ
            stages = ["ì´ˆê¸° ê´€ì°°", "ë‹¤ê°ë„ ë¶„ì„", "ìê°€ ê²€ì¦", "ì ì‘ì  ì‘ë‹µ", "í’ˆì§ˆ í‰ê°€"]
            completed_stages = sum(1 for stage in ['initial_analysis', 'multi_perspective', 'self_verification', 'response_strategy', 'quality_assessment'] 
                                 if stage in meta_analysis)
            
            # ì§„í–‰ë¥  ë°”
            progress = completed_stages / len(stages)
            st.progress(progress)
            st.caption(f"ë©”íƒ€ ì¶”ë¡  ì§„í–‰ë¥ : {completed_stages}/{len(stages)} ë‹¨ê³„ ì™„ë£Œ")
            
            # ê° ë‹¨ê³„ë³„ ìƒì„¸ ì •ë³´
            col1, col2 = st.columns(2)
            
            with col1:
                # 1ë‹¨ê³„: ì´ˆê¸° ê´€ì°°
                if 'initial_analysis' in meta_analysis:
                    st.success("âœ… 1ë‹¨ê³„: ì´ˆê¸° ê´€ì°°")
                    with st.expander("ìƒì„¸ ë³´ê¸°"):
                        initial = meta_analysis['initial_analysis']
                        st.write(f"**ì¿¼ë¦¬ ìœ í˜•:** {initial.get('query_type', 'Unknown')}")
                        st.write(f"**ë³µì¡ë„:** {initial.get('complexity_level', 'Unknown')}")
                        st.write(f"**ë„ë©”ì¸:** {initial.get('detected_domain', 'Unknown')}")
                else:
                    st.info("â³ 1ë‹¨ê³„: ì´ˆê¸° ê´€ì°°")
                
                # 2ë‹¨ê³„: ë‹¤ê°ë„ ë¶„ì„
                if 'multi_perspective' in meta_analysis:
                    st.success("âœ… 2ë‹¨ê³„: ë‹¤ê°ë„ ë¶„ì„")
                    with st.expander("ìƒì„¸ ë³´ê¸°"):
                        perspectives = meta_analysis['multi_perspective']
                        for perspective, analysis in perspectives.items():
                            st.write(f"**{perspective}:** {analysis}")
                else:
                    st.info("â³ 2ë‹¨ê³„: ë‹¤ê°ë„ ë¶„ì„")
                
                # 3ë‹¨ê³„: ìê°€ ê²€ì¦
                if 'self_verification' in meta_analysis:
                    st.success("âœ… 3ë‹¨ê³„: ìê°€ ê²€ì¦")
                    with st.expander("ìƒì„¸ ë³´ê¸°"):
                        verification = meta_analysis['self_verification']
                        st.write(f"**ì‹ ë¢°ë„:** {verification.get('confidence_score', 0):.2f}")
                        st.write(f"**ê²€ì¦ ê²°ê³¼:** {verification.get('verification_result', 'Unknown')}")
                else:
                    st.info("â³ 3ë‹¨ê³„: ìê°€ ê²€ì¦")
            
            with col2:
                # 4ë‹¨ê³„: ì ì‘ì  ì‘ë‹µ
                if 'response_strategy' in meta_analysis:
                    st.success("âœ… 4ë‹¨ê³„: ì ì‘ì  ì‘ë‹µ")
                    with st.expander("ìƒì„¸ ë³´ê¸°"):
                        strategy = meta_analysis['response_strategy']
                        st.write(f"**ì‘ë‹µ ì „ëµ:** {strategy.get('strategy_type', 'Unknown')}")
                        st.write(f"**ì‚¬ìš©ì ìˆ˜ì¤€:** {strategy.get('user_level', 'Unknown')}")
                else:
                    st.info("â³ 4ë‹¨ê³„: ì ì‘ì  ì‘ë‹µ")
                
                # 5ë‹¨ê³„: í’ˆì§ˆ í‰ê°€
                if 'quality_assessment' in meta_analysis:
                    st.success("âœ… 5ë‹¨ê³„: í’ˆì§ˆ í‰ê°€")
                    with st.expander("ìƒì„¸ ë³´ê¸°"):
                        quality = meta_analysis['quality_assessment']
                        st.write(f"**ì „ì²´ í’ˆì§ˆ:** {quality.get('overall_score', 0):.2f}/5.0")
                        
                        # ì„¸ë¶€ í’ˆì§ˆ ì§€í‘œ
                        quality_metrics = quality.get('detailed_scores', {})
                        for metric, score in quality_metrics.items():
                            st.write(f"â€¢ {metric}: {score:.2f}")
                else:
                    st.info("â³ 5ë‹¨ê³„: í’ˆì§ˆ í‰ê°€")
    
    def _render_enhanced_agent_collaboration(self, agent_contributions: List, key_suffix: str):
        """A2A ì—ì´ì „íŠ¸ í˜‘ì—… ìƒíƒœ ì‹œê°í™”"""
        with st.expander("ğŸ¤– A2A ì—ì´ì „íŠ¸ í˜‘ì—… ìƒíƒœ", expanded=False):
            if not agent_contributions:
                st.info("ì—ì´ì „íŠ¸ í˜‘ì—… ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            # í˜‘ì—… ìš”ì•½
            total_agents = len(agent_contributions)
            avg_contribution = sum(contrib.contribution_score for contrib in agent_contributions) / total_agents
            avg_quality = sum(contrib.quality_score for contrib in agent_contributions) / total_agents
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("ì°¸ì—¬ ì—ì´ì „íŠ¸", total_agents)
            with col2:
                st.metric("í‰ê·  ê¸°ì—¬ë„", f"{avg_contribution:.2f}")
            with col3:
                st.metric("í‰ê·  í’ˆì§ˆ", f"{avg_quality:.2f}")
            
            # ì—ì´ì „íŠ¸ë³„ ìƒì„¸ ì •ë³´
            st.write("### ì—ì´ì „íŠ¸ë³„ ê¸°ì—¬ë„")
            
            for i, contrib in enumerate(agent_contributions):
                with st.container():
                    # ì—ì´ì „íŠ¸ í—¤ë”
                    col1, col2, col3, col4 = st.columns([2, 1, 1, 1])
                    
                    with col1:
                        st.write(f"**ğŸ¤– {contrib.agent_name}**")
                    with col2:
                        st.write(f"ê¸°ì—¬ë„: {contrib.contribution_score:.2f}")
                    with col3:
                        st.write(f"í’ˆì§ˆ: {contrib.quality_score:.2f}")
                    with col4:
                        st.write(f"ì‹ ë¢°ì„±: {contrib.reliability_score:.2f}")
                    
                    # ì§„í–‰ë¥  ë°”
                    st.progress(contrib.contribution_score / 5.0)
                    
                    # í•µì‹¬ ì¸ì‚¬ì´íŠ¸
                    if contrib.key_insights:
                        with st.expander(f"{contrib.agent_name} í•µì‹¬ ì¸ì‚¬ì´íŠ¸"):
                            for insight in contrib.key_insights[:5]:  # ìµœëŒ€ 5ê°œ
                                st.write(f"â€¢ {insight}")
                    
                    st.divider()
    
    def _render_progressive_disclosure(self, progressive_options: Dict, key_suffix: str):
        """ì ì§„ì  ì •ë³´ ê³µê°œ ì¸í„°í˜ì´ìŠ¤"""
        st.write("### ğŸ” ë” ìì„¸íˆ ì•Œì•„ë³´ê¸°")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            if st.button("ğŸ“Š ìƒì„¸ ë¶„ì„", key=f"detailed_{key_suffix}"):
                st.session_state[f'disclosure_level_{key_suffix}'] = 'detailed'
                self._show_detailed_analysis(progressive_options.get('detailed_analysis'))
        
        with col2:
            if st.button("ğŸ”¬ ê¸°ìˆ ì  ìƒì„¸", key=f"technical_{key_suffix}"):
                st.session_state[f'disclosure_level_{key_suffix}'] = 'technical'
                self._show_technical_details(progressive_options.get('technical_details'))
        
        with col3:
            if st.button("ğŸ“ ê´€ë ¨ ì£¼ì œ", key=f"exploration_{key_suffix}"):
                st.session_state[f'disclosure_level_{key_suffix}'] = 'exploration'
                self._show_related_topics(progressive_options.get('related_topics'))
        
        with col4:
            if st.button("ğŸ’¡ ì¶”ì²œ ì•¡ì…˜", key=f"actions_{key_suffix}"):
                st.session_state[f'disclosure_level_{key_suffix}'] = 'actions'
                self._show_recommended_actions(progressive_options.get('recommended_actions'))
        
        # ì„ íƒëœ ê³µê°œ ìˆ˜ì¤€ì— ë”°ë¥¸ ë‚´ìš© í‘œì‹œ
        disclosure_level = st.session_state.get(f'disclosure_level_{key_suffix}')
        if disclosure_level:
            self._render_disclosed_content(progressive_options, disclosure_level)
    
    def _render_message_actions(self, message: Dict, key_suffix: str):
        """ë©”ì‹œì§€ ì•¡ì…˜ ë²„íŠ¼"""
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            if st.button("ğŸ‘", key=f"like_{key_suffix}", help="ì´ ì‘ë‹µì´ ë„ì›€ë˜ì—ˆë‚˜ìš”?"):
                self._handle_feedback(message, 'like')
        
        with col2:
            if st.button("ğŸ‘", key=f"dislike_{key_suffix}", help="ì´ ì‘ë‹µì„ ê°œì„ í•  ìˆ˜ ìˆë‚˜ìš”?"):
                self._handle_feedback(message, 'dislike')
        
        with col3:
            if st.button("ğŸ”„", key=f"regenerate_{key_suffix}", help="ë‹¤ì‹œ ìƒì„±"):
                self._regenerate_response(message)
        
        with col4:
            if st.button("ğŸ“‹", key=f"copy_{key_suffix}", help="ë³µì‚¬"):
                st.write("ì‘ë‹µì´ í´ë¦½ë³´ë“œì— ë³µì‚¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    def _render_enhanced_input_interface(self):
        """í–¥ìƒëœ ì…ë ¥ ì¸í„°í˜ì´ìŠ¤"""
        # ì…ë ¥ ì˜µì…˜
        with st.expander("âš™ï¸ ì…ë ¥ ì˜µì…˜", expanded=False):
            col1, col2, col3 = st.columns(3)
            
            with col1:
                input_mode = st.selectbox(
                    "ì…ë ¥ ëª¨ë“œ",
                    ["í…ìŠ¤íŠ¸", "ìŒì„±", "íŒŒì¼ ì—…ë¡œë“œ"],
                    key="input_mode"
                )
            
            with col2:
                response_style = st.selectbox(
                    "ì‘ë‹µ ìŠ¤íƒ€ì¼",
                    ["ê· í˜•ì¡íŒ", "ê°„ê²°í•œ", "ìƒì„¸í•œ", "ê¸°ìˆ ì "],
                    key="response_style"
                )
            
            with col3:
                priority_focus = st.selectbox(
                    "ìš°ì„  ì´ˆì ",
                    ["ìë™ ì„ íƒ", "ì†ë„ ìš°ì„ ", "ì •í™•ë„ ìš°ì„ ", "ì°½ì˜ì„± ìš°ì„ "],
                    key="priority_focus"
                )
        
        # ë©”ì¸ ì…ë ¥
        if st.session_state.get('input_mode', 'í…ìŠ¤íŠ¸') == 'í…ìŠ¤íŠ¸':
            prompt = st.chat_input("ë¶„ì„í•˜ê³  ì‹¶ì€ ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”...")
            if prompt:
                self._handle_text_input(prompt)
        
        elif st.session_state.get('input_mode') == 'íŒŒì¼ ì—…ë¡œë“œ':
            uploaded_file = st.file_uploader(
                "ë¶„ì„í•  íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”",
                type=['csv', 'xlsx', 'json', 'txt'],
                key="file_upload"
            )
            if uploaded_file:
                self._handle_file_upload(uploaded_file)
        
        elif st.session_state.get('input_mode') == 'ìŒì„±':
            st.info("ìŒì„± ì…ë ¥ ê¸°ëŠ¥ì€ í–¥í›„ êµ¬í˜„ ì˜ˆì •ì…ë‹ˆë‹¤.")
    
    def _show_detailed_analysis(self, detailed_analysis: Dict):
        """ìƒì„¸ ë¶„ì„ í‘œì‹œ"""
        if detailed_analysis:
            st.write("### ğŸ“Š ìƒì„¸ ë¶„ì„")
            st.json(detailed_analysis)
    
    def _show_technical_details(self, technical_details: Dict):
        """ê¸°ìˆ ì  ìƒì„¸ ì •ë³´ í‘œì‹œ"""
        if technical_details:
            st.write("### ğŸ”¬ ê¸°ìˆ ì  ìƒì„¸")
            st.json(technical_details)
    
    def _show_related_topics(self, related_topics: List):
        """ê´€ë ¨ ì£¼ì œ í‘œì‹œ"""
        if related_topics:
            st.write("### ğŸ“ ê´€ë ¨ ì£¼ì œ")
            for topic in related_topics:
                st.write(f"â€¢ {topic}")
    
    def _show_recommended_actions(self, recommended_actions: List):
        """ì¶”ì²œ ì•¡ì…˜ í‘œì‹œ"""
        if recommended_actions:
            st.write("### ğŸ’¡ ì¶”ì²œ ì•¡ì…˜")
            for action in recommended_actions:
                st.write(f"â€¢ {action}")
    
    def _render_disclosed_content(self, progressive_options: Dict, disclosure_level: str):
        """ê³µê°œëœ ë‚´ìš© ë Œë”ë§"""
        content_map = {
            'detailed': progressive_options.get('detailed_analysis'),
            'technical': progressive_options.get('technical_details'),
            'exploration': progressive_options.get('related_topics'),
            'actions': progressive_options.get('recommended_actions')
        }
        
        content = content_map.get(disclosure_level)
        if content:
            st.json(content)
    
    def _handle_feedback(self, message: Dict, feedback_type: str):
        """í”¼ë“œë°± ì²˜ë¦¬"""
        # í”¼ë“œë°±ì„ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
        if 'feedback_history' not in st.session_state:
            st.session_state.feedback_history = []
        
        feedback = {
            'message_id': message.get('timestamp', datetime.now().isoformat()),
            'feedback_type': feedback_type,
            'timestamp': datetime.now().isoformat()
        }
        
        st.session_state.feedback_history.append(feedback)
        
        if feedback_type == 'like':
            st.success("í”¼ë“œë°± ê°ì‚¬í•©ë‹ˆë‹¤! ğŸ‘")
            # ë§Œì¡±ë„ ì ìˆ˜ í–¥ìƒ
            st.session_state.satisfaction_score = min(5.0, st.session_state.get('satisfaction_score', 0.0) + 0.1)
        else:
            st.info("í”¼ë“œë°± ê°ì‚¬í•©ë‹ˆë‹¤. ë” ë‚˜ì€ ì‘ë‹µì„ ìœ„í•´ ë…¸ë ¥í•˜ê² ìŠµë‹ˆë‹¤. ğŸ‘")
            # ë§Œì¡±ë„ ì ìˆ˜ ê°ì†Œ
            st.session_state.satisfaction_score = max(0.0, st.session_state.get('satisfaction_score', 0.0) - 0.1)
    
    def _regenerate_response(self, message: Dict):
        """ì‘ë‹µ ì¬ìƒì„±"""
        st.info("ì‘ë‹µì„ ë‹¤ì‹œ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë™ì¼í•œ ì¿¼ë¦¬ë¡œ ë‹¤ì‹œ ì²˜ë¦¬
        # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ í‘œì‹œë§Œ
    
    def _handle_text_input(self, prompt: str):
        """í…ìŠ¤íŠ¸ ì…ë ¥ ì²˜ë¦¬"""
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        st.session_state.messages.append({"role": "user", "content": prompt})
        
        with st.chat_message("user"):
            st.write(prompt)
        
        # Universal Engineìœ¼ë¡œ ë¶„ì„ ìˆ˜í–‰
        with st.chat_message("assistant"):
            asyncio.run(self._process_user_query(prompt))
    
    def _handle_file_upload(self, uploaded_file):
        """íŒŒì¼ ì—…ë¡œë“œ ì²˜ë¦¬"""
        try:
            # íŒŒì¼ íƒ€ì…ì— ë”°ë¥¸ ì²˜ë¦¬
            if uploaded_file.name.endswith('.csv'):
                import pandas as pd
                data = pd.read_csv(uploaded_file)
                st.session_state.current_data = data
                st.success(f"CSV íŒŒì¼ì´ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤: {uploaded_file.name}")
                st.write(f"ë°ì´í„° í¬ê¸°: {data.shape}")
                st.write("ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:")
                st.dataframe(data.head())
                
            elif uploaded_file.name.endswith('.xlsx'):
                import pandas as pd
                data = pd.read_excel(uploaded_file)
                st.session_state.current_data = data
                st.success(f"Excel íŒŒì¼ì´ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤: {uploaded_file.name}")
                st.write(f"ë°ì´í„° í¬ê¸°: {data.shape}")
                st.write("ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:")
                st.dataframe(data.head())
                
            elif uploaded_file.name.endswith('.json'):
                import json
                data = json.load(uploaded_file)
                st.session_state.current_data = data
                st.success(f"JSON íŒŒì¼ì´ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤: {uploaded_file.name}")
                st.json(data)
                
            else:
                content = uploaded_file.read().decode('utf-8')
                st.session_state.current_data = content
                st.success(f"í…ìŠ¤íŠ¸ íŒŒì¼ì´ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤: {uploaded_file.name}")
                st.text(content[:500] + "..." if len(content) > 500 else content)
                
        except Exception as e:
            st.error(f"íŒŒì¼ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
    
    def render_main_interface(self):
        """ë©”ì¸ ì¸í„°í˜ì´ìŠ¤ ë Œë”ë§ (ëª¨ë“  ì»´í¬ë„ŒíŠ¸ í†µí•©)"""
        # í—¤ë”
        self.render_header()
        
        # ì‚¬ì´ë“œë°”
        self.render_sidebar()
        
        # ë©”ì¸ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
        self.render_enhanced_chat_interface()
        
        # ì‹œìŠ¤í…œ ì´ˆê¸°í™” í™•ì¸
        if not self.initialization_complete:
            st.warning("âš ï¸ ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ 'ì‹œìŠ¤í…œ ì´ˆê¸°í™”'ë¥¼ í´ë¦­í•˜ì„¸ìš”.")
            
            # ìë™ ì´ˆê¸°í™” ì˜µì…˜
            if st.button("ğŸš€ ìë™ ì´ˆê¸°í™” ì‹œì‘"):
                asyncio.run(self.initialize_system())