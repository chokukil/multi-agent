"""
Cherry AI Universal Engine UI - ë©”ì¸ UI ì»¨íŠ¸ë¡¤ëŸ¬

ìš”êµ¬ì‚¬í•­ 10.1ì— ë”°ë¥¸ êµ¬í˜„:
- ê¸°ì¡´ ChatGPT ìŠ¤íƒ€ì¼ ì¸í„°í˜ì´ìŠ¤ ìœ ì§€
- Universal Engine ìƒíƒœ ë° A2A ì—ì´ì „íŠ¸ ìˆ˜ í‘œì‹œ
- ì‚¬ì´ë“œë°”ì— Universal Engine ì œì–´íŒ êµ¬í˜„
- ì™„ì „íˆ ìƒˆë¡œìš´ LLM First ë¶„ì„ ì‹¤í–‰
"""

import streamlit as st
import asyncio
import logging
from typing import Dict, List, Any, Optional
from datetime import datetime
import json

from ..universal_query_processor import UniversalQueryProcessor
from ..a2a_integration.a2a_agent_discovery import A2AAgentDiscoverySystem
from ..a2a_integration.llm_based_agent_selector import LLMBasedAgentSelector
from ..a2a_integration.a2a_workflow_orchestrator import A2AWorkflowOrchestrator
from ..a2a_integration.a2a_communication_protocol import A2ACommunicationProtocol
from ..a2a_integration.a2a_result_integrator import A2AResultIntegrator

logger = logging.getLogger(__name__)


class CherryAIUniversalEngineUI:
    """
    Cherry AI Universal Engine UI ì»¨íŠ¸ë¡¤ëŸ¬
    - ê¸°ì¡´ Cherry AI ë¸Œëœë”© ë° ì¸í„°í˜ì´ìŠ¤ ìœ ì§€
    - Universal Engine + A2A ì—ì´ì „íŠ¸ ì™„ì „ í†µí•©
    - ChatGPT ìŠ¤íƒ€ì¼ ì‚¬ìš©ì ê²½í—˜ ì œê³µ
    """
    
    def __init__(self):
        """CherryAIUniversalEngineUI ì´ˆê¸°í™”"""
        self.universal_engine = None
        self.a2a_discovery = None
        self.agent_selector = None
        self.workflow_orchestrator = None
        self.communication_protocol = None
        self.result_integrator = None
        self.available_agents = {}
        self.initialization_complete = False
        
        # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
        self._initialize_session_state()
        logger.info("CherryAIUniversalEngineUI initialized")
    
    def _initialize_session_state(self):
        """Streamlit ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
        if 'messages' not in st.session_state:
            st.session_state.messages = []
        
        if 'universal_engine_status' not in st.session_state:
            st.session_state.universal_engine_status = "initializing"
        
        if 'available_agents' not in st.session_state:
            st.session_state.available_agents = {}
        
        if 'show_reasoning' not in st.session_state:
            st.session_state.show_reasoning = True
        
        if 'reasoning_depth' not in st.session_state:
            st.session_state.reasoning_depth = "ê¸°ë³¸"
        
        if 'expertise_level' not in st.session_state:
            st.session_state.expertise_level = "ìë™ ê°ì§€"
        
        if 'total_analyses' not in st.session_state:
            st.session_state.total_analyses = 0
        
        if 'avg_response_time' not in st.session_state:
            st.session_state.avg_response_time = 0.0
        
        if 'satisfaction_score' not in st.session_state:
            st.session_state.satisfaction_score = 0.0
        
        if 'current_data' not in st.session_state:
            st.session_state.current_data = None
        
        if 'user_profile' not in st.session_state:
            st.session_state.user_profile = {}
        
        if 'show_agent_details' not in st.session_state:
            st.session_state.show_agent_details = True
    
    async def initialize_system(self) -> bool:
        """
        Universal Engine + A2A ì‹œìŠ¤í…œ ì™„ì „ ì´ˆê¸°í™”
        
        Returns:
            ì´ˆê¸°í™” ì„±ê³µ ì—¬ë¶€
        """
        try:
            with st.spinner("ğŸ§  Universal Engine ì´ˆê¸°í™” ì¤‘..."):
                # 1. Universal Engine ì´ˆê¸°í™”
                self.universal_engine = UniversalQueryProcessor()
                
                # 2. A2A ì‹œìŠ¤í…œ ì´ˆê¸°í™”
                self.communication_protocol = A2ACommunicationProtocol()
                self.a2a_discovery = A2AAgentDiscoverySystem()
                self.agent_selector = LLMBasedAgentSelector(self.a2a_discovery)
                self.workflow_orchestrator = A2AWorkflowOrchestrator(self.communication_protocol)
                self.result_integrator = A2AResultIntegrator()
                
                # 3. A2A ì—ì´ì „íŠ¸ ë°œê²¬
                st.write("ğŸ” A2A ì—ì´ì „íŠ¸ ë°œê²¬ ì¤‘...")
                await self.a2a_discovery.start_discovery()
                self.available_agents = self.a2a_discovery.get_available_agents()
                
                # 4. ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸
                st.session_state.universal_engine_status = "active"
                st.session_state.available_agents = {
                    agent_id: {
                        'name': agent.name,
                        'port': agent.port,
                        'status': agent.status,
                        'capabilities': agent.capabilities
                    }
                    for agent_id, agent in self.available_agents.items()
                }
                
                self.initialization_complete = True
                
                st.success(f"âœ… ì´ˆê¸°í™” ì™„ë£Œ! {len(self.available_agents)}ê°œ A2A ì—ì´ì „íŠ¸ ë°œê²¬ë¨")
                return True
                
        except Exception as e:
            logger.error(f"System initialization failed: {e}")
            st.error(f"âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            st.session_state.universal_engine_status = "error"
            return False
    
    def render_header(self):
        """ğŸ’ Cherry AI ë¸Œëœë”© í—¤ë” ìœ ì§€ + Universal Engine ìƒíƒœ í‘œì‹œ"""
        col1, col2, col3, col4 = st.columns([3, 1, 1, 1])
        
        with col1:
            st.markdown("# ğŸ’ Cherry AI - LLM First Universal Engine")
            st.caption("Zero Hardcoding â€¢ Universal Adaptability â€¢ Self-Discovering")
        
        with col2:
            # Universal Engine ìƒíƒœ
            status = st.session_state.get('universal_engine_status', 'initializing')
            status_icons = {
                'initializing': 'ğŸ”„',
                'active': 'ğŸŸ¢',
                'error': 'ğŸ”´',
                'maintenance': 'ğŸŸ¡'
            }
            st.markdown(f"{status_icons.get(status, 'â“')} **Universal Engine**")
            st.caption(f"ìƒíƒœ: {status}")
        
        with col3:
            # A2A ì—ì´ì „íŠ¸ ìˆ˜
            agent_count = len(st.session_state.get('available_agents', {}))
            st.markdown(f"ğŸ¤– **A2A ì—ì´ì „íŠ¸**")
            st.caption(f"{agent_count}ê°œ í™œì„±")
        
        with col4:
            # ì„¤ì • ë²„íŠ¼
            if st.button("âš™ï¸ ì„¤ì •", key="settings_button"):
                st.session_state.show_settings = True
    
    def render_sidebar(self):
        """ğŸ”§ ì—ì´ì „íŠ¸ ìƒíƒœ ë° ì„¤ì • ì‚¬ì´ë“œë°” + Universal Engine ì œì–´"""
        with st.sidebar:
            st.header("ğŸ”§ Universal Engine ì œì–´")
            
            # ì‹œìŠ¤í…œ ì´ˆê¸°í™” ë²„íŠ¼
            if not self.initialization_complete:
                if st.button("ğŸš€ ì‹œìŠ¤í…œ ì´ˆê¸°í™”", key="init_button"):
                    asyncio.run(self.initialize_system())
            
            # ë©”íƒ€ ì¶”ë¡  ì„¤ì •
            st.subheader("ğŸ§  ë©”íƒ€ ì¶”ë¡  ì„¤ì •")
            st.session_state.show_reasoning = st.checkbox(
                "ì¶”ë¡  ê³¼ì • í‘œì‹œ", 
                value=st.session_state.get('show_reasoning', True)
            )
            
            st.session_state.reasoning_depth = st.selectbox(
                "ì¶”ë¡  ê¹Šì´", 
                ["ê¸°ë³¸", "ìƒì„¸", "ì „ë¬¸ê°€"],
                index=["ê¸°ë³¸", "ìƒì„¸", "ì „ë¬¸ê°€"].index(st.session_state.get('reasoning_depth', 'ê¸°ë³¸'))
            )
            
            # A2A Agent ìƒíƒœ
            st.subheader("ğŸ¤– A2A ì—ì´ì „íŠ¸ ìƒíƒœ")
            agents = st.session_state.get('available_agents', {})
            
            if agents:
                for agent_id, agent_info in agents.items():
                    status_icon = "ğŸŸ¢" if agent_info.get('status') == "active" else "ğŸ”´"
                    st.write(f"{status_icon} **{agent_info.get('name', 'Unknown')}**")
                    st.caption(f"í¬íŠ¸: {agent_info.get('port', 'N/A')}")
                    
                    # ì—ì´ì „íŠ¸ ìƒì„¸ ì •ë³´ (ì ‘ê¸°/í¼ì¹˜ê¸°)
                    with st.expander(f"{agent_info.get('name', 'Unknown')} ìƒì„¸ì •ë³´"):
                        st.write("**ëŠ¥ë ¥:**")
                        for capability in agent_info.get('capabilities', []):
                            st.write(f"â€¢ {capability}")
            else:
                st.info("ì‚¬ìš© ê°€ëŠ¥í•œ ì—ì´ì „íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
                if st.button("ğŸ”„ ì—ì´ì „íŠ¸ ì¬ë°œê²¬"):
                    if self.a2a_discovery:
                        asyncio.run(self.a2a_discovery.rediscover_agents())
                        st.rerun()
            
            # ì‚¬ìš©ì í”„ë¡œí•„ ì„¤ì •
            st.subheader("ğŸ‘¤ ì‚¬ìš©ì í”„ë¡œí•„")
            st.session_state.expertise_level = st.selectbox(
                "ì „ë¬¸ì„± ìˆ˜ì¤€", 
                ["ìë™ ê°ì§€", "ì´ˆë³´ì", "ì¤‘ê¸‰ì", "ì „ë¬¸ê°€"],
                index=["ìë™ ê°ì§€", "ì´ˆë³´ì", "ì¤‘ê¸‰ì", "ì „ë¬¸ê°€"].index(
                    st.session_state.get('expertise_level', 'ìë™ ê°ì§€')
                )
            )
            
            # Universal Engine í†µê³„
            st.subheader("ğŸ“Š ì—”ì§„ í†µê³„")
            st.metric("ì´ ë¶„ì„ ìˆ˜í–‰", st.session_state.get('total_analyses', 0))
            st.metric("í‰ê·  ì‘ë‹µ ì‹œê°„", f"{st.session_state.get('avg_response_time', 0):.1f}ì´ˆ")
            st.metric("ì‚¬ìš©ì ë§Œì¡±ë„", f"{st.session_state.get('satisfaction_score', 0):.1f}/5.0")
            
            # ê³ ê¸‰ ì„¤ì •
            with st.expander("ğŸ”§ ê³ ê¸‰ ì„¤ì •"):
                st.session_state.show_agent_details = st.checkbox(
                    "ì—ì´ì „íŠ¸ í˜‘ì—… ìƒì„¸ í‘œì‹œ",
                    value=st.session_state.get('show_agent_details', True)
                )
                
                # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
                if st.button("ğŸ“ˆ ì„±ëŠ¥ ë¦¬í¬íŠ¸ ë³´ê¸°"):
                    self._show_performance_report()
                
                # ì‹œìŠ¤í…œ ì¬ì‹œì‘
                if st.button("ğŸ”„ ì‹œìŠ¤í…œ ì¬ì‹œì‘"):
                    self._restart_system()
    
    def render_chat_interface(self):
        """ğŸ’¬ ChatGPT ìŠ¤íƒ€ì¼ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ ìœ ì§€ + ë©”íƒ€ ì¶”ë¡  í‘œì‹œ"""
        # ê¸°ì¡´ ì±„íŒ… ë©”ì‹œì§€ í‘œì‹œ
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.write(message["content"])
                
                # Universal Engine ë©”íƒ€ ì¶”ë¡  ê²°ê³¼ í‘œì‹œ
                if message.get("meta_reasoning") and st.session_state.get('show_reasoning', True):
                    with st.expander("ğŸ§  ë©”íƒ€ ì¶”ë¡  ê³¼ì •", expanded=False):
                        self._render_meta_reasoning(message["meta_reasoning"])
                
                # A2A Agent ê¸°ì—¬ë„ í‘œì‹œ
                if message.get("agent_contributions") and st.session_state.get('show_agent_details', True):
                    with st.expander("ğŸ¤– ì—ì´ì „íŠ¸ í˜‘ì—…", expanded=False):
                        self._render_agent_contributions(message["agent_contributions"])
        
        # ì‚¬ìš©ì ì…ë ¥
        if prompt := st.chat_input("ë¶„ì„í•˜ê³  ì‹¶ì€ ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”..."):
            # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
            st.session_state.messages.append({"role": "user", "content": prompt})
            
            with st.chat_message("user"):
                st.write(prompt)
            
            # Universal Engineìœ¼ë¡œ ë¶„ì„ ìˆ˜í–‰
            with st.chat_message("assistant"):
                asyncio.run(self._process_user_query(prompt))
    
    async def _process_user_query(self, query: str):
        """
        ì™„ì „íˆ ìƒˆë¡œìš´ LLM First ë¶„ì„ ì‹¤í–‰
        
        Args:
            query: ì‚¬ìš©ì ì¿¼ë¦¬
        """
        if not self.initialization_complete:
            st.error("ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ 'ì‹œìŠ¤í…œ ì´ˆê¸°í™”'ë¥¼ í´ë¦­í•˜ì„¸ìš”.")
            return
        
        start_time = datetime.now()
        
        try:
            # ì§„í–‰ ìƒí™© í‘œì‹œë¥¼ ìœ„í•œ í”Œë ˆì´ìŠ¤í™€ë”ë“¤
            status_placeholder = st.empty()
            progress_placeholder = st.empty()
            result_placeholder = st.empty()
            
            # 1. Universal Engineìœ¼ë¡œ ë©”íƒ€ ì¶”ë¡  ìˆ˜í–‰
            status_placeholder.info("ğŸ§  ë©”íƒ€ ì¶”ë¡  ì¤‘...")
            
            meta_analysis = await self.universal_engine.meta_reasoning_engine.analyze_request(
                query=query,
                data=st.session_state.get('current_data'),
                context=self._get_session_context()
            )
            
            if st.session_state.get('show_reasoning', True):
                with st.expander("ğŸ§  ë©”íƒ€ ì¶”ë¡  ê²°ê³¼", expanded=False):
                    self._render_meta_reasoning(meta_analysis)
            
            # 2. A2A Agent ë™ì  ì„ íƒ ë° í˜‘ì—…
            status_placeholder.info("ğŸ¤– A2A ì—ì´ì „íŠ¸ ì„ íƒ ì¤‘...")
            
            if self.available_agents:
                selection_result = await self.agent_selector.select_agents_for_query(
                    meta_analysis=meta_analysis,
                    query=query,
                    data_info=self._get_data_info(),
                    user_preferences=self._get_user_preferences()
                )
                
                # ì„ íƒëœ ì—ì´ì „íŠ¸ í‘œì‹œ
                if selection_result.selected_agents:
                    status_placeholder.success(f"âœ… {len(selection_result.selected_agents)}ê°œ ì—ì´ì „íŠ¸ ì„ íƒë¨")
                    
                    # ì—ì´ì „íŠ¸ ì„ íƒ ì •ë³´ í‘œì‹œ
                    cols = st.columns(min(len(selection_result.selected_agents), 4))
                    for i, agent in enumerate(selection_result.selected_agents):
                        with cols[i % 4]:
                            st.write(f"ğŸ¤– **{agent.name}**")
                            st.caption(f"í¬íŠ¸: {agent.port}")
                    
                    # 3. ì—ì´ì „íŠ¸ í˜‘ì—… ì‹¤í–‰ (ìŠ¤íŠ¸ë¦¬ë°)
                    status_placeholder.info("âš¡ ì—ì´ì „íŠ¸ í˜‘ì—… ì‹¤í–‰ ì¤‘...")
                    
                    progress_container = progress_placeholder.container()
                    
                    # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
                    workflow_result = None
                    async for progress_update in self.workflow_orchestrator.execute_workflow_with_streaming(
                        selection_result, query, st.session_state.get('current_data')
                    ):
                        self._update_progress_display(progress_container, progress_update)
                        
                        if progress_update.get('type') == 'workflow_completed':
                            workflow_result = progress_update.get('results')
                    
                    if workflow_result:
                        # 4. ê²°ê³¼ í†µí•© ë° ì ì‘ì  ì‘ë‹µ ìƒì„±
                        status_placeholder.info("ğŸ”„ ê²°ê³¼ í†µí•© ë° ì‘ë‹µ ìƒì„± ì¤‘...")
                        
                        # A2A ì‘ë‹µë“¤ì„ A2AResponse í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                        a2a_responses = self._convert_to_a2a_responses(workflow_result)
                        
                        # ê²°ê³¼ í†µí•©
                        integrated_result = await self.result_integrator.integrate_results(
                            responses=a2a_responses,
                            agents=selection_result.selected_agents,
                            original_query=query,
                            meta_analysis=meta_analysis
                        )
                        
                        # Universal Engineìœ¼ë¡œ ìµœì¢… ì ì‘í˜• ì‘ë‹µ ìƒì„±
                        final_response = await self.universal_engine.response_generator.generate_adaptive_response(
                            knowledge_result={'refined_result': integrated_result.consolidated_data},
                            user_profile=meta_analysis.get('user_profile', {}),
                            interaction_context=self._get_session_context()
                        )
                        
                        # ê²°ê³¼ í‘œì‹œ
                        self._display_final_response(result_placeholder, final_response, integrated_result)
                        
                        # ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸
                        self._update_session_statistics(start_time, True)
                        
                        # ë©”ì‹œì§€ ì´ë ¥ì— ì €ì¥
                        assistant_message = {
                            "role": "assistant",
                            "content": final_response.get('core_response', {}).get('summary', 'ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.'),
                            "meta_reasoning": meta_analysis,
                            "agent_contributions": integrated_result.agent_contributions,
                            "timestamp": datetime.now().isoformat()
                        }
                        st.session_state.messages.append(assistant_message)
                        
                    else:
                        st.error("ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
                
                else:
                    st.warning("ì„ íƒëœ ì—ì´ì „íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            else:
                # A2A ì—ì´ì „íŠ¸ê°€ ì—†ëŠ” ê²½ìš° Universal Engineë§Œìœ¼ë¡œ ì²˜ë¦¬
                status_placeholder.info("ğŸ§  Universal Engine ë‹¨ë… ë¶„ì„ ì¤‘...")
                
                result = await self.universal_engine.process_query(
                    query=query,
                    data=st.session_state.get('current_data'),
                    context=self._get_session_context()
                )
                
                # ê²°ê³¼ í‘œì‹œ
                if result.get('success'):
                    result_placeholder.success("âœ… ë¶„ì„ ì™„ë£Œ")
                    st.write(result.get('response', {}).get('core_response', {}).get('summary', 'ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.'))
                    
                    # ë©”ì‹œì§€ ì´ë ¥ì— ì €ì¥
                    assistant_message = {
                        "role": "assistant", 
                        "content": result.get('response', {}).get('core_response', {}).get('summary', 'ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.'),
                        "meta_reasoning": result.get('meta_analysis'),
                        "timestamp": datetime.now().isoformat()
                    }
                    st.session_state.messages.append(assistant_message)
                    
                    self._update_session_statistics(start_time, True)
                else:
                    st.error(f"ë¶„ì„ ì‹¤íŒ¨: {result.get('error', 'Unknown error')}")
                    self._update_session_statistics(start_time, False)
            
            # ìƒíƒœ í‘œì‹œ ì •ë¦¬
            status_placeholder.empty()
            progress_placeholder.empty()
            
        except Exception as e:
            logger.error(f"Error processing user query: {e}")
            st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            self._update_session_statistics(start_time, False)
    
    def _render_meta_reasoning(self, meta_analysis: Dict):
        """ë©”íƒ€ ì¶”ë¡  ê²°ê³¼ ë Œë”ë§"""
        if not meta_analysis:
            return
        
        # íƒ­ìœ¼ë¡œ 4ë‹¨ê³„ ì¶”ë¡  ê³¼ì • í‘œì‹œ
        tab1, tab2, tab3, tab4, tab5 = st.tabs([
            "ì´ˆê¸° ê´€ì°°", "ë‹¤ê°ë„ ë¶„ì„", "ìê°€ ê²€ì¦", "ì ì‘ì  ì‘ë‹µ", "í’ˆì§ˆ í‰ê°€"
        ])
        
        with tab1:
            if 'initial_analysis' in meta_analysis:
                st.json(meta_analysis['initial_analysis'])
        
        with tab2:
            if 'multi_perspective' in meta_analysis:
                st.json(meta_analysis['multi_perspective'])
        
        with tab3:
            if 'self_verification' in meta_analysis:
                st.json(meta_analysis['self_verification'])
        
        with tab4:
            if 'response_strategy' in meta_analysis:
                st.json(meta_analysis['response_strategy'])
        
        with tab5:
            if 'quality_assessment' in meta_analysis:
                st.json(meta_analysis['quality_assessment'])
    
    def _render_agent_contributions(self, agent_contributions: List):
        """ì—ì´ì „íŠ¸ ê¸°ì—¬ë„ ë Œë”ë§"""
        if not agent_contributions:
            return
        
        for contribution in agent_contributions:
            st.write(f"**{contribution.agent_name}** (ê¸°ì—¬ë„: {contribution.contribution_score:.2f})")
            
            col1, col2 = st.columns(2)
            with col1:
                st.write("**í’ˆì§ˆ ì ìˆ˜:**")
                st.write(f"â€¢ í’ˆì§ˆ: {contribution.quality_score:.2f}")
                st.write(f"â€¢ ê³ ìœ ì„±: {contribution.uniqueness_score:.2f}")
                st.write(f"â€¢ ì‹ ë¢°ì„±: {contribution.reliability_score:.2f}")
            
            with col2:
                st.write("**í•µì‹¬ ì¸ì‚¬ì´íŠ¸:**")
                for insight in contribution.key_insights[:3]:  # ìµœëŒ€ 3ê°œë§Œ í‘œì‹œ
                    st.write(f"â€¢ {insight}")
    
    def _update_progress_display(self, container, progress_update: Dict):
        """ì§„í–‰ ìƒí™© í‘œì‹œ ì—…ë°ì´íŠ¸"""
        update_type = progress_update.get('type')
        
        with container:
            if update_type == 'group_started':
                st.info(f"ê·¸ë£¹ {progress_update.get('group_index')}/{progress_update.get('total_groups')} ì‹œì‘")
                st.write(f"ì‹¤í–‰ ì—ì´ì „íŠ¸: {', '.join(progress_update.get('agents', []))}")
            
            elif update_type == 'group_progress':
                progress = progress_update.get('completed', 0) / max(progress_update.get('total', 1), 1)
                st.progress(progress)
                st.caption(f"ê·¸ë£¹ ì§„í–‰ë¥ : {progress_update.get('completed')}/{progress_update.get('total')}")
            
            elif update_type == 'overall_progress':
                st.progress(progress_update.get('progress', 0) / 100)
                st.caption(f"ì „ì²´ ì§„í–‰ë¥ : {progress_update.get('progress', 0):.1f}%")
    
    def _display_final_response(self, placeholder, final_response: Dict, integrated_result):
        """ìµœì¢… ì‘ë‹µ í‘œì‹œ"""
        with placeholder:
            st.success("âœ… ë¶„ì„ ì™„ë£Œ!")
            
            # í•µì‹¬ ì‘ë‹µ
            core_response = final_response.get('core_response', {})
            if core_response.get('summary'):
                st.write("### ğŸ“‹ ë¶„ì„ ìš”ì•½")
                st.write(core_response['summary'])
            
            # ì£¼ìš” ì¸ì‚¬ì´íŠ¸
            if core_response.get('main_insights'):
                st.write("### ğŸ’¡ ì£¼ìš” ì¸ì‚¬ì´íŠ¸")
                for insight in core_response['main_insights']:
                    st.write(f"â€¢ {insight.get('insight', '')}")
            
            # ê¶Œì¥ì‚¬í•­
            if core_response.get('recommendations'):
                st.write("### ğŸ¯ ê¶Œì¥ì‚¬í•­")
                for rec in core_response['recommendations']:
                    st.write(f"â€¢ {rec.get('action', '')}")
            
            # ì ì§„ì  ì •ë³´ ê³µê°œ ì˜µì…˜
            progressive_options = final_response.get('progressive_options', {})
            if progressive_options:
                st.write("### ğŸ” ë” ìì„¸íˆ ì•Œì•„ë³´ê¸°")
                
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    if st.button("ğŸ“Š ë” ìì„¸í•œ ë¶„ì„"):
                        st.session_state.disclosure_level = 'detailed'
                
                with col2:
                    if st.button("ğŸ”¬ ê¸°ìˆ ì  ìƒì„¸"):
                        st.session_state.disclosure_level = 'technical'
                
                with col3:
                    if st.button("ğŸ“ ê´€ë ¨ ì£¼ì œ íƒìƒ‰"):
                        st.session_state.disclosure_level = 'exploration'
    
    def _convert_to_a2a_responses(self, workflow_result: Dict) -> List:
        """ì›Œí¬í”Œë¡œìš° ê²°ê³¼ë¥¼ A2AResponse í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        from ..a2a_integration.a2a_communication_protocol import A2AResponse
        
        responses = []
        agent_results = workflow_result.get('agent_results', {})
        
        for agent_name, result_data in agent_results.items():
            response = A2AResponse(
                request_id=f"workflow_{agent_name}",
                agent_id=result_data.get('agent_id', agent_name),
                status="success",
                data=result_data.get('result', {}),
                metadata={},
                timestamp=datetime.now().isoformat(),
                execution_time=result_data.get('execution_time', 0.0)
            )
            responses.append(response)
        
        return responses
    
    def _get_session_context(self) -> Dict:
        """ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        return {
            'session_id': st.session_state.get('session_id', 'default'),
            'user_profile': st.session_state.get('user_profile', {}),
            'conversation_history': st.session_state.get('messages', [])[-5:],  # ìµœê·¼ 5ê°œ
            'settings': {
                'reasoning_depth': st.session_state.get('reasoning_depth', 'ê¸°ë³¸'),
                'expertise_level': st.session_state.get('expertise_level', 'ìë™ ê°ì§€'),
                'show_reasoning': st.session_state.get('show_reasoning', True)
            }
        }
    
    def _get_data_info(self) -> Dict:
        """í˜„ì¬ ë°ì´í„° ì •ë³´ ì¶”ì¶œ"""
        current_data = st.session_state.get('current_data')
        if current_data is None:
            return {'type': 'none', 'description': 'No data uploaded'}
        
        return {
            'type': type(current_data).__name__,
            'size': len(current_data) if hasattr(current_data, '__len__') else 'unknown',
            'description': 'User uploaded data'
        }
    
    def _get_user_preferences(self) -> Dict:
        """ì‚¬ìš©ì ì„ í˜¸ì‚¬í•­ ì¶”ì¶œ"""
        return {
            'expertise_level': st.session_state.get('expertise_level', 'ìë™ ê°ì§€'),
            'reasoning_depth': st.session_state.get('reasoning_depth', 'ê¸°ë³¸'),
            'show_agent_details': st.session_state.get('show_agent_details', True),
            'preferred_response_style': 'balanced'  # í–¥í›„ ì‚¬ìš©ì ì„¤ì •ìœ¼ë¡œ í™•ì¥ ê°€ëŠ¥
        }
    
    def _update_session_statistics(self, start_time: datetime, success: bool):
        """ì„¸ì…˜ í†µê³„ ì—…ë°ì´íŠ¸"""
        duration = (datetime.now() - start_time).total_seconds()
        
        st.session_state.total_analyses += 1
        
        # í‰ê·  ì‘ë‹µ ì‹œê°„ ì—…ë°ì´íŠ¸
        current_avg = st.session_state.get('avg_response_time', 0.0)
        total_analyses = st.session_state.get('total_analyses', 1)
        st.session_state.avg_response_time = (
            (current_avg * (total_analyses - 1) + duration) / total_analyses
        )
        
        # ì„±ê³µë¥  ê¸°ë°˜ ë§Œì¡±ë„ ì ìˆ˜ ì—…ë°ì´íŠ¸ (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±)
        if success:
            st.session_state.satisfaction_score = min(5.0, st.session_state.get('satisfaction_score', 0.0) + 0.1)
        else:
            st.session_state.satisfaction_score = max(0.0, st.session_state.get('satisfaction_score', 0.0) - 0.2)
    
    def _show_performance_report(self):
        """ì„±ëŠ¥ ë¦¬í¬íŠ¸ í‘œì‹œ"""
        st.write("### ğŸ“ˆ ì„±ëŠ¥ ë¦¬í¬íŠ¸")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.metric("ì´ ë¶„ì„ ìˆ˜", st.session_state.get('total_analyses', 0))
            st.metric("í‰ê·  ì‘ë‹µ ì‹œê°„", f"{st.session_state.get('avg_response_time', 0):.1f}ì´ˆ")
        
        with col2:
            st.metric("ì‚¬ìš©ì ë§Œì¡±ë„", f"{st.session_state.get('satisfaction_score', 0):.1f}/5.0")
            agent_count = len(st.session_state.get('available_agents', {}))
            st.metric("í™œì„± ì—ì´ì „íŠ¸", agent_count)
    
    def _restart_system(self):
        """ì‹œìŠ¤í…œ ì¬ì‹œì‘"""
        # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
        for key in list(st.session_state.keys()):
            if key.startswith(('universal_', 'available_', 'total_', 'avg_', 'satisfaction_')):
                del st.session_state[key]
        
        self.initialization_complete = False
        st.success("ì‹œìŠ¤í…œì´ ì¬ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì´ˆê¸°í™”í•´ì£¼ì„¸ìš”.")
        st.rerun()