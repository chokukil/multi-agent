"""
Enhanced Chat Interface - í–¥ìƒëœ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤

ìš”êµ¬ì‚¬í•­ 3.3ì— ë”°ë¥¸ êµ¬í˜„:
- ChatGPT ìŠ¤íƒ€ì¼ ë©”ì‹œì§€ í‘œì‹œ ìœ ì§€
- ë©”íƒ€ ì¶”ë¡  ê³¼ì • ì‹œê°í™”
- A2A ì—ì´ì „íŠ¸ í˜‘ì—… ìƒíƒœ í‘œì‹œ
- ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì§€ì›
"""

import streamlit as st
import asyncio
import logging
from typing import Dict, List, Any, Optional, AsyncGenerator
from datetime import datetime
import json
import time

from ..universal_query_processor import UniversalQueryProcessor
from ..a2a_integration.a2a_agent_discovery import A2AAgentInfo
from ..a2a_integration.a2a_result_integrator import AgentContribution

logger = logging.getLogger(__name__)


class EnhancedChatInterface:
    """
    í–¥ìƒëœ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
    - ChatGPT ìŠ¤íƒ€ì¼ UI/UX ìœ ì§€
    - Universal Engine ë©”íƒ€ ì¶”ë¡  ì‹œê°í™”
    - A2A ì—ì´ì „íŠ¸ í˜‘ì—… ì‹¤ì‹œê°„ í‘œì‹œ
    - ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ë° ì§„í–‰ ìƒí™© í‘œì‹œ
    """
    
    def __init__(self, universal_engine: UniversalQueryProcessor):
        """EnhancedChatInterface ì´ˆê¸°í™”"""
        self.universal_engine = universal_engine
        self.message_history: List[Dict] = []
        self.typing_indicators: Dict[str, bool] = {}
        logger.info("EnhancedChatInterface initialized")
    
    def render_chat_messages(self):
        """ğŸ’¬ ê¸°ì¡´ ì±„íŒ… ë©”ì‹œì§€ë“¤ì„ ë Œë”ë§"""
        if 'messages' not in st.session_state:
            st.session_state.messages = []
        
        # ë©”ì‹œì§€ ì»¨í…Œì´ë„ˆ
        chat_container = st.container()
        
        with chat_container:
            for i, message in enumerate(st.session_state.messages):
                self._render_single_message(message, i)
    
    def _render_single_message(self, message: Dict, index: int):
        """ê°œë³„ ë©”ì‹œì§€ ë Œë”ë§"""
        role = message.get("role", "user")
        content = message.get("content", "")
        timestamp = message.get("timestamp", "")
        
        with st.chat_message(role):
            # ë©”ì‹œì§€ ë‚´ìš© í‘œì‹œ
            st.write(content)
            
            # íƒ€ì„ìŠ¤íƒ¬í”„ í‘œì‹œ
            if timestamp:
                st.caption(f"â° {self._format_timestamp(timestamp)}")
            
            # Assistant ë©”ì‹œì§€ì¸ ê²½ìš° ì¶”ê°€ ì •ë³´ í‘œì‹œ
            if role == "assistant":
                self._render_assistant_extras(message, index)
    
    def _render_assistant_extras(self, message: Dict, index: int):
        """Assistant ë©”ì‹œì§€ì˜ ì¶”ê°€ ì •ë³´ ë Œë”ë§"""
        # ë©”íƒ€ ì¶”ë¡  ê²°ê³¼ í‘œì‹œ
        if message.get("meta_reasoning") and st.session_state.get('show_reasoning', True):
            with st.expander("ğŸ§  ë©”íƒ€ ì¶”ë¡  ê³¼ì •", expanded=False):
                self._render_meta_reasoning_visualization(message["meta_reasoning"])
        
        # A2A ì—ì´ì „íŠ¸ ê¸°ì—¬ë„ í‘œì‹œ
        if message.get("agent_contributions") and st.session_state.get('show_agent_details', True):
            with st.expander("ğŸ¤– ì—ì´ì „íŠ¸ í˜‘ì—… ìƒì„¸", expanded=False):
                self._render_agent_collaboration_details(message["agent_contributions"])
        
        # ì‘ë‹µ í’ˆì§ˆ í‰ê°€ í‘œì‹œ
        if message.get("quality_metrics"):
            with st.expander("ğŸ“Š ì‘ë‹µ í’ˆì§ˆ í‰ê°€", expanded=False):
                self._render_quality_metrics(message["quality_metrics"])
        
        # í”¼ë“œë°± ë²„íŠ¼ë“¤
        self._render_feedback_buttons(message, index)
    
    def _render_meta_reasoning_visualization(self, meta_reasoning: Dict):
        """ğŸ§  ë©”íƒ€ ì¶”ë¡  ê³¼ì • ì‹œê°í™”"""
        if not meta_reasoning:
            st.info("ë©”íƒ€ ì¶”ë¡  ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # 4ë‹¨ê³„ ì¶”ë¡  ê³¼ì • ì‹œê°í™”
        stages = [
            ("ì´ˆê¸° ê´€ì°°", "initial_analysis", "ğŸ”"),
            ("ë‹¤ê°ë„ ë¶„ì„", "multi_perspective", "ğŸ”„"),
            ("ìê°€ ê²€ì¦", "self_verification", "âœ…"),
            ("ì ì‘ì  ì‘ë‹µ", "response_strategy", "ğŸ¯")
        ]
        
        # ì§„í–‰ ë°” í‘œì‹œ
        completed_stages = sum(1 for _, key, _ in stages if key in meta_reasoning)
        progress = completed_stages / len(stages)
        st.progress(progress)
        st.caption(f"ì¶”ë¡  ì™„ë£Œë„: {completed_stages}/{len(stages)} ë‹¨ê³„")
        
        # ê° ë‹¨ê³„ë³„ ìƒì„¸ ì •ë³´
        cols = st.columns(len(stages))
        for i, (stage_name, stage_key, icon) in enumerate(stages):
            with cols[i]:
                if stage_key in meta_reasoning:
                    st.success(f"{icon} {stage_name}")
                    
                    stage_data = meta_reasoning[stage_key]
                    if isinstance(stage_data, dict):
                        # ì£¼ìš” ì •ë³´ë§Œ í‘œì‹œ
                        if "confidence" in stage_data:
                            st.metric("ì‹ ë¢°ë„", f"{stage_data['confidence']:.1%}")
                        
                        if "key_insights" in stage_data:
                            st.write("**ì£¼ìš” ì¸ì‚¬ì´íŠ¸:**")
                            for insight in stage_data["key_insights"][:2]:
                                st.write(f"â€¢ {insight}")
                else:
                    st.info(f"â³ {stage_name}")
        
        # ì „ì²´ ë©”íƒ€ ë¶„ì„ ê²°ê³¼ (ì ‘ê¸°/í¼ì¹˜ê¸°)
        with st.expander("ğŸ”¬ ì „ì²´ ë©”íƒ€ ë¶„ì„ ë°ì´í„°", expanded=False):
            st.json(meta_reasoning)
    
    def _render_agent_collaboration_details(self, agent_contributions: List):
        """ğŸ¤– A2A ì—ì´ì „íŠ¸ í˜‘ì—… ìƒì„¸ ì •ë³´"""
        if not agent_contributions:
            st.info("ì—ì´ì „íŠ¸ í˜‘ì—… ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ì—ì´ì „íŠ¸ë³„ ê¸°ì—¬ë„ ì°¨íŠ¸
        st.write("### ì—ì´ì „íŠ¸ ê¸°ì—¬ë„ ë¶„ì„")
        
        # ê¸°ì—¬ë„ ë§‰ëŒ€ ì°¨íŠ¸
        contrib_data = []
        for contrib in agent_contributions:
            if hasattr(contrib, 'agent_name'):
                contrib_data.append({
                    "ì—ì´ì „íŠ¸": contrib.agent_name,
                    "ê¸°ì—¬ë„": contrib.contribution_score,
                    "í’ˆì§ˆ": contrib.quality_score,
                    "ê³ ìœ ì„±": contrib.uniqueness_score,
                    "ì‹ ë¢°ì„±": contrib.reliability_score
                })
        
        if contrib_data:
            import pandas as pd
            df = pd.DataFrame(contrib_data)
            st.bar_chart(df.set_index("ì—ì´ì „íŠ¸"))
        
        # ê°œë³„ ì—ì´ì „íŠ¸ ìƒì„¸ ì •ë³´
        for i, contrib in enumerate(agent_contributions):
            if hasattr(contrib, 'agent_name'):
                with st.expander(f"ğŸ¤– {contrib.agent_name} ìƒì„¸", expanded=False):
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.metric("ì „ì²´ ê¸°ì—¬ë„", f"{contrib.contribution_score:.2f}")
                        st.metric("í’ˆì§ˆ ì ìˆ˜", f"{contrib.quality_score:.2f}")
                    
                    with col2:
                        st.metric("ê³ ìœ ì„± ì ìˆ˜", f"{contrib.uniqueness_score:.2f}")
                        st.metric("ì‹ ë¢°ì„± ì ìˆ˜", f"{contrib.reliability_score:.2f}")
                    
                    if hasattr(contrib, 'key_insights') and contrib.key_insights:
                        st.write("**í•µì‹¬ ì¸ì‚¬ì´íŠ¸:**")
                        for insight in contrib.key_insights:
                            st.write(f"â€¢ {insight}")
    
    def _render_quality_metrics(self, quality_metrics: Dict):
        """ğŸ“Š ì‘ë‹µ í’ˆì§ˆ í‰ê°€ í‘œì‹œ"""
        st.write("### ì‘ë‹µ í’ˆì§ˆ ë©”íŠ¸ë¦­")
        
        metrics_layout = [
            ("ì „ì²´ í’ˆì§ˆ", "overall_quality"),
            ("ì •í™•ì„±", "accuracy"),
            ("ê´€ë ¨ì„±", "relevance"),
            ("ìœ ìš©ì„±", "usefulness")
        ]
        
        cols = st.columns(len(metrics_layout))
        for i, (label, key) in enumerate(metrics_layout):
            with cols[i]:
                value = quality_metrics.get(key, 0.0)
                if value >= 0.8:
                    st.metric(label, f"{value:.1%}", delta="ìš°ìˆ˜")
                elif value >= 0.6:
                    st.metric(label, f"{value:.1%}", delta="ì–‘í˜¸")
                else:
                    st.metric(label, f"{value:.1%}", delta="ê°œì„  í•„ìš”")
    
    def _render_feedback_buttons(self, message: Dict, index: int):
        """í”¼ë“œë°± ë²„íŠ¼ë“¤ ë Œë”ë§"""
        st.write("---")
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            if st.button("ğŸ‘ ë„ì›€ë¨", key=f"helpful_{index}"):
                self._record_feedback(message, "helpful", True)
                st.success("í”¼ë“œë°±ì´ ê¸°ë¡ë˜ì—ˆìŠµë‹ˆë‹¤!")
        
        with col2:
            if st.button("ğŸ‘ ë³„ë¡œ", key=f"not_helpful_{index}"):
                self._record_feedback(message, "helpful", False)
                st.info("í”¼ë“œë°±ì´ ê¸°ë¡ë˜ì—ˆìŠµë‹ˆë‹¤!")
        
        with col3:
            if st.button("ğŸ”„ ë‹¤ì‹œ ìƒì„±", key=f"regenerate_{index}"):
                st.session_state.regenerate_request = {
                    "message_index": index,
                    "original_query": message.get("original_query", "")
                }
                st.rerun()
        
        with col4:
            if st.button("ğŸ’¾ ì €ì¥", key=f"save_{index}"):
                self._save_message_to_history(message)
                st.success("ë©”ì‹œì§€ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
    
    def render_typing_indicator(self, agent_name: str = "Assistant"):
        """âŒ¨ï¸ íƒ€ì´í•‘ ì¸ë””ì¼€ì´í„° í‘œì‹œ"""
        if self.typing_indicators.get(agent_name, False):
            with st.chat_message("assistant"):
                typing_placeholder = st.empty()
                
                # ì• ë‹ˆë©”ì´ì…˜ íš¨ê³¼
                for i in range(3):
                    typing_placeholder.write(f"ğŸ¤– {agent_name}ì´(ê°€) ì…ë ¥ ì¤‘" + "." * (i + 1))
                    time.sleep(0.5)
                
                typing_placeholder.empty()
    
    def render_streaming_response(
        self, 
        response_generator: AsyncGenerator[Dict, None], 
        agent_info: Optional[List[A2AAgentInfo]] = None
    ):
        """ğŸŒŠ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ë Œë”ë§"""
        
        # ì‘ë‹µ ì»¨í…Œì´ë„ˆë“¤
        response_container = st.empty()
        meta_container = st.empty()
        agent_container = st.empty()
        
        # ìŠ¤íŠ¸ë¦¬ë° ë°ì´í„° ì¶•ì 
        accumulated_response = {
            "content": "",
            "meta_reasoning": {},
            "agent_status": {},
            "progress": 0
        }
        
        async def process_stream():
            async for chunk in response_generator:
                chunk_type = chunk.get("type", "content")
                
                if chunk_type == "content":
                    accumulated_response["content"] += chunk.get("data", "")
                    
                elif chunk_type == "meta_reasoning":
                    accumulated_response["meta_reasoning"].update(chunk.get("data", {}))
                    
                elif chunk_type == "agent_status":
                    accumulated_response["agent_status"].update(chunk.get("data", {}))
                    
                elif chunk_type == "progress":
                    accumulated_response["progress"] = chunk.get("data", 0)
                
                # UI ì—…ë°ì´íŠ¸
                self._update_streaming_display(
                    response_container, 
                    meta_container, 
                    agent_container, 
                    accumulated_response
                )
        
        # ìŠ¤íŠ¸ë¦¬ë° ì‹¤í–‰
        asyncio.run(process_stream())
        
        return accumulated_response
    
    def _update_streaming_display(
        self, 
        response_container, 
        meta_container, 
        agent_container, 
        data: Dict
    ):
        """ìŠ¤íŠ¸ë¦¬ë° í‘œì‹œ ì—…ë°ì´íŠ¸"""
        
        # ì‘ë‹µ ë‚´ìš© ì—…ë°ì´íŠ¸
        with response_container.container():
            st.write("### ğŸ”„ ì‹¤ì‹œê°„ ì‘ë‹µ")
            if data["content"]:
                st.write(data["content"])
            
            # ì§„í–‰ë¥  í‘œì‹œ
            if data["progress"] > 0:
                st.progress(data["progress"] / 100)
                st.caption(f"ì§„í–‰ë¥ : {data['progress']:.1f}%")
        
        # ë©”íƒ€ ì¶”ë¡  ìƒíƒœ ì—…ë°ì´íŠ¸
        if data["meta_reasoning"]:
            with meta_container.container():
                st.write("### ğŸ§  ì¶”ë¡  ì§„í–‰ ìƒí™©")
                self._render_meta_reasoning_progress(data["meta_reasoning"])
        
        # ì—ì´ì „íŠ¸ ìƒíƒœ ì—…ë°ì´íŠ¸
        if data["agent_status"]:
            with agent_container.container():
                st.write("### ğŸ¤– ì—ì´ì „íŠ¸ í™œë™")
                self._render_agent_activity(data["agent_status"])
    
    def _render_meta_reasoning_progress(self, meta_data: Dict):
        """ë©”íƒ€ ì¶”ë¡  ì§„í–‰ ìƒí™© í‘œì‹œ"""
        stages = ["initial_analysis", "multi_perspective", "self_verification", "response_strategy"]
        completed = sum(1 for stage in stages if stage in meta_data)
        
        progress = completed / len(stages)
        st.progress(progress)
        
        cols = st.columns(len(stages))
        stage_names = ["ì´ˆê¸° ê´€ì°°", "ë‹¤ê°ë„ ë¶„ì„", "ìê°€ ê²€ì¦", "ì ì‘ì  ì‘ë‹µ"]
        
        for i, (stage, name) in enumerate(zip(stages, stage_names)):
            with cols[i]:
                if stage in meta_data:
                    st.success(f"âœ… {name}")
                else:
                    st.info(f"â³ {name}")
    
    def _render_agent_activity(self, agent_status: Dict):
        """ì—ì´ì „íŠ¸ í™œë™ ìƒíƒœ í‘œì‹œ"""
        for agent_id, status in agent_status.items():
            status_icon = {
                "active": "ğŸŸ¢",
                "processing": "ğŸŸ¡", 
                "completed": "âœ…",
                "error": "ğŸ”´"
            }.get(status.get("status", "unknown"), "â“")
            
            st.write(f"{status_icon} **{status.get('name', agent_id)}**: {status.get('task', 'Unknown task')}")
    
    def render_chat_input(self) -> Optional[str]:
        """ğŸ’¬ ì±„íŒ… ì…ë ¥ ìœ„ì ¯ ë Œë”ë§"""
        
        # ìë™ ì™„ì„± ì œì•ˆ
        if st.session_state.get('current_data') is not None:
            st.write("ğŸ’¡ **ì¶”ì²œ ì§ˆë¬¸:**")
            suggestions = self._get_smart_suggestions()
            
            cols = st.columns(min(len(suggestions), 3))
            for i, suggestion in enumerate(suggestions[:3]):
                with cols[i]:
                    if st.button(suggestion, key=f"suggestion_{i}"):
                        return suggestion
        
        # ë©”ì¸ ì…ë ¥
        user_input = st.chat_input("ì§ˆë¬¸ì´ë‚˜ ë¶„ì„ ìš”ì²­ì„ ì…ë ¥í•˜ì„¸ìš”...")
        
        # ìŒì„± ì…ë ¥ ì§€ì› (í–¥í›„ í™•ì¥)
        if st.session_state.get('voice_input_enabled', False):
            col1, col2 = st.columns([4, 1])
            with col2:
                if st.button("ğŸ¤ ìŒì„± ì…ë ¥"):
                    st.info("ìŒì„± ì…ë ¥ ê¸°ëŠ¥ì€ í–¥í›„ ì§€ì› ì˜ˆì •ì…ë‹ˆë‹¤.")
        
        return user_input
    
    def _get_smart_suggestions(self) -> List[str]:
        """ìŠ¤ë§ˆíŠ¸ ì§ˆë¬¸ ì œì•ˆ ìƒì„±"""
        current_data = st.session_state.get('current_data')
        if current_data is None:
            return []
        
        import pandas as pd
        
        if isinstance(current_data, pd.DataFrame):
            suggestions = [
                "ì´ ë°ì´í„°ì˜ ì£¼ìš” íŒ¨í„´ì€ ë¬´ì—‡ì¸ê°€ìš”?",
                "ë°ì´í„°ì—ì„œ ì´ìƒê°’ì„ ì°¾ì•„ì£¼ì„¸ìš”",
                "ì»¬ëŸ¼ ê°„ì˜ ìƒê´€ê´€ê³„ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”"
            ]
        else:
            suggestions = [
                "ì´ ë°ì´í„°ë¥¼ ìš”ì•½í•´ì£¼ì„¸ìš”",
                "ì£¼ìš” ì¸ì‚¬ì´íŠ¸ë¥¼ ì°¾ì•„ì£¼ì„¸ìš”",
                "ë°ì´í„° í’ˆì§ˆì„ í‰ê°€í•´ì£¼ì„¸ìš”"
            ]
        
        return suggestions
    
    def _format_timestamp(self, timestamp: str) -> str:
        """íƒ€ì„ìŠ¤íƒ¬í”„ í¬ë§·íŒ…"""
        try:
            dt = datetime.fromisoformat(timestamp.replace('Z', '+00:00'))
            return dt.strftime("%Y-%m-%d %H:%M:%S")
        except:
            return timestamp
    
    def _record_feedback(self, message: Dict, feedback_type: str, value: Any):
        """í”¼ë“œë°± ê¸°ë¡"""
        if 'feedback_history' not in st.session_state:
            st.session_state.feedback_history = []
        
        feedback_entry = {
            "timestamp": datetime.now().isoformat(),
            "message_id": message.get("id", "unknown"),
            "feedback_type": feedback_type,
            "value": value,
            "message_content": message.get("content", "")[:100]  # ì²˜ìŒ 100ìë§Œ
        }
        
        st.session_state.feedback_history.append(feedback_entry)
        
        # í”¼ë“œë°± ì´ë ¥ í¬ê¸° ì œí•œ
        if len(st.session_state.feedback_history) > 100:
            st.session_state.feedback_history = st.session_state.feedback_history[-100:]
    
    def _save_message_to_history(self, message: Dict):
        """ë©”ì‹œì§€ë¥¼ ì´ë ¥ì— ì €ì¥"""
        if 'saved_messages' not in st.session_state:
            st.session_state.saved_messages = []
        
        saved_message = {
            "timestamp": datetime.now().isoformat(),
            "content": message.get("content", ""),
            "meta_reasoning": message.get("meta_reasoning"),
            "agent_contributions": message.get("agent_contributions"),
            "tags": []  # í–¥í›„ íƒœê·¸ ê¸°ëŠ¥ ì§€ì›
        }
        
        st.session_state.saved_messages.append(saved_message)
    
    def set_typing_indicator(self, agent_name: str, is_typing: bool):
        """íƒ€ì´í•‘ ì¸ë””ì¼€ì´í„° ì„¤ì •"""
        self.typing_indicators[agent_name] = is_typing
    
    def get_conversation_summary(self) -> Dict[str, Any]:
        """ëŒ€í™” ìš”ì•½ ìƒì„±"""
        messages = st.session_state.get('messages', [])
        
        if not messages:
            return {"message": "No conversation history"}
        
        user_messages = [msg for msg in messages if msg.get('role') == 'user']
        assistant_messages = [msg for msg in messages if msg.get('role') == 'assistant']
        
        return {
            "total_messages": len(messages),
            "user_messages": len(user_messages),
            "assistant_messages": len(assistant_messages),
            "conversation_start": messages[0].get('timestamp', 'Unknown'),
            "last_message": messages[-1].get('timestamp', 'Unknown'),
            "topics_discussed": self._extract_topics(user_messages),
            "average_response_quality": self._calculate_avg_quality(assistant_messages)
        }
    
    def _extract_topics(self, user_messages: List[Dict]) -> List[str]:
        """ëŒ€í™” ì£¼ì œ ì¶”ì¶œ (ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜)"""
        # í–¥í›„ LLMì„ ì‚¬ìš©í•œ ë” ì •êµí•œ ì£¼ì œ ì¶”ì¶œë¡œ ê°œì„  ê°€ëŠ¥
        common_keywords = []
        for msg in user_messages:
            content = msg.get('content', '').lower()
            # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ ë¡œì§
            if 'ë¶„ì„' in content:
                common_keywords.append('ë°ì´í„° ë¶„ì„')
            if 'íŒ¨í„´' in content:
                common_keywords.append('íŒ¨í„´ ë°œê²¬')
            if 'ì˜ˆì¸¡' in content:
                common_keywords.append('ì˜ˆì¸¡ ëª¨ë¸ë§')
        
        return list(set(common_keywords))
    
    def _calculate_avg_quality(self, assistant_messages: List[Dict]) -> float:
        """í‰ê·  ì‘ë‹µ í’ˆì§ˆ ê³„ì‚°"""
        quality_scores = []
        for msg in assistant_messages:
            quality_metrics = msg.get('quality_metrics', {})
            if quality_metrics:
                overall_quality = quality_metrics.get('overall_quality', 0.0)
                quality_scores.append(overall_quality)
        
        if quality_scores:
            return sum(quality_scores) / len(quality_scores)
        return 0.0