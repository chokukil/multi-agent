"""
Smart Query Router - LLM ê¸°ë°˜ ì§€ëŠ¥í˜• ì¿¼ë¦¬ ë¼ìš°íŒ… ì‹œìŠ¤í…œ

Requirements 6.1ì— ë”°ë¥¸ êµ¬í˜„:
- LLM ê¸°ë°˜ ì¿¼ë¦¬ ë³µì¡ë„ ë¶„ì„
- fast_track (5-10ì´ˆ) / balanced (10-20ì´ˆ) / thorough (30-60ì´ˆ) / expert_mode
- ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì˜¤ë²„í—¤ë“œ ì—†ëŠ” ì§ì ‘ ì‘ë‹µ
- ë‹¨ì¼ ì—ì´ì „íŠ¸ ì²˜ë¦¬
- ë©€í‹° ì—ì´ì „íŠ¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜
"""

import asyncio
import logging
from typing import Dict, Any, Optional, List, Literal
from datetime import datetime
import json

from ..llm_factory import LLMFactory
from .universal_query_processor import UniversalQueryProcessor
from ..a2a_integration.a2a_agent_discovery import A2AAgentDiscoverySystem
from ..a2a_integration.llm_based_agent_selector import LLMBasedAgentSelector
from ..a2a_integration.a2a_workflow_orchestrator import A2AWorkflowOrchestrator
from ..monitoring.performance_monitoring_system import PerformanceMonitor
from .langfuse_integration import SessionBasedTracer, LangfuseEnhancedA2AExecutor, get_global_tracer

logger = logging.getLogger(__name__)

# ì²˜ë¦¬ ëª¨ë“œ íƒ€ì…
ProcessingMode = Literal["fast_track", "balanced", "thorough", "expert_mode"]


class SmartQueryRouter:
    """
    ì§€ëŠ¥í˜• ì¿¼ë¦¬ ë¼ìš°í„° - LLM First ì›ì¹™ì— ë”°ë¥¸ ë™ì  ë¼ìš°íŒ…
    
    í•˜ë“œì½”ë”©ëœ ê·œì¹™ ì—†ì´ ìˆœìˆ˜ LLM íŒë‹¨ìœ¼ë¡œ:
    1. ì¿¼ë¦¬ ë³µì¡ë„ í‰ê°€
    2. ìµœì  ì²˜ë¦¬ ê²½ë¡œ ê²°ì •
    3. ë¦¬ì†ŒìŠ¤ í• ë‹¹ ìµœì í™”
    """
    
    def __init__(self):
        """SmartQueryRouter ì´ˆê¸°í™”"""
        self.llm_client = LLMFactory.create_llm()
        self.universal_processor = UniversalQueryProcessor()
        self.agent_discovery = A2AAgentDiscoverySystem()
        self.agent_selector = LLMBasedAgentSelector(self.agent_discovery)
        self.workflow_orchestrator = None  # í•„ìš”ì‹œ ì´ˆê¸°í™”
        self.performance_monitor = PerformanceMonitor()
        
        # Langfuse í†µí•© ì™„ë£Œ
        self.langfuse_tracer = get_global_tracer()
        self.enhanced_executor = LangfuseEnhancedA2AExecutor(self.langfuse_tracer)
        
        logger.info("SmartQueryRouter initialized with LLM-first architecture")
    
    async def route_query(
        self, 
        query: str, 
        data: Any = None, 
        context: Dict[str, Any] = None
    ) -> Dict[str, Any]:
        """
        ì¿¼ë¦¬ë¥¼ ë¶„ì„í•˜ê³  ìµœì ì˜ ì²˜ë¦¬ ê²½ë¡œë¡œ ë¼ìš°íŒ…
        
        Args:
            query: ì‚¬ìš©ì ì¿¼ë¦¬
            data: ë¶„ì„í•  ë°ì´í„°
            context: ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸
            
        Returns:
            ì²˜ë¦¬ ê²°ê³¼
        """
        start_time = datetime.now()
        context = context or {}
        
        # Langfuse ì„¸ì…˜ ìƒì„±
        session_id = context.get('session_id')
        if not session_id:
            session_id = self.langfuse_tracer.create_session(query)
            context['session_id'] = session_id
        
        try:
            # ë¼ìš°íŒ… ì‹œì‘ ì¶”ì 
            self.langfuse_tracer.add_span(
                name="smart_query_routing_start",
                input_data={"query": query[:200]},  # ì¿¼ë¦¬ ì¼ë¶€ë§Œ ê¸°ë¡
                start_time=start_time
            )
            
            # 1. ë¹ ë¥¸ ë³µì¡ë„ ì‚¬ì „ íŒë‹¨
            complexity_assessment = await self.quick_complexity_assessment(query, data)
            processing_mode = complexity_assessment['mode']
            
            # ë³µì¡ë„ í‰ê°€ ì¶”ì 
            self.langfuse_tracer.add_span(
                name="complexity_assessment",
                input_data={"query": query[:100]},
                output_data=complexity_assessment
            )
            
            logger.info(f"Query complexity: {complexity_assessment['complexity']} -> Mode: {processing_mode}")
            
            # 2. ì²˜ë¦¬ ëª¨ë“œì— ë”°ë¥¸ ë¼ìš°íŒ…
            if processing_mode == "fast_track":
                # ì§ì ‘ ì‘ë‹µ (5-10ì´ˆ)
                result = await self.direct_response(query, data, context)
                
            elif processing_mode == "balanced":
                # ë‹¨ì¼ ì—ì´ì „íŠ¸ (10-20ì´ˆ)
                result = await self.single_agent_response(query, data, context, complexity_assessment)
                
            elif processing_mode in ["thorough", "expert_mode"]:
                # ë©€í‹° ì—ì´ì „íŠ¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ (30-60ì´ˆ)
                result = await self.orchestrated_response(query, data, context, complexity_assessment)
                
            else:
                # ê¸°ë³¸ê°’: balanced
                result = await self.single_agent_response(query, data, context, complexity_assessment)
            
            # ì²˜ë¦¬ ì‹œê°„ ê¸°ë¡
            processing_time = (datetime.now() - start_time).total_seconds()
            result['processing_time'] = processing_time
            result['processing_mode'] = processing_mode
            
            # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
            await self.performance_monitor.record_query_processing(
                query=query,
                mode=processing_mode,
                processing_time=processing_time,
                success=True
            )
            
            return result
            
        except Exception as e:
            logger.error(f"Error in query routing: {str(e)}")
            processing_time = (datetime.now() - start_time).total_seconds()
            
            await self.performance_monitor.record_query_processing(
                query=query,
                mode="error",
                processing_time=processing_time,
                success=False
            )
            
            return {
                "success": False,
                "error": str(e),
                "processing_time": processing_time
            }
    
    async def quick_complexity_assessment(
        self, 
        query: str, 
        data: Any = None
    ) -> Dict[str, Any]:
        """
        LLM ê¸°ë°˜ ë¹ ë¥¸ ë³µì¡ë„ ì‚¬ì „ íŒë‹¨
        
        Returns:
            {
                "complexity": "trivial|simple|medium|complex",
                "mode": "fast_track|balanced|thorough|expert_mode",
                "confidence": 0.0-1.0,
                "reasoning": "íŒë‹¨ ê·¼ê±°"
            }
        """
        # ë°ì´í„° í¬ê¸° ì •ë³´ ì¤€ë¹„
        data_info = self._get_data_info(data)
        
        # LLM í”„ë¡¬í”„íŠ¸
        prompt = f"""
You are an AI assistant specialized in analyzing query complexity for data analysis tasks.
Analyze the following query and determine its complexity level and appropriate processing mode.

Query: "{query}"

Data Information:
{json.dumps(data_info, indent=2)}

Classify the query into one of these complexity levels:
- trivial: Very simple queries that can be answered directly (e.g., "What is the shape of data?", "Show first 5 rows")
- simple: Basic single-operation queries (e.g., "Calculate mean of column X", "Filter data by condition Y")
- medium: Queries requiring multiple steps or moderate analysis (e.g., "Analyze trends and patterns", "Compare two datasets")
- complex: Queries requiring deep analysis, multiple agents, or domain expertise (e.g., "Perform comprehensive analysis with ML models", "Generate detailed report with insights")

Based on the complexity, assign a processing mode:
- fast_track: For trivial queries (5-10 seconds)
- balanced: For simple queries (10-20 seconds)
- thorough: For medium queries (30-60 seconds)
- expert_mode: For complex queries requiring full capabilities (30-60 seconds)

Respond in JSON format:
{{
    "complexity": "trivial|simple|medium|complex",
    "mode": "fast_track|balanced|thorough|expert_mode",
    "confidence": 0.0-1.0,
    "reasoning": "Brief explanation of your assessment"
}}
"""
        
        try:
            response = await self.llm_client.agenerate([prompt])
            result_text = response.generations[0][0].text.strip()
            
            # JSON íŒŒì‹±
            if "```json" in result_text:
                result_text = result_text.split("```json")[1].split("```")[0].strip()
            
            assessment = json.loads(result_text)
            
            # ê²€ì¦ ë° ê¸°ë³¸ê°’
            if assessment['complexity'] not in ['trivial', 'simple', 'medium', 'complex']:
                assessment['complexity'] = 'simple'
            if assessment['mode'] not in ['fast_track', 'balanced', 'thorough', 'expert_mode']:
                assessment['mode'] = 'balanced'
            if 'confidence' not in assessment:
                assessment['confidence'] = 0.8
                
            return assessment
            
        except Exception as e:
            logger.warning(f"Error in complexity assessment: {str(e)}, using default")
            return {
                "complexity": "simple",
                "mode": "balanced",
                "confidence": 0.5,
                "reasoning": "Default assessment due to error"
            }
    
    async def direct_response(
        self, 
        query: str, 
        data: Any = None, 
        context: Dict[str, Any] = None
    ) -> Dict[str, Any]:
        """
        ì§ì ‘ LLM ì‘ë‹µ - ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì˜¤ë²„í—¤ë“œ ì—†ìŒ (5-10ì´ˆ)
        
        trivial ì¿¼ë¦¬ë¥¼ ìœ„í•œ ë¹ ë¥¸ ì²˜ë¦¬
        """
        logger.info("Processing via direct response (fast_track)")
        
        # ê°„ë‹¨í•œ ì„¸ì…˜ ì¶”ì 
        session_id = context.get('session_id', f"direct_{datetime.now().timestamp()}")
        
        # ë°ì´í„° ì •ë³´ ì¤€ë¹„
        data_info = self._get_data_info(data)
        
        # ì§ì ‘ LLM ì‘ë‹µ ìƒì„±
        prompt = f"""
You are a helpful data analysis assistant. Answer the following query directly and concisely.

Query: {query}

Data Information:
{json.dumps(data_info, indent=2)}

Provide a clear and direct answer. If the query asks for specific data, provide it.
If it's a question about the data, answer it directly.
"""
        
        try:
            response = await self.llm_client.agenerate([prompt])
            answer = response.generations[0][0].text.strip()
            
            return {
                "success": True,
                "result": answer,
                "mode": "fast_track",
                "session_id": session_id,
                "agents_used": []
            }
            
        except Exception as e:
            logger.error(f"Error in direct response: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "mode": "fast_track",
                "session_id": session_id
            }
    
    async def single_agent_response(
        self, 
        query: str, 
        data: Any = None, 
        context: Dict[str, Any] = None,
        complexity_assessment: Dict[str, Any] = None
    ) -> Dict[str, Any]:
        """
        ë‹¨ì¼ ì—ì´ì „íŠ¸ ì‘ë‹µ (10-20ì´ˆ)
        
        LLMì´ ì„ íƒí•œ ê°€ì¥ ì í•©í•œ ë‹¨ì¼ ì—ì´ì „íŠ¸ë¡œ ì²˜ë¦¬
        """
        logger.info("Processing via single agent (balanced)")
        
        session_id = context.get('session_id', f"single_{datetime.now().timestamp()}")
        
        try:
            # LLM ê¸°ë°˜ ìµœì  ì—ì´ì „íŠ¸ ì„ íƒ
            selected_agents = await self.agent_selector.select_agents_for_task(
                query=query,
                context={
                    **context,
                    "mode": "single_agent",
                    "complexity": complexity_assessment
                }
            )
            
            if not selected_agents:
                # ì—ì´ì „íŠ¸ ì„ íƒ ì‹¤íŒ¨ì‹œ ì§ì ‘ ì‘ë‹µìœ¼ë¡œ í´ë°±
                logger.warning("No suitable agent found, falling back to direct response")
                return await self.direct_response(query, data, context)
            
            # ì²« ë²ˆì§¸ ì—ì´ì „íŠ¸ ì‚¬ìš©
            agent = selected_agents[0]
            logger.info(f"Selected agent: {agent['name']} on port {agent['port']}")
            
            # ì—ì´ì „íŠ¸ ì‹¤í–‰
            result = await self._execute_single_agent(agent, query, data)
            
            return {
                "success": True,
                "result": result,
                "mode": "balanced",
                "session_id": session_id,
                "agents_used": [agent['name']]
            }
            
        except Exception as e:
            logger.error(f"Error in single agent response: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "mode": "balanced",
                "session_id": session_id
            }
    
    async def orchestrated_response(
        self, 
        query: str, 
        data: Any = None, 
        context: Dict[str, Any] = None,
        complexity_assessment: Dict[str, Any] = None
    ) -> Dict[str, Any]:
        """
        ë©€í‹° ì—ì´ì „íŠ¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ì‘ë‹µ (30-60ì´ˆ)
        
        ë³µì¡í•œ ì¿¼ë¦¬ë¥¼ ìœ„í•œ ì™„ì „í•œ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜
        """
        logger.info("Processing via multi-agent orchestration (thorough/expert)")
        
        session_id = context.get('session_id', f"orchestrated_{datetime.now().timestamp()}")
        
        # ì›Œí¬í”Œë¡œìš° ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì´ˆê¸°í™” (í•„ìš”ì‹œ)
        if not self.workflow_orchestrator:
            from ..a2a_integration.a2a_communication_protocol import A2ACommunicationProtocol
            comm_protocol = A2ACommunicationProtocol()
            self.workflow_orchestrator = A2AWorkflowOrchestrator(comm_protocol)
        
        try:
            # LLM First Optimized Orchestrator ì‚¬ìš© (Phase 2ì—ì„œ êµ¬í˜„)
            # í˜„ì¬ëŠ” ê¸°ë³¸ Universal Query Processor ì‚¬ìš©
            result = await self.universal_processor.process_query(
                query=query,
                data=data,
                context={
                    **context,
                    "mode": complexity_assessment.get('mode', 'thorough'),
                    "complexity_assessment": complexity_assessment
                }
            )
            
            return {
                "success": True,
                "result": result.get('final_answer', result),
                "mode": complexity_assessment.get('mode', 'thorough'),
                "session_id": session_id,
                "agents_used": result.get('agents_used', []),
                "reasoning_steps": result.get('reasoning_steps', [])
            }
            
        except Exception as e:
            logger.error(f"Error in orchestrated response: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "mode": complexity_assessment.get('mode', 'thorough'),
                "session_id": session_id
            }
    
    def _get_data_info(self, data: Any) -> Dict[str, Any]:
        """ë°ì´í„° ì •ë³´ ì¶”ì¶œ"""
        if data is None:
            return {"type": "none", "description": "No data provided"}
        
        data_info = {"type": type(data).__name__}
        
        # pandas DataFrame ì²˜ë¦¬
        if hasattr(data, 'shape'):
            data_info.update({
                "shape": data.shape,
                "columns": list(data.columns) if hasattr(data, 'columns') else None,
                "dtypes": {col: str(dtype) for col, dtype in data.dtypes.items()} if hasattr(data, 'dtypes') else None
            })
        
        # ë¦¬ìŠ¤íŠ¸/ë”•ì…”ë„ˆë¦¬ ì²˜ë¦¬
        elif isinstance(data, (list, dict)):
            data_info["length"] = len(data)
            if isinstance(data, list) and data:
                data_info["sample"] = str(data[0])[:100]
        
        # ë¬¸ìì—´ ì²˜ë¦¬
        elif isinstance(data, str):
            data_info["length"] = len(data)
            data_info["preview"] = data[:200]
        
        return data_info
    
    async def _execute_single_agent(
        self, 
        agent: Dict[str, Any], 
        query: str, 
        data: Any
    ) -> Any:
        """ë‹¨ì¼ ì—ì´ì „íŠ¸ ì‹¤í–‰"""
        # TODO: ì‹¤ì œ A2A ì—ì´ì „íŠ¸ í˜¸ì¶œ êµ¬í˜„
        # í˜„ì¬ëŠ” ì‹œë®¬ë ˆì´ì…˜
        return f"Result from {agent['name']}: Processed query '{query}'"
    
    async def route_query_with_streaming(self, query: str, data: Any = None) -> AsyncGenerator[Dict[str, Any], None]:
        """
        ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ì¿¼ë¦¬ ì²˜ë¦¬
        
        Args:
            query: ì‚¬ìš©ì ì¿¼ë¦¬
            data: ì„ íƒì  ë°ì´í„°
            
        Yields:
            Dict[str, Any]: ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²­í¬
        """
        logger.info(f"ğŸš€ Streaming query processing started: {query[:50]}...")
        
        try:
            # ë³µì¡ë„ í‰ê°€
            yield {
                "type": "status",
                "content": "ğŸ” ì¿¼ë¦¬ ë³µì¡ë„ë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...",
                "step": "complexity_assessment"
            }
            
            assessment = await self.quick_complexity_assessment(query)
            
            yield {
                "type": "status", 
                "content": f"ğŸ“Š ë³µì¡ë„: {assessment['complexity']} | ëª¨ë“œ: {assessment['mode']}",
                "step": "complexity_result"
            }
            
            # ëª¨ë“œë³„ ì²˜ë¦¬
            if assessment['mode'] == 'fast_track':
                yield {
                    "type": "status",
                    "content": "âš¡ ë¹ ë¥¸ ì‘ë‹µ ëª¨ë“œë¡œ ì²˜ë¦¬ ì¤‘...",
                    "step": "direct_processing"
                }
                
                result = await self.direct_response(query, data, {"session_id": f"stream_{datetime.now().timestamp()}"})
                
                yield {
                    "type": "result",
                    "content": result['result'],
                    "agent": "LLM_Direct",
                    "processing_time": result['processing_time']
                }
                
            elif assessment['mode'] == 'balanced':
                yield {
                    "type": "status",
                    "content": "ğŸ¯ ë‹¨ì¼ ì—ì´ì „íŠ¸ ëª¨ë“œë¡œ ì²˜ë¦¬ ì¤‘...",
                    "step": "single_agent_processing"
                }
                
                result = await self.single_agent_response(query, data, {"session_id": f"stream_{datetime.now().timestamp()}"})
                
                yield {
                    "type": "result",
                    "content": result['result'],
                    "agent": result.get('agent_used', 'Unknown'),
                    "processing_time": result['processing_time']
                }
                
            else:  # thorough or expert_mode
                yield {
                    "type": "status",
                    "content": "ğŸ­ ë‹¤ì¤‘ ì—ì´ì „íŠ¸ í˜‘ì—… ëª¨ë“œë¡œ ì²˜ë¦¬ ì¤‘...",
                    "step": "orchestrated_processing"
                }
                
                result = await self.orchestrated_response(query, data, {"session_id": f"stream_{datetime.now().timestamp()}"})
                
                yield {
                    "type": "result",
                    "content": result['result'],
                    "agent": "Multi-Agent",
                    "processing_time": result['processing_time']
                }
                
        except Exception as e:
            logger.error(f"Streaming query processing error: {e}", exc_info=True)
            yield {
                "type": "error",
                "content": f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            }