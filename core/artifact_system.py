import os
import uuid
import hashlib
import json
import time
import traceback
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple
from pathlib import Path
from collections import OrderedDict
import logging

class ArtifactManager:
    """Canvas/Artifact ìŠ¤íƒ€ì¼ ì•„í‹°íŒ©íŠ¸ ê´€ë¦¬ ì‹œìŠ¤í…œ"""
    
    def __init__(self, max_memory_mb: int = 100, max_cache_items: int = 10):
        self.artifacts = OrderedDict()  # LRU ìºì‹œ
        self.metadata = {}
        self.max_memory_mb = max_memory_mb
        self.max_cache_items = max_cache_items
        self.current_memory_mb = 0
        
        # íŒŒì¼ ì‹œìŠ¤í…œ êµ¬ì¡°
        self.base_path = Path("artifacts")
        self.base_path.mkdir(exist_ok=True)
        
        # íƒ€ì…ë³„ ë””ë ‰í† ë¦¬
        self.type_dirs = {
            "python": self.base_path / "python",
            "markdown": self.base_path / "markdown", 
            "text": self.base_path / "text",
            "data": self.base_path / "data",
            "plots": self.base_path / "plots"
        }
        
        for dir_path in self.type_dirs.values():
            dir_path.mkdir(exist_ok=True)
            
        logging.info(f"ğŸ¨ Artifact Manager initialized: {max_memory_mb}MB limit, {max_cache_items} cache items")
    
    def create_artifact(self, content: str, artifact_type: str, title: Optional[str] = None, 
                       agent_name: Optional[str] = None, metadata: Optional[Dict] = None) -> str:
        """ìƒˆ ì•„í‹°íŒ©íŠ¸ ìƒì„±"""
        artifact_id = str(uuid.uuid4())[:8]
        timestamp = datetime.now().isoformat()
        
        # ë©”íƒ€ë°ì´í„° ìƒì„±
        artifact_metadata = {
            "id": artifact_id,
            "type": artifact_type,
            "title": title or f"{artifact_type.title()} Artifact",
            "agent_name": agent_name or "System",
            "created_at": timestamp,
            "updated_at": timestamp,
            "version": 1,
            "file_path": None,
            "size_bytes": len(content.encode('utf-8')),
            "hash": hashlib.sha256(content.encode('utf-8')).hexdigest()[:16],
            "tags": [],
            "execution_status": "ready",
            "custom_metadata": metadata or {}
        }
        
        # íŒŒì¼ ì €ì¥
        file_path = self._save_to_file(artifact_id, content, artifact_type)
        artifact_metadata["file_path"] = str(file_path)
        
        # ë©”ëª¨ë¦¬ì— ìºì‹œ
        self._add_to_cache(artifact_id, content, artifact_metadata)
        
        # ë©”íƒ€ë°ì´í„° ì €ì¥
        self.metadata[artifact_id] = artifact_metadata
        self._save_metadata()
        
        logging.info(f"ğŸ¨ Created artifact {artifact_id}: {title} ({artifact_type})")
        return artifact_id
    
    def update_artifact(self, artifact_id: str, content: str) -> bool:
        """ì•„í‹°íŒ©íŠ¸ ì—…ë°ì´íŠ¸"""
        if artifact_id not in self.metadata:
            return False
            
        metadata = self.metadata[artifact_id]
        old_version = metadata["version"]
        
        # ë²„ì „ íˆìŠ¤í† ë¦¬ ë°±ì—…
        self._backup_version(artifact_id, old_version)
        
        # ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
        metadata["version"] += 1
        metadata["updated_at"] = datetime.now().isoformat()
        metadata["size_bytes"] = len(content.encode('utf-8'))
        metadata["hash"] = hashlib.sha256(content.encode('utf-8')).hexdigest()[:16]
        
        # íŒŒì¼ ì—…ë°ì´íŠ¸
        file_path = Path(metadata["file_path"])
        file_path.write_text(content, encoding='utf-8')
        
        # ìºì‹œ ì—…ë°ì´íŠ¸
        if artifact_id in self.artifacts:
            self.artifacts[artifact_id] = content
            self.artifacts.move_to_end(artifact_id)  # LRU ì—…ë°ì´íŠ¸
        
        self._save_metadata()
        
        logging.info(f"ğŸ”„ Updated artifact {artifact_id}: v{old_version} â†’ v{metadata['version']}")
        return True
    
    def get_artifact(self, artifact_id: str) -> Optional[Tuple[str, Dict]]:
        """ì•„í‹°íŒ©íŠ¸ ì¡°íšŒ"""
        if artifact_id not in self.metadata:
            return None
            
        # ìºì‹œì—ì„œ í™•ì¸
        if artifact_id in self.artifacts:
            content = self.artifacts[artifact_id]
            self.artifacts.move_to_end(artifact_id)  # LRU ì—…ë°ì´íŠ¸
        else:
            # íŒŒì¼ì—ì„œ ë¡œë“œ
            metadata = self.metadata[artifact_id]
            file_path = Path(metadata["file_path"])
            if not file_path.exists():
                return None
            content = file_path.read_text(encoding='utf-8')
            self._add_to_cache(artifact_id, content, metadata)
        
        return content, self.metadata[artifact_id].copy()
    
    def list_artifacts(self, artifact_type: Optional[str] = None, agent_name: Optional[str] = None, 
                      tags: Optional[List[str]] = None) -> List[Dict]:
        """ì•„í‹°íŒ©íŠ¸ ëª©ë¡ ì¡°íšŒ"""
        results = []
        
        for artifact_id, metadata in self.metadata.items():
            # í•„í„°ë§
            if artifact_type and metadata["type"] != artifact_type:
                continue
            if agent_name and metadata["agent_name"] != agent_name:
                continue
            if tags and not any(tag in metadata["tags"] for tag in tags):
                continue
                
            results.append(metadata.copy())
        
        # ìµœê·¼ ì—…ë°ì´íŠ¸ ìˆœìœ¼ë¡œ ì •ë ¬
        results.sort(key=lambda x: x["updated_at"], reverse=True)
        return results
    
    def delete_artifact(self, artifact_id: str) -> bool:
        """ì•„í‹°íŒ©íŠ¸ ì‚­ì œ"""
        if artifact_id not in self.metadata:
            return False
            
        metadata = self.metadata[artifact_id]
        
        # íŒŒì¼ ì‚­ì œ
        file_path = Path(metadata["file_path"])
        if file_path.exists():
            file_path.unlink()
        
        # ë²„ì „ íˆìŠ¤í† ë¦¬ ì‚­ì œ
        version_dir = file_path.parent / "versions" / artifact_id
        if version_dir.exists():
            import shutil
            shutil.rmtree(version_dir)
        
        # ìºì‹œì—ì„œ ì œê±°
        if artifact_id in self.artifacts:
            del self.artifacts[artifact_id]
            
        # ë©”íƒ€ë°ì´í„°ì—ì„œ ì œê±°
        del self.metadata[artifact_id]
        self._save_metadata()
        
        logging.info(f"ğŸ—‘ï¸ Deleted artifact {artifact_id}")
        return True
    
    def execute_python_artifact(self, artifact_id: str, timeout: int = 30) -> Dict:
        """Python ì•„í‹°íŒ©íŠ¸ ì‹¤í–‰"""
        if artifact_id not in self.metadata:
            return {"error": "Artifact not found"}
            
        metadata = self.metadata[artifact_id]
        if metadata["type"] != "python":
            return {"error": "Not a Python artifact"}
        
        content, _ = self.get_artifact(artifact_id)
        if not content:
            return {"error": "Failed to load artifact content"}
        
        # ì‹¤í–‰ ìƒíƒœ ì—…ë°ì´íŠ¸
        metadata["execution_status"] = "running"
        
        try:
            # ì•ˆì „í•œ ì‹¤í–‰ í™˜ê²½ êµ¬ì„±
            import sys
            from io import StringIO
            import contextlib
            
            # stdout/stderr ìº¡ì²˜
            stdout_capture = StringIO()
            stderr_capture = StringIO()
            
            # ì‹¤í–‰ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ êµ¬ì„±
            exec_namespace = {
                '__name__': '__main__',
                '__builtins__': __builtins__,
                # í—ˆìš©ëœ ëª¨ë“ˆë“¤
                'pandas': None,
                'numpy': None,
                'matplotlib': None,
                'plotly': None,
                'seaborn': None
            }
            
            # ì‹¤ì œ ëª¨ë“ˆ ì„í¬íŠ¸ (ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°)
            try:
                import pandas as pd
                exec_namespace['pandas'] = pd
                exec_namespace['pd'] = pd
            except ImportError:
                pass
            
            try:
                import numpy as np
                exec_namespace['numpy'] = np
                exec_namespace['np'] = np
            except ImportError:
                pass
            
            # ì‹¤í–‰
            start_time = time.time()
            
            with contextlib.redirect_stdout(stdout_capture), \
                 contextlib.redirect_stderr(stderr_capture):
                exec(content, exec_namespace)
            
            execution_time = time.time() - start_time
            
            # ê²°ê³¼ ìˆ˜ì§‘
            stdout_output = stdout_capture.getvalue()
            stderr_output = stderr_capture.getvalue()
            
            result = {
                "success": True,
                "stdout": stdout_output,
                "stderr": stderr_output,
                "execution_time": execution_time,
                "timestamp": datetime.now().isoformat()
            }
            
            metadata["execution_status"] = "completed"
            
        except Exception as e:
            result = {
                "success": False,
                "error": str(e),
                "traceback": traceback.format_exc(),
                "timestamp": datetime.now().isoformat()
            }
            metadata["execution_status"] = "error"
        
        self._save_metadata()
        return result
    
    def get_memory_usage(self) -> Dict:
        """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì •ë³´"""
        return {
            "current_mb": self.current_memory_mb,
            "max_mb": self.max_memory_mb,
            "usage_percent": (self.current_memory_mb / self.max_memory_mb) * 100,
            "cached_items": len(self.artifacts),
            "max_cache_items": self.max_cache_items
        }
    
    def cleanup_cache(self, target_percent: float = 60.0):
        """ìºì‹œ ì •ë¦¬ (LRU + Priority ê¸°ë°˜)"""
        target_mb = (target_percent / 100.0) * self.max_memory_mb
        
        # LRU ìˆœì„œë¡œ ì œê±° (ê°€ì¥ ì˜¤ë˜ëœ ê²ƒë¶€í„°)
        while (self.current_memory_mb > target_mb and 
               len(self.artifacts) > 0):
            # ê°€ì¥ ì˜¤ë˜ëœ ì•„ì´í…œ ì œê±°
            artifact_id, content = self.artifacts.popitem(last=False)
            content_size = len(content.encode('utf-8')) / 1024 / 1024
            self.current_memory_mb -= content_size
            
            logging.info(f"ğŸ§¹ Removed artifact {artifact_id} from cache ({content_size:.2f}MB)")
    
    def _add_to_cache(self, artifact_id: str, content: str, metadata: Dict):
        """ìºì‹œì— ì•„í‹°íŒ©íŠ¸ ì¶”ê°€"""
        content_size = len(content.encode('utf-8')) / 1024 / 1024  # MB
        
        # ë©”ëª¨ë¦¬ ì œí•œ í™•ì¸
        if self.current_memory_mb + content_size > self.max_memory_mb:
            self.cleanup_cache()
        
        # ì•„ì´í…œ ìˆ˜ ì œí•œ í™•ì¸
        if len(self.artifacts) >= self.max_cache_items:
            # ê°€ì¥ ì˜¤ë˜ëœ ì•„ì´í…œ ì œê±°
            old_id, old_content = self.artifacts.popitem(last=False)
            old_size = len(old_content.encode('utf-8')) / 1024 / 1024
            self.current_memory_mb -= old_size
        
        # ìºì‹œì— ì¶”ê°€
        self.artifacts[artifact_id] = content
        self.current_memory_mb += content_size
    
    def _save_to_file(self, artifact_id: str, content: str, artifact_type: str) -> Path:
        """íŒŒì¼ë¡œ ì €ì¥"""
        type_dir = self.type_dirs.get(artifact_type, self.type_dirs["text"])
        
        # íŒŒì¼ í™•ì¥ì ê²°ì •
        extensions = {
            "python": ".py",
            "markdown": ".md",
            "text": ".txt",
            "data": ".json",
            "plots": ".html"
        }
        
        ext = extensions.get(artifact_type, ".txt")
        file_path = type_dir / f"{artifact_id}{ext}"
        
        file_path.write_text(content, encoding='utf-8')
        return file_path
    
    def _backup_version(self, artifact_id: str, version: int):
        """ë²„ì „ ë°±ì—…"""
        metadata = self.metadata[artifact_id]
        file_path = Path(metadata["file_path"])
        
        if not file_path.exists():
            return
            
        # ë²„ì „ ë””ë ‰í† ë¦¬ ìƒì„±
        version_dir = file_path.parent / "versions" / artifact_id
        version_dir.mkdir(parents=True, exist_ok=True)
        
        # ë°±ì—… íŒŒì¼ ìƒì„±
        backup_path = version_dir / f"v{version}{file_path.suffix}"
        content = file_path.read_text(encoding='utf-8')
        backup_path.write_text(content, encoding='utf-8')
    
    def _save_metadata(self):
        """ë©”íƒ€ë°ì´í„° ì €ì¥"""
        metadata_file = self.base_path / "metadata.json"
        with open(metadata_file, 'w', encoding='utf-8') as f:
            json.dump(self.metadata, f, indent=2, ensure_ascii=False)
    
    def _load_metadata(self):
        """ë©”íƒ€ë°ì´í„° ë¡œë“œ"""
        metadata_file = self.base_path / "metadata.json"
        if metadata_file.exists():
            with open(metadata_file, 'r', encoding='utf-8') as f:
                self.metadata = json.load(f)

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
artifact_manager = ArtifactManager()