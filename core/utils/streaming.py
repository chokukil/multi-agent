# File: utils/streaming.py
# Location: ./utils/streaming.py

import logging
import json
from typing import List, Dict, Any, Tuple, Callable
from langchain_core.messages import AIMessage, AIMessageChunk, ToolMessage

async def astream_graph(graph, input_data, config=None, callback=None, stream_mode="messages"):
    """
    LangGraph ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ë¥¼ ìœ„í•œ í—¬í¼ í•¨ìˆ˜
    Plan-Execute íŒ¨í„´ì— ë§ê²Œ ìˆ˜ì •ë¨
    """
    final_result_dict = {}
    all_messages = []
    
    try:
        async for chunk in graph.astream(input_data, config=config, stream_mode=stream_mode):
            logging.debug(f"Received chunk of type {type(chunk)}: {str(chunk)[:200]}")
            
            node_name = "Unknown"
            content = None

            if isinstance(chunk, dict):
                # ìƒíƒœ ì—…ë°ì´íŠ¸ ì²˜ë¦¬
                for node, state_content in chunk.items():
                    node_name = node
                    content = state_content
                    final_result_dict[node_name] = content
                    
                    # Plan-Execute íŠ¹ë³„ ì²˜ë¦¬
                    if node_name == "planner" and hasattr(content, 'plan'):
                        if callback:
                            callback({"node": node_name, "content": {"plan": content.plan}})
                    
                    if hasattr(content, 'messages'):
                        all_messages.extend(content.messages)
                        
            elif isinstance(chunk, tuple) and len(chunk) > 0:
                # ë©”ì‹œì§€ íŠœí”Œ ì²˜ë¦¬
                content = chunk[0]
                if len(chunk) > 1 and isinstance(chunk[1], dict):
                    node_name = chunk[1].get("langgraph_node", "Unknown")
                all_messages.append(content)
            else:
                # ê¸°íƒ€ íƒ€ì…
                content = chunk
                all_messages.append(content)

            if callback and content:
                try:
                    callback({"node": node_name, "content": content})
                except Exception as e:
                    logging.error(f"Error in callback for node {node_name}: {e}", exc_info=True)

        # ìµœì¢… ê²°ê³¼ ì¬êµ¬ì„±
        if not final_result_dict and all_messages:
            final_result_dict = {"messages": all_messages}
        
        logging.info(f"Graph stream finished. Final dictionary keys: {list(final_result_dict.keys())}")
        return final_result_dict

    except Exception as e:
        logging.error(f"FATAL: Error during graph stream: {e}", exc_info=True)
        return {"error": str(e), "messages": all_messages}

def get_streaming_callback(text_placeholder, tool_placeholder) -> Tuple:
    """Plan-Execute íŒ¨í„´ì— ë§ëŠ” ìŠ¤íŠ¸ë¦¬ë° ì½œë°± ìƒì„±"""
    text_buf: List[str] = []
    tool_buf: List[str] = []
    
    # ì‹¤í–‰ ìƒíƒœ ì¶”ì 
    execution_state = {
        "current_executor": None,
        "current_step": 0,
        "total_steps": 0
    }
    
    def flush_txt():
        text_placeholder.write("".join(text_buf))
    
    def flush_tool():
        tool_placeholder.empty()
        tool_placeholder.write("".join(tool_buf))
    
    def callback(msg: Dict[str, Any]):
        node = msg.get("node", "")
        content = msg.get("content")
        
        logging.debug(f"Callback: node={node}, content_type={type(content)}")
        
        # Plan-Execute ë…¸ë“œë³„ ì²˜ë¦¬
        if node == "planner":
            if isinstance(content, dict) and "plan" in content:
                tool_buf.append("\nğŸ“‹ **Execution Plan Created**\n")
                for step in content["plan"]:
                    tool_buf.append(f"  {step['step']}. {step['task']}\n")
                flush_tool()
                
        elif node == "router":
            if hasattr(content, "content"):
                tool_buf.append(f"\nğŸ”€ **Router**: {content.content}\n")
                flush_tool()
                
        elif node == "replanner":
            if hasattr(content, "content"):
                tool_buf.append(f"\nğŸ”„ **Re-planner**: {content.content}\n")
                flush_tool()
                
        elif node == "final_responder":
            # Final Responderì˜ ë‚´ìš©ì€ í…ìŠ¤íŠ¸ ì˜ì—­ìœ¼ë¡œ
            if hasattr(content, "content"):
                text_buf.append(content.content)
                flush_txt()
                
        else:
            # Executor ë…¸ë“œë“¤ì˜ ì¶œë ¥
            if hasattr(content, "content") and content.content:
                # ìƒˆë¡œìš´ Executor ì‹œì‘
                if execution_state["current_executor"] != node:
                    execution_state["current_executor"] = node
                    tool_buf.append(f"\nğŸ’¼ **{node}**\n")
                
                # ë‚´ìš© ì¶”ê°€
                tool_buf.append(f"{content.content}\n")
                flush_tool()
    
    return callback, text_buf, tool_buf