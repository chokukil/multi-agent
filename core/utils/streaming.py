# File: utils/streaming.py
# Location: ./utils/streaming.py

import logging
import json
import re
from typing import List, Dict, Any, Tuple, Callable, Optional
from langchain_core.messages import AIMessage, AIMessageChunk, ToolMessage
import asyncio
import time

async def astream_graph(graph, input_data, config=None, callback=None, stream_mode="messages"):
    """
    LangGraph ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ë¥¼ ìœ„í•œ í—¬í¼ í•¨ìˆ˜
    Plan-Execute íŒ¨í„´ì— ë§ê²Œ ìˆ˜ì •ë¨
    """
    final_result_dict = {}
    all_messages = []
    stream = None  # stream ë³€ìˆ˜ ì´ˆê¸°í™”
    
    try:
        logging.info(f"ğŸš€ Starting graph stream with config: {config}")
        
        stream = graph.astream(input_data, config=config, stream_mode=stream_mode)
        async for chunk in stream:
            try:
                logging.debug(f"Received chunk of type {type(chunk)}: {str(chunk)[:200]}")
                
                node_name = "Unknown"
                content = None

                if isinstance(chunk, dict):
                    # ìƒíƒœ ì—…ë°ì´íŠ¸ ì²˜ë¦¬
                    for node, state_content in chunk.items():
                        node_name = node
                        content = state_content
                        final_result_dict[node_name] = content
                        
                        # Plan-Execute íŠ¹ë³„ ì²˜ë¦¬
                        if node_name == "planner" and hasattr(content, 'plan'):
                            if callback:
                                try:
                                    callback({"node": node_name, "content": {"plan": content.plan}})
                                except Exception as e:
                                    logging.error(f"Callback error for planner: {e}")
                        
                        if hasattr(content, 'messages'):
                            all_messages.extend(content.messages)
                            
                elif isinstance(chunk, tuple) and len(chunk) > 0:
                    # ë©”ì‹œì§€ íŠœí”Œ ì²˜ë¦¬
                    content = chunk[0]
                    if len(chunk) > 1 and isinstance(chunk[1], dict):
                        node_name = chunk[1].get("langgraph_node", "Unknown")
                    all_messages.append(content)
                else:
                    # ê¸°íƒ€ íƒ€ì…
                    content = chunk
                    all_messages.append(content)

                # ì½œë°± í˜¸ì¶œ (ì•ˆì „í•œ ì²˜ë¦¬)
                if callback and content:
                    try:
                        callback({"node": node_name, "content": content})
                    except Exception as e:
                        logging.error(f"Error in callback for node {node_name}: {e}", exc_info=True)

            except Exception as e_chunk:
                # ğŸ†• ì²­í¬ ì²˜ë¦¬ ì˜¤ë¥˜ë¥¼ ë¡œê¹…í•˜ê³  ê³„ì† ì§„í–‰
                logging.error(f"Error processing stream chunk: {e_chunk}", exc_info=True)
                if callback:
                    callback({
                        "node": "error_handler",
                        "content": f"âš ï¸ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e_chunk}"
                    })

        # ìµœì¢… ê²°ê³¼ ì¬êµ¬ì„±
        if not final_result_dict and all_messages:
            final_result_dict = {"messages": all_messages}
        
        logging.info(f"âœ… Graph stream completed successfully. Final dictionary keys: {list(final_result_dict.keys())}")
        return final_result_dict, all_messages

    except Exception as e_stream:
        # ìŠ¤íŠ¸ë¦¼ ìì²´ì˜ ì‹¬ê°í•œ ì˜¤ë¥˜
        logging.error(f"Fatal error in graph stream: {e_stream}", exc_info=True)
        if callback:
            callback({
                "node": "error_handler",
                "content": f"ğŸ†˜ **ì‹œìŠ¤í…œ ì˜¤ë¥˜**: ìŠ¤íŠ¸ë¦¼ì´ ë¹„ì •ìƒì ìœ¼ë¡œ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. {e_stream}"
            })
            
    finally:
        logging.info("ğŸ”š Graph stream finishing...")
        if stream is not None:
            try:
                # ë¹„ë™ê¸° ì œë„ˆë ˆì´í„°ë¥¼ ì•ˆì „í•˜ê²Œ ì¢…ë£Œí•©ë‹ˆë‹¤.
                await stream.aclose()
                logging.info("âœ… Async generator closed successfully.")
            except Exception as e_close:
                logging.error(f"Error closing stream: {e_close}", exc_info=True)

        if callback:
            callback({"node": "stream_end", "content": "ìŠ¤íŠ¸ë¦¼ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."})
            
    return final_result_dict, all_messages

def get_plan_execute_streaming_callback(tool_activity_placeholder) -> Callable:
    """Plan-Execute íŒ¨í„´ì— ìµœì í™”ëœ ìŠ¤íŠ¸ë¦¬ë° ì½œë°± í•¸ë“¤ëŸ¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    
    # ì‹¤í–‰ ìƒíƒœ ì¶”ì 
    execution_state = {
        "current_executor": None,
        "current_step": 0,
        "total_steps": 0,
        "tool_outputs": [],
        "plan": [],
        "step_results": {},
        "data_transformations": [],
        "final_response": None  # ğŸ†• ìµœì¢… ì‘ë‹µ ì €ì¥
    }
    
    def extract_python_code(content: str) -> Optional[str]:
        """ë©”ì‹œì§€ ë‚´ìš©ì—ì„œ Python ì½”ë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        # python_repl_ast ë„êµ¬ í˜¸ì¶œ íŒ¨í„´ ì°¾ê¸°
        python_patterns = [
            r'```python\n(.*?)```',
            r'python_repl_ast\((.*?)\)',
            r'"code":\s*"(.*?)"',
            r"'code':\s*'(.*?)'"
        ]
        
        for pattern in python_patterns:
            matches = re.findall(pattern, content, re.DOTALL | re.IGNORECASE)
            if matches:
                return matches[0].strip()
        
        return None
    
    def format_tool_output(content: str) -> str:
        """ë„êµ¬ ì¶œë ¥ì„ ë³´ê¸° ì¢‹ê²Œ í¬ë§·í•©ë‹ˆë‹¤."""
        # Python ì½”ë“œ ì‹¤í–‰ ê²°ê³¼ í¬ë§·
        if "```python" in content:
            return content
        
        # ê¸´ ì¶œë ¥ ì¤„ì´ê¸°
        lines = content.split('\n')
        if len(lines) > 20:
            return '\n'.join(lines[:10]) + f"\n... ({len(lines) - 20} more lines) ...\n" + '\n'.join(lines[-10:])
        
        return content
    
    def render_tool_activity():
        """ë„êµ¬ í™œë™ì„ ë Œë”ë§í•©ë‹ˆë‹¤."""
        if not execution_state["tool_outputs"]:
            tool_activity_placeholder.empty()
            return
        
        content_parts = []
        
        for output in execution_state["tool_outputs"]:
            node = output["node"]
            content = output["content"]
            timestamp = output.get("timestamp", "")
            
            if node == "planner":
                content_parts.append("### ğŸ“‹ **ê³„íš ìˆ˜ë¦½**")
                if isinstance(content, dict) and "plan" in content:
                    for i, step in enumerate(content["plan"], 1):
                        content_parts.append(f"{i}. {step.get('task', step)}")
                else:
                    content_parts.append(str(content))
                content_parts.append("")
                
            elif node == "router":
                content_parts.append("### ğŸ”€ **ë¼ìš°í„°**")
                content_parts.append(str(content))
                content_parts.append("")
                
            elif node == "replanner":
                content_parts.append("### ğŸ”„ **ì¬ê³„íš**")
                content_parts.append(str(content))
                content_parts.append("")
                
            elif "executor" in node.lower() or node in ["Data_Preprocessor", "EDA_Specialist", "Visualization_Expert", "ML_Engineer", "Statistical_Analyst", "Report_Writer"]:
                # Executor í™œë™
                content_parts.append(f"### ğŸ’¼ **{node}**")
                
                # Python ì½”ë“œ ì¶”ì¶œ ë° í‘œì‹œ
                python_code = extract_python_code(str(content))
                if python_code:
                    content_parts.append("**ì‹¤í–‰ëœ Python ì½”ë“œ:**")
                    content_parts.append("```python")
                    content_parts.append(python_code)
                    content_parts.append("```")
                
                # ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ í‘œì‹œ
                formatted_content = format_tool_output(str(content))
                if formatted_content and python_code != formatted_content:
                    content_parts.append("**ì‹¤í–‰ ê²°ê³¼:**")
                    content_parts.append("```")
                    content_parts.append(formatted_content)
                    content_parts.append("```")
                
                content_parts.append("")
        
        # ì „ì²´ ë‚´ìš©ì„ í•˜ë‚˜ì˜ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ í‘œì‹œ
        full_content = "\n".join(content_parts)
        tool_activity_placeholder.markdown(full_content)
    
    def callback(msg: Dict[str, Any]):
        """ë©”ì¸ ì½œë°± í•¨ìˆ˜"""
        import streamlit as st
        from datetime import datetime
        from ui.artifact_manager import auto_detect_artifacts, notify_artifact_creation
        
        node = msg.get("node", "")
        content = msg.get("content")
        
        if not content:
            return
        
        logging.debug(f"Streaming callback: node={node}, content_type={type(content)}")
        
        # ë©”ì‹œì§€ ë‚´ìš© ì¶”ì¶œ
        if hasattr(content, "content"):
            message_content = content.content
        elif isinstance(content, dict):
            message_content = content
        else:
            message_content = str(content)
        
        # ğŸ†• Final Responder ì²˜ë¦¬ ì¶”ê°€
        if node == "final_responder" or node == "Final_Responder":
            logging.info("ğŸ¯ Processing final_responder content")
            
            # ìµœì¢… ì‘ë‹µì„ ì €ì¥í•˜ê³  UIì— í‘œì‹œ
            if hasattr(content, "content"):
                final_content = content.content
            elif isinstance(content, str):
                final_content = content
            elif hasattr(content, "messages") and content.messages:
                # messagesì—ì„œ ìµœì¢… ì‘ë‹µ ì¶”ì¶œ
                for msg in reversed(content.messages):
                    if hasattr(msg, "content") and msg.content.strip():
                        final_content = msg.content
                        break
                else:
                    final_content = "ìµœì¢… ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."
            else:
                final_content = "ìµœì¢… ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."
            
            # ì„¸ì…˜ ìƒíƒœì— ì €ì¥
            execution_state["final_response"] = final_content
            
            # UIì— ì¦‰ì‹œ í‘œì‹œ
            try:
                if hasattr(st, 'session_state'):
                    st.session_state['final_response'] = final_content
                    st.session_state['final_response_timestamp'] = time.time()
                    logging.info("âœ… Final response saved to session state")
            except Exception as e:
                logging.warning(f"Failed to save final response to session: {e}")
            
            # ë„êµ¬ í™œë™ í‘œì‹œ
            tool_buf.append(f"\\nğŸ¯ **ìµœì¢… ì‘ë‹µ ìƒì„± ì™„ë£Œ**\\n")
            tool_buf.append(f"ì‘ë‹µ ê¸¸ì´: {len(final_content)} ë¬¸ì\\n")
            tool_buf.append(f"ì‹œê°„: {time.strftime('%H:%M:%S')}\\n")
            flush_tool()
            
            logging.info(f"âœ… Final response processed: {len(final_content)} characters")
            
            return  # Final responderëŠ” tool activityì— í‘œì‹œí•˜ì§€ ì•ŠìŒ
        
        # Plan-Execute íŠ¹ë³„ ì²˜ë¦¬
        if node == "planner" and isinstance(content, dict) and "plan" in content:
            execution_state["plan"] = content["plan"]
            execution_state["total_steps"] = len(content["plan"])
            # ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸
            st.session_state.current_plan = content["plan"]
            st.session_state.current_step = 0
            
        elif node == "router":
            # í˜„ì¬ ë‹¨ê³„ ì—…ë°ì´íŠ¸
            current_step = st.session_state.get("current_step", 0)
            if current_step < len(execution_state["plan"]):
                st.session_state.current_step = current_step
                
        elif "executor" in node.lower() or node in ["Data_Validator", "Preprocessing_Expert", "EDA_Analyst", "Visualization_Expert", "ML_Specialist", "Statistical_Analyst", "Report_Generator"]:
            # Executor ì‹¤í–‰ ê²°ê³¼ ì²˜ë¦¬
            current_step = st.session_state.get("current_step", 0)
            
            # ë‹¨ê³„ ê²°ê³¼ ì—…ë°ì´íŠ¸
            if "step_results" not in st.session_state:
                st.session_state.step_results = {}
                
            # ì‘ì—… ì™„ë£Œ ì—¬ë¶€ í™•ì¸
            completed = "TASK COMPLETED:" in str(message_content)
            
            st.session_state.step_results[current_step] = {
                "executor": node,
                "completed": completed,
                "timestamp": datetime.now().isoformat(),
                "content": str(message_content)[:500]  # ìš”ì•½ ì €ì¥
            }
            
            # ìë™ ì•„í‹°íŒ©íŠ¸ ê°ì§€ ë° ìƒì„±
            if isinstance(message_content, str):
                created_artifacts = auto_detect_artifacts(message_content, node)
                if created_artifacts:
                    notify_artifact_creation(created_artifacts)
        
        elif node == "replanner":
            # ì¬ê³„íš ë‹¨ê³„ - ë‹¤ìŒ ë‹¨ê³„ë¡œ ì´ë™
            current_step = st.session_state.get("current_step", 0)
            st.session_state.current_step = current_step + 1
        
        # ë„êµ¬ í™œë™ ê¸°ë¡ì— ì¶”ê°€
        execution_state["tool_outputs"].append({
            "node": node,
            "content": message_content,
            "timestamp": datetime.now().strftime("%H:%M:%S")
        })
        
        # ìµœëŒ€ 50ê°œ í•­ëª©ë§Œ ìœ ì§€ (ë©”ëª¨ë¦¬ ì ˆì•½)
        if len(execution_state["tool_outputs"]) > 50:
            execution_state["tool_outputs"] = execution_state["tool_outputs"][-50:]
        
        # UI ì—…ë°ì´íŠ¸
        render_tool_activity()
    
    return callback

def get_streaming_callback(text_placeholder, tool_placeholder) -> Tuple:
    """ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•œ ë ˆê±°ì‹œ í•¨ìˆ˜"""
    text_buf: List[str] = []
    tool_buf: List[str] = []
    
    # ì‹¤í–‰ ìƒíƒœ ì¶”ì 
    execution_state = {
        "current_executor": None,
        "current_step": 0,
        "total_steps": 0
    }
    
    def flush_txt():
        text_placeholder.write("".join(text_buf))
    
    def flush_tool():
        tool_placeholder.empty()
        tool_placeholder.write("".join(tool_buf))
    
    def callback(msg: Dict[str, Any]):
        node = msg.get("node", "")
        content = msg.get("content")
        
        logging.debug(f"Callback: node={node}, content_type={type(content)}")
        
        # Plan-Execute ë…¸ë“œë³„ ì²˜ë¦¬
        if node == "planner":
            if isinstance(content, dict) and "plan" in content:
                tool_buf.append("\nğŸ“‹ **Execution Plan Created**\n")
                for step in content["plan"]:
                    tool_buf.append(f"  {step['step']}. {step['task']}\n")
                flush_tool()
                
        elif node == "router":
            if hasattr(content, "content"):
                tool_buf.append(f"\nğŸ”€ **Router**: {content.content}\n")
                flush_tool()
                
        elif node == "replanner":
            if hasattr(content, "content"):
                tool_buf.append(f"\nğŸ”„ **Re-planner**: {content.content}\n")
                flush_tool()
                
        elif node == "final_responder" or node == "Final_Responder":
            # ğŸ†• Final Responderì˜ ë‚´ìš©ì€ í…ìŠ¤íŠ¸ ì˜ì—­ìœ¼ë¡œ
            if hasattr(content, "content"):
                text_buf.append(content.content)
                flush_txt()
            elif isinstance(content, str):
                text_buf.append(content)
                flush_txt()
            
            # ì„¸ì…˜ ìƒíƒœì—ë„ ì €ì¥
            import streamlit as st
            st.session_state.final_response = content.content if hasattr(content, "content") else str(content)
            logging.info("ğŸ¯ Final response stored in session state")
                
        # ê¸°íƒ€ executor ë…¸ë“œë“¤
        elif any(executor in node.lower() for executor in ["executor", "analyst", "specialist", "expert", "engineer", "writer", "generator", "preprocessor", "validator"]):
            if hasattr(content, "content"):
                tool_buf.append(f"\nğŸ¤– **{node}**: {content.content[:200]}...\n")
                flush_tool()
    
    return callback, flush_txt, flush_tool