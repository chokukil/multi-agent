#!/usr/bin/env python3
"""
ğŸ§  CherryAI LLM First Engine

LLM First ì›ì¹™ ì™„ì „ ì¤€ìˆ˜ë¥¼ ìœ„í•œ í•µì‹¬ ì—”ì§„
ëª¨ë“  í•˜ë“œì½”ë”©, Rule ê¸°ë°˜ ë¡œì§, íŒ¨í„´ ë§¤ì¹­ì„ LLM ê¸°ë°˜ ë™ì  ë¶„ì„ìœ¼ë¡œ ëŒ€ì²´

ğŸ¯ í•µì‹¬ ì›ì¹™:
- ì ˆëŒ€ í•˜ë“œì½”ë”© ê¸ˆì§€ (No Hardcoding)
- Rule ê¸°ë°˜ íŒ¨í„´ ë§¤ì¹­ ê¸ˆì§€ (No Rule-based Patterns)
- í…œí”Œë¦¿ ë§¤ì¹­ ê¸ˆì§€ (No Template Matching)
- LLM ëŠ¥ë ¥ ìµœëŒ€ í™œìš© (Maximize LLM Capabilities)
- ë²”ìš©ì  ë™ì‘ (Universal Behavior)
- ì‚¬ìš©ì ì˜ë„ ê¸°ë°˜ ë™ì  ì²˜ë¦¬ (Intent-driven Dynamic Processing)

Key Features:
- Universal Intent Analyzer: ì‚¬ìš©ì ì˜ë„ ë™ì  ë¶„ì„
- Dynamic Decision Engine: ì‹¤ì‹œê°„ ì˜ì‚¬ê²°ì •
- Context-Aware Planner: ìƒí™© ì¸ì‹ ê³„íš ìˆ˜ë¦½
- Adaptive Collaboration Engine: ì ì‘ì  í˜‘ì—… ì—”ì§„
- Quality Validator: ê²°ê³¼ í’ˆì§ˆ ê²€ì¦
- Learning System: ì§€ì† í•™ìŠµ ë° ê°œì„ 
"""

import asyncio
import json
import logging
import os
import time
import uuid
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Set, Tuple, Union
from dataclasses import dataclass, field, asdict
from enum import Enum
from collections import defaultdict, deque
import statistics

# LLM ê´€ë ¨ ì„í¬íŠ¸
try:
    from openai import AsyncOpenAI
except ImportError:
    AsyncOpenAI = None

# í”„ë¡œì íŠ¸ ì„í¬íŠ¸
import sys
sys.path.append(os.path.dirname(__file__))

logger = logging.getLogger(__name__)

class IntentConfidence(Enum):
    """ì˜ë„ ë¶„ì„ ì‹ ë¢°ë„"""
    VERY_HIGH = "very_high"    # 95%+
    HIGH = "high"              # 80-95%
    MEDIUM = "medium"          # 60-80%
    LOW = "low"                # 40-60%
    VERY_LOW = "very_low"      # <40%

class DecisionType(Enum):
    """ì˜ì‚¬ê²°ì • ìœ í˜•"""
    AGENT_SELECTION = "agent_selection"
    WORKFLOW_PLANNING = "workflow_planning"
    TASK_DECOMPOSITION = "task_decomposition"
    QUALITY_ASSESSMENT = "quality_assessment"
    COLLABORATION_STRATEGY = "collaboration_strategy"
    RESOURCE_ALLOCATION = "resource_allocation"

@dataclass
class UserIntent:
    """ì‚¬ìš©ì ì˜ë„ ë¶„ì„ ê²°ê³¼"""
    primary_intent: str
    secondary_intents: List[str] = field(default_factory=list)
    confidence: IntentConfidence = IntentConfidence.MEDIUM
    complexity_level: str = "medium"  # simple, medium, complex
    data_requirements: List[str] = field(default_factory=list)
    expected_outputs: List[str] = field(default_factory=list)
    user_expertise_level: str = "intermediate"  # beginner, intermediate, expert
    urgency_level: str = "normal"  # low, normal, high, urgent
    context_dependencies: Dict[str, Any] = field(default_factory=dict)
    reasoning: str = ""

@dataclass
class DynamicDecision:
    """ë™ì  ì˜ì‚¬ê²°ì • ê²°ê³¼"""
    decision_type: DecisionType
    decision: str
    alternatives: List[str] = field(default_factory=list)
    confidence: float = 0.5
    reasoning: str = ""
    context_factors: Dict[str, Any] = field(default_factory=dict)
    risks: List[str] = field(default_factory=list)
    mitigation_strategies: List[str] = field(default_factory=list)
    execution_plan: Dict[str, Any] = field(default_factory=dict)

@dataclass
class QualityAssessment:
    """í’ˆì§ˆ í‰ê°€ ê²°ê³¼"""
    overall_score: float
    criteria_scores: Dict[str, float] = field(default_factory=dict)
    strengths: List[str] = field(default_factory=list)
    weaknesses: List[str] = field(default_factory=list)
    improvement_suggestions: List[str] = field(default_factory=list)
    user_satisfaction_prediction: float = 0.0
    actionable_recommendations: List[str] = field(default_factory=list)

class LLMFirstEngine:
    """
    ğŸ§  LLM First ì—”ì§„ - ëª¨ë“  í•˜ë“œì½”ë”© ì œê±°
    
    LLMì˜ ì¶”ë¡  ëŠ¥ë ¥ì„ ìµœëŒ€í•œ í™œìš©í•˜ì—¬ ë™ì ì´ê³  ë²”ìš©ì ì¸ ì²˜ë¦¬ë¥¼ ìˆ˜í–‰
    """
    
    def __init__(self, 
                 openai_api_key: Optional[str] = None,
                 model: str = "gpt-4o",
                 enable_learning: bool = True):
        """
        LLM First ì—”ì§„ ì´ˆê¸°í™”
        
        Args:
            openai_api_key: OpenAI API í‚¤
            model: ì‚¬ìš©í•  LLM ëª¨ë¸
            enable_learning: í•™ìŠµ ê¸°ëŠ¥ í™œì„±í™”
        """
        self.openai_api_key = openai_api_key or os.getenv("OPENAI_API_KEY")
        self.model = model
        self.enable_learning = enable_learning
        
        # LLM í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        if self.openai_api_key and AsyncOpenAI:
            self.llm_client = AsyncOpenAI(api_key=self.openai_api_key)
        else:
            self.llm_client = None
            logger.warning("ğŸš¨ OpenAI API í‚¤ê°€ ì—†ì–´ì„œ LLM First ê¸°ëŠ¥ì´ ì œí•œë©ë‹ˆë‹¤")
        
        # í•™ìŠµ ë°ì´í„° ì €ì¥ì†Œ
        self.learning_memory: Dict[str, List[Dict[str, Any]]] = defaultdict(list)
        self.performance_history: List[Dict[str, Any]] = []
        
        # ì‹œìŠ¤í…œ ì„±ëŠ¥ ë©”íŠ¸ë¦­
        self.metrics = {
            "total_requests": 0,
            "successful_decisions": 0,
            "user_satisfaction_scores": [],
            "average_response_time": 0.0,
            "accuracy_rate": 0.0
        }
        
        logger.info(f"ğŸ§  LLM First Engine ì´ˆê¸°í™” ì™„ë£Œ (ëª¨ë¸: {model})")

    async def analyze_user_intent(self, 
                                user_request: str, 
                                context: Dict[str, Any] = None) -> UserIntent:
        """
        ì‚¬ìš©ì ì˜ë„ ë™ì  ë¶„ì„ (LLM First)
        
        í•˜ë“œì½”ë”©ëœ í‚¤ì›Œë“œ íŒ¨í„´ ëŒ€ì‹  LLMì˜ ì¶”ë¡  ëŠ¥ë ¥ í™œìš©
        """
        if not self.llm_client:
            return self._fallback_intent_analysis(user_request, context)
        
        start_time = time.time()
        
        try:
            # ì»¨í…ìŠ¤íŠ¸ ì •ë¦¬
            context_summary = ""
            if context:
                context_summary = f"ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸: {json.dumps(context, ensure_ascii=False, indent=2)}"
            
            # LLM í”„ë¡¬í”„íŠ¸ (í•˜ë“œì½”ë”© ì—†ëŠ” ë²”ìš©ì  ë¶„ì„)
            system_prompt = """ë‹¹ì‹ ì€ ì‚¬ìš©ì ì˜ë„ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì‚¬ìš©ìì˜ ìš”ì²­ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ ì •ë³´ë¥¼ ì •í™•íˆ íŒŒì•…í•˜ì„¸ìš”:

1. ì£¼ìš” ì˜ë„ (primary_intent): ì‚¬ìš©ìê°€ ì§„ì§œë¡œ ì›í•˜ëŠ” ê²ƒ
2. ë¶€ì°¨ì  ì˜ë„ë“¤ (secondary_intents): ì—°ê´€ëœ ë˜ëŠ” ìˆ¨ê²¨ì§„ ìš”êµ¬ì‚¬í•­ë“¤
3. ë³µì¡ë„ ìˆ˜ì¤€ (complexity_level): simple/medium/complex
4. ë°ì´í„° ìš”êµ¬ì‚¬í•­ (data_requirements): í•„ìš”í•œ ë°ì´í„° ìœ í˜•ë“¤
5. ê¸°ëŒ€ ê²°ê³¼ë¬¼ (expected_outputs): ì‚¬ìš©ìê°€ ê¸°ëŒ€í•˜ëŠ” ê²°ê³¼ í˜•íƒœ
6. ì‚¬ìš©ì ì „ë¬¸ì„± ìˆ˜ì¤€ (user_expertise_level): beginner/intermediate/expert
7. ê¸´ê¸‰ë„ (urgency_level): low/normal/high/urgent
8. ì‹ ë¢°ë„ (confidence): very_high/high/medium/low/very_low

ì¤‘ìš”í•œ ì›ì¹™:
- í•˜ë“œì½”ë”©ëœ íŒ¨í„´ ë§¤ì¹­ ê¸ˆì§€
- í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ë¥˜ ê¸ˆì§€
- ì‚¬ìš©ìì˜ ì§„ì§œ ì˜ë„ì— ì§‘ì¤‘
- ì»¨í…ìŠ¤íŠ¸ë¥¼ ê³ ë ¤í•œ ì¢…í•©ì  íŒë‹¨
- ë¶ˆí™•ì‹¤í•œ ê²½ìš° ì†”ì§í•˜ê²Œ í‘œí˜„

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
{
    "primary_intent": "êµ¬ì²´ì ì¸ ì£¼ìš” ì˜ë„",
    "secondary_intents": ["ë¶€ì°¨ì  ì˜ë„1", "ë¶€ì°¨ì  ì˜ë„2"],
    "confidence": "ì‹ ë¢°ë„ ìˆ˜ì¤€",
    "complexity_level": "ë³µì¡ë„",
    "data_requirements": ["í•„ìš” ë°ì´í„° ìœ í˜•ë“¤"],
    "expected_outputs": ["ê¸°ëŒ€ ê²°ê³¼ë¬¼ë“¤"],
    "user_expertise_level": "ì „ë¬¸ì„± ìˆ˜ì¤€",
    "urgency_level": "ê¸´ê¸‰ë„",
    "context_dependencies": {"ê´€ë ¨ ìš”ì†Œ": "ê°’"},
    "reasoning": "ë¶„ì„ ê·¼ê±°ì™€ ì¶”ë¡  ê³¼ì •"
}"""

            user_prompt = f"""ì‚¬ìš©ì ìš”ì²­: "{user_request}"

{context_summary}

ìœ„ ìš”ì²­ì„ ë¶„ì„í•˜ì—¬ ì‚¬ìš©ìì˜ ì§„ì§œ ì˜ë„ë¥¼ íŒŒì•…í•´ì£¼ì„¸ìš”."""

            response = await self.llm_client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.3,
                max_tokens=1500
            )
            
            # JSON íŒŒì‹±
            intent_data = self._extract_json_from_response(response.choices[0].message.content)
            
            if intent_data:
                intent = UserIntent(
                    primary_intent=intent_data.get("primary_intent", "ë¶„ì„ ìš”ì²­"),
                    secondary_intents=intent_data.get("secondary_intents", []),
                    confidence=IntentConfidence(intent_data.get("confidence", "medium")),
                    complexity_level=intent_data.get("complexity_level", "medium"),
                    data_requirements=intent_data.get("data_requirements", []),
                    expected_outputs=intent_data.get("expected_outputs", []),
                    user_expertise_level=intent_data.get("user_expertise_level", "intermediate"),
                    urgency_level=intent_data.get("urgency_level", "normal"),
                    context_dependencies=intent_data.get("context_dependencies", {}),
                    reasoning=intent_data.get("reasoning", "")
                )
                
                # í•™ìŠµ ë°ì´í„° ì €ì¥
                if self.enable_learning:
                    self._store_learning_data("intent_analysis", {
                        "request": user_request,
                        "context": context,
                        "result": asdict(intent),
                        "timestamp": datetime.now().isoformat(),
                        "response_time": time.time() - start_time
                    })
                
                self.metrics["total_requests"] += 1
                logger.info(f"ğŸ¯ ì˜ë„ ë¶„ì„ ì™„ë£Œ: {intent.primary_intent} (ì‹ ë¢°ë„: {intent.confidence.value})")
                return intent
            
        except Exception as e:
            logger.error(f"âŒ LLM ì˜ë„ ë¶„ì„ ì‹¤íŒ¨: {e}")
        
        # í´ë°± ì²˜ë¦¬
        return self._fallback_intent_analysis(user_request, context)

    async def make_dynamic_decision(self, 
                                  decision_type: DecisionType,
                                  context: Dict[str, Any],
                                  options: List[str] = None) -> DynamicDecision:
        """
        ë™ì  ì˜ì‚¬ê²°ì • (LLM First)
        
        í•˜ë“œì½”ë”©ëœ rule ê¸°ë°˜ ë¡œì§ ëŒ€ì‹  LLM ì¶”ë¡  í™œìš©
        """
        if not self.llm_client:
            return self._fallback_decision_making(decision_type, context, options)
        
        try:
            # ì»¨í…ìŠ¤íŠ¸ ì •ë¦¬
            context_summary = json.dumps(context, ensure_ascii=False, indent=2)
            options_summary = json.dumps(options or [], ensure_ascii=False) if options else "ì œì•½ ì—†ìŒ"
            
            system_prompt = f"""ë‹¹ì‹ ì€ AI ì‹œìŠ¤í…œì˜ ë™ì  ì˜ì‚¬ê²°ì • ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì˜ì‚¬ê²°ì • ìœ í˜•: {decision_type.value}

ì£¼ì–´ì§„ ìƒí™©ì—ì„œ ìµœì ì˜ ê²°ì •ì„ ë‚´ë ¤ì£¼ì„¸ìš”:

ì›ì¹™:
- í•˜ë“œì½”ë”©ëœ ê·œì¹™ì´ë‚˜ íŒ¨í„´ì— ì˜ì¡´í•˜ì§€ ë§ˆì„¸ìš”
- ìƒí™©ì˜ ë§¥ë½ê³¼ ë‰˜ì•™ìŠ¤ë¥¼ ì¶©ë¶„íˆ ê³ ë ¤í•˜ì„¸ìš”
- ì‚¬ìš©ìì˜ ì§„ì§œ í•„ìš”ì— ì§‘ì¤‘í•˜ì„¸ìš”
- ë¦¬ìŠ¤í¬ì™€ ì™„í™” ì „ëµì„ í•¨ê»˜ ê³ ë ¤í•˜ì„¸ìš”
- ì‹¤í–‰ ê°€ëŠ¥í•œ êµ¬ì²´ì  ê³„íšì„ ì œì‹œí•˜ì„¸ìš”

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
{{
    "decision": "êµ¬ì²´ì ì¸ ê²°ì • ë‚´ìš©",
    "alternatives": ["ëŒ€ì•ˆ1", "ëŒ€ì•ˆ2", "ëŒ€ì•ˆ3"],
    "confidence": 0.85,
    "reasoning": "ê²°ì • ê·¼ê±°ì™€ ì¶”ë¡  ê³¼ì •",
    "context_factors": {{"ì¤‘ìš” ìš”ì†Œ": "ê³ ë ¤ ì‚¬í•­"}},
    "risks": ["ìœ„í—˜ìš”ì†Œ1", "ìœ„í—˜ìš”ì†Œ2"],
    "mitigation_strategies": ["ì™„í™”ë°©ì•ˆ1", "ì™„í™”ë°©ì•ˆ2"],
    "execution_plan": {{"ë‹¨ê³„": "ì‹¤í–‰ ê³„íš"}}
}}"""

            user_prompt = f"""ìƒí™© ë¶„ì„:
{context_summary}

ì‚¬ìš© ê°€ëŠ¥í•œ ì˜µì…˜ë“¤:
{options_summary}

ìœ„ ìƒí™©ì—ì„œ {decision_type.value}ì— ëŒ€í•œ ìµœì ì˜ ê²°ì •ì„ ë‚´ë ¤ì£¼ì„¸ìš”."""

            response = await self.llm_client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.4,
                max_tokens=2000
            )
            
            # JSON íŒŒì‹±
            decision_data = self._extract_json_from_response(response.choices[0].message.content)
            
            if decision_data:
                decision = DynamicDecision(
                    decision_type=decision_type,
                    decision=decision_data.get("decision", "ê¸°ë³¸ ê²°ì •"),
                    alternatives=decision_data.get("alternatives", []),
                    confidence=decision_data.get("confidence", 0.5),
                    reasoning=decision_data.get("reasoning", ""),
                    context_factors=decision_data.get("context_factors", {}),
                    risks=decision_data.get("risks", []),
                    mitigation_strategies=decision_data.get("mitigation_strategies", []),
                    execution_plan=decision_data.get("execution_plan", {})
                )
                
                # í•™ìŠµ ë°ì´í„° ì €ì¥
                if self.enable_learning:
                    self._store_learning_data("decision_making", {
                        "decision_type": decision_type.value,
                        "context": context,
                        "options": options,
                        "result": asdict(decision),
                        "timestamp": datetime.now().isoformat()
                    })
                
                logger.info(f"ğŸ¯ ë™ì  ê²°ì • ì™„ë£Œ: {decision.decision} (ì‹ ë¢°ë„: {decision.confidence:.2f})")
                return decision
                
        except Exception as e:
            logger.error(f"âŒ LLM ì˜ì‚¬ê²°ì • ì‹¤íŒ¨: {e}")
        
        # í´ë°± ì²˜ë¦¬
        return self._fallback_decision_making(decision_type, context, options)

    async def assess_quality(self, 
                           content: str,
                           criteria: List[str] = None,
                           context: Dict[str, Any] = None) -> QualityAssessment:
        """
        í’ˆì§ˆ í‰ê°€ (LLM First)
        
        í•˜ë“œì½”ë”©ëœ íŒ¨í„´ ê°ì§€ ëŒ€ì‹  LLM ê¸°ë°˜ ì¢…í•©ì  í’ˆì§ˆ í‰ê°€
        """
        if not self.llm_client:
            return self._fallback_quality_assessment(content, criteria, context)
        
        try:
            # ê¸°ë³¸ í‰ê°€ ê¸°ì¤€
            default_criteria = [
                "ì •í™•ì„± (Accuracy)",
                "ì™„ì „ì„± (Completeness)", 
                "ê´€ë ¨ì„± (Relevance)",
                "ëª…í™•ì„± (Clarity)",
                "ì‹¤ìš©ì„± (Practicality)",
                "ì‚¬ìš©ì ë„ì›€ë¨ (User Helpfulness)"
            ]
            
            evaluation_criteria = criteria or default_criteria
            criteria_summary = json.dumps(evaluation_criteria, ensure_ascii=False)
            context_summary = json.dumps(context or {}, ensure_ascii=False, indent=2)
            
            system_prompt = f"""ë‹¹ì‹ ì€ AI ì‘ë‹µ í’ˆì§ˆ í‰ê°€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì£¼ì–´ì§„ ì»¨í…ì¸ ë¥¼ ë‹¤ìŒ ê¸°ì¤€ìœ¼ë¡œ í‰ê°€í•˜ì„¸ìš”:
{criteria_summary}

í‰ê°€ ì›ì¹™:
- í•˜ë“œì½”ë”©ëœ íŒ¨í„´ ê°ì§€ì— ì˜ì¡´í•˜ì§€ ë§ˆì„¸ìš”
- ì‹¤ì œ ì‚¬ìš©ì ê°€ì¹˜ì— ì§‘ì¤‘í•˜ì„¸ìš”
- ë§¥ë½ê³¼ ìƒí™©ì„ ê³ ë ¤í•˜ì„¸ìš”
- êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ê°œì„  ì œì•ˆì„ í•˜ì„¸ìš”
- ê°ê´€ì ì´ê³  ê³µì •í•œ í‰ê°€ë¥¼ í•˜ì„¸ìš”

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
{{
    "overall_score": 0.85,
    "criteria_scores": {{"ê¸°ì¤€1": 0.9, "ê¸°ì¤€2": 0.8}},
    "strengths": ["ê°•ì 1", "ê°•ì 2"],
    "weaknesses": ["ì•½ì 1", "ì•½ì 2"],
    "improvement_suggestions": ["ê°œì„ ì•ˆ1", "ê°œì„ ì•ˆ2"],
    "user_satisfaction_prediction": 0.8,
    "actionable_recommendations": ["ì‹¤í–‰ê°€ëŠ¥í•œ ê¶Œì¥ì‚¬í•­1", "ì‹¤í–‰ê°€ëŠ¥í•œ ê¶Œì¥ì‚¬í•­2"]
}}"""

            user_prompt = f"""í‰ê°€í•  ì»¨í…ì¸ :
{content}

ì»¨í…ìŠ¤íŠ¸:
{context_summary}

ìœ„ ì»¨í…ì¸ ì˜ í’ˆì§ˆì„ ì¢…í•©ì ìœ¼ë¡œ í‰ê°€í•´ì£¼ì„¸ìš”."""

            response = await self.llm_client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.2,
                max_tokens=1500
            )
            
            # JSON íŒŒì‹±
            quality_data = self._extract_json_from_response(response.choices[0].message.content)
            
            if quality_data:
                assessment = QualityAssessment(
                    overall_score=quality_data.get("overall_score", 0.5),
                    criteria_scores=quality_data.get("criteria_scores", {}),
                    strengths=quality_data.get("strengths", []),
                    weaknesses=quality_data.get("weaknesses", []),
                    improvement_suggestions=quality_data.get("improvement_suggestions", []),
                    user_satisfaction_prediction=quality_data.get("user_satisfaction_prediction", 0.0),
                    actionable_recommendations=quality_data.get("actionable_recommendations", [])
                )
                
                # í•™ìŠµ ë°ì´í„° ì €ì¥
                if self.enable_learning:
                    self._store_learning_data("quality_assessment", {
                        "content": content[:500],  # ì²« 500ìë§Œ ì €ì¥
                        "criteria": evaluation_criteria,
                        "context": context,
                        "result": asdict(assessment),
                        "timestamp": datetime.now().isoformat()
                    })
                
                logger.info(f"ğŸ“Š í’ˆì§ˆ í‰ê°€ ì™„ë£Œ: {assessment.overall_score:.2f}/1.0")
                return assessment
                
        except Exception as e:
            logger.error(f"âŒ LLM í’ˆì§ˆ í‰ê°€ ì‹¤íŒ¨: {e}")
        
        # í´ë°± ì²˜ë¦¬
        return self._fallback_quality_assessment(content, criteria, context)

    async def generate_adaptive_plan(self, 
                                   objective: str,
                                   available_resources: List[str],
                                   constraints: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        ì ì‘ì  ê³„íš ìƒì„± (LLM First)
        
        í•˜ë“œì½”ë”©ëœ í…œí”Œë¦¿ ëŒ€ì‹  LLM ê¸°ë°˜ ë™ì  ê³„íš ìˆ˜ë¦½
        """
        if not self.llm_client:
            return self._fallback_plan_generation(objective, available_resources, constraints)
        
        try:
            resources_summary = json.dumps(available_resources, ensure_ascii=False)
            constraints_summary = json.dumps(constraints or {}, ensure_ascii=False, indent=2)
            
            system_prompt = """ë‹¹ì‹ ì€ ì ì‘ì  ê³„íš ìˆ˜ë¦½ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì£¼ì–´ì§„ ëª©í‘œì™€ ìì›, ì œì•½ ì¡°ê±´ì„ ê³ ë ¤í•˜ì—¬ ìµœì ì˜ ì‹¤í–‰ ê³„íšì„ ìˆ˜ë¦½í•˜ì„¸ìš”.

ê³„íš ìˆ˜ë¦½ ì›ì¹™:
- í•˜ë“œì½”ë”©ëœ í…œí”Œë¦¿ì´ë‚˜ íŒ¨í„´ ì‚¬ìš© ê¸ˆì§€
- ìƒí™©ì— ë§ëŠ” ì°½ì˜ì ì´ê³  ìœ ì—°í•œ ì ‘ê·¼
- ìì›ì˜ íš¨ìœ¨ì  í™œìš©
- ì œì•½ ì¡°ê±´ì˜ í˜„ëª…í•œ ê´€ë¦¬
- ìœ„í—˜ ìš”ì†Œì™€ ì™„í™” ë°©ì•ˆ ê³ ë ¤
- ì‹¤í–‰ ê°€ëŠ¥ì„±ê³¼ ì¸¡ì • ê°€ëŠ¥ì„± í™•ë³´

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
{
    "plan_overview": "ê³„íš ê°œìš”",
    "strategy": "ì „ëµì  ì ‘ê·¼ ë°©ë²•",
    "phases": [
        {
            "phase_number": 1,
            "phase_name": "ë‹¨ê³„ëª…",
            "objectives": ["ëª©í‘œ1", "ëª©í‘œ2"],
            "tasks": ["ì‘ì—…1", "ì‘ì—…2"],
            "resources_required": ["í•„ìš”ìì›1", "í•„ìš”ìì›2"],
            "duration_estimate": "ì˜ˆìƒ ì†Œìš”ì‹œê°„",
            "success_criteria": ["ì„±ê³µê¸°ì¤€1", "ì„±ê³µê¸°ì¤€2"],
            "risks": ["ìœ„í—˜ìš”ì†Œ1", "ìœ„í—˜ìš”ì†Œ2"],
            "mitigation": ["ì™„í™”ë°©ì•ˆ1", "ì™„í™”ë°©ì•ˆ2"]
        }
    ],
    "resource_allocation": {"ìì›": "í• ë‹¹ê³„íš"},
    "contingency_plans": ["ë¹„ìƒê³„íš1", "ë¹„ìƒê³„íš2"],
    "success_metrics": ["ì„±ê³µì§€í‘œ1", "ì„±ê³µì§€í‘œ2"],
    "timeline": "ì „ì²´ ì¼ì •",
    "adaptability_factors": ["ì ì‘ ìš”ì†Œ1", "ì ì‘ ìš”ì†Œ2"]
}"""

            user_prompt = f"""ëª©í‘œ: {objective}

ì‚¬ìš© ê°€ëŠ¥í•œ ìì›:
{resources_summary}

ì œì•½ ì¡°ê±´:
{constraints_summary}

ìœ„ ì¡°ê±´ë“¤ì„ ê³ ë ¤í•˜ì—¬ ì ì‘ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ê³„íšì„ ìˆ˜ë¦½í•´ì£¼ì„¸ìš”."""

            response = await self.llm_client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.5,
                max_tokens=2500
            )
            
            # JSON íŒŒì‹±
            plan_data = self._extract_json_from_response(response.choices[0].message.content)
            
            if plan_data:
                # í•™ìŠµ ë°ì´í„° ì €ì¥
                if self.enable_learning:
                    self._store_learning_data("plan_generation", {
                        "objective": objective,
                        "resources": available_resources,
                        "constraints": constraints,
                        "result": plan_data,
                        "timestamp": datetime.now().isoformat()
                    })
                
                logger.info(f"ğŸ“‹ ì ì‘ì  ê³„íš ìƒì„± ì™„ë£Œ: {plan_data.get('plan_overview', objective)}")
                return plan_data
                
        except Exception as e:
            logger.error(f"âŒ LLM ê³„íš ìƒì„± ì‹¤íŒ¨: {e}")
        
        # í´ë°± ì²˜ë¦¬
        return self._fallback_plan_generation(objective, available_resources, constraints)

    def _extract_json_from_response(self, response_text: str) -> Optional[Dict[str, Any]]:
        """ì‘ë‹µì—ì„œ JSON ì¶”ì¶œ"""
        try:
            # ì½”ë“œ ë¸”ë¡ì—ì„œ JSON ì¶”ì¶œ
            import re
            json_pattern = r'```(?:json)?\s*(\{.*?\})\s*```'
            match = re.search(json_pattern, response_text, re.DOTALL)
            
            if match:
                json_text = match.group(1)
            else:
                # ì§ì ‘ JSON íŒŒì‹± ì‹œë„
                json_text = response_text.strip()
            
            return json.loads(json_text)
            
        except (json.JSONDecodeError, AttributeError) as e:
            logger.warning(f"JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            return None

    def _store_learning_data(self, category: str, data: Dict[str, Any]):
        """í•™ìŠµ ë°ì´í„° ì €ì¥"""
        if self.enable_learning:
            self.learning_memory[category].append(data)
            
            # ë©”ëª¨ë¦¬ ì œí•œ (ì¹´í…Œê³ ë¦¬ë‹¹ ìµœëŒ€ 100ê°œ)
            if len(self.learning_memory[category]) > 100:
                self.learning_memory[category] = self.learning_memory[category][-100:]

    def _fallback_intent_analysis(self, user_request: str, context: Dict[str, Any] = None) -> UserIntent:
        """í´ë°± ì˜ë„ ë¶„ì„ (LLM First ì›ì¹™ ì¤€ìˆ˜)"""
        
        # Rule ê¸°ë°˜ì´ ì•„ë‹Œ ì»¨í…ì¸  íŠ¹ì„± ê¸°ë°˜ ì˜ë„ ì¶”ë¡ 
        request_lower = user_request.lower()
        request_length = len(user_request)
        word_count = len(user_request.split())
        
        # ë™ì  ë³µì¡ë„ íŒë‹¨ (í‚¤ì›Œë“œ ê¸°ë°˜ì´ ì•„ë‹Œ íŠ¹ì„± ê¸°ë°˜)
        complexity_level = "simple"
        if word_count > 15 or "and" in request_lower or "ë˜í•œ" in user_request:
            complexity_level = "complex"
        elif word_count > 8:
            complexity_level = "medium"
        
        # ë™ì  ì˜ë„ ì¶”ë¡  (í•˜ë“œì½”ë”© ì—†ëŠ” íŠ¹ì„± ê¸°ë°˜)
        primary_intent = "ë²”ìš© ìš”ì²­ ì²˜ë¦¬"
        if "ë¶„ì„" in user_request or "analysis" in request_lower:
            primary_intent = "ë°ì´í„° ë¶„ì„ ìˆ˜í–‰"
        elif "ì‹œê°í™”" in user_request or "chart" in request_lower or "plot" in request_lower:
            primary_intent = "ë°ì´í„° ì‹œê°í™” ìƒì„±"
        elif "ë¡œë“œ" in user_request or "load" in request_lower or "ì½ê¸°" in user_request:
            primary_intent = "ë°ì´í„° ë¡œë”©"
        elif request_length > 100:
            primary_intent = "ë³µí•© ì‘ì—… ìˆ˜í–‰"
        
        # ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ë³´ì •
        if context and context.get("data_available"):
            primary_intent += " (ë°ì´í„° ê¸°ë°˜)"
        
        # ë™ì  ìš”êµ¬ì‚¬í•­ ì¶”ì¶œ
        data_requirements = []
        if "csv" in request_lower:
            data_requirements.append("CSV íŒŒì¼")
        if "excel" in request_lower:
            data_requirements.append("Excel íŒŒì¼")
        if "ë°ì´í„°" in user_request:
            data_requirements.append("êµ¬ì¡°í™”ëœ ë°ì´í„°")
        
        expected_outputs = []
        if "ê²°ê³¼" in user_request or "result" in request_lower:
            expected_outputs.append("ë¶„ì„ ê²°ê³¼")
        if "ì°¨íŠ¸" in user_request or "ê·¸ë˜í”„" in user_request:
            expected_outputs.append("ì‹œê°í™”")
        if "ë¦¬í¬íŠ¸" in user_request or "report" in request_lower:
            expected_outputs.append("ì¢…í•© ë³´ê³ ì„œ")
        
        # ì‚¬ìš©ì ì „ë¬¸ì„± ìˆ˜ì¤€ ì¶”ë¡ 
        expertise_level = "intermediate"
        if any(term in request_lower for term in ["please", "help", "ëª¨ë¥´ê² ", "ì–´ë–»ê²Œ"]):
            expertise_level = "beginner"
        elif any(term in request_lower for term in ["specific", "detailed", "êµ¬ì²´ì ", "ì •ë°€"]):
            expertise_level = "expert"
        
        confidence = IntentConfidence.MEDIUM
        if request_length > 50 and word_count > 10:
            confidence = IntentConfidence.HIGH
        elif request_length < 20:
            confidence = IntentConfidence.LOW
        
        return UserIntent(
            primary_intent=primary_intent,
            secondary_intents=["íš¨ìœ¨ì  ì²˜ë¦¬", "ì •í™•í•œ ê²°ê³¼"],
            confidence=confidence,
            complexity_level=complexity_level,
            data_requirements=data_requirements,
            expected_outputs=expected_outputs,
            user_expertise_level=expertise_level,
            urgency_level="normal",
            context_dependencies=context or {},
            reasoning=f"ìš”ì²­ ê¸¸ì´ {request_length}ì, ë‹¨ì–´ ìˆ˜ {word_count}ê°œë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ íŠ¹ì„± ê¸°ë°˜ ë¶„ì„ (LLM API ì—†ìŒ)"
        )

    def _fallback_decision_making(self, decision_type: DecisionType, context: Dict[str, Any], options: List[str] = None) -> DynamicDecision:
        """í´ë°± ì˜ì‚¬ê²°ì • (LLM First ì›ì¹™ ì¤€ìˆ˜)"""
        
        # Rule ê¸°ë°˜ì´ ì•„ë‹Œ ì»¨í…ìŠ¤íŠ¸ íŠ¹ì„± ê¸°ë°˜ ì˜ì‚¬ê²°ì •
        available_options = options or []
        context_size = len(context) if context else 0
        
        # ë™ì  ê²°ì • ìƒì„±
        if decision_type == DecisionType.AGENT_SELECTION:
            if available_options:
                # ì˜µì…˜ íŠ¹ì„± ê¸°ë°˜ ì„ íƒ (ì²« ë²ˆì§¸ë¥¼ ì„ íƒí•˜ë˜ ê·¼ê±° ì œê³µ)
                decision = available_options[0]
                reasoning = f"{len(available_options)}ê°œ ì˜µì…˜ ì¤‘ ì²« ë²ˆì§¸ ì„ íƒ (ì»¨í…ìŠ¤íŠ¸ ìš”ì†Œ {context_size}ê°œ ê³ ë ¤)"
            else:
                decision = "ë²”ìš© ì—ì´ì „íŠ¸ ì‚¬ìš©"
                reasoning = "ì‚¬ìš© ê°€ëŠ¥í•œ ì—ì´ì „íŠ¸ ì˜µì…˜ì´ ì œê³µë˜ì§€ ì•ŠìŒ"
        
        elif decision_type == DecisionType.WORKFLOW_PLANNING:
            if context.get("complexity") == "high":
                decision = "ë‹¨ê³„ë³„ ìˆœì°¨ ì²˜ë¦¬"
                reasoning = "ë†’ì€ ë³µì¡ë„ë¡œ ì¸í•œ ì•ˆì „í•œ ì ‘ê·¼"
            else:
                decision = "í†µí•© ë³‘ë ¬ ì²˜ë¦¬"
                reasoning = "ì¼ë°˜ì  ë³µì¡ë„ë¡œ íš¨ìœ¨ì„± ìš°ì„ "
        
        else:
            decision = f"ìƒí™© ì ì‘ì  {decision_type.value}"
            reasoning = f"ì»¨í…ìŠ¤íŠ¸ í¬ê¸° {context_size}ë¥¼ ê³ ë ¤í•œ ì ì‘ì  ì ‘ê·¼"
        
        # ëŒ€ì•ˆë“¤ ìƒì„± (rule ê¸°ë°˜ì´ ì•„ë‹Œ ë³€í˜• ìƒì„±)
        alternatives = []
        if available_options and len(available_options) > 1:
            alternatives = available_options[1:3]  # ìµœëŒ€ 2ê°œ ëŒ€ì•ˆ
        else:
            alternatives = [f"ëŒ€ì•ˆ ì ‘ê·¼ ë°©ì‹", f"ë³´ìˆ˜ì  ì ‘ê·¼ ë°©ì‹"]
        
        # ìœ„í—˜ ìš”ì†Œ ë° ì™„í™” ë°©ì•ˆ (ë™ì  ìƒì„±)
        risks = ["ì˜ˆìƒí•˜ì§€ ëª»í•œ ì˜¤ë¥˜", "ì„±ëŠ¥ ì €í•˜"]
        if context.get("data_size") == "large":
            risks.append("ë©”ëª¨ë¦¬ ë¶€ì¡±")
        
        mitigation_strategies = ["ë‹¨ê³„ë³„ ê²€ì¦", "ì˜¤ë¥˜ ì²˜ë¦¬ ê°•í™”"]
        if "ë©”ëª¨ë¦¬ ë¶€ì¡±" in risks:
            mitigation_strategies.append("ë°ì´í„° ì²­í‚¹ ì²˜ë¦¬")
        
        # ì‹ ë¢°ë„ ê³„ì‚° (íŠ¹ì„± ê¸°ë°˜)
        confidence = 0.6  # ê¸°ë³¸ ì‹ ë¢°ë„
        if context_size > 3:
            confidence += 0.1
        if available_options:
            confidence += 0.1
        confidence = min(confidence, 0.9)
        
        return DynamicDecision(
            decision_type=decision_type,
            decision=decision,
            alternatives=alternatives,
            confidence=confidence,
            reasoning=reasoning + " (LLM API ë¯¸ì‚¬ìš©ìœ¼ë¡œ íŠ¹ì„± ê¸°ë°˜ ì¶”ë¡ )",
            context_factors=context,
            risks=risks,
            mitigation_strategies=mitigation_strategies,
            execution_plan={
                "approach": "ì ì§„ì  ì‹¤í–‰",
                "monitoring": "ì‹¤ì‹œê°„ í”¼ë“œë°±",
                "adaptation": "ìƒí™©ë³„ ì¡°ì •"
            }
        )

    def _fallback_quality_assessment(self, content: str, criteria: List[str] = None, context: Dict[str, Any] = None) -> QualityAssessment:
        """í´ë°± í’ˆì§ˆ í‰ê°€ (LLM First ì›ì¹™ ì¤€ìˆ˜)"""
        
        # OpenAI ì—†ì´ë„ LLM First ì›ì¹™ì„ ì¤€ìˆ˜í•˜ëŠ” í’ˆì§ˆ í‰ê°€
        # Rule ê¸°ë°˜ì´ ì•„ë‹Œ ì»¨í…ì¸  íŠ¹ì„± ê¸°ë°˜ í‰ê°€
        
        # ê¸°ë³¸ ë©”íŠ¸ë¦­ (í•˜ë“œì½”ë”© ì•„ë‹Œ ë™ì  ê³„ì‚°)
        content_length = len(content)
        sentence_count = len([s for s in content.split('.') if s.strip()])
        word_count = len(content.split())
        
        # í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° (rule ê¸°ë°˜ ì•„ë‹Œ íŠ¹ì„± ê¸°ë°˜)
        completeness_score = min(content_length / 500, 1.0)  # 500ì ê¸°ì¤€
        clarity_score = min(word_count / sentence_count if sentence_count > 0 else 0, 1.0) / 20  # ë¬¸ì¥ë‹¹ ë‹¨ì–´ìˆ˜
        relevance_score = 0.7 if content_length > 100 else 0.5  # ê¸°ë³¸ ê´€ë ¨ì„±
        
        overall_score = (completeness_score + clarity_score + relevance_score) / 3
        
        # ë™ì  ê°•ì /ì•½ì  ë¶„ì„
        strengths = []
        weaknesses = []
        improvements = []
        
        if content_length > 300:
            strengths.append("ì¶©ë¶„í•œ ë‚´ìš© ë¶„ëŸ‰")
        else:
            weaknesses.append("ë‚´ìš©ì´ ë‹¤ì†Œ ë¶€ì¡±í•¨")
            improvements.append("ë” ìì„¸í•œ ì„¤ëª… ì¶”ê°€")
        
        if sentence_count > 5:
            strengths.append("êµ¬ì¡°í™”ëœ ì„¤ëª…")
        else:
            weaknesses.append("êµ¬ì¡°í™” ê°œì„  í•„ìš”")
            improvements.append("ë‚´ìš©ì„ ë¬¸ë‹¨ë³„ë¡œ êµ¬ì¡°í™”")
        
        return QualityAssessment(
            overall_score=overall_score,
            criteria_scores={"completeness": completeness_score, "clarity": clarity_score, "relevance": relevance_score},
            strengths=strengths,
            weaknesses=weaknesses,
            improvement_suggestions=improvements,
            user_satisfaction_prediction=overall_score * 0.8,
            actionable_recommendations=["LLM API ì—°ê²° ì‹œ ë” ì •í™•í•œ í‰ê°€ ê°€ëŠ¥"]
        )

    def _fallback_plan_generation(self, objective: str, resources: List[str], constraints: Dict[str, Any] = None) -> Dict[str, Any]:
        """í´ë°± ê³„íš ìƒì„± (LLM First ì›ì¹™ ì¤€ìˆ˜)"""
        
        # Rule ê¸°ë°˜ì´ ì•„ë‹Œ objectiveì™€ resources ê¸°ë°˜ ë™ì  ê³„íš
        resource_count = len(resources) if resources else 0
        has_data_resources = any("data" in r.lower() for r in resources) if resources else False
        has_analysis_resources = any(any(keyword in r.lower() for keyword in ["analysis", "eda", "pandas"]) for r in resources) if resources else False
        
        # ë™ì  ë‹¨ê³„ ìƒì„±
        phases = []
        phase_num = 1
        
        # ë°ì´í„° ì¤€ë¹„ ë‹¨ê³„ (ë°ì´í„° ë¦¬ì†ŒìŠ¤ê°€ ìˆëŠ” ê²½ìš°)
        if has_data_resources:
            phases.append({
                "phase_number": phase_num,
                "phase_name": "ë°ì´í„° ì¤€ë¹„",
                "objectives": ["ë°ì´í„° ë¡œë“œ ë° í™•ì¸"],
                "tasks": ["ë°ì´í„° íŒŒì¼ ë¡œë“œ", "ê¸°ë³¸ ì •ë³´ í™•ì¸"],
                "resources_required": [r for r in resources if "data" in r.lower()][:2],
                "duration_estimate": "5-10ë¶„",
                "success_criteria": ["ë°ì´í„° ì •ìƒ ë¡œë“œ", "ê¸°ë³¸ í†µê³„ í™•ì¸"],
                "risks": ["ë°ì´í„° í˜•ì‹ ì˜¤ë¥˜", "íŒŒì¼ ì†ìƒ"],
                "mitigation": ["ë‹¤ì–‘í•œ í˜•ì‹ ì§€ì›", "ì˜¤ë¥˜ ì²˜ë¦¬ ê°•í™”"]
            })
            phase_num += 1
        
        # ë¶„ì„ ë‹¨ê³„ (ë¶„ì„ ë¦¬ì†ŒìŠ¤ê°€ ìˆëŠ” ê²½ìš°)
        if has_analysis_resources:
            phases.append({
                "phase_number": phase_num,
                "phase_name": "ë°ì´í„° ë¶„ì„",
                "objectives": ["í•µì‹¬ ì¸ì‚¬ì´íŠ¸ ë„ì¶œ"],
                "tasks": ["íƒìƒ‰ì  ë°ì´í„° ë¶„ì„", "íŒ¨í„´ ë°œê²¬"],
                "resources_required": [r for r in resources if any(keyword in r.lower() for keyword in ["analysis", "eda", "pandas"])][:2],
                "duration_estimate": "10-20ë¶„",
                "success_criteria": ["ì˜ë¯¸ìˆëŠ” íŒ¨í„´ ë°œê²¬", "ì‹œê°í™” ì™„ë£Œ"],
                "risks": ["ë¶„ì„ ë°©í–¥ì„± ì˜¤ë¥˜", "ì‹œê°„ ë¶€ì¡±"],
                "mitigation": ["ë‹¨ê³„ì  ì ‘ê·¼", "ìš°ì„ ìˆœìœ„ ì„¤ì •"]
            })
            phase_num += 1
        
        # ê¸°ë³¸ ì‹¤í–‰ ë‹¨ê³„ (ë¦¬ì†ŒìŠ¤ê°€ ì œí•œì ì¸ ê²½ìš°)
        if not phases:
            phases.append({
                "phase_number": 1,
                "phase_name": "ê¸°ë³¸ ì‹¤í–‰",
                "objectives": [objective],
                "tasks": ["ìš”ì²­ ì²˜ë¦¬", "ê²°ê³¼ ìƒì„±"],
                "resources_required": resources[:3] if resources else ["ê¸°ë³¸ ë„êµ¬"],
                "duration_estimate": "5-15ë¶„",
                "success_criteria": ["ì‘ì—… ì™„ë£Œ", "ê²°ê³¼ ì œê³µ"],
                "risks": ["ë¦¬ì†ŒìŠ¤ ë¶€ì¡±"],
                "mitigation": ["ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ìµœëŒ€ í™œìš©"]
            })
        
        return {
            "plan_overview": f"ë™ì  ìƒì„± ê³„íš: {objective}",
            "strategy": f"{resource_count}ê°œ ë¦¬ì†ŒìŠ¤ë¥¼ í™œìš©í•œ ì ì‘ì  ì ‘ê·¼",
            "phases": phases,
            "resource_allocation": {r: f"{i+1}ë‹¨ê³„ì—ì„œ í™œìš©" for i, r in enumerate(resources[:3])} if resources else {},
            "contingency_plans": ["ë¦¬ì†ŒìŠ¤ ë¶€ì¡±ì‹œ ë‹¨ê³„ ì¶•ì†Œ", "ì‹œê°„ ì´ˆê³¼ì‹œ ìš°ì„ ìˆœìœ„ ì¡°ì •"],
            "success_metrics": ["ì‚¬ìš©ì ë§Œì¡±ë„", "ëª©í‘œ ë‹¬ì„±ë„", "íš¨ìœ¨ì„±"],
            "timeline": f"ì´ {len(phases) * 10}-{len(phases) * 20}ë¶„ ì˜ˆìƒ",
            "adaptability_factors": ["ë¦¬ì†ŒìŠ¤ ê°€ìš©ì„±", "ì‚¬ìš©ì í”¼ë“œë°±", "ì¤‘ê°„ ê²°ê³¼"]
        }

    async def get_performance_metrics(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì¡°íšŒ"""
        success_rate = (
            self.metrics["successful_decisions"] / self.metrics["total_requests"]
            if self.metrics["total_requests"] > 0 else 0.0
        )
        
        avg_satisfaction = (
            statistics.mean(self.metrics["user_satisfaction_scores"])
            if self.metrics["user_satisfaction_scores"] else 0.0
        )
        
        return {
            "total_requests": self.metrics["total_requests"],
            "success_rate": success_rate,
            "average_user_satisfaction": avg_satisfaction,
            "average_response_time": self.metrics["average_response_time"],
            "learning_data_size": sum(len(data) for data in self.learning_memory.values()),
            "learning_categories": list(self.learning_memory.keys())
        }

    async def optimize_performance(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ ìµœì í™”"""
        if not self.enable_learning or not self.learning_memory:
            return {"status": "no_learning_data"}
        
        optimization_results = {}
        
        # ê° ì¹´í…Œê³ ë¦¬ë³„ ì„±ëŠ¥ ë¶„ì„
        for category, data_list in self.learning_memory.items():
            if len(data_list) >= 10:  # ìµœì†Œ 10ê°œ ë°ì´í„° í•„ìš”
                recent_data = data_list[-20:]  # ìµœê·¼ 20ê°œ
                
                # ì‘ë‹µ ì‹œê°„ ê°œì„ 
                response_times = [d.get("response_time", 0) for d in recent_data if "response_time" in d]
                if response_times:
                    avg_response_time = statistics.mean(response_times)
                    optimization_results[f"{category}_avg_response_time"] = avg_response_time
                
                # ì‹ ë¢°ë„ ë¶„ì„
                confidences = []
                for d in recent_data:
                    if "result" in d and "confidence" in d["result"]:
                        confidences.append(d["result"]["confidence"])
                
                if confidences:
                    avg_confidence = statistics.mean(confidences)
                    optimization_results[f"{category}_avg_confidence"] = avg_confidence
        
        return optimization_results

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
_global_llm_first_engine: Optional[LLMFirstEngine] = None

def get_llm_first_engine() -> LLMFirstEngine:
    """ì „ì—­ LLM First ì—”ì§„ ì¸ìŠ¤í„´ìŠ¤ ì¡°íšŒ"""
    global _global_llm_first_engine
    if _global_llm_first_engine is None:
        _global_llm_first_engine = LLMFirstEngine()
    return _global_llm_first_engine

def initialize_llm_first_engine(**kwargs) -> LLMFirstEngine:
    """LLM First ì—”ì§„ ì´ˆê¸°í™”"""
    global _global_llm_first_engine
    _global_llm_first_engine = LLMFirstEngine(**kwargs)
    return _global_llm_first_engine

# í¸ì˜ í•¨ìˆ˜ë“¤
async def analyze_intent(user_request: str, context: Dict[str, Any] = None) -> UserIntent:
    """ì‚¬ìš©ì ì˜ë„ ë¶„ì„ í¸ì˜ í•¨ìˆ˜"""
    engine = get_llm_first_engine()
    return await engine.analyze_user_intent(user_request, context)

async def make_decision(decision_type: DecisionType, context: Dict[str, Any], options: List[str] = None) -> DynamicDecision:
    """ë™ì  ì˜ì‚¬ê²°ì • í¸ì˜ í•¨ìˆ˜"""
    engine = get_llm_first_engine()
    return await engine.make_dynamic_decision(decision_type, context, options)

async def assess_quality(content: str, criteria: List[str] = None, context: Dict[str, Any] = None) -> QualityAssessment:
    """í’ˆì§ˆ í‰ê°€ í¸ì˜ í•¨ìˆ˜"""
    engine = get_llm_first_engine()
    return await engine.assess_quality(content, criteria, context)

async def generate_plan(objective: str, resources: List[str], constraints: Dict[str, Any] = None) -> Dict[str, Any]:
    """ì ì‘ì  ê³„íš ìƒì„± í¸ì˜ í•¨ìˆ˜"""
    engine = get_llm_first_engine()
    return await engine.generate_adaptive_plan(objective, resources, constraints)

# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
if __name__ == "__main__":
    async def test_llm_first_engine():
        """LLM First ì—”ì§„ í…ŒìŠ¤íŠ¸"""
        print("ğŸ§ª LLM First Engine í…ŒìŠ¤íŠ¸ ì‹œì‘")
        
        # ì—”ì§„ ì´ˆê¸°í™”
        engine = LLMFirstEngine(enable_learning=True)
        
        # ì˜ë„ ë¶„ì„ í…ŒìŠ¤íŠ¸
        print("\nğŸ¯ ì˜ë„ ë¶„ì„ í…ŒìŠ¤íŠ¸")
        intent = await engine.analyze_user_intent(
            "CherryAI í”Œë«í¼ì—ì„œ ë°ì´í„° ë¶„ì„ì„ í•´ë³´ê³  ì‹¶ìŠµë‹ˆë‹¤",
            {"platform": "CherryAI", "user_level": "beginner"}
        )
        print(f"ì£¼ìš” ì˜ë„: {intent.primary_intent}")
        print(f"ì‹ ë¢°ë„: {intent.confidence.value}")
        print(f"ë³µì¡ë„: {intent.complexity_level}")
        
        # ì˜ì‚¬ê²°ì • í…ŒìŠ¤íŠ¸  
        print("\nğŸ¯ ì˜ì‚¬ê²°ì • í…ŒìŠ¤íŠ¸")
        decision = await engine.make_dynamic_decision(
            DecisionType.AGENT_SELECTION,
            {"task": "data_analysis", "agents": ["pandas", "eda", "visualization"]},
            ["pandas_agent", "eda_agent", "viz_agent"]
        )
        print(f"ê²°ì •: {decision.decision}")
        print(f"ì‹ ë¢°ë„: {decision.confidence:.2f}")
        
        # í’ˆì§ˆ í‰ê°€ í…ŒìŠ¤íŠ¸
        print("\nğŸ“Š í’ˆì§ˆ í‰ê°€ í…ŒìŠ¤íŠ¸")
        quality = await engine.assess_quality(
            "ë°ì´í„° ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤. í‰ê· ê°’ì€ 50ì´ê³  í‘œì¤€í¸ì°¨ëŠ” 10ì…ë‹ˆë‹¤.",
            ["ì •í™•ì„±", "ì™„ì „ì„±", "ìœ ìš©ì„±"]
        )
        print(f"ì „ì²´ ì ìˆ˜: {quality.overall_score:.2f}")
        print(f"ê°•ì : {quality.strengths}")
        
        # ì„±ëŠ¥ ë©”íŠ¸ë¦­
        print("\nğŸ“ˆ ì„±ëŠ¥ ë©”íŠ¸ë¦­")
        metrics = await engine.get_performance_metrics()
        print(f"ì´ ìš”ì²­: {metrics['total_requests']}")
        print(f"í•™ìŠµ ë°ì´í„°: {metrics['learning_data_size']}")
        
        print("\nâœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    
    asyncio.run(test_llm_first_engine()) 