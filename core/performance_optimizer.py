#!/usr/bin/env python3
"""
ğŸš€ CherryAI Performance Optimizer

Comprehensive performance optimization system for CherryAI v2.0
Provides automatic performance tuning, memory management, and bottleneck detection.

Author: CherryAI Performance Team
"""

import os
import gc
import psutil
import time
import asyncio
import logging
import threading
import numpy as np
import pandas as pd
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple, Callable
from dataclasses import dataclass, asdict
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
import multiprocessing as mp

logger = logging.getLogger(__name__)

@dataclass
class PerformanceMetrics:
    """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì •ë³´"""
    timestamp: datetime
    cpu_usage: float
    memory_usage: float
    memory_available: float
    disk_usage: float
    network_io: Dict[str, float]
    active_processes: int
    response_time: float
    throughput: float

@dataclass
class OptimizationResult:
    """ìµœì í™” ê²°ê³¼"""
    optimization_type: str
    before_metrics: Dict[str, Any]
    after_metrics: Dict[str, Any]
    improvement_percent: float
    recommendations: List[str]
    success: bool

class PerformanceOptimizer:
    """
    ì„±ëŠ¥ ìµœì í™” ì‹œìŠ¤í…œ
    
    ì£¼ìš” ê¸°ëŠ¥:
    - ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
    - ìë™ ë©”ëª¨ë¦¬ ê´€ë¦¬
    - ë³‘ëª©ì  íƒì§€ ë° í•´ê²°
    - ë™ì  ë¦¬ì†ŒìŠ¤ í• ë‹¹
    - ìµœì í™” ê¶Œì¥ì‚¬í•­ ì œê³µ
    """
    
    def __init__(self):
        # ì„¤ì •
        self.monitoring_interval = 10  # ì´ˆ
        self.optimization_threshold = 80  # CPU/ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ì„ê³„ê°’
        self.max_memory_usage_percent = 85
        self.max_cpu_usage_percent = 90
        
        # ìƒíƒœ
        self.is_monitoring = False
        self.performance_history: List[PerformanceMetrics] = []
        self.optimization_history: List[OptimizationResult] = []
        
        # ë¦¬ì†ŒìŠ¤
        self.cpu_count = mp.cpu_count()
        self.memory_total = psutil.virtual_memory().total
        self.thread_pool = ThreadPoolExecutor(max_workers=self.cpu_count)
        
        # ìºì‹œ ë° ìµœì í™” ì„¤ì •
        self.dataframe_cache: Dict[str, pd.DataFrame] = {}
        self.cache_max_size = 500 * 1024 * 1024  # 500MB
        self.current_cache_size = 0
        
        # ëª¨ë‹ˆí„°ë§ ìŠ¤ë ˆë“œ
        self.monitor_thread: Optional[threading.Thread] = None
        
        logger.info(f"PerformanceOptimizer initialized - CPU: {self.cpu_count}, Memory: {self.memory_total // (1024**3)}GB")
    
    def start_monitoring(self):
        """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        if self.is_monitoring:
            return
        
        self.is_monitoring = True
        self.monitor_thread = threading.Thread(target=self._monitoring_loop, daemon=True)
        self.monitor_thread.start()
        logger.info("Performance monitoring started")
    
    def stop_monitoring(self):
        """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€"""
        self.is_monitoring = False
        if self.monitor_thread:
            self.monitor_thread.join(timeout=5)
        logger.info("Performance monitoring stopped")
    
    def _monitoring_loop(self):
        """ëª¨ë‹ˆí„°ë§ ë£¨í”„"""
        while self.is_monitoring:
            try:
                metrics = self._collect_metrics()
                self.performance_history.append(metrics)
                
                # ì´ë ¥ ì œí•œ (ìµœê·¼ 1000ê°œ)
                if len(self.performance_history) > 1000:
                    self.performance_history = self.performance_history[-1000:]
                
                # ìë™ ìµœì í™” íŠ¸ë¦¬ê±°
                if self._should_optimize(metrics):
                    self._auto_optimize(metrics)
                
                time.sleep(self.monitoring_interval)
                
            except Exception as e:
                logger.error(f"Monitoring error: {e}")
                time.sleep(30)  # ì˜¤ë¥˜ ì‹œ 30ì´ˆ ëŒ€ê¸°
    
    def _collect_metrics(self) -> PerformanceMetrics:
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        cpu_percent = psutil.cpu_percent(interval=1)
        memory = psutil.virtual_memory()
        disk = psutil.disk_usage('/')
        network = psutil.net_io_counters()
        
        return PerformanceMetrics(
            timestamp=datetime.now(),
            cpu_usage=cpu_percent,
            memory_usage=memory.percent,
            memory_available=memory.available / (1024**3),  # GB
            disk_usage=(disk.used / disk.total) * 100,
            network_io={
                'bytes_sent': network.bytes_sent,
                'bytes_recv': network.bytes_recv
            },
            active_processes=len(psutil.pids()),
            response_time=0.0,  # ë³„ë„ ì¸¡ì • í•„ìš”
            throughput=0.0      # ë³„ë„ ì¸¡ì • í•„ìš”
        )
    
    def _should_optimize(self, metrics: PerformanceMetrics) -> bool:
        """ìµœì í™” í•„ìš” ì—¬ë¶€ íŒë‹¨"""
        return (
            metrics.cpu_usage > self.max_cpu_usage_percent or
            metrics.memory_usage > self.max_memory_usage_percent or
            metrics.memory_available < 1.0  # 1GB ë¯¸ë§Œ
        )
    
    def _auto_optimize(self, metrics: PerformanceMetrics):
        """ìë™ ìµœì í™” ìˆ˜í–‰"""
        try:
            before_metrics = asdict(metrics)
            
            # ë©”ëª¨ë¦¬ ìµœì í™”
            if metrics.memory_usage > self.max_memory_usage_percent:
                self.optimize_memory()
            
            # CPU ìµœì í™”
            if metrics.cpu_usage > self.max_cpu_usage_percent:
                self.optimize_cpu_usage()
            
            # ìºì‹œ ì •ë¦¬
            if self.current_cache_size > self.cache_max_size:
                self.optimize_cache()
            
            # ìµœì í™” í›„ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
            time.sleep(2)  # ìµœì í™” íš¨ê³¼ ë°˜ì˜ ëŒ€ê¸°
            after_metrics = asdict(self._collect_metrics())
            
            # ê²°ê³¼ ê¸°ë¡
            optimization = OptimizationResult(
                optimization_type="auto_optimization",
                before_metrics=before_metrics,
                after_metrics=after_metrics,
                improvement_percent=self._calculate_improvement(before_metrics, after_metrics),
                recommendations=[],
                success=True
            )
            
            self.optimization_history.append(optimization)
            logger.info(f"Auto optimization completed - improvement: {optimization.improvement_percent:.1f}%")
            
        except Exception as e:
            logger.error(f"Auto optimization failed: {e}")
    
    def optimize_memory(self) -> OptimizationResult:
        """ë©”ëª¨ë¦¬ ìµœì í™”"""
        logger.info("Starting memory optimization...")
        
        before_memory = psutil.virtual_memory().percent
        
        # 1. ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ê°•ì œ ì‹¤í–‰
        collected = gc.collect()
        
        # 2. ìºì‹œ ì •ë¦¬
        cache_cleared = self._clear_old_cache()
        
        # 3. ì„ì‹œ íŒŒì¼ ì •ë¦¬
        temp_cleared = self._clear_temp_files()
        
        # 4. DataFrame ë©”ëª¨ë¦¬ ìµœì í™”
        df_optimized = self._optimize_dataframes()
        
        after_memory = psutil.virtual_memory().percent
        improvement = ((before_memory - after_memory) / before_memory) * 100
        
        recommendations = []
        if improvement < 5:
            recommendations.append("Consider increasing system RAM or reducing data size")
        if cache_cleared > 100:
            recommendations.append("Implement more aggressive cache eviction policy")
        
        result = OptimizationResult(
            optimization_type="memory_optimization",
            before_metrics={"memory_usage": before_memory},
            after_metrics={"memory_usage": after_memory},
            improvement_percent=improvement,
            recommendations=recommendations,
            success=improvement > 0
        )
        
        logger.info(f"Memory optimization completed - freed {improvement:.1f}% memory")
        return result
    
    def optimize_cpu_usage(self) -> OptimizationResult:
        """CPU ì‚¬ìš©ë¥  ìµœì í™”"""
        logger.info("Starting CPU optimization...")
        
        before_cpu = psutil.cpu_percent(interval=1)
        
        # 1. ìŠ¤ë ˆë“œ í’€ í¬ê¸° ì¡°ì •
        optimal_workers = min(self.cpu_count, max(2, self.cpu_count - 1))
        if self.thread_pool._max_workers != optimal_workers:
            self.thread_pool.shutdown(wait=False)
            self.thread_pool = ThreadPoolExecutor(max_workers=optimal_workers)
        
        # 2. í”„ë¡œì„¸ìŠ¤ ìš°ì„ ìˆœìœ„ ì¡°ì •
        try:
            process = psutil.Process()
            process.nice(5)  # ë‚®ì€ ìš°ì„ ìˆœìœ„ ì„¤ì •
        except:
            pass
        
        # 3. ëŒ€ê¸° ì¤‘ì¸ ì‘ì—… ì •ë¦¬
        self._cleanup_pending_tasks()
        
        time.sleep(3)  # CPU ì•ˆì •í™” ëŒ€ê¸°
        after_cpu = psutil.cpu_percent(interval=1)
        improvement = ((before_cpu - after_cpu) / before_cpu) * 100 if before_cpu > 0 else 0
        
        result = OptimizationResult(
            optimization_type="cpu_optimization",
            before_metrics={"cpu_usage": before_cpu},
            after_metrics={"cpu_usage": after_cpu},
            improvement_percent=improvement,
            recommendations=["Consider using async operations for I/O bound tasks"],
            success=improvement > 0
        )
        
        logger.info(f"CPU optimization completed - reduced {improvement:.1f}% CPU usage")
        return result
    
    def optimize_dataframe_processing(self, df: pd.DataFrame, operation: str = "general") -> Tuple[pd.DataFrame, Dict[str, Any]]:
        """DataFrame ì²˜ë¦¬ ìµœì í™”"""
        start_time = time.time()
        initial_memory = df.memory_usage(deep=True).sum()
        
        optimized_df = df.copy()
        optimizations_applied = []
        
        # 1. ë°ì´í„° íƒ€ì… ìµœì í™”
        if operation in ["general", "memory"]:
            optimized_df = self._optimize_dtypes(optimized_df)
            optimizations_applied.append("dtype_optimization")
        
        # 2. ì¹´í…Œê³ ë¦¬í™”
        if operation in ["general", "categorical"]:
            optimized_df = self._categorize_string_columns(optimized_df)
            optimizations_applied.append("categorization")
        
        # 3. ì¸ë±ìŠ¤ ìµœì í™”
        if operation in ["general", "index"]:
            optimized_df = self._optimize_index(optimized_df)
            optimizations_applied.append("index_optimization")
        
        # 4. ì¤‘ë³µ ì œê±° (í•„ìš”ì‹œ)
        if operation == "deduplication":
            before_size = len(optimized_df)
            optimized_df = optimized_df.drop_duplicates()
            if len(optimized_df) < before_size:
                optimizations_applied.append("deduplication")
        
        final_memory = optimized_df.memory_usage(deep=True).sum()
        processing_time = time.time() - start_time
        
        optimization_stats = {
            "processing_time": processing_time,
            "memory_before": initial_memory / (1024**2),  # MB
            "memory_after": final_memory / (1024**2),    # MB
            "memory_saved": (initial_memory - final_memory) / (1024**2),  # MB
            "memory_reduction_percent": ((initial_memory - final_memory) / initial_memory) * 100,
            "optimizations_applied": optimizations_applied
        }
        
        return optimized_df, optimization_stats
    
    def optimize_large_dataset_processing(self, file_path: str, chunk_size: int = 10000) -> Dict[str, Any]:
        """ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹ ìµœì í™” ì²˜ë¦¬"""
        logger.info(f"Processing large dataset: {file_path}")
        
        start_time = time.time()
        total_rows = 0
        chunk_count = 0
        
        # ì²­í¬ ë‹¨ìœ„ ì²˜ë¦¬
        results = []
        for chunk in pd.read_csv(file_path, chunksize=chunk_size):
            chunk_optimized, _ = self.optimize_dataframe_processing(chunk, "general")
            
            # ê¸°ë³¸ í†µê³„ë§Œ ê³„ì‚°í•˜ì—¬ ë©”ëª¨ë¦¬ ì ˆì•½
            chunk_stats = {
                'count': len(chunk_optimized),
                'numeric_summary': chunk_optimized.select_dtypes(include=[np.number]).describe().to_dict()
            }
            results.append(chunk_stats)
            
            total_rows += len(chunk_optimized)
            chunk_count += 1
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            del chunk, chunk_optimized
            if chunk_count % 10 == 0:
                gc.collect()
        
        processing_time = time.time() - start_time
        
        return {
            "total_rows_processed": total_rows,
            "chunk_count": chunk_count,
            "processing_time": processing_time,
            "average_chunk_time": processing_time / chunk_count,
            "rows_per_second": total_rows / processing_time,
            "chunk_results": results
        }
    
    def optimize_cache(self) -> int:
        """ìºì‹œ ìµœì í™”"""
        cleared_size = self._clear_old_cache()
        
        # LRU ê¸°ë°˜ ìºì‹œ ì •ë¦¬
        if self.current_cache_size > self.cache_max_size:
            cache_items = list(self.dataframe_cache.items())
            # ê°„ë‹¨í•œ LRU ì‹œë®¬ë ˆì´ì…˜ (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ êµ¬í˜„ í•„ìš”)
            for key, df in cache_items[:-10]:  # ìµœê·¼ 10ê°œ ì œì™¸í•˜ê³  ì •ë¦¬
                del self.dataframe_cache[key]
                df_size = df.memory_usage(deep=True).sum()
                self.current_cache_size -= df_size
                cleared_size += df_size
                
                if self.current_cache_size <= self.cache_max_size * 0.8:
                    break
        
        return cleared_size
    
    def get_performance_recommendations(self) -> List[str]:
        """ì„±ëŠ¥ ê°œì„  ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        if not self.performance_history:
            return ["Start monitoring to get performance recommendations"]
        
        recent_metrics = self.performance_history[-10:]  # ìµœê·¼ 10ê°œ ë©”íŠ¸ë¦­
        
        # í‰ê·  ë©”íŠ¸ë¦­ ê³„ì‚°
        avg_cpu = sum(m.cpu_usage for m in recent_metrics) / len(recent_metrics)
        avg_memory = sum(m.memory_usage for m in recent_metrics) / len(recent_metrics)
        avg_memory_available = sum(m.memory_available for m in recent_metrics) / len(recent_metrics)
        
        # CPU ê¶Œì¥ì‚¬í•­
        if avg_cpu > 80:
            recommendations.append("High CPU usage detected. Consider using async operations or increasing CPU cores.")
        elif avg_cpu < 20:
            recommendations.append("Low CPU usage. You can increase parallel processing for better performance.")
        
        # ë©”ëª¨ë¦¬ ê¶Œì¥ì‚¬í•­
        if avg_memory > 85:
            recommendations.append("High memory usage. Enable data sampling or increase RAM.")
        if avg_memory_available < 2:
            recommendations.append("Low available memory. Consider data chunking for large datasets.")
        
        # ìºì‹œ ê¶Œì¥ì‚¬í•­
        if self.current_cache_size > self.cache_max_size * 0.8:
            recommendations.append("Cache near capacity. Consider increasing cache size or improving eviction policy.")
        
        # ì¼ë°˜ì ì¸ ìµœì í™” ê¶Œì¥ì‚¬í•­
        if len(self.optimization_history) == 0:
            recommendations.append("Run performance optimization to improve system efficiency.")
        
        return recommendations
    
    def get_performance_summary(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ ìš”ì•½ ì •ë³´"""
        if not self.performance_history:
            return {"error": "No performance data available"}
        
        recent_metrics = self.performance_history[-100:]  # ìµœê·¼ 100ê°œ
        
        return {
            "monitoring_duration": len(self.performance_history) * self.monitoring_interval,
            "current_status": {
                "cpu_usage": recent_metrics[-1].cpu_usage,
                "memory_usage": recent_metrics[-1].memory_usage,
                "memory_available": recent_metrics[-1].memory_available,
                "disk_usage": recent_metrics[-1].disk_usage
            },
            "averages": {
                "cpu_usage": sum(m.cpu_usage for m in recent_metrics) / len(recent_metrics),
                "memory_usage": sum(m.memory_usage for m in recent_metrics) / len(recent_metrics),
                "memory_available": sum(m.memory_available for m in recent_metrics) / len(recent_metrics)
            },
            "peaks": {
                "max_cpu": max(m.cpu_usage for m in recent_metrics),
                "max_memory": max(m.memory_usage for m in recent_metrics),
                "min_memory_available": min(m.memory_available for m in recent_metrics)
            },
            "optimizations_performed": len(self.optimization_history),
            "cache_stats": {
                "current_size_mb": self.current_cache_size / (1024**2),
                "max_size_mb": self.cache_max_size / (1024**2),
                "utilization_percent": (self.current_cache_size / self.cache_max_size) * 100
            },
            "recommendations": self.get_performance_recommendations()
        }
    
    # ë‚´ë¶€ í—¬í¼ ë©”ì„œë“œë“¤
    
    def _optimize_dtypes(self, df: pd.DataFrame) -> pd.DataFrame:
        """ë°ì´í„° íƒ€ì… ìµœì í™”"""
        optimized_df = df.copy()
        
        for col in optimized_df.columns:
            col_type = optimized_df[col].dtype
            
            # ìˆ«ìí˜• ì»¬ëŸ¼ ìµœì í™”
            if col_type in ['int64', 'int32']:
                min_val = optimized_df[col].min()
                max_val = optimized_df[col].max()
                
                if min_val >= -128 and max_val <= 127:
                    optimized_df[col] = optimized_df[col].astype('int8')
                elif min_val >= -32768 and max_val <= 32767:
                    optimized_df[col] = optimized_df[col].astype('int16')
                elif min_val >= -2147483648 and max_val <= 2147483647:
                    optimized_df[col] = optimized_df[col].astype('int32')
            
            elif col_type == 'float64':
                optimized_df[col] = pd.to_numeric(optimized_df[col], downcast='float')
        
        return optimized_df
    
    def _categorize_string_columns(self, df: pd.DataFrame) -> pd.DataFrame:
        """ë¬¸ìì—´ ì»¬ëŸ¼ ì¹´í…Œê³ ë¦¬í™”"""
        optimized_df = df.copy()
        
        for col in optimized_df.select_dtypes(include=['object']).columns:
            unique_ratio = optimized_df[col].nunique() / len(optimized_df)
            
            # ìœ ë‹ˆí¬ ë¹„ìœ¨ì´ 50% ë¯¸ë§Œì´ë©´ ì¹´í…Œê³ ë¦¬ë¡œ ë³€í™˜
            if unique_ratio < 0.5:
                optimized_df[col] = optimized_df[col].astype('category')
        
        return optimized_df
    
    def _optimize_index(self, df: pd.DataFrame) -> pd.DataFrame:
        """ì¸ë±ìŠ¤ ìµœì í™”"""
        # ê¸°ë³¸ ì •ìˆ˜ ì¸ë±ìŠ¤ê°€ ì•„ë‹Œ ê²½ìš°ì—ë§Œ ìµœì í™” ì‹œë„
        if not isinstance(df.index, pd.RangeIndex):
            try:
                # ì¸ë±ìŠ¤ë¥¼ ì •ìˆ˜ë¡œ ë¦¬ì…‹
                return df.reset_index(drop=True)
            except:
                pass
        
        return df
    
    def _clear_old_cache(self) -> int:
        """ì˜¤ë˜ëœ ìºì‹œ ì •ë¦¬"""
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ì ‘ê·¼ ì‹œê°„ ê¸°ë°˜ LRU êµ¬í˜„ í•„ìš”
        cleared_size = 0
        if len(self.dataframe_cache) > 100:  # ì„ì˜ì˜ ì„ê³„ê°’
            items_to_remove = len(self.dataframe_cache) // 4  # 25% ì œê±°
            for i, (key, df) in enumerate(self.dataframe_cache.items()):
                if i >= items_to_remove:
                    break
                df_size = df.memory_usage(deep=True).sum()
                cleared_size += df_size
                del self.dataframe_cache[key]
        
        return cleared_size
    
    def _clear_temp_files(self) -> int:
        """ì„ì‹œ íŒŒì¼ ì •ë¦¬"""
        cleared_size = 0
        temp_dirs = [
            Path("/tmp"),
            Path("temp"),
            Path("ai_ds_team/temp"),
            Path("artifacts/temp")
        ]
        
        for temp_dir in temp_dirs:
            if temp_dir.exists():
                try:
                    for file_path in temp_dir.glob("*"):
                        if file_path.is_file() and file_path.stat().st_mtime < time.time() - 3600:  # 1ì‹œê°„ ì´ìƒ ëœ íŒŒì¼
                            file_size = file_path.stat().st_size
                            file_path.unlink()
                            cleared_size += file_size
                except:
                    pass
        
        return cleared_size
    
    def _optimize_dataframes(self) -> int:
        """ë©”ëª¨ë¦¬ì˜ DataFrameë“¤ ìµœì í™”"""
        optimized_count = 0
        
        for key, df in self.dataframe_cache.items():
            try:
                optimized_df, _ = self.optimize_dataframe_processing(df, "memory")
                self.dataframe_cache[key] = optimized_df
                optimized_count += 1
            except:
                pass
        
        return optimized_count
    
    def _cleanup_pending_tasks(self):
        """ëŒ€ê¸° ì¤‘ì¸ ì‘ì—… ì •ë¦¬"""
        # ThreadPoolExecutorì˜ ëŒ€ê¸° ì¤‘ì¸ ì‘ì—…ë“¤ì„ ì •ë¦¬
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë” ì •êµí•œ ì‘ì—… ê´€ë¦¬ í•„ìš”
        pass
    
    def _calculate_improvement(self, before: Dict, after: Dict) -> float:
        """ê°œì„ ìœ¨ ê³„ì‚°"""
        try:
            before_score = before.get('cpu_usage', 0) + before.get('memory_usage', 0)
            after_score = after.get('cpu_usage', 0) + after.get('memory_usage', 0)
            
            if before_score > 0:
                return ((before_score - after_score) / before_score) * 100
            return 0.0
        except:
            return 0.0

# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
_performance_optimizer_instance = None

def get_performance_optimizer() -> PerformanceOptimizer:
    """PerformanceOptimizer ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _performance_optimizer_instance
    if _performance_optimizer_instance is None:
        _performance_optimizer_instance = PerformanceOptimizer()
    return _performance_optimizer_instance 