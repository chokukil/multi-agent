"""
Multi-Agent Orchestration System

ìƒˆë¡œìš´ ë©€í‹° ì—ì´ì „íŠ¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ì‹œìŠ¤í…œ
- UniversalDataAnalysisRouter í†µí•©
- ì „ë¬¸í™” ì—ì´ì „íŠ¸ë“¤ (ì •í˜•/ì‹œê³„ì—´/í…ìŠ¤íŠ¸/ì´ë¯¸ì§€) í†µí•©
- pandas-ai ì„œë²„ í†µí•©
- Enhanced Langfuse v2 ì¶”ì  í†µí•©

Author: CherryAI Team
Date: 2024-12-30
"""

import asyncio
import json
import logging
import os
import time
import httpx
from datetime import datetime
from typing import Any, Dict, List, Optional, Union
from dataclasses import dataclass
from enum import Enum

# A2A SDK 0.2.9 í‘œì¤€ ì„í¬íŠ¸
try:
    from a2a.server.apps import A2AStarletteApplication
    from a2a.server.request_handlers import DefaultRequestHandler
    from a2a.server.tasks import InMemoryTaskStore, TaskUpdater
    from a2a.server.agent_execution import AgentExecutor, RequestContext
    from a2a.server.events import EventQueue
    from a2a.types import (
        AgentCard,
        AgentSkill,
        AgentCapabilities,
        TaskState,
        TextPart,
        Part
    )
    from a2a.client import A2ACardResolver, A2AClient
    from a2a.utils import new_agent_text_message, new_task
    A2A_AVAILABLE = True
except ImportError:
    A2A_AVAILABLE = False
    logger.warning("âš ï¸ A2A SDK not available")

# ìš°ë¦¬ê°€ êµ¬í˜„í•œ ì‹œìŠ¤í…œë“¤ í†µí•©
try:
    from core.universal_data_analysis_router import get_universal_router
    from core.specialized_data_agents import get_data_type_detector, DataType, DataAnalysisResult
    from core.enhanced_langfuse_tracer import get_enhanced_tracer
    from core.user_file_tracker import get_user_file_tracker
    from core.session_data_manager import SessionDataManager
    CORE_SYSTEMS_AVAILABLE = True
except ImportError as e:
    CORE_SYSTEMS_AVAILABLE = False
    print(f"âš ï¸ Core systems not available: {e}")

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class OrchestrationStrategy(Enum):
    """ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ì „ëµ"""
    SINGLE_AGENT = "single_agent"           # ë‹¨ì¼ ì—ì´ì „íŠ¸ ì‹¤í–‰
    SEQUENTIAL = "sequential"               # ìˆœì°¨ ì‹¤í–‰
    PARALLEL = "parallel"                   # ë³‘ë ¬ ì‹¤í–‰
    HIERARCHICAL = "hierarchical"           # ê³„ì¸µì  ì‹¤í–‰
    COLLABORATIVE = "collaborative"         # í˜‘ë ¥ì  ì‹¤í–‰


@dataclass
class AgentTask:
    """ì—ì´ì „íŠ¸ ì‘ì—… ì •ì˜"""
    agent_id: str
    agent_type: str
    task_description: str
    input_data: Any
    dependencies: List[str] = None
    priority: int = 5  # 1-10
    timeout: int = 300  # seconds
    retry_count: int = 3


@dataclass
class OrchestrationPlan:
    """ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ì‹¤í–‰ ê³„íš"""
    strategy: OrchestrationStrategy
    tasks: List[AgentTask]
    estimated_duration: int
    confidence: float
    reasoning: str


@dataclass
class OrchestrationResult:
    """ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ê²°ê³¼"""
    success: bool
    results: Dict[str, Any]
    insights: List[str]
    recommendations: List[str]
    execution_time: float
    errors: List[str] = None
    metadata: Dict[str, Any] = None


class MultiAgentOrchestrator:
    """
    ë©€í‹° ì—ì´ì „íŠ¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ì‹œìŠ¤í…œ
    
    ë‹¤ì–‘í•œ ì „ë¬¸í™” ì—ì´ì „íŠ¸ë“¤ì„ ì¡°í•©í•˜ì—¬ ë³µì¡í•œ ë°ì´í„° ë¶„ì„ ì‘ì—…ì„ ìˆ˜í–‰
    """
    
    def __init__(self, config: Optional[Dict] = None):
        self.config = config or {}
        self.enhanced_tracer = None
        self.universal_router = None
        self.data_type_detector = None
        self.user_file_tracker = None
        self.session_data_manager = None
        
        # ì—ì´ì „íŠ¸ ì—”ë“œí¬ì¸íŠ¸ ë§¤í•‘
        self.agent_endpoints = {
            "pandas_ai": "http://localhost:8000",
            "eda_tools": "http://localhost:8001",
            "data_visualization": "http://localhost:8002",
            "data_cleaning": "http://localhost:8003",
            "feature_engineering": "http://localhost:8004",
            "ml_agent": "http://localhost:8005"
        }
        
        # ì‹¤í–‰ íˆìŠ¤í† ë¦¬
        self.execution_history: List[Dict] = []
        
        # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        self._initialize_systems()
        
        logger.info("ğŸš€ Multi-Agent Orchestrator ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _initialize_systems(self):
        """í•µì‹¬ ì‹œìŠ¤í…œë“¤ ì´ˆê¸°í™”"""
        if not CORE_SYSTEMS_AVAILABLE:
            logger.warning("âš ï¸ Core systems not available - using fallback mode")
            return
        
        try:
            # Enhanced Tracking ì´ˆê¸°í™”
            self.enhanced_tracer = get_enhanced_tracer()
            logger.info("âœ… Enhanced Langfuse Tracking í™œì„±í™”")
            
            # Universal Router ì´ˆê¸°í™”
            self.universal_router = get_universal_router()
            logger.info("âœ… Universal Data Analysis Router í™œì„±í™”")
            
            # Data Type Detector ì´ˆê¸°í™”
            self.data_type_detector = get_data_type_detector()
            logger.info("âœ… Data Type Detector í™œì„±í™”")
            
            # User File Tracker ì´ˆê¸°í™”
            self.user_file_tracker = get_user_file_tracker()
            self.session_data_manager = SessionDataManager()
            logger.info("âœ… User File Tracker & Session Manager í™œì„±í™”")
            
        except Exception as e:
            logger.error(f"âŒ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    async def orchestrate_analysis(
        self, 
        user_query: str, 
        data: Optional[Any] = None, 
        session_id: Optional[str] = None,
        context: Optional[Dict] = None
    ) -> OrchestrationResult:
        """
        ë°ì´í„° ë¶„ì„ì„ ìœ„í•œ ë©€í‹° ì—ì´ì „íŠ¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜
        
        Args:
            user_query: ì‚¬ìš©ì ì§ˆë¬¸
            data: ë¶„ì„í•  ë°ì´í„° (ì„ íƒì‚¬í•­)
            session_id: ì„¸ì…˜ ID
            context: ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸
            
        Returns:
            OrchestrationResult: ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ê²°ê³¼
        """
        start_time = time.time()
        
        try:
            logger.info(f"ğŸ”„ ë©€í‹° ì—ì´ì „íŠ¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ì‹œì‘: {user_query[:100]}...")
            
            # Enhanced Tracking
            if self.enhanced_tracer:
                self.enhanced_tracer.log_data_operation(
                    "orchestration_start",
                    {"query": user_query, "session_id": session_id},
                    "Starting multi-agent orchestration"
                )
            
            # 1. ë°ì´í„° ìˆ˜ì§‘ ë° ì¤€ë¹„
            prepared_data = await self._prepare_data(data, session_id, context)
            
            # 2. ì§ˆë¬¸ ë¶„ì„ ë° ë¼ìš°íŒ…
            routing_result = await self._analyze_and_route_query(user_query, prepared_data, session_id, context)
            
            # 3. ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ê³„íš ìƒì„±
            plan = await self._create_orchestration_plan(user_query, routing_result, prepared_data)
            
            # 4. ê³„íš ì‹¤í–‰
            execution_result = await self._execute_orchestration_plan(plan, session_id)
            
            # 5. ê²°ê³¼ í†µí•© ë° í•´ì„
            final_result = await self._integrate_and_interpret_results(
                user_query, execution_result, plan
            )
            
            execution_time = time.time() - start_time
            
            # ì‹¤í–‰ íˆìŠ¤í† ë¦¬ ê¸°ë¡
            self.execution_history.append({
                "timestamp": datetime.now().isoformat(),
                "query": user_query,
                "strategy": plan.strategy.value,
                "execution_time": execution_time,
                "success": final_result.success,
                "session_id": session_id
            })
            
            logger.info(f"âœ… ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ì™„ë£Œ (ì†Œìš”ì‹œê°„: {execution_time:.2f}ì´ˆ)")
            return final_result
            
        except Exception as e:
            execution_time = time.time() - start_time
            logger.error(f"âŒ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ì‹¤íŒ¨: {e}")
            
            return OrchestrationResult(
                success=False,
                results={"error": str(e)},
                insights=[],
                recommendations=["ì‹œìŠ¤í…œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."],
                execution_time=execution_time,
                errors=[str(e)]
            )
    
    async def _prepare_data(
        self, 
        data: Optional[Any], 
        session_id: Optional[str], 
        context: Optional[Dict]
    ) -> Dict[str, Any]:
        """ë°ì´í„° ì¤€ë¹„ ë° ì»¨í…ìŠ¤íŠ¸ ìˆ˜ì§‘"""
        prepared = {
            "provided_data": data,
            "session_files": [],
            "context": context or {}
        }
        
        # ì„¸ì…˜ íŒŒì¼ ìˆ˜ì§‘
        if session_id and self.session_data_manager:
            try:
                uploaded_files = self.session_data_manager.get_uploaded_files(session_id)
                prepared["session_files"] = uploaded_files
                
                # íŒŒì¼ ë°ì´í„° ë¡œë“œ
                if uploaded_files and self.user_file_tracker:
                    file_data = []
                    for file_name in uploaded_files[:3]:  # ìµœëŒ€ 3ê°œ íŒŒì¼
                        file_path = self.user_file_tracker.get_best_file(
                            session_id=session_id,
                            query=file_name
                        )
                        if file_path:
                            # íŒŒì¼ íƒ€ì…ì— ë”°ë¥¸ ë¡œë”© (ê°„ë‹¨í•œ ë²„ì „)
                            file_info = {
                                "name": file_name,
                                "path": file_path,
                                "size": os.path.getsize(file_path) if os.path.exists(file_path) else 0
                            }
                            file_data.append(file_info)
                    
                    prepared["file_data"] = file_data
                    
            except Exception as e:
                logger.warning(f"âš ï¸ ì„¸ì…˜ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        
        return prepared
    
    async def _analyze_and_route_query(
        self, 
        user_query: str, 
        prepared_data: Dict, 
        session_id: Optional[str], 
        context: Optional[Dict]
    ) -> Dict[str, Any]:
        """ì§ˆë¬¸ ë¶„ì„ ë° ë¼ìš°íŒ…"""
        if not self.universal_router:
            return {"error": "Universal router not available"}
        
        try:
            # Universal Routerë¡œ ì§ˆë¬¸ ë¶„ì„
            routing_result = await self.universal_router.route_query(
                user_query, session_id, context
            )
            
            # ë°ì´í„° íƒ€ì… íƒì§€ (ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°)
            data_type_info = None
            if prepared_data.get("provided_data") and self.data_type_detector:
                detection_result = self.data_type_detector.detect_data_type(
                    prepared_data["provided_data"]
                )
                data_type_info = {
                    "detected_type": detection_result.detected_type.value,
                    "confidence": detection_result.confidence,
                    "characteristics": detection_result.characteristics
                }
            
            return {
                "routing": routing_result,
                "data_type": data_type_info,
                "complexity": self._assess_query_complexity(user_query),
                "requires_data": self._requires_data_analysis(user_query)
            }
            
        except Exception as e:
            logger.error(f"âŒ ì§ˆë¬¸ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {"error": str(e)}
    
    def _assess_query_complexity(self, user_query: str) -> str:
        """ì§ˆë¬¸ ë³µì¡ë„ í‰ê°€"""
        query_lower = user_query.lower()
        
        # ë³µì¡í•œ í‚¤ì›Œë“œë“¤
        complex_keywords = [
            'ë¹„êµ', 'ë¶„ì„', 'ì˜ˆì¸¡', 'ëª¨ë¸', 'ìƒê´€ê´€ê³„', 'ë¶„ë¥˜', 'íšŒê·€',
            'compare', 'analyze', 'predict', 'model', 'correlation', 'classify', 'regression'
        ]
        
        # ë‹¤ë‹¨ê³„ í‚¤ì›Œë“œë“¤
        multi_step_keywords = [
            'ê·¸ë¦¬ê³ ', 'ë‹¤ìŒ', 'ê·¸ í›„', 'ë˜í•œ', 'ì¶”ê°€ë¡œ', 'ë§ˆì§€ë§‰ìœ¼ë¡œ',
            'and then', 'next', 'after that', 'also', 'additionally', 'finally'
        ]
        
        if any(keyword in query_lower for keyword in multi_step_keywords):
            return "multi_step"
        elif any(keyword in query_lower for keyword in complex_keywords):
            return "complex"
        else:
            return "simple"
    
    def _requires_data_analysis(self, user_query: str) -> bool:
        """ë°ì´í„° ë¶„ì„ì´ í•„ìš”í•œì§€ íŒë‹¨"""
        data_keywords = [
            'ë°ì´í„°', 'ì°¨íŠ¸', 'ê·¸ë˜í”„', 'ë¶„ì„', 'í†µê³„', 'í‰ê· ', 'ë¶„í¬',
            'data', 'chart', 'graph', 'analysis', 'statistics', 'average', 'distribution'
        ]
        return any(keyword in user_query.lower() for keyword in data_keywords)
    
    async def _create_orchestration_plan(
        self, 
        user_query: str, 
        routing_result: Dict, 
        prepared_data: Dict
    ) -> OrchestrationPlan:
        """ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ì‹¤í–‰ ê³„íš ìƒì„±"""
        complexity = routing_result.get("complexity", "simple")
        requires_data = routing_result.get("requires_data", False)
        
        tasks = []
        strategy = OrchestrationStrategy.SINGLE_AGENT
        estimated_duration = 30  # seconds
        confidence = 0.8
        reasoning = "ê¸°ë³¸ ë‹¨ì¼ ì—ì´ì „íŠ¸ ì „ëµ"
        
        if complexity == "simple" and not requires_data:
            # ë‹¨ìˆœ ì§ˆë¬¸ - LLM ì§ì ‘ ì‘ë‹µ
            tasks.append(AgentTask(
                agent_id="llm_direct",
                agent_type="llm",
                task_description="ë‹¨ìˆœ ì§ˆë¬¸ ì§ì ‘ ì‘ë‹µ",
                input_data={"query": user_query}
            ))
            strategy = OrchestrationStrategy.SINGLE_AGENT
            estimated_duration = 10
            reasoning = "ë‹¨ìˆœ ì§ˆë¬¸ìœ¼ë¡œ LLM ì§ì ‘ ì‘ë‹µ"
            
        elif complexity == "simple" and requires_data:
            # ë‹¨ìˆœ ë°ì´í„° ë¶„ì„ - ì ì ˆí•œ ì—ì´ì „íŠ¸ í•˜ë‚˜ ì„ íƒ
            if routing_result.get("routing", {}).get("success"):
                recommended_agent = routing_result["routing"]["decision"]["recommended_agent"]
                tasks.append(AgentTask(
                    agent_id=recommended_agent,
                    agent_type="specialized",
                    task_description=f"{recommended_agent} ì—ì´ì „íŠ¸ë¥¼ í†µí•œ ë°ì´í„° ë¶„ì„",
                    input_data={"query": user_query, "data": prepared_data}
                ))
                strategy = OrchestrationStrategy.SINGLE_AGENT
                reasoning = f"ë¼ìš°í„° ì¶”ì²œ {recommended_agent} ì—ì´ì „íŠ¸ ì‚¬ìš©"
            
        elif complexity == "complex":
            # ë³µì¡í•œ ë¶„ì„ - ì—¬ëŸ¬ ì—ì´ì „íŠ¸ ìˆœì°¨ ì‹¤í–‰
            tasks.extend([
                AgentTask(
                    agent_id="eda",
                    agent_type="specialized",
                    task_description="íƒìƒ‰ì  ë°ì´í„° ë¶„ì„",
                    input_data={"query": "ë°ì´í„° ê¸°ë³¸ ë¶„ì„", "data": prepared_data},
                    priority=9
                ),
                AgentTask(
                    agent_id="pandas_ai",
                    agent_type="universal",
                    task_description="ìì—°ì–´ ê¸°ë°˜ ì‹¬í™” ë¶„ì„",
                    input_data={"query": user_query, "data": prepared_data},
                    dependencies=["eda"],
                    priority=8
                )
            ])
            strategy = OrchestrationStrategy.SEQUENTIAL
            estimated_duration = 120
            confidence = 0.9
            reasoning = "ë³µì¡í•œ ì§ˆë¬¸ìœ¼ë¡œ EDA í›„ pandas-ai ì‹¬í™” ë¶„ì„"
            
        elif complexity == "multi_step":
            # ë‹¤ë‹¨ê³„ ë¶„ì„ - ê³„ì¸µì  ì‹¤í–‰
            tasks.extend([
                AgentTask(
                    agent_id="data_type_detector",
                    agent_type="detector",
                    task_description="ë°ì´í„° íƒ€ì… íƒì§€",
                    input_data={"data": prepared_data},
                    priority=10
                ),
                AgentTask(
                    agent_id="eda",
                    agent_type="specialized", 
                    task_description="ê¸°ë³¸ íƒìƒ‰ì  ë¶„ì„",
                    input_data={"query": "ê¸°ë³¸ ë¶„ì„", "data": prepared_data},
                    dependencies=["data_type_detector"],
                    priority=9
                ),
                AgentTask(
                    agent_id="specialized_analysis",
                    agent_type="specialized",
                    task_description="ì „ë¬¸í™”ëœ ë¶„ì„",
                    input_data={"query": user_query, "data": prepared_data},
                    dependencies=["eda"],
                    priority=8
                ),
                AgentTask(
                    agent_id="pandas_ai",
                    agent_type="universal",
                    task_description="ì¢…í•© ë¶„ì„ ë° í•´ì„",
                    input_data={"query": user_query, "data": prepared_data},
                    dependencies=["specialized_analysis"],
                    priority=7
                )
            ])
            strategy = OrchestrationStrategy.HIERARCHICAL
            estimated_duration = 180
            confidence = 0.95
            reasoning = "ë‹¤ë‹¨ê³„ ì§ˆë¬¸ìœ¼ë¡œ ê³„ì¸µì  ë¶„ì„ ì›Œí¬í”Œë¡œìš°"
        
        return OrchestrationPlan(
            strategy=strategy,
            tasks=tasks,
            estimated_duration=estimated_duration,
            confidence=confidence,
            reasoning=reasoning
        )
    
    async def _execute_orchestration_plan(
        self, 
        plan: OrchestrationPlan, 
        session_id: Optional[str]
    ) -> Dict[str, Any]:
        """ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ê³„íš ì‹¤í–‰"""
        results = {}
        
        if plan.strategy == OrchestrationStrategy.SINGLE_AGENT:
            # ë‹¨ì¼ ì—ì´ì „íŠ¸ ì‹¤í–‰
            if plan.tasks:
                task = plan.tasks[0]
                result = await self._execute_single_task(task, session_id)
                results[task.agent_id] = result
                
        elif plan.strategy == OrchestrationStrategy.SEQUENTIAL:
            # ìˆœì°¨ ì‹¤í–‰
            for task in sorted(plan.tasks, key=lambda t: t.priority, reverse=True):
                # ì˜ì¡´ì„± í™•ì¸
                if task.dependencies:
                    dependencies_met = all(dep in results for dep in task.dependencies)
                    if not dependencies_met:
                        logger.warning(f"âš ï¸ ì‘ì—… {task.agent_id}ì˜ ì˜ì¡´ì„±ì´ ì¶©ì¡±ë˜ì§€ ì•ŠìŒ")
                        continue
                
                result = await self._execute_single_task(task, session_id)
                results[task.agent_id] = result
                
        elif plan.strategy == OrchestrationStrategy.PARALLEL:
            # ë³‘ë ¬ ì‹¤í–‰
            tasks_to_run = [self._execute_single_task(task, session_id) for task in plan.tasks]
            parallel_results = await asyncio.gather(*tasks_to_run, return_exceptions=True)
            
            for i, task in enumerate(plan.tasks):
                results[task.agent_id] = parallel_results[i]
                
        elif plan.strategy == OrchestrationStrategy.HIERARCHICAL:
            # ê³„ì¸µì  ì‹¤í–‰ (ì˜ì¡´ì„± ìˆœì„œì— ë”°ë¼)
            remaining_tasks = plan.tasks.copy()
            
            while remaining_tasks:
                # ì‹¤í–‰ ê°€ëŠ¥í•œ ì‘ì—… ì°¾ê¸°
                ready_tasks = [
                    task for task in remaining_tasks
                    if not task.dependencies or all(dep in results for dep in task.dependencies)
                ]
                
                if not ready_tasks:
                    logger.error("âŒ ìˆœí™˜ ì˜ì¡´ì„± ë˜ëŠ” í•´ê²°í•  ìˆ˜ ì—†ëŠ” ì˜ì¡´ì„± ë°œê²¬")
                    break
                
                # ìš°ì„ ìˆœìœ„ê°€ ë†’ì€ ì‘ì—…ë¶€í„° ì‹¤í–‰
                ready_tasks.sort(key=lambda t: t.priority, reverse=True)
                
                for task in ready_tasks:
                    result = await self._execute_single_task(task, session_id)
                    results[task.agent_id] = result
                    remaining_tasks.remove(task)
        
        return results
    
    async def _execute_single_task(self, task: AgentTask, session_id: Optional[str]) -> Dict[str, Any]:
        """ë‹¨ì¼ ì‘ì—… ì‹¤í–‰"""
        try:
            logger.info(f"ğŸ”„ ì‘ì—… ì‹¤í–‰: {task.agent_id} - {task.task_description}")
            
            if task.agent_type == "llm":
                return await self._execute_llm_task(task)
            elif task.agent_type == "specialized":
                return await self._execute_specialized_agent_task(task)
            elif task.agent_type == "universal":
                return await self._execute_universal_agent_task(task)
            elif task.agent_type == "detector":
                return await self._execute_detector_task(task)
            else:
                return {"error": f"Unknown agent type: {task.agent_type}"}
                
        except Exception as e:
            logger.error(f"âŒ ì‘ì—… ì‹¤í–‰ ì‹¤íŒ¨ {task.agent_id}: {e}")
            return {"error": str(e), "agent_id": task.agent_id}
    
    async def _execute_llm_task(self, task: AgentTask) -> Dict[str, Any]:
        """LLM ì§ì ‘ ì‹¤í–‰"""
        try:
            # ê°„ë‹¨í•œ LLM ì‘ë‹µ (ì‹¤ì œë¡œëŠ” OpenAI API í˜¸ì¶œ)
            query = task.input_data.get("query", "")
            
            response = f"'{query}'ì— ëŒ€í•œ ë‹µë³€ì…ë‹ˆë‹¤. ì´ëŠ” LLMì´ ì§ì ‘ ìƒì„±í•œ ì‘ë‹µìœ¼ë¡œ, ì¶”ê°€ì ì¸ ë°ì´í„° ë¶„ì„ì´ í•„ìš”í•˜ì§€ ì•Šì€ ì¼ë°˜ì ì¸ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì…ë‹ˆë‹¤."
            
            return {
                "success": True,
                "response": response,
                "type": "llm_direct",
                "confidence": 0.8
            }
            
        except Exception as e:
            return {"error": str(e), "success": False}
    
    async def _execute_specialized_agent_task(self, task: AgentTask) -> Dict[str, Any]:
        """ì „ë¬¸í™” ì—ì´ì „íŠ¸ ì‹¤í–‰"""
        try:
            if not self.data_type_detector:
                return {"error": "Data type detector not available", "success": False}
            
            query = task.input_data.get("query", "")
            data = task.input_data.get("data", {}).get("provided_data")
            
            if data is not None:
                # ì „ë¬¸í™” ì—ì´ì „íŠ¸ë¡œ ë¶„ì„
                result = await self.data_type_detector.analyze_with_best_agent(data, query)
                
                return {
                    "success": True,
                    "analysis_type": result.analysis_type,
                    "data_type": result.data_type.value,
                    "results": result.results,
                    "insights": result.insights,
                    "recommendations": result.recommendations,
                    "confidence": result.confidence
                }
            else:
                return {
                    "success": False,
                    "error": "No data provided for specialized analysis"
                }
                
        except Exception as e:
            return {"error": str(e), "success": False}
    
    async def _execute_universal_agent_task(self, task: AgentTask) -> Dict[str, Any]:
        """ë²”ìš© ì—ì´ì „íŠ¸ (pandas-ai) ì‹¤í–‰"""
        try:
            # pandas-ai ì„œë²„ í˜¸ì¶œ ì‹œë®¬ë ˆì´ì…˜
            endpoint = self.agent_endpoints.get("pandas_ai", "http://localhost:8000")
            query = task.input_data.get("query", "")
            
            # ì‹¤ì œë¡œëŠ” HTTP ìš”ì²­ì„ ë³´ëƒ„
            response_text = f"pandas-ai ì—ì´ì „íŠ¸ê°€ '{query}'ì— ëŒ€í•´ ë¶„ì„í–ˆìŠµë‹ˆë‹¤. ìì—°ì–´ ì²˜ë¦¬ë¥¼ í†µí•œ ë°ì´í„° ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤."
            
            return {
                "success": True,
                "response": response_text,
                "type": "pandas_ai",
                "confidence": 0.9,
                "code_generated": "# pandas-ai generated code\ndf.describe()",
                "execution_result": "ë¶„ì„ ì™„ë£Œ"
            }
            
        except Exception as e:
            return {"error": str(e), "success": False}
    
    async def _execute_detector_task(self, task: AgentTask) -> Dict[str, Any]:
        """ë°ì´í„° íƒ€ì… íƒì§€ ì‹¤í–‰"""
        try:
            if not self.data_type_detector:
                return {"error": "Data type detector not available", "success": False}
            
            data = task.input_data.get("data", {}).get("provided_data")
            
            if data is not None:
                detection_result = self.data_type_detector.detect_data_type(data)
                
                return {
                    "success": True,
                    "detected_type": detection_result.detected_type.value,
                    "confidence": detection_result.confidence,
                    "reasoning": detection_result.reasoning,
                    "characteristics": detection_result.characteristics,
                    "recommendations": detection_result.recommendations
                }
            else:
                return {
                    "success": False,
                    "error": "No data provided for type detection"
                }
                
        except Exception as e:
            return {"error": str(e), "success": False}
    
    async def _integrate_and_interpret_results(
        self, 
        user_query: str, 
        execution_results: Dict, 
        plan: OrchestrationPlan
    ) -> OrchestrationResult:
        """ê²°ê³¼ í†µí•© ë° í•´ì„"""
        try:
            # ì„±ê³µí•œ ê²°ê³¼ë“¤ ìˆ˜ì§‘
            successful_results = {
                k: v for k, v in execution_results.items() 
                if isinstance(v, dict) and v.get("success", False)
            }
            
            # ì˜¤ë¥˜ ìˆ˜ì§‘
            errors = [
                f"{k}: {v.get('error', 'Unknown error')}" 
                for k, v in execution_results.items()
                if isinstance(v, dict) and not v.get("success", True)
            ]
            
            # ì¸ì‚¬ì´íŠ¸ í†µí•©
            all_insights = []
            all_recommendations = []
            
            for agent_id, result in successful_results.items():
                if "insights" in result:
                    all_insights.extend(result["insights"])
                if "recommendations" in result:
                    all_recommendations.extend(result["recommendations"])
                if "response" in result:
                    all_insights.append(f"{agent_id}: {result['response']}")
            
            # ê¸°ë³¸ ì¸ì‚¬ì´íŠ¸ ì¶”ê°€ (ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš°)
            if not all_insights:
                all_insights.append(f"'{user_query}'ì— ëŒ€í•œ ë¶„ì„ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤.")
                
            if not all_recommendations:
                all_recommendations.append("ì¶”ê°€ì ì¸ ë¶„ì„ì´ë‚˜ ì§ˆë¬¸ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë¬¸ì˜í•´ì£¼ì„¸ìš”.")
            
            # ì„±ê³µ ì—¬ë¶€ íŒë‹¨
            success = len(successful_results) > 0 and len(errors) == 0
            
            return OrchestrationResult(
                success=success,
                results=execution_results,
                insights=all_insights,
                recommendations=all_recommendations,
                execution_time=0,  # ì‹¤ì œë¡œëŠ” ê³„ì‚°ë¨
                errors=errors if errors else None,
                metadata={
                    "strategy": plan.strategy.value,
                    "tasks_executed": len(execution_results),
                    "successful_tasks": len(successful_results),
                    "plan_confidence": plan.confidence
                }
            )
            
        except Exception as e:
            logger.error(f"âŒ ê²°ê³¼ í†µí•© ì‹¤íŒ¨: {e}")
            return OrchestrationResult(
                success=False,
                results=execution_results,
                insights=[],
                recommendations=["ê²°ê³¼ í†µí•© ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."],
                execution_time=0,
                errors=[str(e)]
            )
    
    def get_orchestration_statistics(self) -> Dict[str, Any]:
        """ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ í†µê³„ ì¡°íšŒ"""
        if not self.execution_history:
            return {
                "total_executions": 0,
                "success_rate": 0,
                "average_execution_time": 0,
                "strategy_distribution": {},
                "recent_executions": []
            }
        
        total = len(self.execution_history)
        successful = sum(1 for h in self.execution_history if h.get("success", False))
        
        strategies = {}
        total_time = 0
        
        for history in self.execution_history:
            strategy = history.get("strategy", "unknown")
            strategies[strategy] = strategies.get(strategy, 0) + 1
            total_time += history.get("execution_time", 0)
        
        return {
            "total_executions": total,
            "success_rate": successful / total if total > 0 else 0,
            "average_execution_time": total_time / total if total > 0 else 0,
            "strategy_distribution": strategies,
            "recent_executions": self.execution_history[-5:]  # ìµœê·¼ 5ê°œ
        }
    
    def clear_execution_history(self):
        """ì‹¤í–‰ íˆìŠ¤í† ë¦¬ ì •ë¦¬"""
        self.execution_history.clear()
        logger.info("âœ… ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ì‹¤í–‰ íˆìŠ¤í† ë¦¬ ì •ë¦¬ ì™„ë£Œ")


# A2A SDK í†µí•©ì„ ìœ„í•œ Executor í´ë˜ìŠ¤
class MultiAgentA2AExecutor(AgentExecutor):
    """A2A SDK í˜¸í™˜ Multi-Agent Executor"""
    
    def __init__(self, orchestrator: MultiAgentOrchestrator):
        super().__init__()
        self.orchestrator = orchestrator
    
    async def execute(self, context: RequestContext, event_queue: EventQueue) -> None:
        """A2A í‘œì¤€ ì‹¤í–‰ ë©”ì„œë“œ"""
        updater = TaskUpdater(event_queue, context.task_id, context.context_id)
        
        try:
            await updater.submit()
            await updater.start_work()
            
            # ì‚¬ìš©ì ì…ë ¥ ì¶”ì¶œ
            user_input = self._extract_user_input(context)
            
            await updater.update_status(
                TaskState.working,
                message=new_agent_text_message("ğŸ¤– ë©€í‹° ì—ì´ì „íŠ¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ì‹œì‘...")
            )
            
            # ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ì‹¤í–‰
            result = await self.orchestrator.orchestrate_analysis(
                user_query=user_input,
                session_id=context.context_id
            )
            
            if result.success:
                # ì¸ì‚¬ì´íŠ¸ë¥¼ í…ìŠ¤íŠ¸ë¡œ ê²°í•©
                response_text = "\n".join(result.insights)
                if result.recommendations:
                    response_text += "\n\nê¶Œì¥ì‚¬í•­:\n" + "\n".join(f"- {rec}" for rec in result.recommendations)
                
                await updater.add_artifact(
                    [TextPart(text=response_text)],
                    name="orchestration_result"
                )
                await updater.complete()
            else:
                error_message = "ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
                if result.errors:
                    error_message += f"\nì˜¤ë¥˜: {'; '.join(result.errors)}"
                
                await updater.update_status(
                    TaskState.error,
                    message=new_agent_text_message(error_message)
                )
                
        except Exception as e:
            logger.error(f"âŒ A2A ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            await updater.update_status(
                TaskState.error,
                message=new_agent_text_message(f"ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}")
            )
    
    async def cancel(self, context: RequestContext, event_queue: EventQueue) -> None:
        """ì‘ì—… ì·¨ì†Œ"""
        logger.info("ğŸ›‘ Multi-Agent ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ì·¨ì†Œ")
    
    def _extract_user_input(self, context: RequestContext) -> str:
        """ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì‚¬ìš©ì ì…ë ¥ ì¶”ì¶œ"""
        try:
            if context.current_task and context.current_task.message and context.current_task.message.parts:
                for part in context.current_task.message.parts:
                    if hasattr(part, 'text') and part.text:
                        return part.text
            return "ë°ì´í„° ë¶„ì„ì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”"
        except Exception as e:
            logger.warning(f"âš ï¸ ì‚¬ìš©ì ì…ë ¥ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return "ë°ì´í„° ë¶„ì„ì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”"


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
_orchestrator_instance = None


def get_multi_agent_orchestrator(config: Optional[Dict] = None) -> MultiAgentOrchestrator:
    """Multi-Agent Orchestrator ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _orchestrator_instance
    if _orchestrator_instance is None:
        _orchestrator_instance = MultiAgentOrchestrator(config)
    return _orchestrator_instance


# A2A ì„œë²„ ì„¤ì • í•¨ìˆ˜
def create_multi_agent_card() -> Optional[AgentCard]:
    """Multi-Agent A2A ì¹´ë“œ ìƒì„±"""
    if not A2A_AVAILABLE:
        return None
    
    return AgentCard(
        name="Multi-Agent Data Analysis Orchestrator",
        description="ì§€ëŠ¥í˜• ë©€í‹° ì—ì´ì „íŠ¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ì„ í†µí•œ í¬ê´„ì  ë°ì´í„° ë¶„ì„",
        capabilities=AgentCapabilities(
            skills=[
                AgentSkill(
                    name="multi_agent_orchestration",
                    description="ì—¬ëŸ¬ ì „ë¬¸í™” ì—ì´ì „íŠ¸ë¥¼ ì¡°í•©í•œ ë³µí•© ë°ì´í„° ë¶„ì„"
                ),
                AgentSkill(
                    name="intelligent_routing",
                    description="LLM ê¸°ë°˜ ì§€ëŠ¥í˜• ì—ì´ì „íŠ¸ ë¼ìš°íŒ…"
                ),
                AgentSkill(
                    name="data_type_detection",
                    description="ìë™ ë°ì´í„° íƒ€ì… íƒì§€ ë° ë§ì¶¤ ë¶„ì„"
                ),
                AgentSkill(
                    name="comprehensive_analysis",
                    description="ì •í˜•/ì‹œê³„ì—´/í…ìŠ¤íŠ¸/ì´ë¯¸ì§€ ë°ì´í„° ì¢…í•© ë¶„ì„"
                )
            ]
        )
    )


def create_multi_agent_a2a_app() -> Optional[A2AStarletteApplication]:
    """Multi-Agent A2A ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒì„±"""
    if not A2A_AVAILABLE:
        return None
    
    orchestrator = get_multi_agent_orchestrator()
    executor = MultiAgentA2AExecutor(orchestrator)
    card = create_multi_agent_card()
    
    if card:
        return A2AStarletteApplication(
            task_store=InMemoryTaskStore(),
            request_handler=DefaultRequestHandler(card, executor)
        )
    return None


# CLI í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
async def test_multi_agent_orchestrator():
    """Multi-Agent Orchestrator í…ŒìŠ¤íŠ¸"""
    print("ğŸ”„ Multi-Agent Orchestrator í…ŒìŠ¤íŠ¸ ì‹œì‘\n")
    
    orchestrator = get_multi_agent_orchestrator()
    
    # í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ë“¤
    test_queries = [
        "ì•ˆë…•í•˜ì„¸ìš”?",
        "ë°ì´í„°ì˜ ê¸°ë³¸ í†µê³„ë¥¼ ë³´ì—¬ì£¼ì„¸ìš”",
        "ìƒê´€ê´€ê³„ë¥¼ ë¶„ì„í•˜ê³  ì‹œê°í™”í•´ì£¼ì„¸ìš”",
        "ë°ì´í„°ë¥¼ ì •ì œí•˜ê³  ì˜ˆì¸¡ ëª¨ë¸ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”"
    ]
    
    # ìƒ˜í”Œ ë°ì´í„°
    import pandas as pd
    sample_data = pd.DataFrame({
        'A': [1, 2, 3, 4, 5],
        'B': [2, 4, 6, 8, 10],
        'C': ['x', 'y', 'x', 'y', 'x']
    })
    
    for i, query in enumerate(test_queries):
        print(f"ğŸ“ í…ŒìŠ¤íŠ¸ {i+1}: {query}")
        
        result = await orchestrator.orchestrate_analysis(
            user_query=query,
            data=sample_data if "ë°ì´í„°" in query else None,
            session_id=f"test_session_{i}"
        )
        
        print(f"  âœ… ì„±ê³µ: {result.success}")
        print(f"  ğŸ” ì¸ì‚¬ì´íŠ¸: {len(result.insights)}ê°œ")
        print(f"  ğŸ’¡ ì¶”ì²œì‚¬í•­: {len(result.recommendations)}ê°œ")
        print(f"  â±ï¸ ì‹¤í–‰ì‹œê°„: {result.execution_time:.2f}ì´ˆ")
        print()
    
    # í†µê³„ ì¶œë ¥
    stats = orchestrator.get_orchestration_statistics()
    print("ğŸ“Š ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ í†µê³„:")
    print(f"  ì´ ì‹¤í–‰: {stats['total_executions']}")
    print(f"  ì„±ê³µë¥ : {stats['success_rate']:.2%}")
    print(f"  í‰ê·  ì‹œê°„: {stats['average_execution_time']:.2f}ì´ˆ")
    print(f"  ì „ëµ ë¶„í¬: {stats['strategy_distribution']}")
    
    print("\nâœ… Multi-Agent Orchestrator í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")


if __name__ == "__main__":
    asyncio.run(test_multi_agent_orchestrator()) 