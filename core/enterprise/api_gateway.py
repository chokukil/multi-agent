"""
Enterprise API Gateway
Phase 4.4: API ë° í†µí•©

í•µì‹¬ ê¸°ëŠ¥:
- RESTful API ê²Œì´íŠ¸ì›¨ì´
- GraphQL API ì§€ì›
- ì™¸ë¶€ ì‹œìŠ¤í…œ í†µí•© (BigQuery, Snowflake, Slack, Teams)
- ì¸ì¦ ë° ê¶Œí•œ ê´€ë¦¬
- ë ˆì´íŠ¸ ë¦¬ë¯¸íŒ… ë° ìŠ¤ë¡œí‹€ë§
- ì›¹í›… ë° ì´ë²¤íŠ¸ ì²˜ë¦¬
- API ë¬¸ì„œí™” ë° ëª¨ë‹ˆí„°ë§
"""

import asyncio
import json
import logging
import time
import hashlib
import hmac
import secrets
from datetime import datetime, timedelta
from dataclasses import dataclass, field
from typing import Dict, List, Any, Optional, Union, Callable, Tuple
from enum import Enum
import sqlite3
from pathlib import Path
import jwt
import httpx
import aioredis
from fastapi import FastAPI, HTTPException, Depends, Request, Response, BackgroundTasks
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from fastapi.middleware.cors import CORSMiddleware
from fastapi.middleware.trustedhost import TrustedHostMiddleware
from pydantic import BaseModel, Field
import strawberry
from strawberry.fastapi import GraphQLRouter
import uvicorn
from contextlib import asynccontextmanager

logger = logging.getLogger(__name__)

class APIMethod(Enum):
    """API ë©”ì†Œë“œ"""
    GET = "GET"
    POST = "POST"
    PUT = "PUT"
    DELETE = "DELETE"
    PATCH = "PATCH"

class IntegrationType(Enum):
    """í†µí•© ì‹œìŠ¤í…œ ìœ í˜•"""
    DATABASE = "database"
    MESSAGING = "messaging"
    STORAGE = "storage"
    ANALYTICS = "analytics"
    COLLABORATION = "collaboration"
    MONITORING = "monitoring"

class WebhookEventType(Enum):
    """ì›¹í›… ì´ë²¤íŠ¸ ìœ í˜•"""
    ANALYSIS_COMPLETED = "analysis_completed"
    INSIGHT_GENERATED = "insight_generated"
    ANOMALY_DETECTED = "anomaly_detected"
    SYSTEM_ALERT = "system_alert"
    USER_ACTION = "user_action"

# Pydantic Models
class APIKeyRequest(BaseModel):
    name: str
    description: Optional[str] = None
    permissions: List[str] = Field(default_factory=list)
    expires_at: Optional[datetime] = None

class AnalysisRequest(BaseModel):
    dataset_name: str
    data: Union[Dict[str, Any], List[Dict[str, Any]]]
    analysis_type: str = "comprehensive"
    save_results: bool = True
    webhook_url: Optional[str] = None

class IntegrationConfig(BaseModel):
    integration_id: str
    integration_type: IntegrationType
    name: str
    config: Dict[str, Any]
    is_active: bool = True

class WebhookConfig(BaseModel):
    webhook_id: str
    url: str
    events: List[WebhookEventType]
    secret: Optional[str] = None
    is_active: bool = True

# Strawberry GraphQL Types
@strawberry.type
class InsightType:
    insight_id: str
    title: str
    description: str
    severity: str
    confidence_score: float
    created_at: str

@strawberry.type
class AnalysisResult:
    analysis_id: str
    status: str
    patterns_count: int
    anomalies_count: int
    insights_count: int
    execution_time_ms: float
    created_at: str

@dataclass
class RateLimitRule:
    """ë ˆì´íŠ¸ ë¦¬ë¯¸íŒ… ê·œì¹™"""
    endpoint: str
    max_requests: int
    time_window_seconds: int
    per_api_key: bool = True

@dataclass
class APIKey:
    """API í‚¤ ì •ë³´"""
    key_id: str
    api_key: str
    name: str
    permissions: List[str]
    created_at: datetime
    expires_at: Optional[datetime]
    is_active: bool = True
    last_used: Optional[datetime] = None
    usage_count: int = 0

class AuthenticationManager:
    """ì¸ì¦ ê´€ë¦¬"""
    
    def __init__(self, secret_key: str):
        self.secret_key = secret_key
        self.db_path = "core/enterprise/api_keys.db"
        self._initialize_database()
    
    def _initialize_database(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
        Path(self.db_path).parent.mkdir(parents=True, exist_ok=True)
        
        with sqlite3.connect(self.db_path) as conn:
            conn.execute("""
                CREATE TABLE IF NOT EXISTS api_keys (
                    key_id TEXT PRIMARY KEY,
                    api_key TEXT UNIQUE NOT NULL,
                    name TEXT NOT NULL,
                    permissions TEXT NOT NULL,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    expires_at TIMESTAMP,
                    is_active BOOLEAN DEFAULT TRUE,
                    last_used TIMESTAMP,
                    usage_count INTEGER DEFAULT 0
                )
            """)
    
    def generate_api_key(self, request: APIKeyRequest) -> APIKey:
        """API í‚¤ ìƒì„±"""
        key_id = secrets.token_urlsafe(16)
        api_key = f"cherry_{secrets.token_urlsafe(32)}"
        
        api_key_obj = APIKey(
            key_id=key_id,
            api_key=api_key,
            name=request.name,
            permissions=request.permissions,
            created_at=datetime.now(),
            expires_at=request.expires_at
        )
        
        # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
        with sqlite3.connect(self.db_path) as conn:
            conn.execute("""
                INSERT INTO api_keys 
                (key_id, api_key, name, permissions, created_at, expires_at, is_active)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            """, (
                api_key_obj.key_id,
                api_key_obj.api_key,
                api_key_obj.name,
                json.dumps(api_key_obj.permissions),
                api_key_obj.created_at.isoformat(),
                api_key_obj.expires_at.isoformat() if api_key_obj.expires_at else None,
                api_key_obj.is_active
            ))
        
        return api_key_obj
    
    def validate_api_key(self, api_key: str) -> Optional[APIKey]:
        """API í‚¤ ê²€ì¦"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.execute("""
                    SELECT * FROM api_keys 
                    WHERE api_key = ? AND is_active = TRUE
                """, (api_key,))
                
                row = cursor.fetchone()
                if not row:
                    return None
                
                api_key_obj = APIKey(
                    key_id=row[0],
                    api_key=row[1],
                    name=row[2],
                    permissions=json.loads(row[3]),
                    created_at=datetime.fromisoformat(row[4]),
                    expires_at=datetime.fromisoformat(row[5]) if row[5] else None,
                    is_active=bool(row[6]),
                    last_used=datetime.fromisoformat(row[7]) if row[7] else None,
                    usage_count=row[8]
                )
                
                # ë§Œë£Œ í™•ì¸
                if api_key_obj.expires_at and api_key_obj.expires_at < datetime.now():
                    return None
                
                # ì‚¬ìš© ê¸°ë¡ ì—…ë°ì´íŠ¸
                self._update_usage(api_key_obj.key_id)
                
                return api_key_obj
                
        except Exception as e:
            logger.error(f"API í‚¤ ê²€ì¦ ì‹¤íŒ¨: {e}")
            return None
    
    def _update_usage(self, key_id: str):
        """API í‚¤ ì‚¬ìš© ê¸°ë¡ ì—…ë°ì´íŠ¸"""
        with sqlite3.connect(self.db_path) as conn:
            conn.execute("""
                UPDATE api_keys 
                SET last_used = ?, usage_count = usage_count + 1
                WHERE key_id = ?
            """, (datetime.now().isoformat(), key_id))

class RateLimiter:
    """ë ˆì´íŠ¸ ë¦¬ë¯¸í„°"""
    
    def __init__(self):
        self.redis_client = None
        self.memory_cache = {}  # Redis ì—†ì„ ë•Œ í´ë°±
        self.rules = [
            RateLimitRule("/api/v1/analyze", 100, 3600),  # ì‹œê°„ë‹¹ 100íšŒ
            RateLimitRule("/api/v1/insights", 200, 3600),  # ì‹œê°„ë‹¹ 200íšŒ
            RateLimitRule("/graphql", 500, 3600),  # ì‹œê°„ë‹¹ 500íšŒ
        ]
    
    async def initialize(self):
        """Redis ì—°ê²° ì´ˆê¸°í™”"""
        try:
            self.redis_client = await aioredis.from_url("redis://localhost:6379", decode_responses=True)
            await self.redis_client.ping()
            logger.info("Redis ì—°ê²° ì„±ê³µ")
        except Exception as e:
            logger.warning(f"Redis ì—°ê²° ì‹¤íŒ¨, ë©”ëª¨ë¦¬ ìºì‹œ ì‚¬ìš©: {e}")
            self.redis_client = None
    
    async def check_rate_limit(self, endpoint: str, api_key: str) -> Tuple[bool, Dict[str, Any]]:
        """ë ˆì´íŠ¸ ë¦¬ë¯¸íŠ¸ í™•ì¸"""
        rule = self._find_rule(endpoint)
        if not rule:
            return True, {}
        
        key = f"rate_limit:{api_key}:{endpoint}"
        current_time = int(time.time())
        window_start = current_time - rule.time_window_seconds
        
        if self.redis_client:
            return await self._check_redis_rate_limit(key, rule, current_time, window_start)
        else:
            return self._check_memory_rate_limit(key, rule, current_time, window_start)
    
    def _find_rule(self, endpoint: str) -> Optional[RateLimitRule]:
        """ì—”ë“œí¬ì¸íŠ¸ì— í•´ë‹¹í•˜ëŠ” ê·œì¹™ ì°¾ê¸°"""
        for rule in self.rules:
            if endpoint.startswith(rule.endpoint):
                return rule
        return None
    
    async def _check_redis_rate_limit(self, key: str, rule: RateLimitRule, 
                                    current_time: int, window_start: int) -> Tuple[bool, Dict[str, Any]]:
        """Redis ê¸°ë°˜ ë ˆì´íŠ¸ ë¦¬ë¯¸íŠ¸ í™•ì¸"""
        pipe = self.redis_client.pipeline()
        pipe.zremrangebyscore(key, 0, window_start)
        pipe.zcard(key)
        pipe.zadd(key, {current_time: current_time})
        pipe.expire(key, rule.time_window_seconds)
        
        results = await pipe.execute()
        current_requests = results[1]
        
        if current_requests >= rule.max_requests:
            return False, {
                "current_requests": current_requests,
                "max_requests": rule.max_requests,
                "time_window": rule.time_window_seconds,
                "reset_time": current_time + rule.time_window_seconds
            }
        
        return True, {
            "current_requests": current_requests + 1,
            "max_requests": rule.max_requests,
            "remaining_requests": rule.max_requests - current_requests - 1
        }
    
    def _check_memory_rate_limit(self, key: str, rule: RateLimitRule, 
                                current_time: int, window_start: int) -> Tuple[bool, Dict[str, Any]]:
        """ë©”ëª¨ë¦¬ ê¸°ë°˜ ë ˆì´íŠ¸ ë¦¬ë¯¸íŠ¸ í™•ì¸"""
        if key not in self.memory_cache:
            self.memory_cache[key] = []
        
        # ì˜¤ë˜ëœ ìš”ì²­ ì œê±°
        self.memory_cache[key] = [t for t in self.memory_cache[key] if t > window_start]
        
        current_requests = len(self.memory_cache[key])
        
        if current_requests >= rule.max_requests:
            return False, {
                "current_requests": current_requests,
                "max_requests": rule.max_requests,
                "time_window": rule.time_window_seconds
            }
        
        self.memory_cache[key].append(current_time)
        
        return True, {
            "current_requests": current_requests + 1,
            "max_requests": rule.max_requests,
            "remaining_requests": rule.max_requests - current_requests - 1
        }

class ExternalIntegrations:
    """ì™¸ë¶€ ì‹œìŠ¤í…œ í†µí•©"""
    
    def __init__(self):
        self.integrations = {}
        self.db_path = "core/enterprise/integrations.db"
        self._initialize_database()
    
    def _initialize_database(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
        Path(self.db_path).parent.mkdir(parents=True, exist_ok=True)
        
        with sqlite3.connect(self.db_path) as conn:
            conn.execute("""
                CREATE TABLE IF NOT EXISTS integrations (
                    integration_id TEXT PRIMARY KEY,
                    integration_type TEXT NOT NULL,
                    name TEXT NOT NULL,
                    config TEXT NOT NULL,
                    is_active BOOLEAN DEFAULT TRUE,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    last_used TIMESTAMP
                )
            """)
    
    async def add_integration(self, config: IntegrationConfig) -> bool:
        """í†µí•© ì¶”ê°€"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.execute("""
                    INSERT OR REPLACE INTO integrations 
                    (integration_id, integration_type, name, config, is_active)
                    VALUES (?, ?, ?, ?, ?)
                """, (
                    config.integration_id,
                    config.integration_type.value,
                    config.name,
                    json.dumps(config.config),
                    config.is_active
                ))
            
            logger.info(f"í†µí•© ì¶”ê°€ë¨: {config.name}")
            return True
        except Exception as e:
            logger.error(f"í†µí•© ì¶”ê°€ ì‹¤íŒ¨: {e}")
            return False
    
    async def send_slack_notification(self, webhook_url: str, message: str, title: str = "CherryAI Alert") -> bool:
        """Slack ì•Œë¦¼ ì „ì†¡"""
        try:
            payload = {
                "text": title,
                "attachments": [
                    {
                        "color": "good",
                        "text": message,
                        "ts": int(time.time())
                    }
                ]
            }
            
            async with httpx.AsyncClient() as client:
                response = await client.post(webhook_url, json=payload)
                return response.status_code == 200
                
        except Exception as e:
            logger.error(f"Slack ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨: {e}")
            return False
    
    async def send_teams_notification(self, webhook_url: str, message: str, title: str = "CherryAI Alert") -> bool:
        """Teams ì•Œë¦¼ ì „ì†¡"""
        try:
            payload = {
                "@type": "MessageCard",
                "@context": "https://schema.org/extensions",
                "summary": title,
                "themeColor": "0078D4",
                "title": title,
                "text": message
            }
            
            async with httpx.AsyncClient() as client:
                response = await client.post(webhook_url, json=payload)
                return response.status_code == 200
                
        except Exception as e:
            logger.error(f"Teams ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨: {e}")
            return False
    
    async def query_bigquery(self, project_id: str, query: str, credentials_path: str) -> Optional[List[Dict[str, Any]]]:
        """BigQuery ì¿¼ë¦¬ ì‹¤í–‰"""
        try:
            # BigQuery í´ë¼ì´ì–¸íŠ¸ êµ¬í˜„ (ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” google-cloud-bigquery ì‚¬ìš©)
            logger.info(f"BigQuery ì¿¼ë¦¬ ì‹¤í–‰: {project_id}")
            
            # ëª¨ì˜ ê²°ê³¼ ë°˜í™˜
            return [
                {"column1": "value1", "column2": 123},
                {"column1": "value2", "column2": 456}
            ]
            
        except Exception as e:
            logger.error(f"BigQuery ì¿¼ë¦¬ ì‹¤íŒ¨: {e}")
            return None
    
    async def connect_snowflake(self, account: str, user: str, password: str, warehouse: str) -> bool:
        """Snowflake ì—°ê²°"""
        try:
            # Snowflake ì—°ê²° êµ¬í˜„ (ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” snowflake-connector-python ì‚¬ìš©)
            logger.info(f"Snowflake ì—°ê²°: {account}")
            return True
            
        except Exception as e:
            logger.error(f"Snowflake ì—°ê²° ì‹¤íŒ¨: {e}")
            return False

class WebhookManager:
    """ì›¹í›… ê´€ë¦¬"""
    
    def __init__(self):
        self.webhooks = {}
        self.db_path = "core/enterprise/webhooks.db"
        self._initialize_database()
    
    def _initialize_database(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
        Path(self.db_path).parent.mkdir(parents=True, exist_ok=True)
        
        with sqlite3.connect(self.db_path) as conn:
            conn.execute("""
                CREATE TABLE IF NOT EXISTS webhooks (
                    webhook_id TEXT PRIMARY KEY,
                    url TEXT NOT NULL,
                    events TEXT NOT NULL,
                    secret TEXT,
                    is_active BOOLEAN DEFAULT TRUE,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    last_triggered TIMESTAMP
                )
            """)
    
    async def register_webhook(self, config: WebhookConfig) -> bool:
        """ì›¹í›… ë“±ë¡"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.execute("""
                    INSERT OR REPLACE INTO webhooks 
                    (webhook_id, url, events, secret, is_active)
                    VALUES (?, ?, ?, ?, ?)
                """, (
                    config.webhook_id,
                    config.url,
                    json.dumps([event.value for event in config.events]),
                    config.secret,
                    config.is_active
                ))
            
            logger.info(f"ì›¹í›… ë“±ë¡ë¨: {config.webhook_id}")
            return True
        except Exception as e:
            logger.error(f"ì›¹í›… ë“±ë¡ ì‹¤íŒ¨: {e}")
            return False
    
    async def trigger_webhook(self, event_type: WebhookEventType, data: Dict[str, Any]) -> bool:
        """ì›¹í›… íŠ¸ë¦¬ê±°"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.execute("""
                    SELECT webhook_id, url, events, secret FROM webhooks 
                    WHERE is_active = TRUE
                """)
                
                for row in cursor.fetchall():
                    webhook_id, url, events_json, secret = row
                    events = json.loads(events_json)
                    
                    if event_type.value in events:
                        await self._send_webhook(webhook_id, url, secret, event_type, data)
            
            return True
        except Exception as e:
            logger.error(f"ì›¹í›… íŠ¸ë¦¬ê±° ì‹¤íŒ¨: {e}")
            return False
    
    async def _send_webhook(self, webhook_id: str, url: str, secret: Optional[str], 
                          event_type: WebhookEventType, data: Dict[str, Any]):
        """ì›¹í›… ì „ì†¡"""
        try:
            payload = {
                "event_type": event_type.value,
                "timestamp": datetime.now().isoformat(),
                "data": data
            }
            
            headers = {"Content-Type": "application/json"}
            
            # HMAC ì„œëª… ì¶”ê°€
            if secret:
                signature = hmac.new(
                    secret.encode(),
                    json.dumps(payload).encode(),
                    hashlib.sha256
                ).hexdigest()
                headers["X-Cherry-Signature"] = f"sha256={signature}"
            
            async with httpx.AsyncClient() as client:
                response = await client.post(url, json=payload, headers=headers, timeout=30.0)
                
                if response.status_code == 200:
                    logger.info(f"ì›¹í›… ì „ì†¡ ì„±ê³µ: {webhook_id}")
                    
                    # ì „ì†¡ ê¸°ë¡ ì—…ë°ì´íŠ¸
                    with sqlite3.connect(self.db_path) as conn:
                        conn.execute("""
                            UPDATE webhooks 
                            SET last_triggered = ? 
                            WHERE webhook_id = ?
                        """, (datetime.now().isoformat(), webhook_id))
                else:
                    logger.warning(f"ì›¹í›… ì „ì†¡ ì‹¤íŒ¨: {webhook_id}, ìƒíƒœ ì½”ë“œ: {response.status_code}")
                    
        except Exception as e:
            logger.error(f"ì›¹í›… ì „ì†¡ ì˜¤ë¥˜: {webhook_id}, {e}")

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ë“¤
auth_manager = AuthenticationManager(secret_key="cherry_ai_secret_key_change_in_production")
rate_limiter = RateLimiter()
integrations = ExternalIntegrations()
webhook_manager = WebhookManager()

# FastAPI ì•± ì´ˆê¸°í™”
@asynccontextmanager
async def lifespan(app: FastAPI):
    """ì•± ë¼ì´í”„ì‚¬ì´í´ ê´€ë¦¬"""
    # ì‹œì‘ ì‹œ ì´ˆê¸°í™”
    await rate_limiter.initialize()
    yield
    # ì¢…ë£Œ ì‹œ ì •ë¦¬ (í•„ìš”ì‹œ)

app = FastAPI(
    title="CherryAI Enterprise API Gateway",
    description="Enterprise-grade API for AI-powered data analysis",
    version="1.0.0",
    lifespan=lifespan
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” íŠ¹ì • ë„ë©”ì¸ìœ¼ë¡œ ì œí•œ
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ë³´ì•ˆ í—¤ë”
app.add_middleware(
    TrustedHostMiddleware,
    allowed_hosts=["*"]  # ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” íŠ¹ì • í˜¸ìŠ¤íŠ¸ë¡œ ì œí•œ
)

# ì¸ì¦ ì˜ì¡´ì„±
security = HTTPBearer()

async def get_current_api_key(credentials: HTTPAuthorizationCredentials = Depends(security)) -> APIKey:
    """í˜„ì¬ API í‚¤ ê²€ì¦"""
    api_key = auth_manager.validate_api_key(credentials.credentials)
    if not api_key:
        raise HTTPException(status_code=401, detail="Invalid API key")
    return api_key

async def check_rate_limit_dependency(request: Request, api_key: APIKey = Depends(get_current_api_key)):
    """ë ˆì´íŠ¸ ë¦¬ë¯¸íŠ¸ í™•ì¸ ì˜ì¡´ì„±"""
    allowed, info = await rate_limiter.check_rate_limit(request.url.path, api_key.key_id)
    
    if not allowed:
        raise HTTPException(
            status_code=429,
            detail="Rate limit exceeded",
            headers={"X-RateLimit-Reset": str(info.get("reset_time", 0))}
        )
    
    # ì‘ë‹µ í—¤ë”ì— ë ˆì´íŠ¸ ë¦¬ë¯¸íŠ¸ ì •ë³´ ì¶”ê°€
    return info

# REST API ì—”ë“œí¬ì¸íŠ¸ë“¤

@app.post("/api/v1/auth/keys")
async def create_api_key(request: APIKeyRequest):
    """API í‚¤ ìƒì„±"""
    try:
        api_key = auth_manager.generate_api_key(request)
        return {
            "status": "success",
            "key_id": api_key.key_id,
            "api_key": api_key.api_key,
            "name": api_key.name,
            "permissions": api_key.permissions,
            "expires_at": api_key.expires_at.isoformat() if api_key.expires_at else None
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/v1/analyze")
async def analyze_data(
    request: AnalysisRequest,
    background_tasks: BackgroundTasks,
    api_key: APIKey = Depends(get_current_api_key),
    rate_info: Dict = Depends(check_rate_limit_dependency)
):
    """ë°ì´í„° ë¶„ì„ API"""
    try:
        # AI Insight Engine í†µí•©
        from .ai_insight_engine import get_ai_insight_engine
        import pandas as pd
        
        # ë°ì´í„° ë³€í™˜
        if isinstance(request.data, list):
            df = pd.DataFrame(request.data)
        else:
            df = pd.DataFrame([request.data])
        
        # ë¶„ì„ ì‹¤í–‰
        engine = get_ai_insight_engine()
        result = await engine.analyze_data(df, save_results=request.save_results)
        
        # ì›¹í›… íŠ¸ë¦¬ê±° (ë°±ê·¸ë¼ìš´ë“œ)
        if request.webhook_url:
            background_tasks.add_task(
                webhook_manager.trigger_webhook,
                WebhookEventType.ANALYSIS_COMPLETED,
                {"analysis_result": result, "webhook_url": request.webhook_url}
            )
        
        return {
            "status": "success",
            "analysis_id": f"analysis_{int(time.time())}",
            "dataset_name": request.dataset_name,
            "result": result,
            "rate_limit": rate_info
        }
        
    except Exception as e:
        logger.error(f"ë¶„ì„ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/v1/insights")
async def get_insights(
    limit: int = 10,
    api_key: APIKey = Depends(get_current_api_key),
    rate_info: Dict = Depends(check_rate_limit_dependency)
):
    """ì¸ì‚¬ì´íŠ¸ ì¡°íšŒ API"""
    try:
        from .ai_insight_engine import get_ai_insight_engine
        
        engine = get_ai_insight_engine()
        dashboard = engine.get_insight_dashboard()
        
        return {
            "status": "success",
            "dashboard": dashboard,
            "rate_limit": rate_info
        }
        
    except Exception as e:
        logger.error(f"ì¸ì‚¬ì´íŠ¸ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/v1/integrations")
async def add_integration(
    config: IntegrationConfig,
    api_key: APIKey = Depends(get_current_api_key)
):
    """ì™¸ë¶€ ì‹œìŠ¤í…œ í†µí•© ì¶”ê°€"""
    if "admin" not in api_key.permissions:
        raise HTTPException(status_code=403, detail="Admin permission required")
    
    success = await integrations.add_integration(config)
    if success:
        return {"status": "success", "integration_id": config.integration_id}
    else:
        raise HTTPException(status_code=500, detail="Failed to add integration")

@app.post("/api/v1/webhooks")
async def register_webhook(
    config: WebhookConfig,
    api_key: APIKey = Depends(get_current_api_key)
):
    """ì›¹í›… ë“±ë¡"""
    if "admin" not in api_key.permissions:
        raise HTTPException(status_code=403, detail="Admin permission required")
    
    success = await webhook_manager.register_webhook(config)
    if success:
        return {"status": "success", "webhook_id": config.webhook_id}
    else:
        raise HTTPException(status_code=500, detail="Failed to register webhook")

@app.post("/api/v1/notifications/slack")
async def send_slack_notification(
    webhook_url: str,
    message: str,
    title: str = "CherryAI Notification",
    api_key: APIKey = Depends(get_current_api_key)
):
    """Slack ì•Œë¦¼ ì „ì†¡"""
    success = await integrations.send_slack_notification(webhook_url, message, title)
    if success:
        return {"status": "success", "message": "Slack notification sent"}
    else:
        raise HTTPException(status_code=500, detail="Failed to send Slack notification")

@app.post("/api/v1/notifications/teams")
async def send_teams_notification(
    webhook_url: str,
    message: str,
    title: str = "CherryAI Notification",
    api_key: APIKey = Depends(get_current_api_key)
):
    """Teams ì•Œë¦¼ ì „ì†¡"""
    success = await integrations.send_teams_notification(webhook_url, message, title)
    if success:
        return {"status": "success", "message": "Teams notification sent"}
    else:
        raise HTTPException(status_code=500, detail="Failed to send Teams notification")

# GraphQL ìŠ¤í‚¤ë§ˆ ì •ì˜
@strawberry.type
class Query:
    @strawberry.field
    async def insights(self, limit: int = 10) -> List[InsightType]:
        """ì¸ì‚¬ì´íŠ¸ GraphQL ì¿¼ë¦¬"""
        try:
            from .ai_insight_engine import get_ai_insight_engine
            
            engine = get_ai_insight_engine()
            insights = engine.database.get_insights(limit)
            
            return [
                InsightType(
                    insight_id=insight.insight_id,
                    title=insight.title,
                    description=insight.description,
                    severity=insight.severity.value,
                    confidence_score=insight.confidence_score,
                    created_at=insight.created_at.isoformat()
                )
                for insight in insights
            ]
        except Exception as e:
            logger.error(f"GraphQL ì¸ì‚¬ì´íŠ¸ ì¿¼ë¦¬ ì‹¤íŒ¨: {e}")
            return []
    
    @strawberry.field
    async def analysis_results(self, limit: int = 10) -> List[AnalysisResult]:
        """ë¶„ì„ ê²°ê³¼ GraphQL ì¿¼ë¦¬"""
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë¶„ì„ ê²°ê³¼ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì¡°íšŒ
        return [
            AnalysisResult(
                analysis_id="sample_analysis_1",
                status="completed",
                patterns_count=5,
                anomalies_count=3,
                insights_count=7,
                execution_time_ms=450.0,
                created_at=datetime.now().isoformat()
            )
        ]

@strawberry.type
class Mutation:
    @strawberry.mutation
    async def trigger_analysis(self, dataset_name: str, data: str) -> str:
        """ë¶„ì„ íŠ¸ë¦¬ê±° GraphQL ë®¤í…Œì´ì…˜"""
        try:
            # ì‹¤ì œ ë¶„ì„ ë¡œì§ í˜¸ì¶œ
            return f"Analysis triggered for {dataset_name}"
        except Exception as e:
            logger.error(f"GraphQL ë¶„ì„ íŠ¸ë¦¬ê±° ì‹¤íŒ¨: {e}")
            return f"Error: {str(e)}"

# GraphQL ìŠ¤í‚¤ë§ˆ ìƒì„±
schema = strawberry.Schema(query=Query, mutation=Mutation)

# GraphQL ë¼ìš°í„° ì¶”ê°€
graphql_app = GraphQLRouter(schema)
app.include_router(graphql_app, prefix="/graphql")

# í—¬ìŠ¤ ì²´í¬ ì—”ë“œí¬ì¸íŠ¸
@app.get("/health")
async def health_check():
    """í—¬ìŠ¤ ì²´í¬"""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "version": "1.0.0"
    }

# API ë¬¸ì„œí™” ì •ë³´
@app.get("/api/v1/info")
async def api_info():
    """API ì •ë³´"""
    return {
        "name": "CherryAI Enterprise API Gateway",
        "version": "1.0.0",
        "description": "Enterprise-grade API for AI-powered data analysis",
        "endpoints": {
            "auth": "/api/v1/auth/keys",
            "analyze": "/api/v1/analyze",
            "insights": "/api/v1/insights",
            "integrations": "/api/v1/integrations",
            "webhooks": "/api/v1/webhooks",
            "graphql": "/graphql"
        },
        "features": [
            "RESTful APIs",
            "GraphQL support", 
            "Rate limiting",
            "Authentication & Authorization",
            "External integrations",
            "Webhook support",
            "Real-time notifications"
        ]
    }

def run_api_gateway(host: str = "0.0.0.0", port: int = 8080):
    """API ê²Œì´íŠ¸ì›¨ì´ ì‹¤í–‰"""
    uvicorn.run(app, host=host, port=port)

async def test_api_gateway():
    """API ê²Œì´íŠ¸ì›¨ì´ í…ŒìŠ¤íŠ¸"""
    print("ğŸ§ª Enterprise API Gateway í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    try:
        # API í‚¤ ìƒì„± í…ŒìŠ¤íŠ¸
        api_key_request = APIKeyRequest(
            name="Test API Key",
            description="í…ŒìŠ¤íŠ¸ìš© API í‚¤",
            permissions=["read", "write", "admin"]
        )
        
        api_key = auth_manager.generate_api_key(api_key_request)
        print(f"âœ… API í‚¤ ìƒì„±: {api_key.key_id}")
        
        # API í‚¤ ê²€ì¦ í…ŒìŠ¤íŠ¸
        validated_key = auth_manager.validate_api_key(api_key.api_key)
        print(f"âœ… API í‚¤ ê²€ì¦: {validated_key.name}")
        
        # ë ˆì´íŠ¸ ë¦¬ë¯¸í„° í…ŒìŠ¤íŠ¸
        await rate_limiter.initialize()
        allowed, info = await rate_limiter.check_rate_limit("/api/v1/analyze", api_key.key_id)
        print(f"âœ… ë ˆì´íŠ¸ ë¦¬ë¯¸íŠ¸ ì²´í¬: í—ˆìš©={allowed}, ì •ë³´={info}")
        
        # í†µí•© í…ŒìŠ¤íŠ¸
        integration_config = IntegrationConfig(
            integration_id="test_slack",
            integration_type=IntegrationType.COLLABORATION,
            name="Test Slack Integration",
            config={"webhook_url": "https://hooks.slack.com/test"}
        )
        
        success = await integrations.add_integration(integration_config)
        print(f"âœ… í†µí•© ì¶”ê°€: {success}")
        
        # ì›¹í›… í…ŒìŠ¤íŠ¸
        webhook_config = WebhookConfig(
            webhook_id="test_webhook",
            url="https://example.com/webhook",
            events=[WebhookEventType.ANALYSIS_COMPLETED]
        )
        
        success = await webhook_manager.register_webhook(webhook_config)
        print(f"âœ… ì›¹í›… ë“±ë¡: {success}")
        
        print("âœ… Enterprise API Gateway í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        return True
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="CherryAI Enterprise API Gateway")
    parser.add_argument("--test", action="store_true", help="Run tests")
    parser.add_argument("--host", default="0.0.0.0", help="Host to bind to")
    parser.add_argument("--port", type=int, default=8080, help="Port to bind to")
    
    args = parser.parse_args()
    
    if args.test:
        asyncio.run(test_api_gateway())
    else:
        print(f"ğŸš€ Starting CherryAI Enterprise API Gateway on {args.host}:{args.port}")
        run_api_gateway(args.host, args.port) 