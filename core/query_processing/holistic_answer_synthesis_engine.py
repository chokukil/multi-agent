"""
Holistic Answer Synthesis Engine

ì´ ëª¨ë“ˆì€ Phase 1ê³¼ Phase 2ì˜ ëª¨ë“  ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ 
ì „ì²´ë¡ ì ì´ê³  ì™„ì „í•œ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” í•µì‹¬ ì—”ì§„ìž…ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
- ë‹¤ì¤‘ ì†ŒìŠ¤ ì •ë³´ í†µí•© ë° í•©ì„±
- ë„ë©”ì¸ë³„ ì „ë¬¸ê°€ ìˆ˜ì¤€ ë‹µë³€ ìƒì„±
- êµ¬ì¡°í™”ëœ ë‹µë³€ í¬ë§· ì œê³µ
- ì‚¬ìš©ìž ì˜ë„ì— ë§žëŠ” ë‹µë³€ ìŠ¤íƒ€ì¼ ì ì‘
- í’ˆì§ˆ ë³´ìž¥ ë° ì¼ê´€ì„± ê²€ì¦
"""

import asyncio
import json
import logging
from typing import Dict, List, Optional, Any, Union
from dataclasses import dataclass, field
from enum import Enum
from datetime import datetime
import time

from core.llm_factory import create_llm_instance

# Phase 1 imports
from .intelligent_query_processor import EnhancedQuery
from .domain_extractor import EnhancedDomainKnowledge
from .answer_predictor import AnswerTemplate

# Phase 2 imports
from .domain_aware_agent_selector import AgentSelectionResult
from .a2a_agent_execution_orchestrator import ExecutionResult
from .multi_agent_result_integration import IntegrationResult
from .execution_plan_manager import ManagedExecutionPlan

logger = logging.getLogger(__name__)


class AnswerStyle(Enum):
    """ë‹µë³€ ìŠ¤íƒ€ì¼"""
    TECHNICAL = "technical"          # ê¸°ìˆ ì  ìƒì„¸ ë‹µë³€
    BUSINESS = "business"            # ë¹„ì¦ˆë‹ˆìŠ¤ ì¤‘ì‹¬ ë‹µë³€
    EXECUTIVE = "executive"          # ìž„ì›ê¸‰ ìš”ì•½ ë‹µë³€
    OPERATIONAL = "operational"      # ìš´ì˜ ì‹¤í–‰ ì¤‘ì‹¬ ë‹µë³€
    EDUCATIONAL = "educational"      # êµìœ¡ì  ì„¤ëª… ë‹µë³€
    COMPREHENSIVE = "comprehensive"  # ì¢…í•©ì  ìƒì„¸ ë‹µë³€


class AnswerPriority(Enum):
    """ë‹µë³€ ìš°ì„ ìˆœìœ„"""
    INSIGHTS = "insights"           # ì¸ì‚¬ì´íŠ¸ ì¤‘ì‹¬
    ACTIONS = "actions"            # ì‹¤í–‰ ë°©ì•ˆ ì¤‘ì‹¬
    ANALYSIS = "analysis"          # ë¶„ì„ ê²°ê³¼ ì¤‘ì‹¬
    RECOMMENDATIONS = "recommendations"  # ê¶Œê³ ì‚¬í•­ ì¤‘ì‹¬
    SOLUTIONS = "solutions"        # í•´ê²°ì±… ì¤‘ì‹¬


class SynthesisStrategy(Enum):
    """í•©ì„± ì „ëžµ"""
    LAYERED = "layered"            # ê³„ì¸µì  í•©ì„±
    INTEGRATED = "integrated"      # í†µí•©ì  í•©ì„±
    NARRATIVE = "narrative"        # ì„œì‚¬ì  í•©ì„±
    ANALYTICAL = "analytical"      # ë¶„ì„ì  í•©ì„±


@dataclass
class AnswerSection:
    """ë‹µë³€ ì„¹ì…˜"""
    title: str
    content: str
    priority: int
    section_type: str
    confidence: float
    sources: List[str] = field(default_factory=list)
    metadata: Dict[str, Any] = field(default_factory=dict)


@dataclass
class SynthesisContext:
    """í•©ì„± ì»¨í…ìŠ¤íŠ¸"""
    user_intent: str
    domain_context: str
    urgency_level: str
    target_audience: str
    answer_style: AnswerStyle
    answer_priority: AnswerPriority
    synthesis_strategy: SynthesisStrategy
    quality_requirements: Dict[str, float] = field(default_factory=dict)
    constraints: List[str] = field(default_factory=list)


@dataclass
class HolisticAnswer:
    """ì „ì²´ë¡ ì  ë‹µë³€"""
    answer_id: str
    query_summary: str
    executive_summary: str
    main_sections: List[AnswerSection]
    key_insights: List[str]
    recommendations: List[str]
    next_steps: List[str]
    confidence_score: float
    quality_metrics: Dict[str, float]
    synthesis_metadata: Dict[str, Any]
    generated_at: datetime
    synthesis_time: float


class HolisticAnswerSynthesisEngine:
    """ì „ì²´ë¡ ì  ë‹µë³€ í•©ì„± ì—”ì§„"""
    
    def __init__(self):
        self.llm = create_llm_instance()
        self.synthesis_history: List[HolisticAnswer] = []
        
        # ê¸°ë³¸ ì„¤ì •
        self.default_style = AnswerStyle.COMPREHENSIVE
        self.default_priority = AnswerPriority.INSIGHTS
        self.default_strategy = SynthesisStrategy.INTEGRATED
        
        logger.info("HolisticAnswerSynthesisEngine initialized")
    
    async def synthesize_holistic_answer(
        self,
        # Phase 1 ê²°ê³¼ë“¤
        enhanced_query: EnhancedQuery,
        domain_knowledge: EnhancedDomainKnowledge,
        answer_template: AnswerTemplate,
        
        # Phase 2 ê²°ê³¼ë“¤
        agent_selection_result: AgentSelectionResult,
        execution_result: ExecutionResult,
        integration_result: IntegrationResult,
        managed_plan: Optional[ManagedExecutionPlan] = None,
        
        # í•©ì„± ì„¤ì •
        synthesis_context: Optional[SynthesisContext] = None
    ) -> HolisticAnswer:
        """
        ì „ì²´ë¡ ì  ë‹µë³€ í•©ì„±
        
        Args:
            enhanced_query: Phase 1 í–¥ìƒëœ ì¿¼ë¦¬
            domain_knowledge: Phase 1 ë„ë©”ì¸ ì§€ì‹
            answer_template: Phase 1 ë‹µë³€ í…œí”Œë¦¿
            agent_selection_result: Phase 2 ì—ì´ì „íŠ¸ ì„ íƒ ê²°ê³¼
            execution_result: Phase 2 ì‹¤í–‰ ê²°ê³¼
            integration_result: Phase 2 í†µí•© ê²°ê³¼
            managed_plan: Phase 2 ê´€ë¦¬ëœ ê³„íš (ì„ íƒì‚¬í•­)
            synthesis_context: í•©ì„± ì»¨í…ìŠ¤íŠ¸ (ì„ íƒì‚¬í•­)
            
        Returns:
            HolisticAnswer: ì „ì²´ë¡ ì  ë‹µë³€
        """
        start_time = time.time()
        answer_id = f"holistic_{int(start_time)}"
        
        logger.info(f"ðŸ”„ Starting holistic answer synthesis: {answer_id}")
        
        try:
            # 1. í•©ì„± ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„
            if synthesis_context is None:
                synthesis_context = await self._create_synthesis_context(
                    enhanced_query, domain_knowledge, integration_result
                )
            
            # 2. ì¢…í•© ë¶„ì„ ìˆ˜í–‰
            comprehensive_analysis = await self._perform_comprehensive_analysis(
                enhanced_query, domain_knowledge, answer_template,
                agent_selection_result, execution_result, integration_result,
                synthesis_context
            )
            
            # 3. ë‹µë³€ ì„¹ì…˜ ìƒì„±
            answer_sections = await self._generate_answer_sections(
                comprehensive_analysis, synthesis_context
            )
            
            # 4. í•µì‹¬ ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ
            key_insights = await self._extract_key_insights(
                comprehensive_analysis, integration_result, synthesis_context
            )
            
            # 5. ì‹¤í–‰ ê¶Œê³ ì‚¬í•­ ìƒì„±
            recommendations = await self._generate_actionable_recommendations(
                comprehensive_analysis, integration_result, synthesis_context
            )
            
            # 6. ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ
            next_steps = await self._suggest_next_steps(
                recommendations, execution_result, synthesis_context
            )
            
            # 7. ìž„ì› ìš”ì•½ ìƒì„±
            executive_summary = await self._generate_executive_summary(
                comprehensive_analysis, key_insights, recommendations, synthesis_context
            )
            
            # 8. í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚°
            quality_metrics = await self._calculate_quality_metrics(
                answer_sections, key_insights, recommendations, integration_result
            )
            
            # 9. ì „ì²´ ì‹ ë¢°ë„ ê³„ì‚°
            confidence_score = self._calculate_overall_confidence(
                quality_metrics, integration_result, execution_result
            )
            
            synthesis_time = time.time() - start_time
            
            # 10. ì „ì²´ë¡ ì  ë‹µë³€ êµ¬ì„±
            holistic_answer = HolisticAnswer(
                answer_id=answer_id,
                query_summary=(enhanced_query.enhanced_queries[0][:200] + "..." if enhanced_query.enhanced_queries else enhanced_query.original_query[:200] + "..."),
                executive_summary=executive_summary,
                main_sections=answer_sections,
                key_insights=key_insights,
                recommendations=recommendations,
                next_steps=next_steps,
                confidence_score=confidence_score,
                quality_metrics=quality_metrics,
                synthesis_metadata={
                    "synthesis_context": synthesis_context.__dict__,
                    "source_confidence": {
                        "query_processing": getattr(enhanced_query, 'confidence_score', 0.8),
                        "agent_selection": agent_selection_result.total_confidence,
                        "execution": execution_result.confidence_score,
                        "integration": integration_result.confidence_score
                    },
                    "analysis_depth": len(answer_sections),
                    "insight_count": len(key_insights),
                    "recommendation_count": len(recommendations)
                },
                generated_at=datetime.now(),
                synthesis_time=synthesis_time
            )
            
            self.synthesis_history.append(holistic_answer)
            
            logger.info(f"âœ… Holistic answer synthesis completed: {answer_id} ({synthesis_time:.2f}s)")
            return holistic_answer
            
        except Exception as e:
            logger.error(f"âŒ Holistic answer synthesis failed: {answer_id} - {e}")
            raise
    
    async def _create_synthesis_context(
        self,
        enhanced_query: EnhancedQuery,
        domain_knowledge: EnhancedDomainKnowledge,
        integration_result: IntegrationResult
    ) -> SynthesisContext:
        """í•©ì„± ì»¨í…ìŠ¤íŠ¸ ìƒì„±"""
        
        context_prompt = f"""ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ í•©ì„±ì„ ìœ„í•œ ìµœì ì˜ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê²°ì •í•´ì£¼ì„¸ìš”:

**í–¥ìƒëœ ì¿¼ë¦¬**:
- ì›ë³¸ ì¿¼ë¦¬: {enhanced_query.original_query}
- í–¥ìƒëœ ì¿¼ë¦¬: {enhanced_query.enhanced_queries[0][:300] + '...' if enhanced_query.enhanced_queries else enhanced_query.original_query}
- ì˜ë„ ë¶„ì„: {enhanced_query.intent_analysis.primary_intent if enhanced_query.intent_analysis else 'N/A'}

**ë„ë©”ì¸ ì§€ì‹**:
- ì£¼ìš” ë„ë©”ì¸: {domain_knowledge.taxonomy.primary_domain.value}
- ê¸°ìˆ  ì˜ì—­: {domain_knowledge.taxonomy.technical_area}
- ì£¼ìš” ê°œë…: {', '.join(list(domain_knowledge.key_concepts.keys())[:3])}

**í†µí•© ê²°ê³¼**:
- ì‹ ë¢°ë„: {integration_result.confidence_score:.2f}
- ì¸ì‚¬ì´íŠ¸ ìˆ˜: {len(integration_result.integrated_insights)}
- ê¶Œê³ ì‚¬í•­ ìˆ˜: {len(integration_result.recommendations)}

**ì»¨í…ìŠ¤íŠ¸ ê²°ì • ìš”êµ¬ì‚¬í•­**:
1. ì‚¬ìš©ìž ì˜ë„ (user_intent)
2. ë„ë©”ì¸ ì»¨í…ìŠ¤íŠ¸ (domain_context)
3. ê¸´ê¸‰ë„ ìˆ˜ì¤€ (urgency_level: low/medium/high)
4. ëŒ€ìƒ ì²­ì¤‘ (target_audience: technical/business/mixed)
5. ë‹µë³€ ìŠ¤íƒ€ì¼ (answer_style: technical/business/executive/operational/educational/comprehensive)
6. ë‹µë³€ ìš°ì„ ìˆœìœ„ (answer_priority: insights/actions/analysis/recommendations/solutions)
7. í•©ì„± ì „ëžµ (synthesis_strategy: layered/integrated/narrative/analytical)

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
  "user_intent": "ë°˜ë„ì²´ ê³µì • ì´ìƒ ë¶„ì„ ë° ê¸°ìˆ ì  ì¡°ì¹˜ ë°©í–¥ ë„ì¶œ",
  "domain_context": "semiconductor_manufacturing_quality_control",
  "urgency_level": "high",
  "target_audience": "technical",
  "answer_style": "comprehensive",
  "answer_priority": "actions",
  "synthesis_strategy": "integrated",
  "quality_requirements": {{"completeness": 0.9, "accuracy": 0.95, "actionability": 0.85}},
  "constraints": ["ì‹¤í–‰ ê°€ëŠ¥í•œ ì¡°ì¹˜ ì¤‘ì‹¬", "ê¸°ìˆ ì  ì •í™•ì„± í•„ìˆ˜"]
}}"""

        try:
            response = await self.llm.ainvoke(context_prompt)
            content = response.content.strip()
            
            # JSON ì¶”ì¶œ
            if content.startswith('{') and content.endswith('}'):
                context_data = json.loads(content)
            else:
                import re
                json_match = re.search(r'```json\s*(.*?)\s*```', content, re.DOTALL)
                if json_match:
                    context_data = json.loads(json_match.group(1))
                else:
                    context_data = {}
            
            # SynthesisContext ê°ì²´ ìƒì„±
            synthesis_context = SynthesisContext(
                user_intent=context_data.get("user_intent", "ì •ë³´ ë¶„ì„ ë° ì¸ì‚¬ì´íŠ¸ ë„ì¶œ"),
                domain_context=context_data.get("domain_context", domain_knowledge.taxonomy.primary_domain.value),
                urgency_level=context_data.get("urgency_level", "medium"),
                target_audience=context_data.get("target_audience", "mixed"),
                answer_style=AnswerStyle(context_data.get("answer_style", "comprehensive")),
                answer_priority=AnswerPriority(context_data.get("answer_priority", "insights")),
                synthesis_strategy=SynthesisStrategy(context_data.get("synthesis_strategy", "integrated")),
                quality_requirements=context_data.get("quality_requirements", {"completeness": 0.8, "accuracy": 0.9}),
                constraints=context_data.get("constraints", [])
            )
            
            return synthesis_context
            
        except Exception as e:
            logger.warning(f"Synthesis context creation failed, using defaults: {e}")
            return SynthesisContext(
                user_intent="ì •ë³´ ë¶„ì„ ë° ì¸ì‚¬ì´íŠ¸ ë„ì¶œ",
                domain_context=domain_knowledge.taxonomy.primary_domain.value,
                urgency_level="medium",
                target_audience="mixed",
                answer_style=self.default_style,
                answer_priority=self.default_priority,
                synthesis_strategy=self.default_strategy
            )
    
    async def _perform_comprehensive_analysis(
        self,
        enhanced_query: EnhancedQuery,
        domain_knowledge: EnhancedDomainKnowledge,
        answer_template: AnswerTemplate,
        agent_selection_result: AgentSelectionResult,
        execution_result: ExecutionResult,
        integration_result: IntegrationResult,
        synthesis_context: SynthesisContext
    ) -> Dict[str, Any]:
        """ì¢…í•© ë¶„ì„ ìˆ˜í–‰"""
        
        analysis_prompt = f"""ë‹¤ìŒ ëª¨ë“  ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ ì „ë¬¸ê°€ ìˆ˜ì¤€ì˜ í¬ê´„ì  ë¶„ì„ì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”:

**1. ì¿¼ë¦¬ ë¶„ì„**:
- ì›ë³¸ ì˜ë„: {enhanced_query.original_query}
- í–¥ìƒëœ ë¶„ì„: {enhanced_query.enhanced_queries[0][:400] + '...' if enhanced_query.enhanced_queries else enhanced_query.original_query}
- ì‹ ë¢°ë„: {getattr(enhanced_query, 'confidence_score', 0.8):.2f}

**2. ë„ë©”ì¸ ì§€ì‹**:
- ë„ë©”ì¸: {domain_knowledge.taxonomy.primary_domain.value}
- ê¸°ìˆ  ì˜ì—­: {domain_knowledge.taxonomy.technical_area}
- í•µì‹¬ ê°œë…: {json.dumps(list(domain_knowledge.key_concepts.keys())[:5], ensure_ascii=False)}

**3. ì—ì´ì „íŠ¸ ì„ íƒ ë° ì‹¤í–‰**:
- ì„ íƒëœ ì—ì´ì „íŠ¸: {len(agent_selection_result.selected_agents)}ê°œ
- ì‹¤í–‰ ì„±ê³µë¥ : {execution_result.completed_tasks}/{execution_result.total_tasks}
- ì‹¤í–‰ ì‹œê°„: {execution_result.execution_time:.2f}ì´ˆ

**4. í†µí•© ê²°ê³¼**:
- í†µí•© ì¸ì‚¬ì´íŠ¸: {len(integration_result.integrated_insights)}ê°œ
- ê¶Œê³ ì‚¬í•­: {len(integration_result.recommendations)}ê°œ
- ì‹ ë¢°ë„: {integration_result.confidence_score:.2f}

**5. í•©ì„± ì»¨í…ìŠ¤íŠ¸**:
- ì‚¬ìš©ìž ì˜ë„: {synthesis_context.user_intent}
- ë‹µë³€ ìŠ¤íƒ€ì¼: {synthesis_context.answer_style.value}
- ìš°ì„ ìˆœìœ„: {synthesis_context.answer_priority.value}

**ì¢…í•© ë¶„ì„ ìš”êµ¬ì‚¬í•­**:
1. ì „ì²´ ìƒí™© ìš”ì•½ ë° ë¬¸ì œ ì •ì˜
2. ìˆ˜ì§‘ëœ ë°ì´í„° ë° ë¶„ì„ ê²°ê³¼ í†µí•©
3. í•µì‹¬ ë°œê²¬ì‚¬í•­ ë° íŒ¨í„´ ì‹ë³„
4. ë¦¬ìŠ¤í¬ ë° ê¸°íšŒ ìš”ì¸ ë¶„ì„
5. ì „ë¬¸ê°€ì  í•´ì„ ë° ì‹œì‚¬ì 
6. ì‹¤í–‰ ê°€ëŠ¥ì„± ë° ìš°ì„ ìˆœìœ„ í‰ê°€

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
  "situation_summary": "í˜„ìž¬ ìƒí™©ì— ëŒ€í•œ ëª…í™•í•œ ìš”ì•½",
  "problem_definition": "í•´ê²°í•´ì•¼ í•  í•µì‹¬ ë¬¸ì œë“¤",
  "data_integration": "ìˆ˜ì§‘ëœ ëª¨ë“  ë°ì´í„°ì˜ í†µí•© ë¶„ì„",
  "key_findings": ["ë°œê²¬ì‚¬í•­ 1", "ë°œê²¬ì‚¬í•­ 2", "ë°œê²¬ì‚¬í•­ 3"],
  "patterns_identified": ["íŒ¨í„´ 1", "íŒ¨í„´ 2"],
  "risk_analysis": {{"risks": ["ë¦¬ìŠ¤í¬ 1", "ë¦¬ìŠ¤í¬ 2"], "opportunities": ["ê¸°íšŒ 1", "ê¸°íšŒ 2"]}},
  "expert_interpretation": "ì „ë¬¸ê°€ì  í•´ì„ ë° ì‹œì‚¬ì ",
  "feasibility_assessment": "ì‹¤í–‰ ê°€ëŠ¥ì„± í‰ê°€",
  "priority_matrix": {{"high": ["ìš°ì„ ìˆœìœ„ ë†’ìŒ"], "medium": ["ë³´í†µ"], "low": ["ë‚®ìŒ"]}}
}}"""

        try:
            response = await self.llm.ainvoke(analysis_prompt)
            content = response.content.strip()
            
            # JSON ì¶”ì¶œ
            if content.startswith('{') and content.endswith('}'):
                analysis_result = json.loads(content)
            else:
                import re
                json_match = re.search(r'```json\s*(.*?)\s*```', content, re.DOTALL)
                if json_match:
                    analysis_result = json.loads(json_match.group(1))
                else:
                    analysis_result = {"error": "Failed to parse analysis"}
            
            return analysis_result
            
        except Exception as e:
            logger.warning(f"Comprehensive analysis failed: {e}")
            return {
                "situation_summary": "ì¢…í•© ë¶„ì„ ê²°ê³¼ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                "problem_definition": "ë¬¸ì œ ì •ì˜ ì‹¤íŒ¨",
                "data_integration": "ë°ì´í„° í†µí•© ë¶„ì„ ì‹¤íŒ¨",
                "key_findings": ["ë¶„ì„ ê²°ê³¼ ìƒì„± ì‹¤íŒ¨"],
                "patterns_identified": [],
                "risk_analysis": {"risks": [], "opportunities": []},
                "expert_interpretation": "ì „ë¬¸ê°€ í•´ì„ ìƒì„± ì‹¤íŒ¨",
                "feasibility_assessment": "ì‹¤í–‰ ê°€ëŠ¥ì„± í‰ê°€ ì‹¤íŒ¨",
                "priority_matrix": {"high": [], "medium": [], "low": []}
            }
    
    async def _generate_answer_sections(
        self,
        comprehensive_analysis: Dict[str, Any],
        synthesis_context: SynthesisContext
    ) -> List[AnswerSection]:
        """ë‹µë³€ ì„¹ì…˜ ìƒì„±"""
        
        sections_prompt = f"""ë‹¤ìŒ ì¢…í•© ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì²´ê³„ì ì¸ ë‹µë³€ ì„¹ì…˜ë“¤ì„ ìƒì„±í•´ì£¼ì„¸ìš”:

**ì¢…í•© ë¶„ì„ ê²°ê³¼**:
{json.dumps(comprehensive_analysis, ensure_ascii=False, indent=2)}

**ë‹µë³€ ìŠ¤íƒ€ì¼**: {synthesis_context.answer_style.value}
**ìš°ì„ ìˆœìœ„**: {synthesis_context.answer_priority.value}
**ëŒ€ìƒ ì²­ì¤‘**: {synthesis_context.target_audience}

**ì„¹ì…˜ ìƒì„± ìš”êµ¬ì‚¬í•­**:
1. ì‚¬ìš©ìž ì˜ë„ì— ë§žëŠ” ë…¼ë¦¬ì  êµ¬ì¡°
2. ê° ì„¹ì…˜ë³„ ëª…í™•í•œ ëª©ì ê³¼ ë‚´ìš©
3. ìš°ì„ ìˆœìœ„ì— ë”°ë¥¸ ì„¹ì…˜ ìˆœì„œ
4. ëŒ€ìƒ ì²­ì¤‘ì— ì í•©í•œ ìƒì„¸ë„

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
  "sections": [
    {{
      "title": "ìƒí™© ë¶„ì„ ë° ë¬¸ì œ ì •ì˜",
      "content": "ìƒì„¸í•œ ì„¹ì…˜ ë‚´ìš©...",
      "priority": 1,
      "section_type": "analysis",
      "confidence": 0.9,
      "sources": ["comprehensive_analysis"]
    }}
  ]
}}"""

        try:
            response = await self.llm.ainvoke(sections_prompt)
            content = response.content.strip()
            
            # JSON ì¶”ì¶œ
            if content.startswith('{') and content.endswith('}'):
                sections_data = json.loads(content)
            else:
                import re
                json_match = re.search(r'```json\s*(.*?)\s*```', content, re.DOTALL)
                if json_match:
                    sections_data = json.loads(json_match.group(1))
                else:
                    sections_data = {"sections": []}
            
            # AnswerSection ê°ì²´ë¡œ ë³€í™˜
            answer_sections = []
            for section_data in sections_data.get("sections", []):
                section = AnswerSection(
                    title=section_data.get("title", "ì œëª© ì—†ìŒ"),
                    content=section_data.get("content", "ë‚´ìš© ì—†ìŒ"),
                    priority=section_data.get("priority", 5),
                    section_type=section_data.get("section_type", "general"),
                    confidence=section_data.get("confidence", 0.5),
                    sources=section_data.get("sources", []),
                    metadata={"generated_by": "holistic_synthesis"}
                )
                answer_sections.append(section)
            
            # ìš°ì„ ìˆœìœ„ë³„ ì •ë ¬
            answer_sections.sort(key=lambda x: x.priority)
            
            return answer_sections
            
        except Exception as e:
            logger.warning(f"Answer sections generation failed: {e}")
            return [
                AnswerSection(
                    title="ë¶„ì„ ê²°ê³¼ ìš”ì•½",
                    content="ë‹µë³€ ì„¹ì…˜ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                    priority=1,
                    section_type="error",
                    confidence=0.0,
                    sources=["error_fallback"]
                )
            ]
    
    async def _extract_key_insights(
        self,
        comprehensive_analysis: Dict[str, Any],
        integration_result: IntegrationResult,
        synthesis_context: SynthesisContext
    ) -> List[str]:
        """í•µì‹¬ ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ"""
        
        insights_prompt = f"""ë‹¤ìŒ ì •ë³´ë“¤ì„ ì¢…í•©í•˜ì—¬ ê°€ìž¥ ì¤‘ìš”í•œ í•µì‹¬ ì¸ì‚¬ì´íŠ¸ë“¤ì„ ì¶”ì¶œí•´ì£¼ì„¸ìš”:

**ì¢…í•© ë¶„ì„**:
- í•µì‹¬ ë°œê²¬ì‚¬í•­: {comprehensive_analysis.get('key_findings', [])}
- ì‹ë³„ëœ íŒ¨í„´: {comprehensive_analysis.get('patterns_identified', [])}
- ì „ë¬¸ê°€ í•´ì„: {comprehensive_analysis.get('expert_interpretation', '')}

**í†µí•© ì¸ì‚¬ì´íŠ¸**:
{json.dumps([{
    'type': insight.insight_type,
    'content': insight.content,
    'confidence': insight.confidence
} for insight in integration_result.integrated_insights], ensure_ascii=False, indent=2)}

**ì‚¬ìš©ìž ì˜ë„**: {synthesis_context.user_intent}
**ìš°ì„ ìˆœìœ„**: {synthesis_context.answer_priority.value}

**ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ ìš”êµ¬ì‚¬í•­**:
1. ì‹¤í–‰ ê°€ëŠ¥í•˜ê³  êµ¬ì²´ì ì¸ ì¸ì‚¬ì´íŠ¸
2. ì‚¬ìš©ìž ì˜ë„ì™€ ì§ì ‘ì  ì—°ê´€ì„±
3. ë†’ì€ ì˜í–¥ë„ì™€ ì‹¤ìš©ì„±
4. ëª…í™•í•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ í‘œí˜„

í•µì‹¬ ì¸ì‚¬ì´íŠ¸ 3-7ê°œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”. ê°ê° í•œ ë¬¸ìž¥ìœ¼ë¡œ ëª…í™•í•˜ê²Œ í‘œí˜„í•˜ê³ , ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”."""

        try:
            response = await self.llm.ainvoke(insights_prompt)
            content = response.content.strip()
            
            # ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ íŒŒì‹±
            insights = []
            lines = content.split('\n')
            for line in lines:
                line = line.strip()
                if line and (line.startswith('-') or line.startswith('â€¢') or line.startswith('*')):
                    insights.append(line[1:].strip())
                elif line and any(char.isdigit() for char in line[:3]):
                    # ë²ˆí˜¸ê°€ ìžˆëŠ” í•­ëª©
                    insights.append(line.split('.', 1)[-1].strip())
            
            return insights if insights else [content]
            
        except Exception as e:
            logger.warning(f"Key insights extraction failed: {e}")
            return ["í•µì‹¬ ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."]
    
    async def _generate_actionable_recommendations(
        self,
        comprehensive_analysis: Dict[str, Any],
        integration_result: IntegrationResult,
        synthesis_context: SynthesisContext
    ) -> List[str]:
        """ì‹¤í–‰ ê°€ëŠ¥í•œ ê¶Œê³ ì‚¬í•­ ìƒì„±"""
        
        recommendations_prompt = f"""ë‹¤ìŒ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹¤í–‰ ê°€ëŠ¥í•œ êµ¬ì²´ì  ê¶Œê³ ì‚¬í•­ì„ ìƒì„±í•´ì£¼ì„¸ìš”:

**ì¢…í•© ë¶„ì„**:
- ìš°ì„ ìˆœìœ„ ë§¤íŠ¸ë¦­ìŠ¤: {comprehensive_analysis.get('priority_matrix', {})}
- ì‹¤í–‰ ê°€ëŠ¥ì„± í‰ê°€: {comprehensive_analysis.get('feasibility_assessment', '')}
- ë¦¬ìŠ¤í¬ ë¶„ì„: {comprehensive_analysis.get('risk_analysis', {})}

**ê¸°ì¡´ ê¶Œê³ ì‚¬í•­**:
{json.dumps(integration_result.recommendations, ensure_ascii=False, indent=2)}

**ì»¨í…ìŠ¤íŠ¸**:
- ê¸´ê¸‰ë„: {synthesis_context.urgency_level}
- ì œì•½ì‚¬í•­: {synthesis_context.constraints}
- í’ˆì§ˆ ìš”êµ¬ì‚¬í•­: {synthesis_context.quality_requirements}

**ê¶Œê³ ì‚¬í•­ ìƒì„± ì›ì¹™**:
1. ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ ì¡°ì¹˜
2. ëª…í™•í•œ ì‹¤í–‰ ì£¼ì²´ ë° ë°©ë²•
3. ì¸¡ì • ê°€ëŠ¥í•œ ê²°ê³¼ ì§€í‘œ
4. ë¦¬ìŠ¤í¬ ìµœì†Œí™” ë°©ì•ˆ í¬í•¨
5. ìš°ì„ ìˆœìœ„ë³„ ë‹¨ê³„ì  ì ‘ê·¼

ì‹¤í–‰ ê°€ëŠ¥í•œ ê¶Œê³ ì‚¬í•­ 5-10ê°œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”."""

        try:
            response = await self.llm.ainvoke(recommendations_prompt)
            content = response.content.strip()
            
            # ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ íŒŒì‹±
            recommendations = []
            lines = content.split('\n')
            for line in lines:
                line = line.strip()
                if line and (line.startswith('-') or line.startswith('â€¢') or line.startswith('*')):
                    recommendations.append(line[1:].strip())
                elif line and any(char.isdigit() for char in line[:3]):
                    recommendations.append(line.split('.', 1)[-1].strip())
            
            return recommendations if recommendations else [content]
            
        except Exception as e:
            logger.warning(f"Recommendations generation failed: {e}")
            return ["ê¶Œê³ ì‚¬í•­ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."]
    
    async def _suggest_next_steps(
        self,
        recommendations: List[str],
        execution_result: ExecutionResult,
        synthesis_context: SynthesisContext
    ) -> List[str]:
        """ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ"""
        
        next_steps_prompt = f"""ë‹¤ìŒ ê¶Œê³ ì‚¬í•­ê³¼ ì‹¤í–‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ êµ¬ì²´ì ì¸ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ì œì•ˆí•´ì£¼ì„¸ìš”:

**ìƒì„±ëœ ê¶Œê³ ì‚¬í•­**:
{json.dumps(recommendations, ensure_ascii=False, indent=2)}

**ì‹¤í–‰ ê²°ê³¼ ìš”ì•½**:
- ì™„ë£Œëœ ë¶„ì„: {execution_result.completed_tasks}/{execution_result.total_tasks}
- ì‹¤í–‰ ì‹œê°„: {execution_result.execution_time:.2f}ì´ˆ
- ì‹ ë¢°ë„: {execution_result.confidence_score:.2f}

**ì»¨í…ìŠ¤íŠ¸**:
- ê¸´ê¸‰ë„: {synthesis_context.urgency_level}
- ëŒ€ìƒ ì²­ì¤‘: {synthesis_context.target_audience}

**ë‹¤ìŒ ë‹¨ê³„ ìš”êµ¬ì‚¬í•­**:
1. ì‹œê°„ìˆœì„œì— ë”°ë¥¸ êµ¬ì²´ì  ì•¡ì…˜
2. ë‹´ë‹¹ìž ë° ë¦¬ì†ŒìŠ¤ ìš”êµ¬ì‚¬í•­ ëª…ì‹œ
3. ì˜ˆìƒ ì†Œìš” ì‹œê°„ ë° ë§ˆì¼ìŠ¤í†¤
4. ì„±ê³µ ì¸¡ì • ê¸°ì¤€
5. ë¦¬ìŠ¤í¬ ëŒ€ì‘ ë°©ì•ˆ

ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ ë‹¤ìŒ ë‹¨ê³„ 3-6ê°œë¥¼ ì œì•ˆí•´ì£¼ì„¸ìš”."""

        try:
            response = await self.llm.ainvoke(next_steps_prompt)
            content = response.content.strip()
            
            # ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ íŒŒì‹±
            next_steps = []
            lines = content.split('\n')
            for line in lines:
                line = line.strip()
                if line and (line.startswith('-') or line.startswith('â€¢') or line.startswith('*')):
                    next_steps.append(line[1:].strip())
                elif line and any(char.isdigit() for char in line[:3]):
                    next_steps.append(line.split('.', 1)[-1].strip())
            
            return next_steps if next_steps else [content]
            
        except Exception as e:
            logger.warning(f"Next steps suggestion failed: {e}")
            return ["ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."]
    
    async def _generate_executive_summary(
        self,
        comprehensive_analysis: Dict[str, Any],
        key_insights: List[str],
        recommendations: List[str],
        synthesis_context: SynthesisContext
    ) -> str:
        """ìž„ì› ìš”ì•½ ìƒì„±"""
        
        summary_prompt = f"""ë‹¤ìŒ ëª¨ë“  ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìž„ì›ì§„ì„ ìœ„í•œ í•µì‹¬ ìš”ì•½ì„ ìž‘ì„±í•´ì£¼ì„¸ìš”:

**ìƒí™© ìš”ì•½**: {comprehensive_analysis.get('situation_summary', '')}
**í•µì‹¬ ì¸ì‚¬ì´íŠ¸**: {key_insights[:3]}
**ì£¼ìš” ê¶Œê³ ì‚¬í•­**: {recommendations[:3]}
**ëŒ€ìƒ ì²­ì¤‘**: {synthesis_context.target_audience}
**ê¸´ê¸‰ë„**: {synthesis_context.urgency_level}

**ìž„ì› ìš”ì•½ ìš”êµ¬ì‚¬í•­**:
1. 3-4ë¬¸ìž¥ìœ¼ë¡œ í•µì‹¬ë§Œ ê°„ê²°í•˜ê²Œ
2. ë¹„ì¦ˆë‹ˆìŠ¤ ì˜í–¥ë„ ì¤‘ì‹¬
3. ì˜ì‚¬ê²°ì •ì— í•„ìš”í•œ í•µì‹¬ ì •ë³´
4. ì‹¤í–‰ ì‹œê¸‰ì„± ë° ìš°ì„ ìˆœìœ„ ëª…ì‹œ

ì „ë¬¸ì ì´ê³  ê°„ê²°í•œ ìž„ì› ìš”ì•½ì„ ìž‘ì„±í•´ì£¼ì„¸ìš”."""

        try:
            response = await self.llm.ainvoke(summary_prompt)
            return response.content.strip()
            
        except Exception as e:
            logger.warning(f"Executive summary generation failed: {e}")
            return "ìž„ì› ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    async def _calculate_quality_metrics(
        self,
        answer_sections: List[AnswerSection],
        key_insights: List[str],
        recommendations: List[str],
        integration_result: IntegrationResult
    ) -> Dict[str, float]:
        """í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚°"""
        
        # ì™„ì„±ë„: ì„¹ì…˜ ìˆ˜ì™€ ë‚´ìš© ê¸¸ì´ ê¸°ë°˜
        completeness = min(1.0, len(answer_sections) / 5.0) * 0.5 + \
                      min(1.0, sum(len(section.content) for section in answer_sections) / 2000) * 0.5
        
        # ì¼ê´€ì„±: ì„¹ì…˜ ê°„ ì‹ ë¢°ë„ íŽ¸ì°¨ ê¸°ë°˜
        if answer_sections:
            section_confidences = [section.confidence for section in answer_sections]
            consistency = 1.0 - (max(section_confidences) - min(section_confidences))
        else:
            consistency = 0.0
        
        # ì‹¤í–‰ê°€ëŠ¥ì„±: ê¶Œê³ ì‚¬í•­ ìˆ˜ì™€ ì¸ì‚¬ì´íŠ¸ ìˆ˜ ê¸°ë°˜
        actionability = min(1.0, len(recommendations) / 8.0) * 0.7 + \
                       min(1.0, len(key_insights) / 6.0) * 0.3
        
        # ê´€ë ¨ì„±: í†µí•© ê²°ê³¼ ì‹ ë¢°ë„ í™œìš©
        relevance = integration_result.confidence_score
        
        # ëª…í™•ì„±: ì„¹ì…˜ë³„ í‰ê·  ì‹ ë¢°ë„
        if answer_sections:
            clarity = sum(section.confidence for section in answer_sections) / len(answer_sections)
        else:
            clarity = 0.0
        
        # í¬ê´„ì„±: ë‹¤ì–‘í•œ ì¸¡ë©´ì˜ ì»¤ë²„ë¦¬ì§€
        comprehensiveness = min(1.0, len(answer_sections) / 6.0) * 0.4 + \
                           min(1.0, len(key_insights) / 5.0) * 0.3 + \
                           min(1.0, len(recommendations) / 7.0) * 0.3
        
        return {
            "completeness": completeness,
            "consistency": consistency,
            "actionability": actionability,
            "relevance": relevance,
            "clarity": clarity,
            "comprehensiveness": comprehensiveness
        }
    
    def _calculate_overall_confidence(
        self,
        quality_metrics: Dict[str, float],
        integration_result: IntegrationResult,
        execution_result: ExecutionResult
    ) -> float:
        """ì „ì²´ ì‹ ë¢°ë„ ê³„ì‚°"""
        
        # í’ˆì§ˆ ë©”íŠ¸ë¦­ í‰ê· 
        quality_score = sum(quality_metrics.values()) / len(quality_metrics)
        
        # ì†ŒìŠ¤ ì‹ ë¢°ë„ ê°€ì¤‘ í‰ê· 
        source_confidence = (
            integration_result.confidence_score * 0.4 +
            execution_result.confidence_score * 0.3 +
            quality_score * 0.3
        )
        
        # ì‹¤í–‰ ì„±ê³µë¥  ë³´ì •
        execution_success_rate = execution_result.completed_tasks / max(1, execution_result.total_tasks)
        
        # ìµœì¢… ì‹ ë¢°ë„ ê³„ì‚°
        final_confidence = source_confidence * 0.8 + execution_success_rate * 0.2
        
        return max(0.0, min(1.0, final_confidence))
    
    async def get_synthesis_history(self) -> List[HolisticAnswer]:
        """í•©ì„± ì´ë ¥ ì¡°íšŒ"""
        return self.synthesis_history.copy()
    
    async def get_answer_summary(self, answer_id: str) -> Optional[Dict[str, Any]]:
        """ë‹µë³€ ìš”ì•½ ì¡°íšŒ"""
        for answer in self.synthesis_history:
            if answer.answer_id == answer_id:
                return {
                    "answer_id": answer.answer_id,
                    "query_summary": answer.query_summary,
                    "confidence_score": answer.confidence_score,
                    "section_count": len(answer.main_sections),
                    "insight_count": len(answer.key_insights),
                    "recommendation_count": len(answer.recommendations),
                    "synthesis_time": answer.synthesis_time,
                    "generated_at": answer.generated_at.isoformat()
                }
        return None 