"""
Execution Plan Manager í…ŒìŠ¤íŠ¸

ì´ í…ŒìŠ¤íŠ¸ëŠ” ì‹¤í–‰ ê³„íš ê´€ë¦¬ìì˜ ê¸°ëŠ¥ì„ ê²€ì¦í•©ë‹ˆë‹¤.
"""

import asyncio
import json
from datetime import datetime
from unittest.mock import Mock, patch, AsyncMock

from core.query_processing.execution_plan_manager import (
    ExecutionPlanManager,
    PlanStatus,
    MonitoringLevel,
    OptimizationStrategy,
    ManagedExecutionPlan
)
from core.query_processing.domain_aware_agent_selector import (
    AgentSelectionResult,
    AgentSelection,
    AgentType
)
from core.query_processing.a2a_agent_execution_orchestrator import (
    ExecutionPlan,
    ExecutionResult,
    ExecutionStatus,
    ExecutionStrategy
)


async def test_execution_plan_manager():
    """Execution Plan Manager ì™„ì „ í…ŒìŠ¤íŠ¸"""
    
    print("ğŸ§ª Execution Plan Manager í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 80)
    
    # ê´€ë¦¬ì ì´ˆê¸°í™”
    manager = ExecutionPlanManager()
    
    # 1. ëª¨ì˜ ì—ì´ì „íŠ¸ ì„ íƒ ê²°ê³¼ ìƒì„±
    print("\n1ï¸âƒ£ ëª¨ì˜ ì—ì´ì „íŠ¸ ì„ íƒ ê²°ê³¼ ìƒì„±")
    
    mock_agent_selections = [
        AgentSelection(
            agent_type=AgentType.DATA_CLEANING,
            reasoning="ë°ì´í„° í’ˆì§ˆ ê°œì„ ì„ ìœ„í•œ ì •ë¦¬ ì‘ì—… í•„ìš”",
            confidence=0.85,
            priority=1,
            expected_outputs=["cleaned_data", "quality_report"],
            dependencies=[]
        ),
        AgentSelection(
            agent_type=AgentType.EDA_TOOLS,
            reasoning="ë°ì´í„° íƒìƒ‰ì  ë¶„ì„ì„ í†µí•œ íŒ¨í„´ ë°œê²¬",
            confidence=0.92,
            priority=2,
            expected_outputs=["statistical_analysis", "pattern_insights"],
            dependencies=["data_cleaning"]
        ),
        AgentSelection(
            agent_type=AgentType.DATA_VISUALIZATION,
            reasoning="ë¶„ì„ ê²°ê³¼ ì‹œê°í™”ë¡œ ì¸ì‚¬ì´íŠ¸ ì „ë‹¬",
            confidence=0.78,
            priority=3,
            expected_outputs=["charts", "dashboards"],
            dependencies=["eda_tools"]
        )
    ]
    
    mock_selection_result = AgentSelectionResult(
        selected_agents=mock_agent_selections,
        selection_strategy="pipeline",
        total_confidence=0.85,
        reasoning="ë°ì´í„° í’ˆì§ˆ â†’ ë¶„ì„ â†’ ì‹œê°í™” íŒŒì´í”„ë¼ì¸ êµ¬ì„±",
        execution_order=[AgentType.DATA_CLEANING, AgentType.EDA_TOOLS, AgentType.DATA_VISUALIZATION],
        estimated_duration="15-20 minutes",
        success_probability=0.85,
        alternative_options=[]
    )
    
    enhanced_query = "ë°˜ë„ì²´ LOT íˆìŠ¤í† ë¦¬ì™€ ê³„ì¸¡ê°’ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ê³µì • ì´ìƒ ì—¬ë¶€ë¥¼ íŒë‹¨í•˜ê³  ê¸°ìˆ ì  ì¡°ì¹˜ ë°©í–¥ì„ ì œì•ˆí•˜ì„¸ìš”."
    
    print(f"   ì—ì´ì „íŠ¸ ì„ íƒ ê²°ê³¼:")
    print(f"   - ì„ íƒëœ ì—ì´ì „íŠ¸: {len(mock_selection_result.selected_agents)}ê°œ")
    print(f"   - ì „ì²´ ì‹ ë¢°ë„: {mock_selection_result.total_confidence:.2f}")
    print(f"   - ì‹¤í–‰ ì „ëµ: {mock_selection_result.selection_strategy}")
    
    # 2. ê´€ë¦¬ë˜ëŠ” ì‹¤í–‰ ê³„íš ìƒì„± í…ŒìŠ¤íŠ¸
    print("\n2ï¸âƒ£ ê´€ë¦¬ë˜ëŠ” ì‹¤í–‰ ê³„íš ìƒì„± í…ŒìŠ¤íŠ¸")
    
    try:
        # LLM ëª¨í‚¹
        with patch.object(manager, 'llm') as mock_llm:
            # ê³„íš ê²€ì¦ ì‘ë‹µ ëª¨í‚¹
            validation_response = Mock(content='{"valid": true, "issues": [], "warnings": ["ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ ê¶Œì¥"], "score": 0.92, "recommendations": ["ì—ì´ì „íŠ¸ ê°„ ì˜ì¡´ì„± ìµœì í™”"]}')
            mock_llm.ainvoke = AsyncMock(return_value=validation_response)
            
            # ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ëª¨í‚¹
            mock_execution_plan = ExecutionPlan(
                plan_id="test_plan_001",
                objective="ë°˜ë„ì²´ ë°ì´í„° ì¢…í•© ë¶„ì„",
                strategy=ExecutionStrategy.PIPELINE,
                tasks=[],
                context={"enhanced_query": enhanced_query},
                total_tasks=3
            )
            
            manager.orchestrator.create_execution_plan = AsyncMock(return_value=mock_execution_plan)
            
            # ê´€ë¦¬ë˜ëŠ” ê³„íš ìƒì„±
            managed_plan = await manager.create_managed_plan(
                mock_selection_result,
                enhanced_query,
                {"analysis_focus": "quality_assessment"},
                MonitoringLevel.DETAILED
            )
            
            print(f"   âœ… ê´€ë¦¬ë˜ëŠ” ê³„íš ìƒì„± ì„±ê³µ")
            print(f"   - ê³„íš ID: {managed_plan.plan_id}")
            print(f"   - ìƒíƒœ: {managed_plan.status.value}")
            print(f"   - ìƒì„± ì‹œê°„: {managed_plan.created_at}")
            print(f"   - ëª¨ë‹ˆí„°ë§ ì´ë²¤íŠ¸: {len(managed_plan.monitoring_events)}ê°œ")
            
    except Exception as e:
        print(f"   âŒ ê´€ë¦¬ë˜ëŠ” ê³„íš ìƒì„± ì‹¤íŒ¨: {e}")
        return False
    
    # 3. ê³„íš ìƒíƒœ ì¡°íšŒ í…ŒìŠ¤íŠ¸
    print("\n3ï¸âƒ£ ê³„íš ìƒíƒœ ì¡°íšŒ í…ŒìŠ¤íŠ¸")
    
    try:
        plan_status = await manager.get_plan_status(managed_plan.plan_id)
        
        if plan_status:
            print(f"   âœ… ê³„íš ìƒíƒœ ì¡°íšŒ ì„±ê³µ")
            print(f"   - ê³„íš ID: {plan_status['plan_id']}")
            print(f"   - ìƒíƒœ: {plan_status['status']}")
            print(f"   - ì´ íƒœìŠ¤í¬: {plan_status['total_tasks']}")
            print(f"   - ì´ë²¤íŠ¸ ìˆ˜: {plan_status['event_count']}")
        else:
            print(f"   âŒ ê³„íš ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: ê³„íšì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            return False
            
    except Exception as e:
        print(f"   âŒ ê³„íš ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return False
    
    # 4. ëª¨ì˜ ê´€ë¦¬ë˜ëŠ” ê³„íš ì‹¤í–‰ í…ŒìŠ¤íŠ¸
    print("\n4ï¸âƒ£ ëª¨ì˜ ê´€ë¦¬ë˜ëŠ” ê³„íš ì‹¤í–‰ í…ŒìŠ¤íŠ¸")
    
    try:
        # ì‹¤í–‰ ê²°ê³¼ ëª¨í‚¹
        mock_execution_result = ExecutionResult(
            plan_id=managed_plan.plan_id,
            objective="ë°˜ë„ì²´ ë°ì´í„° ì¢…í•© ë¶„ì„",
            overall_status=ExecutionStatus.COMPLETED,
            total_tasks=3,
            completed_tasks=3,
            failed_tasks=0,
            execution_time=45.7,
            task_results=[
                {"agent_name": "DataCleaningAgent", "status": "completed", "execution_time": 12.3},
                {"agent_name": "EDAAgent", "status": "completed", "execution_time": 18.5},
                {"agent_name": "VisualizationAgent", "status": "completed", "execution_time": 14.9}
            ],
            aggregated_results={"summary": "ëª¨ë“  ë¶„ì„ ì™„ë£Œ"},
            execution_summary="3ê°œ ì—ì´ì „íŠ¸ ì„±ê³µì  ì‹¤í–‰ ì™„ë£Œ",
            confidence_score=0.91
        )
        
        # í†µí•© ê²°ê³¼ ëª¨í‚¹
        from core.query_processing.multi_agent_result_integration import (
            IntegrationResult,
            IntegrationStrategy,
            IntegratedInsight
        )
        
        mock_integration_result = IntegrationResult(
            integration_id="integration_test_001",
            strategy=IntegrationStrategy.HIERARCHICAL,
            agent_results=[],
            cross_validation=Mock(consistency_score=0.89),
            integrated_insights=[
                IntegratedInsight(
                    insight_type="quality_assessment",
                    content="ë°ì´í„° í’ˆì§ˆì´ ìš°ìˆ˜í•˜ë©° ë¶„ì„ ê²°ê³¼ ì‹ ë¢°ë„ê°€ ë†’ìŒ",
                    confidence=0.93,
                    supporting_agents=["DataCleaningAgent", "EDAAgent"],
                    evidence_strength=0.91,
                    actionable_items=["í˜„ì¬ í’ˆì§ˆ í”„ë¡œì„¸ìŠ¤ ìœ ì§€", "ì •ê¸° ëª¨ë‹ˆí„°ë§ ê°•í™”"],
                    priority=1
                )
            ],
            quality_assessment={},
            synthesis_report="ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ ë‚´ìš©",
            recommendations=["í’ˆì§ˆ í”„ë¡œì„¸ìŠ¤ ìœ ì§€", "ëª¨ë‹ˆí„°ë§ ê°•í™”"],
            confidence_score=0.92,
            integration_time=3.4,
            metadata={}
        )
        
        # ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ë° í†µí•©ê¸° ëª¨í‚¹
        manager.orchestrator.execute_plan = AsyncMock(return_value=mock_execution_result)
        manager.integrator.integrate_results = AsyncMock(return_value=mock_integration_result)
        
        # LLM ëª¨í‚¹ (ìµœì í™” ê¶Œê³ ì‚¬í•­ ìƒì„±ìš©)
        optimization_response = Mock(content='{"recommendations": [{"optimization_type": "performance", "description": "ë³‘ë ¬ ì‹¤í–‰ìœ¼ë¡œ 20% ì„±ëŠ¥ í–¥ìƒ", "expected_improvement": 0.2, "implementation_effort": "medium", "priority": 1, "estimated_impact": {"time_reduction": 0.2}}]}')
        
        # ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§ ì½œë°±
        progress_messages = []
        def progress_callback(message):
            progress_messages.append(message)
        
        # ê´€ë¦¬ë˜ëŠ” ê³„íš ì‹¤í–‰
        integration_result = await manager.execute_managed_plan(
            managed_plan.plan_id,
            progress_callback
        )
        
        print(f"   âœ… ê´€ë¦¬ë˜ëŠ” ê³„íš ì‹¤í–‰ ì„±ê³µ")
        print(f"   - ì‹¤í–‰ ê²°ê³¼: {integration_result.integration_id}")
        print(f"   - ì „ì²´ ì‹ ë¢°ë„: {integration_result.confidence_score:.2f}")
        print(f"   - í†µí•© ì¸ì‚¬ì´íŠ¸: {len(integration_result.integrated_insights)}ê°œ")
        print(f"   - ì§„í–‰ ë©”ì‹œì§€: {len(progress_messages)}ê°œ")
        
        # ì‹¤í–‰ í›„ ìƒíƒœ í™•ì¸
        updated_plan = manager.managed_plans[managed_plan.plan_id]
        print(f"   - ê³„íš ìƒíƒœ: {updated_plan.status.value}")
        print(f"   - ì‹¤í–‰ ì‹œê°„: {updated_plan.execution_result.execution_time:.2f}ì´ˆ")
        print(f"   - ìµœì í™” ê¶Œê³ : {len(updated_plan.optimization_recommendations)}ê°œ")
        
    except Exception as e:
        print(f"   âŒ ê´€ë¦¬ë˜ëŠ” ê³„íš ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        return False
    
    # 5. ê³„íš ë¶„ì„ ì •ë³´ ì¡°íšŒ í…ŒìŠ¤íŠ¸
    print("\n5ï¸âƒ£ ê³„íš ë¶„ì„ ì •ë³´ ì¡°íšŒ í…ŒìŠ¤íŠ¸")
    
    try:
        analytics = await manager.get_plan_analytics(managed_plan.plan_id)
        
        if analytics:
            print(f"   âœ… ê³„íš ë¶„ì„ ì •ë³´ ì¡°íšŒ ì„±ê³µ")
            print(f"   - ì‹¤í–‰ ë©”íŠ¸ë¦­: {len(analytics['execution_metrics'])}ê°œ")
            print(f"   - ëª¨ë‹ˆí„°ë§ ìš”ì•½: {analytics['monitoring_summary']['total_events']}ê°œ ì´ë²¤íŠ¸")
            print(f"   - ìµœì í™” ê¶Œê³ : {len(analytics['optimization_recommendations'])}ê°œ")
            
            if 'integration_summary' in analytics:
                print(f"   - í†µí•© ìš”ì•½: ì‹ ë¢°ë„ {analytics['integration_summary']['confidence_score']:.2f}")
        else:
            print(f"   âŒ ê³„íš ë¶„ì„ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: ë¶„ì„ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            return False
            
    except Exception as e:
        print(f"   âŒ ê³„íš ë¶„ì„ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return False
    
    # 6. ëª¨ë“  ê³„íš ëª©ë¡ ì¡°íšŒ í…ŒìŠ¤íŠ¸
    print("\n6ï¸âƒ£ ëª¨ë“  ê³„íš ëª©ë¡ ì¡°íšŒ í…ŒìŠ¤íŠ¸")
    
    try:
        all_plans = await manager.get_all_plans()
        
        print(f"   âœ… ëª¨ë“  ê³„íš ëª©ë¡ ì¡°íšŒ ì„±ê³µ")
        print(f"   - ì´ ê³„íš ìˆ˜: {len(all_plans)}")
        
        if all_plans:
            for plan in all_plans:
                print(f"   - ê³„íš {plan['plan_id']}: {plan['status']} ({plan['total_tasks']} íƒœìŠ¤í¬)")
        
    except Exception as e:
        print(f"   âŒ ëª¨ë“  ê³„íš ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return False
    
    # 7. ê³„íš ì·¨ì†Œ í…ŒìŠ¤íŠ¸
    print("\n7ï¸âƒ£ ê³„íš ì·¨ì†Œ í…ŒìŠ¤íŠ¸")
    
    try:
        # ìƒˆë¡œìš´ í…ŒìŠ¤íŠ¸ìš© ê³„íš ìƒì„±
        test_plan = await manager.create_managed_plan(
            mock_selection_result,
            "í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬",
            {"test": True},
            MonitoringLevel.MINIMAL
        )
        
        # ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì·¨ì†Œ ëª¨í‚¹
        manager.orchestrator.cancel_execution = AsyncMock(return_value=True)
        
        # ê³„íš ì·¨ì†Œ
        cancel_result = await manager.cancel_plan(test_plan.plan_id)
        
        if cancel_result:
            print(f"   âœ… ê³„íš ì·¨ì†Œ ì„±ê³µ")
            print(f"   - ì·¨ì†Œëœ ê³„íš ID: {test_plan.plan_id}")
            print(f"   - ê³„íš ìƒíƒœ: {test_plan.status.value}")
        else:
            print(f"   âŒ ê³„íš ì·¨ì†Œ ì‹¤íŒ¨")
            return False
            
    except Exception as e:
        print(f"   âŒ ê³„íš ì·¨ì†Œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False
    
    # 8. ê³„íš ì •ë¦¬ í…ŒìŠ¤íŠ¸
    print("\n8ï¸âƒ£ ê³„íš ì •ë¦¬ í…ŒìŠ¤íŠ¸")
    
    try:
        initial_count = len(manager.managed_plans)
        cleaned_count = manager.cleanup_old_plans(max_age_days=0)  # ì¦‰ì‹œ ì •ë¦¬
        final_count = len(manager.managed_plans)
        
        print(f"   âœ… ê³„íš ì •ë¦¬ ì„±ê³µ")
        print(f"   - ì´ˆê¸° ê³„íš ìˆ˜: {initial_count}")
        print(f"   - ì •ë¦¬ëœ ê³„íš ìˆ˜: {cleaned_count}")
        print(f"   - ìµœì¢… ê³„íš ìˆ˜: {final_count}")
        
    except Exception as e:
        print(f"   âŒ ê³„íš ì •ë¦¬ ì‹¤íŒ¨: {e}")
        return False
    
    print("\nğŸ‰ Execution Plan Manager í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    print("=" * 80)
    print(f"âœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼!")
    print(f"âœ… ê´€ë¦¬ë˜ëŠ” ê³„íš ìƒì„± ë° ì‹¤í–‰")
    print(f"âœ… ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ë° ì´ë²¤íŠ¸ ì¶”ì ")
    print(f"âœ… ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê³„ì‚° ë° ìµœì í™” ê¶Œê³ ")
    print(f"âœ… ê³„íš ìƒíƒœ ê´€ë¦¬ ë° ë¶„ì„")
    print(f"âœ… ê³„íš ì·¨ì†Œ ë° ì •ë¦¬ ê¸°ëŠ¥")
    
    return True


async def test_monitoring_levels():
    """ëª¨ë‹ˆí„°ë§ ë ˆë²¨ë³„ í…ŒìŠ¤íŠ¸"""
    
    print("\nğŸ§ª ëª¨ë‹ˆí„°ë§ ë ˆë²¨ë³„ í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    levels = [
        (MonitoringLevel.MINIMAL, "ìµœì†Œ ëª¨ë‹ˆí„°ë§"),
        (MonitoringLevel.STANDARD, "í‘œì¤€ ëª¨ë‹ˆí„°ë§"),
        (MonitoringLevel.DETAILED, "ìƒì„¸ ëª¨ë‹ˆí„°ë§"),
        (MonitoringLevel.COMPREHENSIVE, "ì¢…í•© ëª¨ë‹ˆí„°ë§")
    ]
    
    for level, description in levels:
        print(f"\nğŸ” {description} í…ŒìŠ¤íŠ¸")
        print(f"   ë ˆë²¨: {level.value}")
        print(f"   âœ… {description} ì„¤ì • ì™„ë£Œ")
    
    print(f"\nâœ… ëª¨ë“  ëª¨ë‹ˆí„°ë§ ë ˆë²¨ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")


async def test_optimization_strategies():
    """ìµœì í™” ì „ëµë³„ í…ŒìŠ¤íŠ¸"""
    
    print("\nğŸ§ª ìµœì í™” ì „ëµë³„ í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    strategies = [
        (OptimizationStrategy.PERFORMANCE, "ì„±ëŠ¥ ìµœì í™”"),
        (OptimizationStrategy.RELIABILITY, "ì‹ ë¢°ì„± ìµœì í™”"),
        (OptimizationStrategy.COST, "ë¹„ìš© ìµœì í™”"),
        (OptimizationStrategy.BALANCED, "ê· í˜• ìµœì í™”")
    ]
    
    for strategy, description in strategies:
        print(f"\nâš¡ {description} í…ŒìŠ¤íŠ¸")
        print(f"   ì „ëµ: {strategy.value}")
        print(f"   âœ… {description} ì„¤ì • ì™„ë£Œ")
    
    print(f"\nâœ… ëª¨ë“  ìµœì í™” ì „ëµ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")


async def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    
    print("ğŸš€ Execution Plan Manager ì¢…í•© í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("ğŸ”§ Phase 2.4: Execution Plan Manager ê²€ì¦")
    print("=" * 80)
    
    try:
        # 1. ë©”ì¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
        success = await test_execution_plan_manager()
        
        if success:
            # 2. ëª¨ë‹ˆí„°ë§ ë ˆë²¨ í…ŒìŠ¤íŠ¸
            await test_monitoring_levels()
            
            # 3. ìµœì í™” ì „ëµ í…ŒìŠ¤íŠ¸
            await test_optimization_strategies()
            
            print("\nğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼!")
            print("âœ… Execution Plan Manager êµ¬í˜„ ì™„ë£Œ")
            print("âœ… Phase 2.4 ì™„ë£Œ ì¤€ë¹„ë¨")
            
        else:
            print("\nâŒ ì¼ë¶€ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
            
    except Exception as e:
        print(f"\nâŒ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main()) 