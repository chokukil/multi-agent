"""
A2A ì—°ê²° í’€ ë° íƒ€ì„ì•„ì›ƒ ìµœì í™” ì‹œìŠ¤í…œ
Phase 2.2: A2A í†µì‹  ì„±ëŠ¥ ìµœì í™”

ê¸°ëŠ¥:
- ë™ì  ì—°ê²° í’€ í¬ê¸° ì¡°ì •
- ì ì‘ì  íƒ€ì„ì•„ì›ƒ ì„¤ì •
- ì—°ê²° ì¬ì‚¬ìš© ìµœì í™”
- ë°±í”„ë ˆì…” ì²˜ë¦¬
- ì„œí‚· ë¸Œë ˆì´ì»¤ íŒ¨í„´
- ì—°ê²° ê±´ê°•ì„± ëª¨ë‹ˆí„°ë§
"""

import asyncio
import time
import statistics
import logging
from dataclasses import dataclass, field
from typing import Dict, List, Any, Optional, Tuple, Set
from datetime import datetime, timedelta
from collections import defaultdict, deque
from enum import Enum
import httpx
import json
from pathlib import Path

logger = logging.getLogger(__name__)

class ConnectionState(Enum):
    """ì—°ê²° ìƒíƒœ"""
    HEALTHY = "healthy"
    DEGRADED = "degraded"
    UNHEALTHY = "unhealthy"
    CIRCUIT_OPEN = "circuit_open"

@dataclass
class ConnectionMetrics:
    """ì—°ê²° ë©”íŠ¸ë¦­"""
    total_requests: int = 0
    successful_requests: int = 0
    failed_requests: int = 0
    avg_response_time: float = 0.0
    max_response_time: float = 0.0
    min_response_time: float = float('inf')
    timeout_count: int = 0
    connection_errors: int = 0
    last_success_time: Optional[datetime] = None
    last_failure_time: Optional[datetime] = None
    response_times: deque = field(default_factory=lambda: deque(maxlen=100))
    
    @property
    def success_rate(self) -> float:
        """ì„±ê³µë¥  ê³„ì‚°"""
        if self.total_requests == 0:
            return 0.0
        return self.successful_requests / self.total_requests
    
    @property
    def error_rate(self) -> float:
        """ì—ëŸ¬ìœ¨ ê³„ì‚°"""
        if self.total_requests == 0:
            return 0.0
        return self.failed_requests / self.total_requests

@dataclass
class ConnectionPoolConfig:
    """ì—°ê²° í’€ ì„¤ì •"""
    min_pool_size: int = 5
    max_pool_size: int = 100
    initial_pool_size: int = 10
    pool_growth_factor: float = 1.5
    pool_shrink_factor: float = 0.8
    idle_timeout: float = 300.0  # 5ë¶„
    max_keepalive_connections: int = 20
    keepalive_expiry: float = 30.0
    
@dataclass
class TimeoutConfig:
    """íƒ€ì„ì•„ì›ƒ ì„¤ì •"""
    connect_timeout: float = 10.0
    read_timeout: float = 30.0
    write_timeout: float = 10.0
    pool_timeout: float = 5.0
    min_timeout: float = 1.0
    max_timeout: float = 300.0
    timeout_adaptation_factor: float = 0.1
    
@dataclass
class CircuitBreakerConfig:
    """ì„œí‚· ë¸Œë ˆì´ì»¤ ì„¤ì •"""
    failure_threshold: int = 5
    recovery_timeout: float = 60.0
    half_open_max_calls: int = 3
    success_threshold: int = 2

class AdaptiveConnectionPool:
    """ì ì‘ì  ì—°ê²° í’€"""
    
    def __init__(self, agent_url: str, pool_config: ConnectionPoolConfig, timeout_config: TimeoutConfig):
        self.agent_url = agent_url
        self.pool_config = pool_config
        self.timeout_config = timeout_config
        
        # ì—°ê²° í’€
        self.active_connections: Set[httpx.AsyncClient] = set()
        self.idle_connections: deque = deque()
        self.pool_size = pool_config.initial_pool_size
        
        # ë©”íŠ¸ë¦­
        self.metrics = ConnectionMetrics()
        self.state = ConnectionState.HEALTHY
        
        # íƒ€ì„ì•„ì›ƒ ì ì‘
        self.current_timeout = timeout_config.read_timeout
        self.timeout_history: deque = deque(maxlen=50)
        
        # í’€ ì¡°ì • íƒ€ì´ë¨¸
        self.last_pool_adjustment = datetime.now()
        self.pool_adjustment_interval = 30.0  # 30ì´ˆë§ˆë‹¤ í’€ í¬ê¸° ì¡°ì •
        
    async def get_connection(self) -> Optional[httpx.AsyncClient]:
        """ì—°ê²° í’€ì—ì„œ ì—°ê²° ê°€ì ¸ì˜¤ê¸°"""
        try:
            # ìœ íœ´ ì—°ê²° ì¬ì‚¬ìš©
            if self.idle_connections:
                client = self.idle_connections.popleft()
                if not client.is_closed:
                    self.active_connections.add(client)
                    return client
                else:
                    await client.aclose()
            
            # ìƒˆ ì—°ê²° ìƒì„± (í’€ í¬ê¸° ì œí•œ í™•ì¸)
            if len(self.active_connections) < self.pool_size:
                client = await self._create_new_connection()
                if client:
                    self.active_connections.add(client)
                    return client
            
            # í’€ì´ ê°€ë“ ì°¸ - ëŒ€ê¸° ë˜ëŠ” í’€ í™•ì¥ ê³ ë ¤
            if self._should_expand_pool():
                await self._expand_pool()
                client = await self._create_new_connection()
                if client:
                    self.active_connections.add(client)
                    return client
            
            return None
            
        except Exception as e:
            logger.error(f"ì—°ê²° í’€ì—ì„œ ì—°ê²° ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
            return None
    
    async def return_connection(self, client: httpx.AsyncClient, reusable: bool = True):
        """ì—°ê²°ì„ í’€ë¡œ ë°˜í™˜"""
        try:
            if client in self.active_connections:
                self.active_connections.remove(client)
            
            if reusable and not client.is_closed and len(self.idle_connections) < self.pool_config.max_keepalive_connections:
                self.idle_connections.append(client)
            else:
                await client.aclose()
                
        except Exception as e:
            logger.error(f"ì—°ê²° ë°˜í™˜ ì¤‘ ì˜¤ë¥˜: {e}")
            try:
                await client.aclose()
            except:
                pass
    
    async def _create_new_connection(self) -> Optional[httpx.AsyncClient]:
        """ìƒˆ ì—°ê²° ìƒì„±"""
        try:
            timeout = httpx.Timeout(
                connect=self.timeout_config.connect_timeout,
                read=self.current_timeout,
                write=self.timeout_config.write_timeout,
                pool=self.timeout_config.pool_timeout
            )
            
            limits = httpx.Limits(
                max_keepalive_connections=self.pool_config.max_keepalive_connections,
                max_connections=self.pool_config.max_pool_size,
                keepalive_expiry=self.pool_config.keepalive_expiry
            )
            
            client = httpx.AsyncClient(
                timeout=timeout,
                limits=limits,
                http2=True  # HTTP/2 ì§€ì›ìœ¼ë¡œ ì„±ëŠ¥ í–¥ìƒ
            )
            
            return client
            
        except Exception as e:
            logger.error(f"ìƒˆ ì—°ê²° ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    def _should_expand_pool(self) -> bool:
        """í’€ í™•ì¥ í•„ìš” ì—¬ë¶€ íŒë‹¨"""
        # ìµœê·¼ ì„±ëŠ¥ì´ ì €í•˜ë˜ê³  ìˆê³  í’€ì´ ê°€ë“ ì°¬ ê²½ìš°
        if (self.metrics.avg_response_time > self.current_timeout * 0.8 and
            self.pool_size < self.pool_config.max_pool_size and
            len(self.active_connections) >= self.pool_size * 0.9):
            return True
        
        # ì—ëŸ¬ìœ¨ì´ ë†’ì€ ê²½ìš°
        if (self.metrics.error_rate > 0.1 and
            self.pool_size < self.pool_config.max_pool_size):
            return True
        
        return False
    
    async def _expand_pool(self):
        """í’€ í¬ê¸° í™•ì¥"""
        old_size = self.pool_size
        self.pool_size = min(
            int(self.pool_size * self.pool_config.pool_growth_factor),
            self.pool_config.max_pool_size
        )
        
        logger.info(f"ì—°ê²° í’€ í™•ì¥: {old_size} -> {self.pool_size}")
    
    def _should_shrink_pool(self) -> bool:
        """í’€ ì¶•ì†Œ í•„ìš” ì—¬ë¶€ íŒë‹¨"""
        # ìµœê·¼ ì‚¬ìš©ëŸ‰ì´ ë‚®ê³  ì„±ëŠ¥ì´ ì¢‹ì€ ê²½ìš°
        if (len(self.active_connections) < self.pool_size * 0.3 and
            self.metrics.avg_response_time < self.current_timeout * 0.5 and
            self.pool_size > self.pool_config.min_pool_size):
            return True
        
        return False
    
    async def _shrink_pool(self):
        """í’€ í¬ê¸° ì¶•ì†Œ"""
        old_size = self.pool_size
        self.pool_size = max(
            int(self.pool_size * self.pool_config.pool_shrink_factor),
            self.pool_config.min_pool_size
        )
        
        # ì—¬ë¶„ì˜ ìœ íœ´ ì—°ê²° ë‹«ê¸°
        while len(self.idle_connections) > self.pool_size and self.idle_connections:
            client = self.idle_connections.pop()
            await client.aclose()
        
        logger.info(f"ì—°ê²° í’€ ì¶•ì†Œ: {old_size} -> {self.pool_size}")
    
    def adapt_timeout(self, response_time: float, success: bool):
        """íƒ€ì„ì•„ì›ƒ ì ì‘ì  ì¡°ì •"""
        self.timeout_history.append((response_time, success))
        
        if len(self.timeout_history) < 10:
            return
        
        # ìµœê·¼ ì‘ë‹µì‹œê°„ ë¶„ì„
        recent_times = [t for t, s in self.timeout_history[-10:] if s]
        
        if recent_times:
            avg_time = statistics.mean(recent_times)
            p95_time = self._percentile(recent_times, 95)
            
            # íƒ€ì„ì•„ì›ƒ ì¡°ì • (P95 + ë²„í¼)
            target_timeout = p95_time * 1.5
            
            # ì ì§„ì  ì¡°ì •
            adjustment = (target_timeout - self.current_timeout) * self.timeout_config.timeout_adaptation_factor
            self.current_timeout += adjustment
            
            # ë²”ìœ„ ì œí•œ
            self.current_timeout = max(self.timeout_config.min_timeout, 
                                     min(self.timeout_config.max_timeout, self.current_timeout))
    
    def update_metrics(self, response_time: float, success: bool, error_type: Optional[str] = None):
        """ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸"""
        self.metrics.total_requests += 1
        self.metrics.response_times.append(response_time)
        
        if success:
            self.metrics.successful_requests += 1
            self.metrics.last_success_time = datetime.now()
        else:
            self.metrics.failed_requests += 1
            self.metrics.last_failure_time = datetime.now()
            
            if error_type == "timeout":
                self.metrics.timeout_count += 1
            elif error_type == "connection":
                self.metrics.connection_errors += 1
        
        # í‰ê·  ì‘ë‹µì‹œê°„ ì—…ë°ì´íŠ¸
        if self.metrics.response_times:
            self.metrics.avg_response_time = statistics.mean(self.metrics.response_times)
            self.metrics.max_response_time = max(self.metrics.response_times)
            self.metrics.min_response_time = min(self.metrics.response_times)
        
        # íƒ€ì„ì•„ì›ƒ ì ì‘
        self.adapt_timeout(response_time, success)
        
        # ìƒíƒœ ì—…ë°ì´íŠ¸
        self._update_connection_state()
    
    def _update_connection_state(self):
        """ì—°ê²° ìƒíƒœ ì—…ë°ì´íŠ¸"""
        if self.metrics.total_requests < 5:
            return  # ì¶©ë¶„í•œ ë°ì´í„°ê°€ ì—†ìŒ
        
        error_rate = self.metrics.error_rate
        avg_response_time = self.metrics.avg_response_time
        
        if error_rate > 0.5 or avg_response_time > self.current_timeout * 2:
            self.state = ConnectionState.UNHEALTHY
        elif error_rate > 0.2 or avg_response_time > self.current_timeout * 1.5:
            self.state = ConnectionState.DEGRADED
        else:
            self.state = ConnectionState.HEALTHY
    
    async def periodic_maintenance(self):
        """ì£¼ê¸°ì ì¸ ì—°ê²° í’€ ìœ ì§€ë³´ìˆ˜"""
        try:
            now = datetime.now()
            
            # í’€ í¬ê¸° ì¡°ì • (30ì´ˆë§ˆë‹¤)
            if (now - self.last_pool_adjustment).total_seconds() > self.pool_adjustment_interval:
                if self._should_expand_pool():
                    await self._expand_pool()
                elif self._should_shrink_pool():
                    await self._shrink_pool()
                
                self.last_pool_adjustment = now
            
            # ì˜¤ë˜ëœ ìœ íœ´ ì—°ê²° ì •ë¦¬
            await self._cleanup_idle_connections()
            
        except Exception as e:
            logger.error(f"ì—°ê²° í’€ ìœ ì§€ë³´ìˆ˜ ì¤‘ ì˜¤ë¥˜: {e}")
    
    async def _cleanup_idle_connections(self):
        """ì˜¤ë˜ëœ ìœ íœ´ ì—°ê²° ì •ë¦¬"""
        # ê°„ë‹¨í•œ ì •ë¦¬ ë¡œì§ (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ íƒ€ì´ë° ì¶”ì  í•„ìš”)
        if len(self.idle_connections) > self.pool_config.max_keepalive_connections:
            while len(self.idle_connections) > self.pool_config.max_keepalive_connections:
                client = self.idle_connections.popleft()
                await client.aclose()
    
    def _percentile(self, data: List[float], percentile: float) -> float:
        """ë°±ë¶„ìœ„ìˆ˜ ê³„ì‚°"""
        if not data:
            return 0
        sorted_data = sorted(data)
        index = int(len(sorted_data) * percentile / 100)
        return sorted_data[min(index, len(sorted_data) - 1)]
    
    def get_status(self) -> Dict[str, Any]:
        """ì—°ê²° í’€ ìƒíƒœ ë°˜í™˜"""
        return {
            "agent_url": self.agent_url,
            "state": self.state.value,
            "pool_size": self.pool_size,
            "active_connections": len(self.active_connections),
            "idle_connections": len(self.idle_connections),
            "current_timeout": self.current_timeout,
            "metrics": {
                "total_requests": self.metrics.total_requests,
                "success_rate": self.metrics.success_rate,
                "error_rate": self.metrics.error_rate,
                "avg_response_time": self.metrics.avg_response_time,
                "timeout_count": self.metrics.timeout_count
            }
        }

class CircuitBreaker:
    """ì„œí‚· ë¸Œë ˆì´ì»¤ íŒ¨í„´ êµ¬í˜„"""
    
    def __init__(self, config: CircuitBreakerConfig):
        self.config = config
        self.failure_count = 0
        self.success_count = 0
        self.last_failure_time = None
        self.state = "closed"  # closed, open, half_open
        self.half_open_attempts = 0
    
    def should_allow_request(self) -> bool:
        """ìš”ì²­ í—ˆìš© ì—¬ë¶€ íŒë‹¨"""
        if self.state == "closed":
            return True
        elif self.state == "open":
            # ë³µêµ¬ ì‹œê°„ì´ ì§€ë‚¬ìœ¼ë©´ half-openìœ¼ë¡œ ì „í™˜
            if (self.last_failure_time and
                (datetime.now() - self.last_failure_time).total_seconds() > self.config.recovery_timeout):
                self.state = "half_open"
                self.half_open_attempts = 0
                return True
            return False
        elif self.state == "half_open":
            return self.half_open_attempts < self.config.half_open_max_calls
        
        return False
    
    def record_success(self):
        """ì„±ê³µ ê¸°ë¡"""
        if self.state == "half_open":
            self.success_count += 1
            if self.success_count >= self.config.success_threshold:
                self.state = "closed"
                self.failure_count = 0
                self.success_count = 0
        else:
            self.failure_count = 0
    
    def record_failure(self):
        """ì‹¤íŒ¨ ê¸°ë¡"""
        self.failure_count += 1
        self.last_failure_time = datetime.now()
        
        if self.state == "closed" and self.failure_count >= self.config.failure_threshold:
            self.state = "open"
        elif self.state == "half_open":
            self.state = "open"
            self.half_open_attempts = 0
        
        if self.state == "half_open":
            self.half_open_attempts += 1

class A2AConnectionOptimizer:
    """A2A ì—°ê²° ìµœì í™” ê´€ë¦¬ì"""
    
    def __init__(self):
        # ê¸°ë³¸ ì„¤ì •
        self.pool_config = ConnectionPoolConfig()
        self.timeout_config = TimeoutConfig()
        self.circuit_config = CircuitBreakerConfig()
        
        # ì—ì´ì „íŠ¸ë³„ ì—°ê²° í’€
        self.connection_pools: Dict[str, AdaptiveConnectionPool] = {}
        self.circuit_breakers: Dict[str, CircuitBreaker] = {}
        
        # ì „ì—­ ë©”íŠ¸ë¦­
        self.global_metrics = {
            "total_requests": 0,
            "total_successes": 0,
            "total_failures": 0,
            "avg_response_time": 0.0,
            "pool_efficiency": 0.0
        }
        
        # ëª¨ë‹ˆí„°ë§ íƒœìŠ¤í¬
        self.monitoring_task: Optional[asyncio.Task] = None
        self.is_monitoring = False
        
        # A2A ì—ì´ì „íŠ¸ êµ¬ì„±
        self.a2a_agents = {
            "orchestrator": "http://localhost:8100",
            "data_cleaning": "http://localhost:8306",
            "data_loader": "http://localhost:8307",
            "data_visualization": "http://localhost:8308",
            "data_wrangling": "http://localhost:8309",
            "feature_engineering": "http://localhost:8310",
            "sql_database": "http://localhost:8311",
            "eda_tools": "http://localhost:8312",
            "h2o_modeling": "http://localhost:8313",
            "mlflow_tracking": "http://localhost:8314",
            "pandas_data_analyst": "http://localhost:8315"
        }
        
        # ê²°ê³¼ ì €ì¥ ê²½ë¡œ
        self.results_dir = Path("monitoring/optimization_results")
        self.results_dir.mkdir(parents=True, exist_ok=True)
    
    async def initialize(self):
        """ìµœì í™” ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        logger.info("ğŸ”§ A2A ì—°ê²° ìµœì í™” ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
        
        # ê° ì—ì´ì „íŠ¸ë³„ ì—°ê²° í’€ ë° ì„œí‚· ë¸Œë ˆì´ì»¤ ìƒì„±
        for agent_name, agent_url in self.a2a_agents.items():
            self.connection_pools[agent_name] = AdaptiveConnectionPool(
                agent_url, self.pool_config, self.timeout_config
            )
            self.circuit_breakers[agent_name] = CircuitBreaker(self.circuit_config)
        
        # ëª¨ë‹ˆí„°ë§ ì‹œì‘
        await self.start_monitoring()
        
        logger.info("âœ… A2A ì—°ê²° ìµœì í™” ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
    
    async def send_optimized_request(self, agent_name: str, payload: Dict[str, Any]) -> Tuple[bool, Dict[str, Any], float]:
        """ìµœì í™”ëœ A2A ìš”ì²­ ì „ì†¡"""
        if agent_name not in self.connection_pools:
            return False, {"error": f"Unknown agent: {agent_name}"}, 0.0
        
        pool = self.connection_pools[agent_name]
        circuit_breaker = self.circuit_breakers[agent_name]
        
        # ì„œí‚· ë¸Œë ˆì´ì»¤ ì²´í¬
        if not circuit_breaker.should_allow_request():
            return False, {"error": "Circuit breaker open"}, 0.0
        
        start_time = time.time()
        client = None
        success = False
        response_data = {}
        
        try:
            # ì—°ê²° í’€ì—ì„œ ì—°ê²° ê°€ì ¸ì˜¤ê¸°
            client = await pool.get_connection()
            if not client:
                raise Exception("No available connections")
            
            # ìš”ì²­ ì „ì†¡
            response = await client.post(
                pool.agent_url,
                json=payload,
                headers={"Content-Type": "application/json"}
            )
            
            response_time = time.time() - start_time
            
            if response.status_code == 200:
                success = True
                response_data = response.json()
                circuit_breaker.record_success()
            else:
                response_data = {"error": f"HTTP {response.status_code}", "detail": response.text}
                circuit_breaker.record_failure()
            
            # ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
            pool.update_metrics(response_time, success, None)
            self._update_global_metrics(response_time, success)
            
            return success, response_data, response_time
            
        except asyncio.TimeoutError:
            response_time = time.time() - start_time
            pool.update_metrics(response_time, False, "timeout")
            circuit_breaker.record_failure()
            self._update_global_metrics(response_time, False)
            return False, {"error": "Request timeout"}, response_time
            
        except Exception as e:
            response_time = time.time() - start_time
            error_type = "connection" if "connection" in str(e).lower() else "unknown"
            pool.update_metrics(response_time, False, error_type)
            circuit_breaker.record_failure()
            self._update_global_metrics(response_time, False)
            return False, {"error": str(e)}, response_time
            
        finally:
            # ì—°ê²° ë°˜í™˜
            if client:
                await pool.return_connection(client, success)
    
    async def benchmark_optimization(self, test_duration_minutes: int = 10) -> Dict[str, Any]:
        """ìµœì í™” íš¨ê³¼ ë²¤ì¹˜ë§ˆí‚¹"""
        logger.info(f"ğŸ“Š {test_duration_minutes}ë¶„ê°„ ìµœì í™” íš¨ê³¼ ë²¤ì¹˜ë§ˆí‚¹ ì‹œì‘")
        
        start_time = datetime.now()
        end_time = start_time + timedelta(minutes=test_duration_minutes)
        
        benchmark_results = {
            "test_duration_minutes": test_duration_minutes,
            "start_time": start_time.isoformat(),
            "end_time": end_time.isoformat(),
            "agent_results": {},
            "optimization_metrics": {},
            "recommendations": []
        }
        
        # í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€
        test_messages = [
            "ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€",
            "ë°ì´í„° ë¶„ì„ì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”",
            "ì°¨íŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”",
            "ìš”ì•½ í†µê³„ë¥¼ ê³„ì‚°í•´ì£¼ì„¸ìš”"
        ]
        
        # ê° ì—ì´ì „íŠ¸ë³„ ë²¤ì¹˜ë§ˆí‚¹
        for agent_name in self.a2a_agents.keys():
            agent_results = []
            
            message_index = 0
            while datetime.now() < end_time:
                message = test_messages[message_index % len(test_messages)]
                
                payload = {
                    "jsonrpc": "2.0",
                    "id": f"benchmark_{time.time()}",
                    "method": "message/send",
                    "params": {
                        "message": {
                            "role": "user",
                            "parts": [{"kind": "text", "text": message}],
                            "messageId": f"bench_msg_{time.time()}"
                        },
                        "metadata": {}
                    }
                }
                
                success, response, response_time = await self.send_optimized_request(agent_name, payload)
                
                agent_results.append({
                    "timestamp": datetime.now().isoformat(),
                    "success": success,
                    "response_time": response_time,
                    "message": message
                })
                
                message_index += 1
                
                # 2ì´ˆ ê°„ê²©ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
                await asyncio.sleep(2)
            
            # ì—ì´ì „íŠ¸ë³„ ê²°ê³¼ ë¶„ì„
            benchmark_results["agent_results"][agent_name] = self._analyze_benchmark_results(agent_results)
        
        # ì „ì²´ ìµœì í™” ë©”íŠ¸ë¦­ ë¶„ì„
        benchmark_results["optimization_metrics"] = self._analyze_optimization_effectiveness()
        
        # ê°œì„  ê¶Œì¥ì‚¬í•­
        benchmark_results["recommendations"] = self._generate_optimization_recommendations()
        
        # ê²°ê³¼ ì €ì¥
        await self._save_benchmark_results(benchmark_results)
        
        return benchmark_results
    
    def _analyze_benchmark_results(self, results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ë²¤ì¹˜ë§ˆí‚¹ ê²°ê³¼ ë¶„ì„"""
        if not results:
            return {"error": "No benchmark data"}
        
        successful_results = [r for r in results if r["success"]]
        failed_results = [r for r in results if not r["success"]]
        
        response_times = [r["response_time"] for r in successful_results]
        
        analysis = {
            "total_requests": len(results),
            "successful_requests": len(successful_results),
            "failed_requests": len(failed_results),
            "success_rate": len(successful_results) / len(results) if results else 0,
            "response_time_stats": {}
        }
        
        if response_times:
            analysis["response_time_stats"] = {
                "avg": statistics.mean(response_times),
                "median": statistics.median(response_times),
                "min": min(response_times),
                "max": max(response_times),
                "p95": self._percentile(response_times, 95),
                "p99": self._percentile(response_times, 99)
            }
        
        return analysis
    
    def _analyze_optimization_effectiveness(self) -> Dict[str, Any]:
        """ìµœì í™” íš¨ê³¼ ë¶„ì„"""
        optimization_metrics = {}
        
        for agent_name, pool in self.connection_pools.items():
            pool_status = pool.get_status()
            
            optimization_metrics[agent_name] = {
                "pool_efficiency": self._calculate_pool_efficiency(pool),
                "timeout_adaptation": {
                    "initial_timeout": self.timeout_config.read_timeout,
                    "current_timeout": pool.current_timeout,
                    "adaptation_ratio": pool.current_timeout / self.timeout_config.read_timeout
                },
                "connection_state": pool_status["state"],
                "performance_grade": self._calculate_performance_grade(pool.metrics)
            }
        
        return optimization_metrics
    
    def _calculate_pool_efficiency(self, pool: AdaptiveConnectionPool) -> float:
        """ì—°ê²° í’€ íš¨ìœ¨ì„± ê³„ì‚°"""
        if pool.metrics.total_requests == 0:
            return 0.0
        
        # ì„±ê³µë¥  + ì ì • í’€ í™œìš©ë¥ ì„ ê¸°ë°˜ìœ¼ë¡œ íš¨ìœ¨ì„± ê³„ì‚°
        success_component = pool.metrics.success_rate
        
        # í’€ í™œìš©ë¥  (ë„ˆë¬´ í¬ì§€ë„ ì‘ì§€ë„ ì•Šì•„ì•¼ í•¨)
        utilization = len(pool.active_connections) / pool.pool_size
        optimal_utilization = 0.7  # 70%ê°€ ìµœì 
        utilization_component = 1 - abs(utilization - optimal_utilization)
        
        # ì‘ë‹µì‹œê°„ component
        if pool.metrics.avg_response_time > 0:
            response_component = min(1.0, pool.current_timeout / pool.metrics.avg_response_time / 2)
        else:
            response_component = 1.0
        
        efficiency = (success_component * 0.5 + utilization_component * 0.3 + response_component * 0.2)
        return max(0.0, min(1.0, efficiency))
    
    def _calculate_performance_grade(self, metrics: ConnectionMetrics) -> str:
        """ì„±ëŠ¥ ë“±ê¸‰ ê³„ì‚°"""
        if metrics.total_requests == 0:
            return "N/A"
        
        if metrics.success_rate > 0.95 and metrics.avg_response_time < 2.0:
            return "A"
        elif metrics.success_rate > 0.9 and metrics.avg_response_time < 3.0:
            return "B"
        elif metrics.success_rate > 0.8 and metrics.avg_response_time < 5.0:
            return "C"
        elif metrics.success_rate > 0.7:
            return "D"
        else:
            return "F"
    
    def _generate_optimization_recommendations(self) -> List[str]:
        """ìµœì í™” ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        for agent_name, pool in self.connection_pools.items():
            efficiency = self._calculate_pool_efficiency(pool)
            
            if efficiency < 0.6:
                recommendations.append(f"ğŸ”§ {agent_name}: ì—°ê²° í’€ íš¨ìœ¨ì„± ê°œì„  í•„ìš” (í˜„ì¬: {efficiency:.2f})")
            
            if pool.metrics.avg_response_time > pool.current_timeout * 0.8:
                recommendations.append(f"â±ï¸ {agent_name}: íƒ€ì„ì•„ì›ƒ ì¦ê°€ ê³ ë ¤ (í˜„ì¬: {pool.current_timeout:.2f}ì´ˆ)")
            
            if pool.metrics.error_rate > 0.1:
                recommendations.append(f"ğŸš¨ {agent_name}: ì—ëŸ¬ìœ¨ ê°œì„  í•„ìš” (í˜„ì¬: {pool.metrics.error_rate:.2%})")
            
            if len(pool.active_connections) >= pool.pool_size * 0.9:
                recommendations.append(f"ğŸ“ˆ {agent_name}: ì—°ê²° í’€ í¬ê¸° ì¦ê°€ ê³ ë ¤")
        
        return recommendations
    
    async def start_monitoring(self):
        """ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        if not self.is_monitoring:
            self.is_monitoring = True
            self.monitoring_task = asyncio.create_task(self._monitoring_loop())
            logger.info("ğŸ”„ A2A ì—°ê²° ìµœì í™” ëª¨ë‹ˆí„°ë§ ì‹œì‘")
    
    async def stop_monitoring(self):
        """ëª¨ë‹ˆí„°ë§ ì¤‘ì§€"""
        if self.is_monitoring and self.monitoring_task:
            self.is_monitoring = False
            self.monitoring_task.cancel()
            try:
                await self.monitoring_task
            except asyncio.CancelledError:
                pass
            logger.info("â¹ï¸ A2A ì—°ê²° ìµœì í™” ëª¨ë‹ˆí„°ë§ ì¤‘ì§€")
    
    async def _monitoring_loop(self):
        """ëª¨ë‹ˆí„°ë§ ë£¨í”„"""
        while self.is_monitoring:
            try:
                # ê° ì—°ê²° í’€ì˜ ì£¼ê¸°ì  ìœ ì§€ë³´ìˆ˜
                for pool in self.connection_pools.values():
                    await pool.periodic_maintenance()
                
                # 30ì´ˆë§ˆë‹¤ ì‹¤í–‰
                await asyncio.sleep(30)
                
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"ëª¨ë‹ˆí„°ë§ ë£¨í”„ ì˜¤ë¥˜: {e}")
                await asyncio.sleep(10)
    
    def _update_global_metrics(self, response_time: float, success: bool):
        """ì „ì—­ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸"""
        self.global_metrics["total_requests"] += 1
        
        if success:
            self.global_metrics["total_successes"] += 1
        else:
            self.global_metrics["total_failures"] += 1
        
        # ì´ë™ í‰ê· ìœ¼ë¡œ ì „ì—­ ì‘ë‹µì‹œê°„ ì—…ë°ì´íŠ¸
        alpha = 0.1
        if self.global_metrics["avg_response_time"] == 0:
            self.global_metrics["avg_response_time"] = response_time
        else:
            self.global_metrics["avg_response_time"] = (
                alpha * response_time + 
                (1 - alpha) * self.global_metrics["avg_response_time"]
            )
    
    async def _save_benchmark_results(self, results: Dict[str, Any]):
        """ë²¤ì¹˜ë§ˆí‚¹ ê²°ê³¼ ì €ì¥"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        file_path = self.results_dir / f"optimization_benchmark_{timestamp}.json"
        
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False, default=str)
        
        logger.info(f"ğŸ’¾ ìµœì í™” ë²¤ì¹˜ë§ˆí‚¹ ê²°ê³¼ ì €ì¥: {file_path}")
    
    def _percentile(self, data: List[float], percentile: float) -> float:
        """ë°±ë¶„ìœ„ìˆ˜ ê³„ì‚°"""
        if not data:
            return 0
        sorted_data = sorted(data)
        index = int(len(sorted_data) * percentile / 100)
        return sorted_data[min(index, len(sorted_data) - 1)]
    
    def get_optimization_status(self) -> Dict[str, Any]:
        """ìµœì í™” ì‹œìŠ¤í…œ ì „ì²´ ìƒíƒœ"""
        agent_statuses = {}
        for agent_name, pool in self.connection_pools.items():
            agent_statuses[agent_name] = pool.get_status()
        
        return {
            "system_status": "active" if self.is_monitoring else "inactive",
            "global_metrics": self.global_metrics,
            "agent_statuses": agent_statuses,
            "total_agents": len(self.connection_pools),
            "healthy_agents": len([p for p in self.connection_pools.values() if p.state == ConnectionState.HEALTHY]),
            "degraded_agents": len([p for p in self.connection_pools.values() if p.state == ConnectionState.DEGRADED])
        }


# ì‚¬ìš© ì˜ˆì‹œ ë° í…ŒìŠ¤íŠ¸
async def main():
    """ì—°ê²° ìµœì í™” ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
    optimizer = A2AConnectionOptimizer()
    
    # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    await optimizer.initialize()
    
    # ìµœì í™” íš¨ê³¼ ë²¤ì¹˜ë§ˆí‚¹ (5ë¶„ê°„)
    results = await optimizer.benchmark_optimization(test_duration_minutes=5)
    
    print("ğŸ”§ A2A ì—°ê²° ìµœì í™” ë²¤ì¹˜ë§ˆí‚¹ ê²°ê³¼:")
    print(f"ì „ì²´ ìµœì í™” íš¨ê³¼: {len(results['agent_results'])}ê°œ ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    
    # ê°œì„  ê¶Œì¥ì‚¬í•­ ì¶œë ¥
    if results["recommendations"]:
        print("\nğŸ“‹ ìµœì í™” ê¶Œì¥ì‚¬í•­:")
        for rec in results["recommendations"][:5]:
            print(f"  - {rec}")
    
    # ì‹œìŠ¤í…œ ìƒíƒœ ì¶œë ¥
    status = optimizer.get_optimization_status()
    print(f"\nğŸ“Š ì‹œìŠ¤í…œ ìƒíƒœ: {status['system_status']}")
    print(f"ê±´ê°•í•œ ì—ì´ì „íŠ¸: {status['healthy_agents']}/{status['total_agents']}")
    
    # ëª¨ë‹ˆí„°ë§ ì¤‘ì§€
    await optimizer.stop_monitoring()

if __name__ == "__main__":
    asyncio.run(main()) 