#!/usr/bin/env python3
"""
ğŸ§ª CherryAI Shared Knowledge Bank í…ŒìŠ¤íŠ¸

ê³ ê¸‰ ì„ë² ë”© ê²€ìƒ‰ ì‹œìŠ¤í…œì˜ ê¸°ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•˜ê³  ê²€ì¦í•©ë‹ˆë‹¤.
"""

import asyncio
import os
import sys
import logging

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python pathì— ì¶”ê°€
sys.path.append(os.path.dirname(__file__))

from core.shared_knowledge_bank import (
    AdvancedSharedKnowledgeBank,
    KnowledgeType,
    SearchStrategy,
    initialize_shared_knowledge_bank,
    add_user_file_knowledge,
    add_agent_memory,
    search_relevant_knowledge
)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

async def test_basic_functionality():
    """ê¸°ë³¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print("ğŸ§ª ê¸°ë³¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    # ì§€ì‹ ë±…í¬ ì´ˆê¸°í™”
    kb = initialize_shared_knowledge_bank(
        persist_directory="./test_chroma_kb",
        max_chunk_size=256,
        chunk_overlap=25
    )
    
    # 1. ì§€ì‹ ì¶”ê°€ í…ŒìŠ¤íŠ¸
    print("\n1ï¸âƒ£ ì§€ì‹ ì¶”ê°€ í…ŒìŠ¤íŠ¸")
    
    # CherryAI ê´€ë ¨ ì§€ì‹ ì¶”ê°€
    cherry_ai_knowledge = """
    CherryAIëŠ” ì„¸ê³„ ìµœì´ˆì˜ A2A (Agent-to-Agent) + MCP (Model Context Protocol) í†µí•© í”Œë«í¼ì…ë‹ˆë‹¤.
    
    ì£¼ìš” íŠ¹ì§•:
    - 11ê°œì˜ A2A ì—ì´ì „íŠ¸ê°€ í˜‘ì—…í•˜ì—¬ ë°ì´í„° ë¶„ì„ ìˆ˜í–‰
    - 7ê°œì˜ MCP ë„êµ¬ì™€ ì™„ì „ í†µí•©
    - ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ ì§€ì›
    - Context Engineering 6 Data Layers êµ¬í˜„
    - LLM First ì›ì¹™ ì¤€ìˆ˜
    
    A2A ì—ì´ì „íŠ¸ ëª©ë¡:
    1. Orchestrator (8100) - ì „ì²´ ì¡°ìœ¨
    2. Pandas Data Analyst (8315) - ë°ì´í„° ë¶„ì„
    3. Data Loader (8306) - ë°ì´í„° ë¡œë”©
    4. Data Cleaning (8307) - ë°ì´í„° ì •ì œ
    5. EDA Tools (8308) - íƒìƒ‰ì  ë°ì´í„° ë¶„ì„
    6. Data Visualization (8309) - ì‹œê°í™”
    7. Feature Engineering (8310) - í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§
    8. H2O ML (8311) - ë¨¸ì‹ ëŸ¬ë‹
    9. MLflow Tools (8312) - ML ì‹¤í—˜ ê´€ë¦¬
    10. Data Wrangling (8313) - ë°ì´í„° ê°€ê³µ
    11. SQL Database (8314) - ë°ì´í„°ë² ì´ìŠ¤ ì—°ë™
    
    MCP ë„êµ¬ ëª©ë¡:
    1. Playwright (3000) - ì›¹ ë¸Œë¼ìš°ì € ìë™í™”
    2. File Manager (3001) - íŒŒì¼ ì‹œìŠ¤í…œ ê´€ë¦¬
    3. Database Connector (3002) - DB ì—°ê²°
    4. API Gateway (3003) - ì™¸ë¶€ API í˜¸ì¶œ
    5. Data Analyzer (3004) - ê³ ê¸‰ ë°ì´í„° ë¶„ì„
    6. Chart Generator (3005) - ê³ ê¸‰ ì‹œê°í™”
    7. LLM Gateway (3006) - ë‹¤ì¤‘ LLM í†µí•©
    """
    
    entry_id1 = await kb.add_knowledge(
        content=cherry_ai_knowledge,
        knowledge_type=KnowledgeType.SYSTEM_CONFIG,
        source_agent="system",
        title="CherryAI í”Œë«í¼ ì™„ì „ ê°€ì´ë“œ",
        summary="CherryAIì˜ A2A+MCP í†µí•© ì•„í‚¤í…ì²˜ ì„¤ëª…",
        keywords=["CherryAI", "A2A", "MCP", "ì—ì´ì „íŠ¸", "í˜‘ì—…"],
        tags={"platform", "architecture", "guide"}
    )
    print(f"âœ… CherryAI ì§€ì‹ ì¶”ê°€ ì™„ë£Œ: {entry_id1}")
    
    # ë°ì´í„° ë¶„ì„ ëª¨ë²” ì‚¬ë¡€ ì¶”ê°€
    analysis_best_practices = """
    ë°ì´í„° ë¶„ì„ ëª¨ë²” ì‚¬ë¡€:
    
    1. ë°ì´í„° íƒìƒ‰ ë‹¨ê³„
    - ë°ì´í„° í˜•íƒœì™€ í¬ê¸° íŒŒì•…
    - ê²°ì¸¡ê°’ê³¼ ì´ìƒì¹˜ í™•ì¸
    - ê¸°ë³¸ í†µê³„ëŸ‰ ê³„ì‚°
    - ë°ì´í„° ë¶„í¬ ì‹œê°í™”
    
    2. ë°ì´í„° ì „ì²˜ë¦¬
    - ê²°ì¸¡ê°’ ì²˜ë¦¬ (ì‚­ì œ/ëŒ€ì²´)
    - ì´ìƒì¹˜ ì²˜ë¦¬
    - ë°ì´í„° íƒ€ì… ë³€í™˜
    - ì •ê·œí™”/í‘œì¤€í™”
    
    3. íƒìƒ‰ì  ë°ì´í„° ë¶„ì„ (EDA)
    - ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„ ë¶„ì„
    - íŒ¨í„´ê³¼ íŠ¸ë Œë“œ ë°œê²¬
    - ê°€ì„¤ ìˆ˜ë¦½ ë° ê²€ì¦
    - ì‹œê°í™”ë¥¼ í†µí•œ ì¸ì‚¬ì´íŠ¸ ë„ì¶œ
    
    4. ëª¨ë¸ë§
    - ì ì ˆí•œ ì•Œê³ ë¦¬ì¦˜ ì„ íƒ
    - êµì°¨ ê²€ì¦ ìˆ˜í–‰
    - í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
    - ì„±ëŠ¥ í‰ê°€ ë° í•´ì„
    """
    
    entry_id2 = await kb.add_knowledge(
        content=analysis_best_practices,
        knowledge_type=KnowledgeType.BEST_PRACTICE,
        source_agent="pandas_collaboration_hub",
        title="ë°ì´í„° ë¶„ì„ ëª¨ë²” ì‚¬ë¡€",
        summary="ì²´ê³„ì ì¸ ë°ì´í„° ë¶„ì„ í”„ë¡œì„¸ìŠ¤ ê°€ì´ë“œ",
        keywords=["ë°ì´í„°ë¶„ì„", "EDA", "ì „ì²˜ë¦¬", "ëª¨ë¸ë§"],
        tags={"best_practice", "data_analysis", "methodology"}
    )
    print(f"âœ… ë¶„ì„ ëª¨ë²” ì‚¬ë¡€ ì¶”ê°€ ì™„ë£Œ: {entry_id2}")
    
    # Python í”„ë¡œê·¸ë˜ë° íŒ ì¶”ê°€
    python_tips = """
    Python ë°ì´í„° ë¶„ì„ íŒ:
    
    1. Pandas í™œìš©ë²•
    - DataFrameê³¼ Series íš¨ê³¼ì  ì‚¬ìš©
    - ê·¸ë£¹ë°”ì´ì™€ ì§‘ê³„ ì—°ì‚°
    - ë°ì´í„° ë³‘í•©ê³¼ ì¡°ì¸
    - ë‚ ì§œ/ì‹œê°„ ë°ì´í„° ì²˜ë¦¬
    
    2. ì‹œê°í™” ë¼ì´ë¸ŒëŸ¬ë¦¬
    - Matplotlib ê¸°ë³¸ í”Œë¡¯
    - Seaborn í†µê³„ ì‹œê°í™”
    - Plotly ì¸í„°ë™í‹°ë¸Œ ì°¨íŠ¸
    - ë§ì¶¤í˜• ì°¨íŠ¸ ìƒì„±
    
    3. ì„±ëŠ¥ ìµœì í™”
    - ë²¡í„°í™” ì—°ì‚° í™œìš©
    - ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ë°ì´í„° íƒ€ì… ì‚¬ìš©
    - ì²­í¬ ë‹¨ìœ„ ë°ì´í„° ì²˜ë¦¬
    - ë©€í‹°í”„ë¡œì„¸ì‹± í™œìš©
    """
    
    entry_id3 = await kb.add_knowledge(
        content=python_tips,
        knowledge_type=KnowledgeType.DOMAIN_KNOWLEDGE,
        source_agent="data_loader",
        title="Python ë°ì´í„° ë¶„ì„ íŒ",
        summary="íš¨ìœ¨ì ì¸ Python ë°ì´í„° ë¶„ì„ ê¸°ë²•",
        keywords=["Python", "Pandas", "ì‹œê°í™”", "ìµœì í™”"],
        tags={"programming", "tips", "python"}
    )
    print(f"âœ… Python íŒ ì¶”ê°€ ì™„ë£Œ: {entry_id3}")
    
    return entry_id1, entry_id2, entry_id3

async def test_search_functionality(entry_ids):
    """ê²€ìƒ‰ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print("\n2ï¸âƒ£ ê²€ìƒ‰ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸")
    
    kb = initialize_shared_knowledge_bank()
    
    # ë‹¤ì–‘í•œ ê²€ìƒ‰ ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸
    test_queries = [
        "A2A ì—ì´ì „íŠ¸ëŠ” ëª‡ ê°œì¸ê°€ìš”?",
        "ë°ì´í„° ì „ì²˜ë¦¬ ë°©ë²•",
        "Python Pandas ì‚¬ìš©ë²•",
        "MCP ë„êµ¬ ëª©ë¡",
        "ì‹œê°í™” ë¼ì´ë¸ŒëŸ¬ë¦¬",
        "CherryAI ì•„í‚¤í…ì²˜"
    ]
    
    for query in test_queries:
        print(f"\nğŸ” ì¿¼ë¦¬: '{query}'")
        
        results = await kb.search_knowledge(
            query=query,
            strategy=SearchStrategy.HYBRID,
            max_results=3,
            min_similarity=0.1
        )
        
        if results:
            for i, result in enumerate(results, 1):
                print(f"  {i}. {result.title}")
                print(f"     ìœ ì‚¬ë„: {result.similarity_score:.3f}")
                print(f"     ì¶œì²˜: {result.source_agent}")
                print(f"     íƒ€ì…: {result.knowledge_type.value}")
                print(f"     ìŠ¤ë‹ˆí«: {result.context_snippet[:100]}...")
                print()
        else:
            print("  ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")

async def test_agent_specific_search():
    """ì—ì´ì „íŠ¸ë³„ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸"""
    print("\n3ï¸âƒ£ ì—ì´ì „íŠ¸ë³„ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸")
    
    kb = initialize_shared_knowledge_bank()
    
    # ì—ì´ì „íŠ¸ë³„ ì§€ì‹ ì¡°íšŒ
    agents = ["system", "pandas_collaboration_hub", "data_loader"]
    
    for agent in agents:
        print(f"\nğŸ“Š {agent} ì—ì´ì „íŠ¸ì˜ ì§€ì‹:")
        
        agent_knowledge = await kb.get_agent_knowledge(agent, limit=5)
        
        if agent_knowledge:
            for knowledge in agent_knowledge:
                print(f"  - {knowledge.title}")
                print(f"    ìƒì„±ì¼: {knowledge.created_at.strftime('%Y-%m-%d %H:%M')}")
        else:
            print("  ì €ì¥ëœ ì§€ì‹ ì—†ìŒ")

async def test_statistics():
    """í†µê³„ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print("\n4ï¸âƒ£ í†µê³„ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸")
    
    kb = initialize_shared_knowledge_bank()
    
    stats = await kb.get_stats()
    
    print(f"ğŸ“ˆ ì§€ì‹ ë±…í¬ í†µê³„:")
    print(f"  - ì´ ì§€ì‹ í•­ëª©: {stats.total_entries}ê°œ")
    print(f"  - ì´ ê²€ìƒ‰ íšŸìˆ˜: {stats.total_searches}íšŒ")
    print(f"  - í‰ê·  ì‘ë‹µ ì‹œê°„: {stats.avg_response_time:.3f}ì´ˆ")
    print(f"  - ì €ì¥ì†Œ í¬ê¸°: {stats.storage_size_mb:.2f}MB")
    print(f"  - ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: {stats.last_update.strftime('%Y-%m-%d %H:%M:%S')}")
    
    print(f"\nğŸ“Š ì§€ì‹ ìœ í˜•ë³„ ë¶„í¬:")
    for knowledge_type, count in stats.entries_by_type.items():
        print(f"  - {knowledge_type.value}: {count}ê°œ")
    
    print(f"\nğŸ¤– ì—ì´ì „íŠ¸ë³„ ë¶„í¬:")
    for agent, count in stats.entries_by_agent.items():
        print(f"  - {agent}: {count}ê°œ")

async def test_context_engineering_integration():
    """Context Engineering í†µí•© í…ŒìŠ¤íŠ¸"""
    print("\n5ï¸âƒ£ Context Engineering í†µí•© í…ŒìŠ¤íŠ¸")
    
    # ì‚¬ìš©ì íŒŒì¼ ì§€ì‹ ì¶”ê°€ í…ŒìŠ¤íŠ¸
    file_content = """
    ìƒ˜í”Œ ë°ì´í„°ì…‹ ë¶„ì„ ìš”ì²­
    
    ì´ íŒŒì¼ì€ ê³ ê° êµ¬ë§¤ ë°ì´í„°ë¥¼ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤.
    - ê³ ê° ID, êµ¬ë§¤ ë‚ ì§œ, ìƒí’ˆëª…, ê¸ˆì•¡
    - 2023ë…„ ì „ì²´ ê±°ë˜ ë°ì´í„°
    - ì´ 10,000ê±´ì˜ ê±°ë˜ ê¸°ë¡
    
    ë¶„ì„ ìš”êµ¬ì‚¬í•­:
    1. ì›”ë³„ ë§¤ì¶œ íŠ¸ë Œë“œ ë¶„ì„
    2. ì¸ê¸° ìƒí’ˆ TOP 10 ë„ì¶œ
    3. ê³ ê° ì„¸ë¶„í™” ë° RFM ë¶„ì„
    4. ê³„ì ˆì„± íŒ¨í„´ ë°œê²¬
    """
    
    file_entry_id = await add_user_file_knowledge(
        file_content=file_content,
        filename="customer_data_analysis.txt",
        session_id="test_session_001"
    )
    print(f"âœ… ì‚¬ìš©ì íŒŒì¼ ì§€ì‹ ì¶”ê°€: {file_entry_id}")
    
    # ì—ì´ì „íŠ¸ ë©”ëª¨ë¦¬ ì¶”ê°€ í…ŒìŠ¤íŠ¸
    memory_content = """
    Pandas í˜‘ì—… í—ˆë¸Œì—ì„œ í•™ìŠµí•œ ë‚´ìš©:
    - ì‚¬ìš©ìê°€ ìì£¼ ìš”ì²­í•˜ëŠ” ë¶„ì„: íŠ¸ë Œë“œ ë¶„ì„, ìƒê´€ê´€ê³„ ë¶„ì„
    - íš¨ê³¼ì ì¸ ì‹œê°í™”: ì‹œê³„ì—´ í”Œë¡¯, íˆíŠ¸ë§µ, ë°•ìŠ¤í”Œë¡¯
    - ì„±ëŠ¥ ìµœì í™”: ë²¡í„° ì—°ì‚°, ì¸ë±ì‹± í™œìš©
    """
    
    memory_entry_id = await add_agent_memory(
        content=memory_content,
        agent_id="pandas_collaboration_hub",
        memory_type="learning_pattern"
    )
    print(f"âœ… ì—ì´ì „íŠ¸ ë©”ëª¨ë¦¬ ì¶”ê°€: {memory_entry_id}")
    
    # ê´€ë ¨ ì§€ì‹ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    print(f"\nğŸ”— ê´€ë ¨ ì§€ì‹ ê²€ìƒ‰:")
    relevant_knowledge = await search_relevant_knowledge(
        query="ê³ ê° ë°ì´í„° ë¶„ì„ ë°©ë²•",
        agent_id="pandas_collaboration_hub"
    )
    
    for knowledge in relevant_knowledge[:3]:
        print(f"  - {knowledge.title} (ìœ ì‚¬ë„: {knowledge.similarity_score:.3f})")

async def test_cleanup_and_export():
    """ì •ë¦¬ ë° ë‚´ë³´ë‚´ê¸° í…ŒìŠ¤íŠ¸"""
    print("\n6ï¸âƒ£ ì •ë¦¬ ë° ë‚´ë³´ë‚´ê¸° í…ŒìŠ¤íŠ¸")
    
    kb = initialize_shared_knowledge_bank()
    
    # ì§€ì‹ ë±…í¬ ë‚´ë³´ë‚´ê¸°
    export_path = "./knowledge_bank_export.json"
    success = await kb.export_knowledge(export_path)
    
    if success and os.path.exists(export_path):
        file_size = os.path.getsize(export_path) / 1024  # KB
        print(f"âœ… ì§€ì‹ ë±…í¬ ë‚´ë³´ë‚´ê¸° ì™„ë£Œ: {export_path} ({file_size:.1f}KB)")
        
        # ë‚´ë³´ë‚¸ íŒŒì¼ ì‚­ì œ (í…ŒìŠ¤íŠ¸ ì •ë¦¬)
        os.remove(export_path)
        print("ğŸ—‘ï¸  ë‚´ë³´ë‚¸ íŒŒì¼ ì •ë¦¬ ì™„ë£Œ")
    else:
        print("âŒ ì§€ì‹ ë±…í¬ ë‚´ë³´ë‚´ê¸° ì‹¤íŒ¨")

async def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    print("ğŸš€ CherryAI Shared Knowledge Bank í…ŒìŠ¤íŠ¸ ì‹œì‘\n")
    
    try:
        # 1. ê¸°ë³¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
        entry_ids = await test_basic_functionality()
        
        # 2. ê²€ìƒ‰ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸  
        await test_search_functionality(entry_ids)
        
        # 3. ì—ì´ì „íŠ¸ë³„ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
        await test_agent_specific_search()
        
        # 4. í†µê³„ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
        await test_statistics()
        
        # 5. Context Engineering í†µí•© í…ŒìŠ¤íŠ¸
        await test_context_engineering_integration()
        
        # 6. ì •ë¦¬ ë° ë‚´ë³´ë‚´ê¸° í…ŒìŠ¤íŠ¸
        await test_cleanup_and_export()
        
        print("\nğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        print("\nğŸ“‹ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½:")
        print("âœ… ChromaDB ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì—°ë™")
        print("âœ… ì„ë² ë”© ê¸°ë°˜ ì˜ë¯¸ì  ê²€ìƒ‰")
        print("âœ… ë©”íƒ€ë°ì´í„° í•„í„°ë§")
        print("âœ… A2A ì—ì´ì „íŠ¸ë³„ ì§€ì‹ ê´€ë¦¬")
        print("âœ… Context Engineering í†µí•©")
        print("âœ… ì‹¤ì‹œê°„ í†µê³„ ì¶”ì ")
        print("âœ… ì§€ì‹ ë‚´ë³´ë‚´ê¸°/ì •ë¦¬")
        
    except Exception as e:
        print(f"\nâŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(main()) 