# CherryAI ì‹œìŠ¤í…œ ìµœì í™” ì„¤ê³„ ë¬¸ì„œ

## ğŸ“‹ ê°œìš”

CherryAIëŠ” A2A SDK 0.2.9 ê¸°ë°˜ì˜ ì°¨ì„¸ëŒ€ ë©€í‹°ì—ì´ì „íŠ¸ ë°ì´í„° ë¶„ì„ í”Œë«í¼ìœ¼ë¡œ, 11ê°œ ì—ì´ì „íŠ¸ì˜ 88ê°œ ê¸°ëŠ¥ì„ 100% ê²€ì¦í•˜ì—¬ ChatGPT Data Analyst ìˆ˜ì¤€ì˜ ì„±ëŠ¥ê³¼ ì‚¬ìš©ì„±ì„ ë‹¬ì„±í•©ë‹ˆë‹¤.

### í˜„ì¬ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ ë¶„ì„

**ê¸°ì¡´ êµ¬í˜„ ìƒíƒœ (2025.01.19):**
- âœ… A2A SDK 0.2.9 ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° (a2a_orchestrator.py) - ì™„ì „ êµ¬í˜„
- âœ… 11ê°œ A2A ì—ì´ì „íŠ¸ ì„œë²„ (í¬íŠ¸ 8306-8316) - ê¸°ë³¸ êµ¬í˜„ ì™„ë£Œ
- âœ… Universal Engine ê¸°ë°˜ cherry_ai.py - êµ¬ì¡° ì™„ì„±
- âœ… start.sh/stop.sh ì‹œìŠ¤í…œ ê´€ë¦¬ - ì™„ì „ êµ¬í˜„
- âš ï¸ Langfuse v2 í†µí•© - ê¸°ë³¸ êµ¬ì¡° ì¡´ì¬, EMP_NO í†µí•© í•„ìš”
- âš ï¸ SSE ìŠ¤íŠ¸ë¦¬ë° - ê¸°ë³¸ êµ¬í˜„, 0.001ì´ˆ ì§€ì—° ìµœì í™” í•„ìš”
- âŒ E2E ê²€ì¦ ì‹œìŠ¤í…œ - Playwright MCP í†µí•© í•„ìš”
- âŒ ë²”ìš© ë„ë©”ì¸ ì ì‘ ì‹œìŠ¤í…œ - LLM First Universal Engine ì™„ì „ ê²€ì¦ í•„ìš”

### ìµœì í™” ëª©í‘œ

1. **ì™„ì „í•œ ê¸°ëŠ¥ êµ¬í˜„**: ëª¨ë“  ì—ì´ì „íŠ¸ì˜ 88ê°œ ê¸°ëŠ¥ 100% ë™ì‘ ë³´ì¥
2. **ì„±ëŠ¥ ìµœì í™”**: qwen3-4b-fast ëª¨ë¸ ê¸°ë°˜ ì‹¤ìš©ì  ì†ë„ ë‹¬ì„± (í‰ê·  45ì´ˆ)
3. **ì‚¬ìš©ì ê²½í—˜**: ChatGPT ìˆ˜ì¤€ì˜ ì§ê´€ì  UI/UX ì™„ì„±
4. **ê²€ì¦ ì‹œìŠ¤í…œ**: Playwright MCP ê¸°ë°˜ ì™„ì „ ìë™í™” í…ŒìŠ¤íŠ¸
5. **LLM First ì›ì¹™**: Zero-Hardcoding 100% ë‹¬ì„±, ë²”ìš© ë„ë©”ì¸ ì ì‘

### 11ê°œ ê¸°ì¡´ ì—ì´ì „íŠ¸ ì „ì²´ ê¸°ëŠ¥ ê²€ì¦ ì‹œìŠ¤í…œ

**ê²€ì¦ ëŒ€ìƒ ì—ì´ì „íŠ¸ (ì´ë¯¸ êµ¬í˜„ë¨):**
- Data Cleaning Agent (8306): ê¸°ì¡´ êµ¬í˜„ëœ ëª¨ë“  ê¸°ëŠ¥ ê²€ì¦
- Data Loader Agent (8307): ê¸°ì¡´ êµ¬í˜„ëœ ëª¨ë“  ê¸°ëŠ¥ ê²€ì¦
- Data Visualization Agent (8308): ê¸°ì¡´ êµ¬í˜„ëœ ëª¨ë“  ê¸°ëŠ¥ ê²€ì¦
- Data Wrangling Agent (8309): ê¸°ì¡´ êµ¬í˜„ëœ ëª¨ë“  ê¸°ëŠ¥ ê²€ì¦
- Feature Engineering Agent (8310): ê¸°ì¡´ êµ¬í˜„ëœ ëª¨ë“  ê¸°ëŠ¥ ê²€ì¦
- SQL Database Agent (8311): ê¸°ì¡´ êµ¬í˜„ëœ ëª¨ë“  ê¸°ëŠ¥ ê²€ì¦
- EDA Tools Agent (8312): ê¸°ì¡´ êµ¬í˜„ëœ ëª¨ë“  ê¸°ëŠ¥ ê²€ì¦
- H2O ML Agent (8313): ê¸°ì¡´ êµ¬í˜„ëœ ëª¨ë“  ê¸°ëŠ¥ ê²€ì¦
- MLflow Tools Agent (8314): ê¸°ì¡´ êµ¬í˜„ëœ ëª¨ë“  ê¸°ëŠ¥ ê²€ì¦
- Pandas Analyst Agent (8210): ê¸°ì¡´ êµ¬í˜„ëœ ëª¨ë“  ê¸°ëŠ¥ ê²€ì¦
- Report Generator Agent (8316): ê¸°ì¡´ êµ¬í˜„ëœ ëª¨ë“  ê¸°ëŠ¥ ê²€ì¦

**ê²€ì¦ ëª©í‘œ:** ê° ì—ì´ì „íŠ¸ì˜ í˜„ì¬ êµ¬í˜„ëœ ëª¨ë“  ê¸°ëŠ¥ì„ ë°œê²¬í•˜ê³  100% ê²€ì¦

## ğŸ—ï¸ ì•„í‚¤í…ì²˜

### ì‹œìŠ¤í…œ ì „ì²´ ì•„í‚¤í…ì²˜

```mermaid
graph TB
    subgraph "ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ ê³„ì¸µ"
        UI[Cherry AI Streamlit UI]
        Chat[ChatGPT ìŠ¤íƒ€ì¼ ì±„íŒ…]
        Upload[ë“œë˜ê·¸ì•¤ë“œë¡­ ì—…ë¡œë“œ]
        Progress[ì‹¤ì‹œê°„ ì§„í–‰ í‘œì‹œ]
    end
    
    subgraph "ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ê³„ì¸µ"
        Orch[A2A ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°<br/>í¬íŠ¸ 8100]
        Plan[LLM ê¸°ë°˜ ê³„íš ìˆ˜ë¦½]
        Route[ë™ì  ì—ì´ì „íŠ¸ ë¼ìš°íŒ…]
        Stream[SSE ìŠ¤íŠ¸ë¦¬ë° ê´€ë¦¬]
    end
    
    subgraph "A2A ì—ì´ì „íŠ¸ ê³„ì¸µ"
        A1[Data Cleaning<br/>8306]
        A2[Data Loader<br/>8307] 
        A3[Data Visualization<br/>8308]
        A4[Data Wrangling<br/>8309]
        A5[Feature Engineering<br/>8310]
        A6[SQL Database<br/>8311]
        A7[EDA Tools<br/>8312]
        A8[H2O ML<br/>8313]
        A9[MLflow Tools<br/>8314]
        A10[Pandas Analyst<br/>8210]
        A11[Report Generator<br/>8316]
    end
    
    subgraph "ì§€ì› ì„œë¹„ìŠ¤ ê³„ì¸µ"
        LLM[qwen3-4b-fast<br/>Ollama]
        Langfuse[Langfuse v2<br/>ì¶”ì  ì‹œìŠ¤í…œ]
        Cache[ê²°ê³¼ ìºì‹œ]
        Monitor[ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§]
    end
    
    subgraph "ê²€ì¦ ê³„ì¸µ"
        E2E[Playwright MCP<br/>E2E í…ŒìŠ¤íŠ¸]
        Unit[ë‹¨ìœ„ í…ŒìŠ¤íŠ¸]
        Integration[í†µí•© í…ŒìŠ¤íŠ¸]
        Domain[ë„ë©”ì¸ í…ŒìŠ¤íŠ¸]
    end
    
    UI --> Orch
    Chat --> Plan
    Upload --> Route
    Progress --> Stream
    
    Orch --> A1
    Orch --> A2
    Orch --> A3
    Orch --> A4
    Orch --> A5
    Orch --> A6
    Orch --> A7
    Orch --> A8
    Orch --> A9
    Orch --> A10
    Orch --> A11
    
    Plan --> LLM
    Route --> LLM
    Stream --> Langfuse
    
    A1 --> Cache
    A2 --> Cache
    A3 --> Cache
    A4 --> Cache
    A5 --> Cache
    A6 --> Cache
    A7 --> Cache
    A8 --> Cache
    A9 --> Cache
    A10 --> Cache
    A11 --> Cache
    
    E2E --> UI
    Unit --> A1
    Integration --> Orch
    Domain --> A7
```

### ëª¨ë“ˆ êµ¬ì¡° ì„¤ê³„

```
cherry_ai.py (ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜)
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ orchestrator/
â”‚   â”‚   â”œâ”€â”€ a2a_orchestrator_optimized.py    # ìµœì í™”ëœ A2A ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°
â”‚   â”‚   â”œâ”€â”€ streaming_manager.py             # SSE ìŠ¤íŠ¸ë¦¬ë° ê´€ë¦¬ (0.001ì´ˆ ì§€ì—°)
â”‚   â”‚   â”œâ”€â”€ agent_health_monitor.py          # ì‹¤ì‹œê°„ ì—ì´ì „íŠ¸ ìƒíƒœ ëª¨ë‹ˆí„°ë§
â”‚   â”‚   â””â”€â”€ performance_optimizer.py         # qwen3-4b-fast ì„±ëŠ¥ ìµœì í™”
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ agent_validator.py               # 88ê°œ ê¸°ëŠ¥ ê²€ì¦ ì‹œìŠ¤í…œ
â”‚   â”‚   â”œâ”€â”€ agent_communication.py           # A2A SDK 0.2.9 ì™„ì „ ì¤€ìˆ˜
â”‚   â”‚   â”œâ”€â”€ agent_discovery.py               # ë™ì  ì—ì´ì „íŠ¸ ë°œê²¬
â”‚   â”‚   â””â”€â”€ agent_failover.py                # ì—ì´ì „íŠ¸ ì¥ì•  ë³µêµ¬
â”‚   â”œâ”€â”€ langfuse_integration/
â”‚   â”‚   â”œâ”€â”€ session_tracer.py                # EMP_NO=2055186 ì„¸ì…˜ ì¶”ì 
â”‚   â”‚   â”œâ”€â”€ agent_tracer.py                  # ë©€í‹°ì—ì´ì „íŠ¸ ì¶”ì 
â”‚   â”‚   â”œâ”€â”€ performance_tracer.py            # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì¶”ì 
â”‚   â”‚   â””â”€â”€ trace_aggregator.py              # ì¶”ì  ë°ì´í„° ì§‘ê³„
â”‚   â””â”€â”€ universal_adaptation/
â”‚       â”œâ”€â”€ universal_domain_system.py       # LLM-First ë²”ìš© ë„ë©”ì¸ ì ì‘
â”‚       â”œâ”€â”€ dynamic_query_processor.py       # ë™ì  ì¿¼ë¦¬ ì²˜ë¦¬ ì‹œìŠ¤í…œ
â”‚       â”œâ”€â”€ adaptive_insight_generator.py    # ì ì‘í˜• ì¸ì‚¬ì´íŠ¸ ìƒì„±ê¸°
â”‚       â””â”€â”€ zero_hardcoding_engine.py        # Zero-Hardcoding ì—”ì§„
â”œâ”€â”€ ui/
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ chatgpt_interface.py             # ChatGPT ìŠ¤íƒ€ì¼ ì±„íŒ…
â”‚   â”‚   â”œâ”€â”€ file_upload_enhanced.py          # ë“œë˜ê·¸ì•¤ë“œë¡­ ì—…ë¡œë“œ
â”‚   â”‚   â”œâ”€â”€ progress_visualizer.py           # ì‹¤ì‹œê°„ ì§„í–‰ ì‹œê°í™”
â”‚   â”‚   â”œâ”€â”€ agent_dashboard.py               # ì—ì´ì „íŠ¸ ìƒíƒœ ëŒ€ì‹œë³´ë“œ
â”‚   â”‚   â””â”€â”€ results_presenter.py             # ë¶„ì„ ê²°ê³¼ í‘œì‹œ
â”‚   â”œâ”€â”€ streaming/
â”‚   â”‚   â”œâ”€â”€ sse_handler.py                   # SSE ì´ë²¤íŠ¸ ì²˜ë¦¬
â”‚   â”‚   â”œâ”€â”€ chunk_processor.py               # ì²­í¬ ë‹¨ìœ„ ì²˜ë¦¬
â”‚   â”‚   â”œâ”€â”€ progress_tracker.py              # ì§„í–‰ ìƒí™© ì¶”ì 
â”‚   â”‚   â””â”€â”€ real_time_updater.py             # ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸
â”‚   â””â”€â”€ styles/
â”‚       â”œâ”€â”€ chatgpt_theme.py                 # ChatGPT ìŠ¤íƒ€ì¼ í…Œë§ˆ
â”‚       â”œâ”€â”€ responsive_layout.py             # ë°˜ì‘í˜• ë ˆì´ì•„ì›ƒ
â”‚       â””â”€â”€ animation_effects.py             # ë¶€ë“œëŸ¬ìš´ ì• ë‹ˆë©”ì´ì…˜
â”œâ”€â”€ testing/
â”‚   â”œâ”€â”€ e2e_playwright/
â”‚   â”‚   â”œâ”€â”€ test_suite.py                    # Playwright MCP ê¸°ë°˜ E2E í…ŒìŠ¤íŠ¸
â”‚   â”‚   â”œâ”€â”€ expert_scenarios.py              # ì „ë¬¸ê°€ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸
â”‚   â”‚   â”œâ”€â”€ general_scenarios.py             # ì¼ë°˜ ì‚¬ìš©ì ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸
â”‚   â”‚   â””â”€â”€ performance_tests.py             # ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
â”‚   â”œâ”€â”€ unit_tests/
â”‚   â”‚   â”œâ”€â”€ agent_function_tests.py          # 88ê°œ ê¸°ëŠ¥ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
â”‚   â”‚   â”œâ”€â”€ orchestrator_tests.py            # ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° í…ŒìŠ¤íŠ¸
â”‚   â”‚   â””â”€â”€ streaming_tests.py               # ìŠ¤íŠ¸ë¦¬ë° í…ŒìŠ¤íŠ¸
â”‚   â””â”€â”€ integration_tests/
â”‚       â”œâ”€â”€ full_workflow_tests.py           # ì „ì²´ ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸
â”‚       â”œâ”€â”€ langfuse_integration_tests.py    # Langfuse í†µí•© í…ŒìŠ¤íŠ¸
â”‚       â””â”€â”€ domain_expertise_tests.py        # ë„ë©”ì¸ ì „ë¬¸ì„± í…ŒìŠ¤íŠ¸
â””â”€â”€ config/
    â”œâ”€â”€ agent_config.py                      # ì—ì´ì „íŠ¸ ì„¤ì •
    â”œâ”€â”€ llm_config.py                        # LLM ì„¤ì •
    â”œâ”€â”€ streaming_config.py                  # ìŠ¤íŠ¸ë¦¬ë° ì„¤ì •
    â””â”€â”€ langfuse_config.py                   # Langfuse ì„¤ì •
```

## ğŸ”§ í•µì‹¬ ì»´í¬ë„ŒíŠ¸

### 0. ê¸°ì¡´ ì—ì´ì „íŠ¸ ê¸°ëŠ¥ ê²€ì¦ ì‹œìŠ¤í…œ

```python
class ExistingAgentFunctionValidator:
    """ê¸°ì¡´ êµ¬í˜„ëœ 11ê°œ ì—ì´ì „íŠ¸ì˜ ëª¨ë“  ê¸°ëŠ¥ì„ ë°œê²¬í•˜ê³  ê²€ì¦í•˜ëŠ” ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.agent_discovery = AgentFunctionDiscovery()
        self.function_tester = ComprehensiveFunctionTester()
        self.validation_reporter = ValidationReporter()
        
    async def discover_and_validate_all_agents(self) -> Dict:
        """ëª¨ë“  ì—ì´ì „íŠ¸ì˜ ê¸°ëŠ¥ì„ ë°œê²¬í•˜ê³  ê²€ì¦"""
        
        validation_results = {}
        
        # 11ê°œ ì—ì´ì „íŠ¸ ìˆœì°¨ ê²€ì¦
        agents = [
            {"name": "data_cleaning", "port": 8306},
            {"name": "data_loader", "port": 8307},
            {"name": "data_visualization", "port": 8308},
            {"name": "data_wrangling", "port": 8309},
            {"name": "feature_engineering", "port": 8310},
            {"name": "sql_database", "port": 8311},
            {"name": "eda_tools", "port": 8312},
            {"name": "h2o_ml", "port": 8313},
            {"name": "mlflow_tools", "port": 8314},
            {"name": "pandas_analyst", "port": 8210},
            {"name": "report_generator", "port": 8316}
        ]
        
        for agent in agents:
            print(f"ğŸ” {agent['name']} ì—ì´ì „íŠ¸ ê¸°ëŠ¥ ê²€ì¦ ì‹œì‘...")
            
            # 1. ê¸°ëŠ¥ ë°œê²¬
            discovered_functions = await self.agent_discovery.discover_agent_functions(
                agent_name=agent['name'],
                port=agent['port']
            )
            
            # 2. ê° ê¸°ëŠ¥ ê²€ì¦
            function_results = {}
            for func_name, func_info in discovered_functions.items():
                print(f"  ğŸ“‹ {func_name} ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì¤‘...")
                
                test_result = await self.function_tester.test_function(
                    agent_name=agent['name'],
                    function_name=func_name,
                    function_info=func_info
                )
                
                function_results[func_name] = test_result
                
            validation_results[agent['name']] = {
                "discovered_functions": discovered_functions,
                "validation_results": function_results,
                "total_functions": len(discovered_functions),
                "passed_functions": sum(1 for r in function_results.values() if r['status'] == 'PASS'),
                "failed_functions": sum(1 for r in function_results.values() if r['status'] == 'FAIL')
            }
            
            print(f"âœ… {agent['name']} ê²€ì¦ ì™„ë£Œ: {validation_results[agent['name']]['passed_functions']}/{validation_results[agent['name']]['total_functions']} í†µê³¼")
        
        # 3. ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±
        comprehensive_report = await self.validation_reporter.generate_comprehensive_report(validation_results)
        
        return comprehensive_report

class AgentFunctionDiscovery:
    """ì—ì´ì „íŠ¸ì˜ êµ¬í˜„ëœ ê¸°ëŠ¥ë“¤ì„ ìë™ ë°œê²¬"""
    
    async def discover_agent_functions(self, agent_name: str, port: int) -> Dict:
        """ì—ì´ì „íŠ¸ì˜ ëª¨ë“  ê¸°ëŠ¥ì„ ë°œê²¬"""
        
        discovered_functions = {}
        
        try:
            # 1. ì—ì´ì „íŠ¸ ì—°ê²° ë° ê¸°ë³¸ ì •ë³´ ìˆ˜ì§‘
            agent_client = A2AClient(f"http://localhost:{port}")
            agent_info = await agent_client.get_agent_info()
            
            # 2. ì—ì´ì „íŠ¸ ì¹´ë“œì—ì„œ ê¸°ëŠ¥ ëª©ë¡ ì¶”ì¶œ
            if 'capabilities' in agent_info:
                for capability in agent_info['capabilities']:
                    discovered_functions[capability['name']] = {
                        'description': capability.get('description', ''),
                        'parameters': capability.get('parameters', {}),
                        'return_type': capability.get('return_type', 'unknown'),
                        'examples': capability.get('examples', [])
                    }
            
            # 3. ì‹¤ì œ êµ¬í˜„ íŒŒì¼ì—ì„œ ì¶”ê°€ ê¸°ëŠ¥ ë°œê²¬
            implementation_functions = await self.discover_from_implementation(agent_name)
            discovered_functions.update(implementation_functions)
            
            # 4. API ì—”ë“œí¬ì¸íŠ¸ì—ì„œ ê¸°ëŠ¥ ë°œê²¬
            api_functions = await self.discover_from_api_endpoints(port)
            discovered_functions.update(api_functions)
            
        except Exception as e:
            print(f"âŒ {agent_name} ê¸°ëŠ¥ ë°œê²¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            
        return discovered_functions
    
    async def discover_from_implementation(self, agent_name: str) -> Dict:
        """êµ¬í˜„ íŒŒì¼ì—ì„œ ê¸°ëŠ¥ ë°œê²¬"""
        
        implementation_file = f"a2a_ds_servers/{agent_name}_server.py"
        functions = {}
        
        try:
            # íŒŒì¼ ì½ê¸° ë° í•¨ìˆ˜ ì¶”ì¶œ
            with open(implementation_file, 'r', encoding='utf-8') as f:
                content = f.read()
                
            # í•¨ìˆ˜ ì •ì˜ íŒ¨í„´ ë§¤ì¹­
            import re
            function_pattern = r'async def (\w+)\(.*?\):'
            matches = re.findall(function_pattern, content)
            
            for func_name in matches:
                if not func_name.startswith('_'):  # private í•¨ìˆ˜ ì œì™¸
                    functions[func_name] = {
                        'source': 'implementation',
                        'discovered_from': implementation_file
                    }
                    
        except Exception as e:
            print(f"âš ï¸ {agent_name} êµ¬í˜„ íŒŒì¼ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
            
        return functions

class ComprehensiveFunctionTester:
    """ë°œê²¬ëœ ê¸°ëŠ¥ë“¤ì„ ì¢…í•©ì ìœ¼ë¡œ í…ŒìŠ¤íŠ¸"""
    
    async def test_function(self, agent_name: str, function_name: str, function_info: Dict) -> Dict:
        """ê°œë³„ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
        
        test_result = {
            'function_name': function_name,
            'agent_name': agent_name,
            'status': 'UNKNOWN',
            'test_cases': [],
            'error_messages': [],
            'performance_metrics': {},
            'timestamp': datetime.now().isoformat()
        }
        
        try:
            # 1. ê¸°ë³¸ ì—°ê²° í…ŒìŠ¤íŠ¸
            connection_test = await self.test_basic_connection(agent_name, function_name)
            test_result['test_cases'].append(connection_test)
            
            # 2. íŒŒë¼ë¯¸í„° ê²€ì¦ í…ŒìŠ¤íŠ¸
            if 'parameters' in function_info:
                param_test = await self.test_parameters(agent_name, function_name, function_info['parameters'])
                test_result['test_cases'].append(param_test)
            
            # 3. ì‹¤ì œ ê¸°ëŠ¥ ì‹¤í–‰ í…ŒìŠ¤íŠ¸
            execution_test = await self.test_function_execution(agent_name, function_name, function_info)
            test_result['test_cases'].append(execution_test)
            
            # 4. ì—ëŸ¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
            error_handling_test = await self.test_error_handling(agent_name, function_name)
            test_result['test_cases'].append(error_handling_test)
            
            # 5. ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
            performance_test = await self.test_performance(agent_name, function_name)
            test_result['test_cases'].append(performance_test)
            test_result['performance_metrics'] = performance_test.get('metrics', {})
            
            # ì „ì²´ ê²°ê³¼ íŒì •
            all_passed = all(tc['status'] == 'PASS' for tc in test_result['test_cases'])
            test_result['status'] = 'PASS' if all_passed else 'FAIL'
            
        except Exception as e:
            test_result['status'] = 'ERROR'
            test_result['error_messages'].append(str(e))
            
        return test_result
    
    async def test_basic_connection(self, agent_name: str, function_name: str) -> Dict:
        """ê¸°ë³¸ ì—°ê²° í…ŒìŠ¤íŠ¸"""
        
        try:
            # ì—ì´ì „íŠ¸ í¬íŠ¸ ë§¤í•‘
            port_mapping = {
                'data_cleaning': 8306, 'data_loader': 8307, 'data_visualization': 8308,
                'data_wrangling': 8309, 'feature_engineering': 8310, 'sql_database': 8311,
                'eda_tools': 8312, 'h2o_ml': 8313, 'mlflow_tools': 8314,
                'pandas_analyst': 8210, 'report_generator': 8316
            }
            
            port = port_mapping.get(agent_name, 8100)
            
            # ê¸°ë³¸ ì—°ê²° í™•ì¸
            import aiohttp
            async with aiohttp.ClientSession() as session:
                async with session.get(f"http://localhost:{port}/health") as response:
                    if response.status == 200:
                        return {'test_name': 'basic_connection', 'status': 'PASS', 'message': 'Agent is responsive'}
                    else:
                        return {'test_name': 'basic_connection', 'status': 'FAIL', 'message': f'HTTP {response.status}'}
                        
        except Exception as e:
            return {'test_name': 'basic_connection', 'status': 'FAIL', 'message': str(e)}
    
    async def test_function_execution(self, agent_name: str, function_name: str, function_info: Dict) -> Dict:
        """ì‹¤ì œ ê¸°ëŠ¥ ì‹¤í–‰ í…ŒìŠ¤íŠ¸"""
        
        try:
            # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„
            test_data = await self.prepare_test_data(agent_name, function_name)
            
            # A2A í´ë¼ì´ì–¸íŠ¸ë¡œ ê¸°ëŠ¥ ì‹¤í–‰
            port_mapping = {
                'data_cleaning': 8306, 'data_loader': 8307, 'data_visualization': 8308,
                'data_wrangling': 8309, 'feature_engineering': 8310, 'sql_database': 8311,
                'eda_tools': 8312, 'h2o_ml': 8313, 'mlflow_tools': 8314,
                'pandas_analyst': 8210, 'report_generator': 8316
            }
            
            port = port_mapping.get(agent_name, 8100)
            
            # ì‹¤ì œ ê¸°ëŠ¥ í˜¸ì¶œ
            result = await self.call_agent_function(port, function_name, test_data)
            
            if result and 'error' not in result:
                return {'test_name': 'function_execution', 'status': 'PASS', 'result': result}
            else:
                return {'test_name': 'function_execution', 'status': 'FAIL', 'error': result.get('error', 'Unknown error')}
                
        except Exception as e:
            return {'test_name': 'function_execution', 'status': 'FAIL', 'error': str(e)}

class ValidationReporter:
    """ê²€ì¦ ê²°ê³¼ ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±"""
    
    async def generate_comprehensive_report(self, validation_results: Dict) -> Dict:
        """ì¢…í•© ê²€ì¦ ë¦¬í¬íŠ¸ ìƒì„±"""
        
        total_agents = len(validation_results)
        total_functions = sum(agent['total_functions'] for agent in validation_results.values())
        total_passed = sum(agent['passed_functions'] for agent in validation_results.values())
        total_failed = sum(agent['failed_functions'] for agent in validation_results.values())
        
        success_rate = (total_passed / total_functions * 100) if total_functions > 0 else 0
        
        report = {
            'validation_summary': {
                'total_agents': total_agents,
                'total_functions_discovered': total_functions,
                'total_functions_passed': total_passed,
                'total_functions_failed': total_failed,
                'overall_success_rate': round(success_rate, 2),
                'validation_timestamp': datetime.now().isoformat()
            },
            'agent_details': validation_results,
            'recommendations': await self.generate_recommendations(validation_results),
            'next_steps': await self.generate_next_steps(validation_results)
        }
        
        # ë¦¬í¬íŠ¸ íŒŒì¼ ì €ì¥
        report_filename = f"agent_validation_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_filename, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
            
        print(f"ğŸ“Š ì¢…í•© ê²€ì¦ ë¦¬í¬íŠ¸ê°€ {report_filename}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        print(f"ğŸ“ˆ ì „ì²´ ì„±ê³µë¥ : {success_rate:.1f}% ({total_passed}/{total_functions})")
        
        return report
```

### 1. LLM First ìµœì í™”ëœ A2A ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°

```python
class LLMFirstOptimizedOrchestrator:
    """ì™„ì „í•œ LLM First ì›ì¹™ ê¸°ë°˜ qwen3-4b-fast ìµœì í™” ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°"""
    
    def __init__(self):
        self.llm_client = LLMFactory.create_llm()
        self.agent_pool = AgentPool()
        self.streaming_manager = StreamingManager()
        self.langfuse_tracer = LangfuseIntegration()
        self.complexity_analyzer = LLMFirstComplexityAnalyzer()
        self.critique_system = SeparatedCritiqueSystem()
        self.replanning_system = SeparatedReplanningSystem()
        
    async def process_query_llm_first(self, query: str, session_id: str) -> AsyncGenerator[str, None]:
        """LLM First ì›ì¹™ìœ¼ë¡œ ì™„ì „íˆ ìµœì í™”ëœ ì²˜ë¦¬"""
        
        # 1. Langfuse ì„¸ì…˜ ì‹œì‘
        trace = await self.langfuse_tracer.start_session(
            session_id=session_id,
            user_id="2055186",  # EMP_NO
            query=query
        )
        
        try:
            # 2. LLM ê¸°ë°˜ í†µí•© ë³µì¡ë„ ë¶„ì„ ë° ì „ëµ ê²°ì • (1íšŒ LLM í˜¸ì¶œ)
            yield "ğŸ§  LLMì´ ì¿¼ë¦¬ë¥¼ ë¶„ì„í•˜ê³  ìµœì  ì „ëµì„ ìˆ˜ë¦½í•˜ê³  ìˆìŠµë‹ˆë‹¤..."
            
            strategy_analysis = await self.analyze_and_strategize_llm_first(query)
            await self.langfuse_tracer.trace_llm_call(trace, "strategy_analysis", strategy_analysis)
            
            # 3. ì „ëµì— ë”°ë¥¸ ì ì‘í˜• ì‹¤í–‰
            if strategy_analysis.approach == "fast_track":
                yield "âš¡ ë¹ ë¥¸ ì²˜ë¦¬ ëª¨ë“œë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤..."
                final_result = await self.execute_fast_track(query, strategy_analysis, trace)
            elif strategy_analysis.approach == "balanced":
                yield "âš–ï¸ ê· í˜• ëª¨ë“œë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤..."
                final_result = await self.execute_balanced(query, strategy_analysis, trace)
            elif strategy_analysis.approach == "thorough":
                yield "ğŸ” ì •ë°€ ë¶„ì„ ëª¨ë“œë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤..."
                final_result = await self.execute_thorough(query, strategy_analysis, trace)
            else:  # expert_mode
                yield "ğŸ“ ì „ë¬¸ê°€ ëª¨ë“œë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤..."
                final_result = await self.execute_expert_mode(query, strategy_analysis, trace)
            
            # 4. Langfuse ì„¸ì…˜ ì¢…ë£Œ
            await self.langfuse_tracer.end_session(trace, final_result)
            
            yield f"âœ… ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!"
            yield final_result
            
        except Exception as e:
            await self.langfuse_tracer.log_error(trace, str(e))
            yield f"âŒ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    async def analyze_and_strategize_llm_first(self, query: str) -> Dict:
        """LLMì´ ë¶„ì„ê³¼ ì „ëµì„ í•œ ë²ˆì— ê²°ì •"""
        
        unified_prompt = f"""
        ì¿¼ë¦¬: {query}
        
        ë‹¤ìŒì„ í•œ ë²ˆì— ë¶„ì„í•˜ê³  ê²°ì •í•´ì£¼ì„¸ìš”:
        
        1. ë³µì¡ë„ ì¢…í•© ë¶„ì„
        2. ìµœì  ì²˜ë¦¬ ì „ëµ ê²°ì •
        3. í•„ìš”í•œ ì—ì´ì „íŠ¸ì™€ ìˆœì„œ ê³„íš
        4. í’ˆì§ˆ ê´€ë¦¬ ì „ëµ (critique/replanning í•„ìš”ì„±)
        5. ì˜ˆìƒ ì²˜ë¦¬ ì‹œê°„ê³¼ LLM í˜¸ì¶œ íšŸìˆ˜
        
        JSON ì‘ë‹µ:
        {{
            "complexity_analysis": {{
                "overall_level": "low|medium|high|expert",
                "key_challenges": ["challenge1", "challenge2"],
                "domain_expertise_needed": true/false
            }},
            "execution_strategy": {{
                "approach": "fast_track|balanced|thorough|expert_mode",
                "agent_sequence": ["agent1", "agent2", "agent3"],
                "parallel_possible": true/false,
                "checkpoints": ["checkpoint1", "checkpoint2"]
            }},
            "quality_strategy": {{
                "critique_needed": true/false,
                "critique_timing": "mid|end|both",
                "replanning_threshold": "low|medium|high",
                "self_correction_points": ["point1", "point2"]
            }},
            "resource_planning": {{
                "estimated_llm_calls": 2-5,
                "estimated_time_seconds": 20-60,
                "memory_requirements": "low|medium|high"
            }},
            "confidence": 0.0-1.0
        }}
        
        qwen3-4b-fast ëª¨ë¸ì˜ ì„±ëŠ¥ íŠ¹ì„±ì„ ê³ ë ¤í•˜ì—¬ ì†ë„ì™€ í’ˆì§ˆì˜ ìµœì  ê· í˜•ì„ ì°¾ì•„ì£¼ì„¸ìš”.
        """
        
        return await self.single_llm_call_unified(unified_prompt)
    
    async def execute_balanced(self, query: str, strategy: Dict, trace) -> Dict:
        """ê· í˜• ëª¨ë“œ ì‹¤í–‰ with ë¶„ë¦¬ëœ critique & replanning"""
        
        # 1. ì—ì´ì „íŠ¸ ì‹¤í–‰
        execution_results = await self.execute_agents_streaming(
            strategy.execution_strategy.agent_sequence, query, trace
        )
        
        # 2. ë¶„ë¦¬ëœ ë¹„íŒ (í•„ìš”ì‹œì—ë§Œ)
        if strategy.quality_strategy.critique_needed:
            critique_result = await self.critique_system.perform_separated_critique(
                execution_results, query, strategy
            )
            await self.langfuse_tracer.trace_llm_call(trace, "critique", critique_result)
            
            # 3. ë¶„ë¦¬ëœ ì¬ê³„íš (ë¹„íŒ ê²°ê³¼ì— ë”°ë¼)
            if critique_result.needs_replanning:
                replan_result = await self.replanning_system.perform_separated_replanning(
                    strategy, execution_results, critique_result
                )
                await self.langfuse_tracer.trace_llm_call(trace, "replanning", replan_result)
                
                # 4. ì¬ì‹¤í–‰
                final_results = await self.execute_agents_streaming(
                    replan_result.new_plan.agent_sequence, query, trace
                )
            else:
                final_results = execution_results
        else:
            final_results = execution_results
            
        # 5. ìµœì¢… í†µí•© (LLM ê¸°ë°˜)
        return await self.integrate_results_llm_based(final_results, query)
```

### 1.1. ë¶„ë¦¬ëœ Critique & Replanning ì‹œìŠ¤í…œ

```python
class SeparatedCritiqueSystem:
    """ìˆœìˆ˜ ë¹„íŒ ì—­í•  - ì¬ê³„íš ì œì•ˆ ì—†ìŒ"""
    
    async def perform_separated_critique(self, results: List[Dict], query: str, strategy: Dict) -> Dict:
        """ë¶„ë¦¬ëœ ë¹„íŒ ì‹œìŠ¤í…œ - í‰ê°€ë§Œ ìˆ˜í–‰"""
        
        critique_prompt = f"""
        ë‹¹ì‹ ì€ ë°ì´í„° ë¶„ì„ ê²°ê³¼ë¥¼ í‰ê°€í•˜ëŠ” ì „ë¬¸ í‰ê°€ìì…ë‹ˆë‹¤.
        
        ì›ë³¸ ì¿¼ë¦¬: {query}
        ì‹¤í–‰ ì „ëµ: {strategy}
        ë¶„ì„ ê²°ê³¼: {json.dumps(results, ensure_ascii=False)}
        
        ë‹¤ìŒ ê¸°ì¤€ìœ¼ë¡œë§Œ í‰ê°€í•´ì£¼ì„¸ìš” (í•´ê²°ì±… ì œì•ˆ ê¸ˆì§€):
        1. ì •í™•ì„±: ê²°ê³¼ê°€ ì¿¼ë¦¬ ì˜ë„ì™€ ì¼ì¹˜í•˜ëŠ”ê°€?
        2. ì™„ì „ì„±: ëˆ„ë½ëœ ì¤‘ìš”í•œ ë¶„ì„ì´ ìˆëŠ”ê°€?
        3. í’ˆì§ˆ: ê²°ê³¼ì˜ ì‹ ë¢°ì„±ê³¼ ìœ ìš©ì„±ì€?
        4. ì¼ê´€ì„±: ê²°ê³¼ë“¤ ê°„ ë…¼ë¦¬ì  ì¼ê´€ì„±ì´ ìˆëŠ”ê°€?
        
        JSON ì‘ë‹µ:
        {{
            "accuracy_score": 0-10,
            "completeness_score": 0-10,
            "quality_score": 0-10,
            "consistency_score": 0-10,
            "critical_issues": ["issue1", "issue2"],
            "needs_replanning": true/false,
            "confidence": 0.0-1.0,
            "evaluation_summary": "í‰ê°€ ìš”ì•½"
        }}
        
        ìˆœìˆ˜í•˜ê²Œ í‰ê°€ë§Œ í•˜ê³  í•´ê²°ì±…ì€ ì œì•ˆí•˜ì§€ ë§ˆì„¸ìš”.
        """
        
        return await self.llm_call_critique_only(critique_prompt)

class SeparatedReplanningSystem:
    """ìˆœìˆ˜ ì¬ê³„íš ì—­í•  - í‰ê°€ ì—†ìŒ"""
    
    async def perform_separated_replanning(self, original_strategy: Dict, results: List[Dict], critique: Dict) -> Dict:
        """ë¶„ë¦¬ëœ ì¬ê³„íš ì‹œìŠ¤í…œ - ê³„íš ìˆ˜ë¦½ë§Œ ìˆ˜í–‰"""
        
        replan_prompt = f"""
        ë‹¹ì‹ ì€ ë°ì´í„° ë¶„ì„ ê³„íšì„ ìˆ˜ë¦½í•˜ëŠ” ì „ë¬¸ ê³„íšìì…ë‹ˆë‹¤.
        
        ì›ë³¸ ì „ëµ: {json.dumps(original_strategy, ensure_ascii=False)}
        ì‹¤í–‰ ê²°ê³¼: {json.dumps(results, ensure_ascii=False)}
        í‰ê°€ì í”¼ë“œë°±: {json.dumps(critique, ensure_ascii=False)}
        
        í‰ê°€ìì˜ í”¼ë“œë°±ì„ ë°”íƒ•ìœ¼ë¡œ ê°œì„ ëœ ê³„íšì„ ìˆ˜ë¦½í•´ì£¼ì„¸ìš”:
        
        JSON ì‘ë‹µ:
        {{
            "new_plan": {{
                "approach": "fast_track|balanced|thorough|expert_mode",
                "agent_sequence": ["agent1", "agent2", "agent3"],
                "focus_areas": ["area1", "area2"],
                "quality_checkpoints": ["checkpoint1", "checkpoint2"]
            }},
            "changes_made": ["change1", "change2"],
            "expected_improvements": ["improvement1", "improvement2"],
            "resource_adjustment": {{
                "estimated_llm_calls": 2-4,
                "estimated_time_seconds": 15-45
            }},
            "confidence": 0.0-1.0
        }}
        
        í‰ê°€ëŠ” í•˜ì§€ ë§ê³  ìˆœìˆ˜í•˜ê²Œ ê°œì„ ëœ ê³„íšë§Œ ìˆ˜ë¦½í•˜ì„¸ìš”.
        """
        
        return await self.llm_call_replan_only(replan_prompt)

class LLMFirstComplexityAnalyzer:
    """LLM First ì›ì¹™ ê¸°ë°˜ í†µí•© ë³µì¡ë„ ë¶„ì„ê¸°"""
    
    async def analyze_query_complexity_llm_first(self, query: str, context: Dict) -> Dict:
        """LLMì´ ëª¨ë“  ë³µì¡ë„ë¥¼ í•œ ë²ˆì— ì¢…í•© ë¶„ì„"""
        
        complexity_prompt = f"""
        ë‹¤ìŒ ì¿¼ë¦¬ì™€ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ì²˜ë¦¬ ì „ëµì„ ê²°ì •í•´ì£¼ì„¸ìš”:
        
        ì¿¼ë¦¬: {query}
        ì»¨í…ìŠ¤íŠ¸: {json.dumps(context, ensure_ascii=False)}
        
        ë‹¤ìŒì„ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ JSONìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
        
        1. êµ¬ì¡°ì  ë³µì¡ë„: ì¿¼ë¦¬ì˜ ë¬¸ì¥ êµ¬ì¡°, ìš”êµ¬ì‚¬í•­ ìˆ˜, ì¡°ê±´ë¬¸ ë³µì¡ì„±
        2. ë„ë©”ì¸ ë³µì¡ë„: ì „ë¬¸ ì§€ì‹ í•„ìš”ì„±, ë„ë©”ì¸ íŠ¹í™” ìš©ì–´, ê¸°ìˆ ì  ê¹Šì´
        3. ì˜ë„ ë³µì¡ë„: ëª©í‘œì˜ ëª…í™•ì„±, ë‹¤ì¤‘ ì˜ë„, ëª¨í˜¸ì„± ì •ë„
        4. ë°ì´í„° ë³µì¡ë„: ì˜ˆìƒ ë°ì´í„° í¬ê¸°, í˜•ì‹, ì²˜ë¦¬ ë‚œì´ë„
        5. í˜‘ì—… ë³µì¡ë„: í•„ìš”í•œ ì—ì´ì „íŠ¸ ìˆ˜, ìƒí˜¸ ì˜ì¡´ì„±
        
        {{
            "complexity_assessment": {{
                "structural": {{"level": "low|medium|high", "reasons": ["reason1", "reason2"]}},
                "domain": {{"level": "low|medium|high", "specialization": "domain_name", "expertise_required": true/false}},
                "intent": {{"level": "low|medium|high", "clarity": "clear|ambiguous|complex", "multiple_goals": true/false}},
                "data": {{"level": "low|medium|high", "expected_size": "small|medium|large", "formats": ["csv", "json"]}},
                "collaboration": {{"level": "low|medium|high", "agent_count": 1-5, "dependencies": "sequential|parallel|mixed"}}
            }},
            "processing_strategy": {{
                "approach": "fast_track|balanced|thorough|expert_mode",
                "critique_needed": true/false,
                "replanning_likelihood": "low|medium|high",
                "estimated_llm_calls": 2-5,
                "recommended_timeout": 30-120
            }},
            "risk_factors": ["factor1", "factor2"],
            "confidence": 0.0-1.0
        }}
        
        í•˜ë“œì½”ë”©ëœ ê·œì¹™ ì—†ì´ ìˆœìˆ˜í•˜ê²Œ ì¿¼ë¦¬ ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ íŒë‹¨í•˜ì„¸ìš”.
        """
        
        return await self.single_llm_call_for_complexity(complexity_prompt)
```

### 1.2. Smart Query Router

```python
class SmartQueryRouter:
    """ì¿¼ë¦¬ ë³µì¡ë„ì— ë”°ë¥¸ ìŠ¤ë§ˆíŠ¸ ë¼ìš°íŒ… ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.llm_client = LLMFactory.create_llm()
        self.agent_pool = AgentPool()
        self.orchestrator = LLMFirstOptimizedOrchestrator()
        self.langfuse_tracer = LangfuseIntegration()
    
    async def route_query(self, query: str, session_id: str) -> AsyncGenerator[str, None]:
        """ì¿¼ë¦¬ ë³µì¡ë„ì— ë”°ë¥¸ ìŠ¤ë§ˆíŠ¸ ë¼ìš°íŒ…"""
        
        # 1. ë¹ ë¥¸ ë³µì¡ë„ ì‚¬ì „ íŒë‹¨ (1íšŒ LLM í˜¸ì¶œ)
        quick_assessment = await self.quick_complexity_assessment(query)
        
        if quick_assessment.complexity_level == "trivial":
            # ì§ì ‘ ì‘ë‹µ (ì¶”ê°€ LLM í˜¸ì¶œ ì—†ì´)
            yield "ğŸ’¡ ê°„ë‹¨í•œ ì§ˆë¬¸ìœ¼ë¡œ íŒë‹¨ë˜ì–´ ë°”ë¡œ ë‹µë³€ë“œë¦¬ê² ìŠµë‹ˆë‹¤..."
            async for response in self.direct_response(query, session_id):
                yield response
                
        elif quick_assessment.complexity_level == "simple":
            # ë‹¨ì¼ ì—ì´ì „íŠ¸ ì²˜ë¦¬
            yield "âš¡ ë‹¨ìˆœ ë¶„ì„ìœ¼ë¡œ ë¹ ë¥´ê²Œ ì²˜ë¦¬í•˜ê² ìŠµë‹ˆë‹¤..."
            async for response in self.single_agent_response(query, quick_assessment, session_id):
                yield response
                
        else:
            # ë©€í‹°ì—ì´ì „íŠ¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜
            yield "ğŸ§  ë³µì¡í•œ ë¶„ì„ì„ ìœ„í•´ ë©€í‹°ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì„ í™œìš©í•˜ê² ìŠµë‹ˆë‹¤..."
            async for response in self.orchestrated_response(query, quick_assessment, session_id):
                yield response
    
    async def quick_complexity_assessment(self, query: str) -> Dict:
        """ë¹ ë¥¸ ë³µì¡ë„ ì‚¬ì „ íŒë‹¨"""
        
        assessment_prompt = f"""
        ì¿¼ë¦¬: {query}
        
        ì´ ì¿¼ë¦¬ì˜ ë³µì¡ë„ë¥¼ ë¹ ë¥´ê²Œ íŒë‹¨í•´ì£¼ì„¸ìš”:
        
        JSON ì‘ë‹µ:
        {{
            "complexity_level": "trivial|simple|medium|complex",
            "reasoning": "íŒë‹¨ ê·¼ê±°",
            "recommended_approach": "direct|single_agent|multi_agent",
            "estimated_time": "5-60ì´ˆ",
            "confidence": 0.0-1.0
        }}
        
        íŒë‹¨ ê¸°ì¤€:
        - trivial: ì¸ì‚¬, ê°„ë‹¨í•œ ì •ì˜, ê¸°ë³¸ ì„¤ëª… ë“±
        - simple: ë‹¨ìˆœ ê³„ì‚°, ê¸°ë³¸ í†µê³„, ê°„ë‹¨í•œ ì‹œê°í™”
        - medium: ë°ì´í„° ë¶„ì„, ë³µí•© ì²˜ë¦¬, ì—¬ëŸ¬ ë‹¨ê³„ ì‘ì—…
        - complex: ì „ë¬¸ ë„ë©”ì¸, ë©€í‹°ëª¨ë‹¬, ë³µì¡í•œ ì¶”ë¡ 
        """
        
        return await self.llm_call_quick_assessment(assessment_prompt)
    
    async def direct_response(self, query: str, session_id: str) -> AsyncGenerator[str, None]:
        """ì§ì ‘ ì‘ë‹µ (ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì—†ì´) - 5-10ì´ˆ"""
        
        # Langfuse ê°„ë‹¨ ì¶”ì 
        trace = await self.langfuse_tracer.start_simple_session(session_id, query)
        
        try:
            # ì§ì ‘ LLM ì‘ë‹µ
            direct_prompt = f"""
            ì‚¬ìš©ì ì§ˆë¬¸: {query}
            
            ì´ ì§ˆë¬¸ì— ëŒ€í•´ ì¹œê·¼í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.
            CherryAI ë°ì´í„° ë¶„ì„ í”Œë«í¼ì˜ ì–´ì‹œìŠ¤í„´íŠ¸ë¡œì„œ ì‘ë‹µí•˜ì„¸ìš”.
            """
            
            response = await self.llm_client.ainvoke(direct_prompt)
            await self.langfuse_tracer.trace_direct_response(trace, direct_prompt, response)
            
            yield response.content if hasattr(response, 'content') else str(response)
            
        except Exception as e:
            yield f"ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        finally:
            await self.langfuse_tracer.end_simple_session(trace)
    
    async def single_agent_response(self, query: str, assessment: Dict, session_id: str) -> AsyncGenerator[str, None]:
        """ë‹¨ì¼ ì—ì´ì „íŠ¸ ì²˜ë¦¬ - 10-20ì´ˆ"""
        
        # ê°€ì¥ ì í•©í•œ ì—ì´ì „íŠ¸ ì„ íƒ
        best_agent = await self.select_best_single_agent(query, assessment)
        
        yield f"ğŸ“Š {best_agent.name} ì—ì´ì „íŠ¸ê°€ ì²˜ë¦¬í•˜ê² ìŠµë‹ˆë‹¤..."
        
        # ë‹¨ì¼ ì—ì´ì „íŠ¸ ì‹¤í–‰
        result = await self.agent_pool.execute_single_agent(
            agent_id=best_agent.id,
            query=query,
            session_id=session_id
        )
        
        yield f"âœ… ë¶„ì„ ì™„ë£Œ!"
        yield result
    
    async def orchestrated_response(self, query: str, assessment: Dict, session_id: str) -> AsyncGenerator[str, None]:
        """ë©€í‹°ì—ì´ì „íŠ¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ - 30-60ì´ˆ"""
        
        # ì „ì²´ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì‹¤í–‰
        async for response in self.orchestrator.process_query_llm_first(query, session_id):
            yield response
    
    async def select_best_single_agent(self, query: str, assessment: Dict) -> Dict:
        """ë‹¨ì¼ ì—ì´ì „íŠ¸ ì„ íƒì„ ìœ„í•œ LLM ê¸°ë°˜ íŒë‹¨"""
        
        agent_selection_prompt = f"""
        ì¿¼ë¦¬: {query}
        ë³µì¡ë„ í‰ê°€: {assessment}
        
        ë‹¤ìŒ ì—ì´ì „íŠ¸ ì¤‘ ê°€ì¥ ì í•©í•œ í•˜ë‚˜ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”:
        
        ì‚¬ìš© ê°€ëŠ¥í•œ ì—ì´ì „íŠ¸:
        - pandas_analyst: ê¸°ë³¸ ë°ì´í„° ë¶„ì„, í†µê³„
        - data_visualization: ì°¨íŠ¸, ê·¸ë˜í”„ ìƒì„±
        - eda_tools: íƒìƒ‰ì  ë°ì´í„° ë¶„ì„
        - data_cleaning: ë°ì´í„° ì •ë¦¬
        - report_generator: ë¦¬í¬íŠ¸ ìƒì„±
        
        JSON ì‘ë‹µ:
        {{
            "selected_agent": "agent_name",
            "reasoning": "ì„ íƒ ì´ìœ ",
            "confidence": 0.0-1.0
        }}
        """
        
        selection_result = await self.llm_client.ainvoke(agent_selection_prompt)
        return {
            "id": selection_result.get("selected_agent", "pandas_analyst"),
            "name": selection_result.get("selected_agent", "Pandas Analyst").replace("_", " ").title()
        }
```

### 1.2. Smart Query Router

```python
class SmartQueryRouter:
    """ì¿¼ë¦¬ ë³µì¡ë„ì— ë”°ë¥¸ ìŠ¤ë§ˆíŠ¸ ë¼ìš°íŒ… ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.llm_client = LLMFactory.create_llm()
        self.agent_pool = AgentPool()
        self.orchestrator = LLMFirstOptimizedOrchestrator()
        self.langfuse_tracer = LangfuseIntegration()
    
    async def route_query(self, query: str, session_id: str) -> AsyncGenerator[str, None]:
        """ì¿¼ë¦¬ ë³µì¡ë„ì— ë”°ë¥¸ ìŠ¤ë§ˆíŠ¸ ë¼ìš°íŒ…"""
        
        # 1. ë¹ ë¥¸ ë³µì¡ë„ ì‚¬ì „ íŒë‹¨ (1íšŒ LLM í˜¸ì¶œ)
        quick_assessment = await self.quick_complexity_assessment(query)
        
        if quick_assessment.complexity_level == "trivial":
            # ì§ì ‘ ì‘ë‹µ (ì¶”ê°€ LLM í˜¸ì¶œ ì—†ì´)
            yield "ğŸ’¡ ê°„ë‹¨í•œ ì§ˆë¬¸ìœ¼ë¡œ íŒë‹¨ë˜ì–´ ë°”ë¡œ ë‹µë³€ë“œë¦¬ê² ìŠµë‹ˆë‹¤..."
            async for response in self.direct_response(query, session_id):
                yield response
                
        elif quick_assessment.complexity_level == "simple":
            # ë‹¨ì¼ ì—ì´ì „íŠ¸ ì²˜ë¦¬
            yield "âš¡ ë‹¨ìˆœ ë¶„ì„ìœ¼ë¡œ ë¹ ë¥´ê²Œ ì²˜ë¦¬í•˜ê² ìŠµë‹ˆë‹¤..."
            async for response in self.single_agent_response(query, quick_assessment, session_id):
                yield response
                
        else:
            # ë©€í‹°ì—ì´ì „íŠ¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜
            yield "ğŸ§  ë³µì¡í•œ ë¶„ì„ì„ ìœ„í•´ ë©€í‹°ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì„ í™œìš©í•˜ê² ìŠµë‹ˆë‹¤..."
            async for response in self.orchestrated_response(query, quick_assessment, session_id):
                yield response
    
    async def quick_complexity_assessment(self, query: str) -> Dict:
        """ë¹ ë¥¸ ë³µì¡ë„ ì‚¬ì „ íŒë‹¨"""
        
        assessment_prompt = f"""
        ì¿¼ë¦¬: {query}
        
        ì´ ì¿¼ë¦¬ì˜ ë³µì¡ë„ë¥¼ ë¹ ë¥´ê²Œ íŒë‹¨í•´ì£¼ì„¸ìš”:
        
        JSON ì‘ë‹µ:
        {{
            "complexity_level": "trivial|simple|medium|complex",
            "reasoning": "íŒë‹¨ ê·¼ê±°",
            "recommended_approach": "direct|single_agent|multi_agent",
            "estimated_time": "5-60ì´ˆ",
            "confidence": 0.0-1.0
        }}
        
        íŒë‹¨ ê¸°ì¤€:
        - trivial: ì¸ì‚¬, ê°„ë‹¨í•œ ì •ì˜, ê¸°ë³¸ ì„¤ëª… ë“±
        - simple: ë‹¨ìˆœ ê³„ì‚°, ê¸°ë³¸ í†µê³„, ê°„ë‹¨í•œ ì‹œê°í™”
        - medium: ë°ì´í„° ë¶„ì„, ë³µí•© ì²˜ë¦¬, ì—¬ëŸ¬ ë‹¨ê³„ ì‘ì—…
        - complex: ì „ë¬¸ ë„ë©”ì¸, ë©€í‹°ëª¨ë‹¬, ë³µì¡í•œ ì¶”ë¡ 
        """
        
        return await self.llm_call_quick_assessment(assessment_prompt)
    
    async def direct_response(self, query: str, session_id: str) -> AsyncGenerator[str, None]:
        """ì§ì ‘ ì‘ë‹µ (ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì—†ì´) - 5-10ì´ˆ"""
        
        # Langfuse ê°„ë‹¨ ì¶”ì 
        trace = await self.langfuse_tracer.start_simple_session(session_id, query)
        
        try:
            # ì§ì ‘ LLM ì‘ë‹µ
            direct_prompt = f"""
            ì‚¬ìš©ì ì§ˆë¬¸: {query}
            
            ì´ ì§ˆë¬¸ì— ëŒ€í•´ ì¹œê·¼í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.
            CherryAI ë°ì´í„° ë¶„ì„ í”Œë«í¼ì˜ ì–´ì‹œìŠ¤í„´íŠ¸ë¡œì„œ ì‘ë‹µí•˜ì„¸ìš”.
            """
            
            response = await self.llm_client.ainvoke(direct_prompt)
            await self.langfuse_tracer.trace_direct_response(trace, direct_prompt, response)
            
            yield response.content if hasattr(response, 'content') else str(response)
            
        except Exception as e:
            yield f"ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        finally:
            await self.langfuse_tracer.end_simple_session(trace)
    
    async def single_agent_response(self, query: str, assessment: Dict, session_id: str) -> AsyncGenerator[str, None]:
        """ë‹¨ì¼ ì—ì´ì „íŠ¸ ì²˜ë¦¬ - 10-20ì´ˆ"""
        
        # ê°€ì¥ ì í•©í•œ ì—ì´ì „íŠ¸ ì„ íƒ
        best_agent = await self.select_best_single_agent(query, assessment)
        
        yield f"ğŸ“Š {best_agent.name} ì—ì´ì „íŠ¸ê°€ ì²˜ë¦¬í•˜ê² ìŠµë‹ˆë‹¤..."
        
        # ë‹¨ì¼ ì—ì´ì „íŠ¸ ì‹¤í–‰
        result = await self.agent_pool.execute_single_agent(
            agent_id=best_agent.id,
            query=query,
            session_id=session_id
        )
        
        yield f"âœ… ë¶„ì„ ì™„ë£Œ!"
        yield result
    
    async def orchestrated_response(self, query: str, assessment: Dict, session_id: str) -> AsyncGenerator[str, None]:
        """ë©€í‹°ì—ì´ì „íŠ¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ - 30-60ì´ˆ"""
        
        # ì „ì²´ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì‹¤í–‰
        async for response in self.orchestrator.process_query_llm_first(query, session_id):
            yield response
    
    async def select_best_single_agent(self, query: str, assessment: Dict) -> Dict:
        """ë‹¨ì¼ ì—ì´ì „íŠ¸ ì„ íƒì„ ìœ„í•œ LLM ê¸°ë°˜ íŒë‹¨"""
        
        agent_selection_prompt = f"""
        ì¿¼ë¦¬: {query}
        ë³µì¡ë„ í‰ê°€: {assessment}
        
        ë‹¤ìŒ ì—ì´ì „íŠ¸ ì¤‘ ê°€ì¥ ì í•©í•œ í•˜ë‚˜ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”:
        
        ì‚¬ìš© ê°€ëŠ¥í•œ ì—ì´ì „íŠ¸:
        - pandas_analyst: ê¸°ë³¸ ë°ì´í„° ë¶„ì„, í†µê³„
        - data_visualization: ì°¨íŠ¸, ê·¸ë˜í”„ ìƒì„±
        - eda_tools: íƒìƒ‰ì  ë°ì´í„° ë¶„ì„
        - data_cleaning: ë°ì´í„° ì •ë¦¬
        - report_generator: ë¦¬í¬íŠ¸ ìƒì„±
        
        JSON ì‘ë‹µ:
        {{
            "selected_agent": "agent_name",
            "reasoning": "ì„ íƒ ì´ìœ ",
            "confidence": 0.0-1.0
        }}
        """
        
        selection_result = await self.llm_client.ainvoke(agent_selection_prompt)
        return {
            "id": selection_result.get("selected_agent", "pandas_analyst"),
            "name": selection_result.get("selected_agent", "Pandas Analyst").replace("_", " ").title()
        }
```

### 1.2. Smart Query Router

```python
class SmartQueryRouter:
    """ì¿¼ë¦¬ ë³µì¡ë„ì— ë”°ë¥¸ ìŠ¤ë§ˆíŠ¸ ë¼ìš°íŒ… ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.llm_client = LLMFactory.create_llm()
        self.agent_pool = AgentPool()
        self.orchestrator = LLMFirstOptimizedOrchestrator()
        self.langfuse_tracer = LangfuseIntegration()
    
    async def route_query(self, query: str, session_id: str) -> AsyncGenerator[str, None]:
        """ì¿¼ë¦¬ ë³µì¡ë„ì— ë”°ë¥¸ ìŠ¤ë§ˆíŠ¸ ë¼ìš°íŒ…"""
        
        # 1. ë¹ ë¥¸ ë³µì¡ë„ ì‚¬ì „ íŒë‹¨ (1íšŒ LLM í˜¸ì¶œ)
        quick_assessment = await self.quick_complexity_assessment(query)
        
        if quick_assessment.complexity_level == "trivial":
            # ì§ì ‘ ì‘ë‹µ (ì¶”ê°€ LLM í˜¸ì¶œ ì—†ì´)
            yield "ğŸ’¡ ê°„ë‹¨í•œ ì§ˆë¬¸ìœ¼ë¡œ íŒë‹¨ë˜ì–´ ë°”ë¡œ ë‹µë³€ë“œë¦¬ê² ìŠµë‹ˆë‹¤..."
            async for response in self.direct_response(query, session_id):
                yield response
                
        elif quick_assessment.complexity_level == "simple":
            # ë‹¨ì¼ ì—ì´ì „íŠ¸ ì²˜ë¦¬
            yield "âš¡ ë‹¨ìˆœ ë¶„ì„ìœ¼ë¡œ ë¹ ë¥´ê²Œ ì²˜ë¦¬í•˜ê² ìŠµë‹ˆë‹¤..."
            async for response in self.single_agent_response(query, quick_assessment, session_id):
                yield response
                
        else:
            # ë©€í‹°ì—ì´ì „íŠ¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜
            yield "ğŸ§  ë³µì¡í•œ ë¶„ì„ì„ ìœ„í•´ ë©€í‹°ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì„ í™œìš©í•˜ê² ìŠµë‹ˆë‹¤..."
            async for response in self.orchestrated_response(query, quick_assessment, session_id):
                yield response
    
    async def quick_complexity_assessment(self, query: str) -> Dict:
        """ë¹ ë¥¸ ë³µì¡ë„ ì‚¬ì „ íŒë‹¨"""
        
        assessment_prompt = f"""
        ì¿¼ë¦¬: {query}
        
        ì´ ì¿¼ë¦¬ì˜ ë³µì¡ë„ë¥¼ ë¹ ë¥´ê²Œ íŒë‹¨í•´ì£¼ì„¸ìš”:
        
        JSON ì‘ë‹µ:
        {{
            "complexity_level": "trivial|simple|medium|complex",
            "reasoning": "íŒë‹¨ ê·¼ê±°",
            "recommended_approach": "direct|single_agent|multi_agent",
            "estimated_time": "5-60ì´ˆ",
            "confidence": 0.0-1.0
        }}
        
        íŒë‹¨ ê¸°ì¤€:
        - trivial: ì¸ì‚¬, ê°„ë‹¨í•œ ì •ì˜, ê¸°ë³¸ ì„¤ëª… ë“±
        - simple: ë‹¨ìˆœ ê³„ì‚°, ê¸°ë³¸ í†µê³„, ê°„ë‹¨í•œ ì‹œê°í™”
        - medium: ë°ì´í„° ë¶„ì„, ë³µí•© ì²˜ë¦¬, ì—¬ëŸ¬ ë‹¨ê³„ ì‘ì—…
        - complex: ì „ë¬¸ ë„ë©”ì¸, ë©€í‹°ëª¨ë‹¬, ë³µì¡í•œ ì¶”ë¡ 
        """
        
        return await self.llm_call_quick_assessment(assessment_prompt)
    
    async def direct_response(self, query: str, session_id: str) -> AsyncGenerator[str, None]:
        """ì§ì ‘ ì‘ë‹µ (ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì—†ì´) - 5-10ì´ˆ"""
        
        # Langfuse ê°„ë‹¨ ì¶”ì 
        trace = await self.langfuse_tracer.start_simple_session(session_id, query)
        
        try:
            # ì§ì ‘ LLM ì‘ë‹µ
            direct_prompt = f"""
            ì‚¬ìš©ì ì§ˆë¬¸: {query}
            
            ì´ ì§ˆë¬¸ì— ëŒ€í•´ ì¹œê·¼í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.
            CherryAI ë°ì´í„° ë¶„ì„ í”Œë«í¼ì˜ ì–´ì‹œìŠ¤í„´íŠ¸ë¡œì„œ ì‘ë‹µí•˜ì„¸ìš”.
            """
            
            response = await self.llm_client.ainvoke(direct_prompt)
            await self.langfuse_tracer.trace_direct_response(trace, direct_prompt, response)
            
            yield response.content if hasattr(response, 'content') else str(response)
            
        except Exception as e:
            yield f"ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        finally:
            await self.langfuse_tracer.end_simple_session(trace)
    
    async def single_agent_response(self, query: str, assessment: Dict, session_id: str) -> AsyncGenerator[str, None]:
        """ë‹¨ì¼ ì—ì´ì „íŠ¸ ì²˜ë¦¬ - 10-20ì´ˆ"""
        
        # ê°€ì¥ ì í•©í•œ ì—ì´ì „íŠ¸ ì„ íƒ
        best_agent = await self.select_best_single_agent(query, assessment)
        
        yield f"ğŸ“Š {best_agent.name} ì—ì´ì „íŠ¸ê°€ ì²˜ë¦¬í•˜ê² ìŠµë‹ˆë‹¤..."
        
        # ë‹¨ì¼ ì—ì´ì „íŠ¸ ì‹¤í–‰
        result = await self.agent_pool.execute_single_agent(
            agent_id=best_agent.id,
            query=query,
            session_id=session_id
        )
        
        yield f"âœ… ë¶„ì„ ì™„ë£Œ!"
        yield result
    
    async def orchestrated_response(self, query: str, assessment: Dict, session_id: str) -> AsyncGenerator[str, None]:
        """ë©€í‹°ì—ì´ì „íŠ¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ - 30-60ì´ˆ"""
        
        # ì „ì²´ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì‹¤í–‰
        async for response in self.orchestrator.process_query_llm_first(query, session_id):
            yield response
    
    async def select_best_single_agent(self, query: str, assessment: Dict) -> Dict:
        """ë‹¨ì¼ ì—ì´ì „íŠ¸ ì„ íƒì„ ìœ„í•œ LLM ê¸°ë°˜ íŒë‹¨"""
        
        agent_selection_prompt = f"""
        ì¿¼ë¦¬: {query}
        ë³µì¡ë„ í‰ê°€: {assessment}
        
        ë‹¤ìŒ ì—ì´ì „íŠ¸ ì¤‘ ê°€ì¥ ì í•©í•œ í•˜ë‚˜ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”:
        
        ì‚¬ìš© ê°€ëŠ¥í•œ ì—ì´ì „íŠ¸:
        - pandas_analyst: ê¸°ë³¸ ë°ì´í„° ë¶„ì„, í†µê³„
        - data_visualization: ì°¨íŠ¸, ê·¸ë˜í”„ ìƒì„±
        - eda_tools: íƒìƒ‰ì  ë°ì´í„° ë¶„ì„
        - data_cleaning: ë°ì´í„° ì •ë¦¬
        - report_generator: ë¦¬í¬íŠ¸ ìƒì„±
        
        JSON ì‘ë‹µ:
        {{
            "selected_agent": "agent_name",
            "reasoning": "ì„ íƒ ì´ìœ ",
            "confidence": 0.0-1.0
        }}
        """
        
        selection_result = await self.llm_client.ainvoke(agent_selection_prompt)
        return {
            "id": selection_result.get("selected_agent", "pandas_analyst"),
            "name": selection_result.get("selected_agent", "Pandas Analyst").replace("_", " ").title()
        }
```

### 1.2. Smart Query Router

```python
class SmartQueryRouter:
    """ì¿¼ë¦¬ ë³µì¡ë„ì— ë”°ë¥¸ ìŠ¤ë§ˆíŠ¸ ë¼ìš°íŒ… ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.llm_client = LLMFactory.create_llm()
        self.agent_pool = AgentPool()
        self.orchestrator = LLMFirstOptimizedOrchestrator()
        self.langfuse_tracer = LangfuseIntegration()
    
    async def route_query(self, query: str, session_id: str) -> AsyncGenerator[str, None]:
        """ì¿¼ë¦¬ ë³µì¡ë„ì— ë”°ë¥¸ ìŠ¤ë§ˆíŠ¸ ë¼ìš°íŒ…"""
        
        # 1. ë¹ ë¥¸ ë³µì¡ë„ ì‚¬ì „ íŒë‹¨ (1íšŒ LLM í˜¸ì¶œ)
        quick_assessment = await self.quick_complexity_assessment(query)
        
        if quick_assessment.complexity_level == "trivial":
            # ì§ì ‘ ì‘ë‹µ (ì¶”ê°€ LLM í˜¸ì¶œ ì—†ì´)
            yield "ğŸ’¡ ê°„ë‹¨í•œ ì§ˆë¬¸ìœ¼ë¡œ íŒë‹¨ë˜ì–´ ë°”ë¡œ ë‹µë³€ë“œë¦¬ê² ìŠµë‹ˆë‹¤..."
            async for response in self.direct_response(query, session_id):
                yield response
                
        elif quick_assessment.complexity_level == "simple":
            # ë‹¨ì¼ ì—ì´ì „íŠ¸ ì²˜ë¦¬
            yield "âš¡ ë‹¨ìˆœ ë¶„ì„ìœ¼ë¡œ ë¹ ë¥´ê²Œ ì²˜ë¦¬í•˜ê² ìŠµë‹ˆë‹¤..."
            async for response in self.single_agent_response(query, quick_assessment, session_id):
                yield response
                
        else:
            # ë©€í‹°ì—ì´ì „íŠ¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜
            yield "ğŸ§  ë³µì¡í•œ ë¶„ì„ì„ ìœ„í•´ ë©€í‹°ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì„ í™œìš©í•˜ê² ìŠµë‹ˆë‹¤..."
            async for response in self.orchestrated_response(query, quick_assessment, session_id):
                yield response
    
    async def quick_complexity_assessment(self, query: str) -> Dict:
        """ë¹ ë¥¸ ë³µì¡ë„ ì‚¬ì „ íŒë‹¨"""
        
        assessment_prompt = f"""
        ì¿¼ë¦¬: {query}
        
        ì´ ì¿¼ë¦¬ì˜ ë³µì¡ë„ë¥¼ ë¹ ë¥´ê²Œ íŒë‹¨í•´ì£¼ì„¸ìš”:
        
        JSON ì‘ë‹µ:
        {{
            "complexity_level": "trivial|simple|medium|complex",
            "reasoning": "íŒë‹¨ ê·¼ê±°",
            "recommended_approach": "direct|single_agent|multi_agent",
            "estimated_time": "5-60ì´ˆ",
            "confidence": 0.0-1.0
        }}
        
        íŒë‹¨ ê¸°ì¤€:
        - trivial: ì¸ì‚¬, ê°„ë‹¨í•œ ì •ì˜, ê¸°ë³¸ ì„¤ëª… ë“±
        - simple: ë‹¨ìˆœ ê³„ì‚°, ê¸°ë³¸ í†µê³„, ê°„ë‹¨í•œ ì‹œê°í™”
        - medium: ë°ì´í„° ë¶„ì„, ë³µí•© ì²˜ë¦¬, ì—¬ëŸ¬ ë‹¨ê³„ ì‘ì—…
        - complex: ì „ë¬¸ ë„ë©”ì¸, ë©€í‹°ëª¨ë‹¬, ë³µì¡í•œ ì¶”ë¡ 
        """
        
        return await self.llm_call_quick_assessment(assessment_prompt)
    
    async def direct_response(self, query: str, session_id: str) -> AsyncGenerator[str, None]:
        """ì§ì ‘ ì‘ë‹µ (ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì—†ì´) - 5-10ì´ˆ"""
        
        # Langfuse ê°„ë‹¨ ì¶”ì 
        trace = await self.langfuse_tracer.start_simple_session(session_id, query)
        
        try:
            # ì§ì ‘ LLM ì‘ë‹µ
            direct_prompt = f"""
            ì‚¬ìš©ì ì§ˆë¬¸: {query}
            
            ì´ ì§ˆë¬¸ì— ëŒ€í•´ ì¹œê·¼í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.
            CherryAI ë°ì´í„° ë¶„ì„ í”Œë«í¼ì˜ ì–´ì‹œìŠ¤í„´íŠ¸ë¡œì„œ ì‘ë‹µí•˜ì„¸ìš”.
            """
            
            response = await self.llm_client.ainvoke(direct_prompt)
            await self.langfuse_tracer.trace_direct_response(trace, direct_prompt, response)
            
            yield response.content if hasattr(response, 'content') else str(response)
            
        except Exception as e:
            yield f"ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        finally:
            await self.langfuse_tracer.end_simple_session(trace)
    
    async def single_agent_response(self, query: str, assessment: Dict, session_id: str) -> AsyncGenerator[str, None]:
        """ë‹¨ì¼ ì—ì´ì „íŠ¸ ì²˜ë¦¬ - 10-20ì´ˆ"""
        
        # ê°€ì¥ ì í•©í•œ ì—ì´ì „íŠ¸ ì„ íƒ
        best_agent = await self.select_best_single_agent(query, assessment)
        
        yield f"ğŸ“Š {best_agent.name} ì—ì´ì „íŠ¸ê°€ ì²˜ë¦¬í•˜ê² ìŠµë‹ˆë‹¤..."
        
        # ë‹¨ì¼ ì—ì´ì „íŠ¸ ì‹¤í–‰
        result = await self.agent_pool.execute_single_agent(
            agent_id=best_agent.id,
            query=query,
            session_id=session_id
        )
        
        yield f"âœ… ë¶„ì„ ì™„ë£Œ!"
        yield result
    
    async def orchestrated_response(self, query: str, assessment: Dict, session_id: str) -> AsyncGenerator[str, None]:
        """ë©€í‹°ì—ì´ì „íŠ¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ - 30-60ì´ˆ"""
        
        # ì „ì²´ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì‹¤í–‰
        async for response in self.orchestrator.process_query_llm_first(query, session_id):
            yield response
    
    async def select_best_single_agent(self, query: str, assessment: Dict) -> Dict:
        """ë‹¨ì¼ ì—ì´ì „íŠ¸ ì„ íƒì„ ìœ„í•œ LLM ê¸°ë°˜ íŒë‹¨"""
        
        agent_selection_prompt = f"""
        ì¿¼ë¦¬: {query}
        ë³µì¡ë„ í‰ê°€: {assessment}
        
        ë‹¤ìŒ ì—ì´ì „íŠ¸ ì¤‘ ê°€ì¥ ì í•©í•œ í•˜ë‚˜ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”:
        
        ì‚¬ìš© ê°€ëŠ¥í•œ ì—ì´ì „íŠ¸:
        - pandas_analyst: ê¸°ë³¸ ë°ì´í„° ë¶„ì„, í†µê³„
        - data_visualization: ì°¨íŠ¸, ê·¸ë˜í”„ ìƒì„±
        - eda_tools: íƒìƒ‰ì  ë°ì´í„° ë¶„ì„
        - data_cleaning: ë°ì´í„° ì •ë¦¬
        - report_generator: ë¦¬í¬íŠ¸ ìƒì„±
        
        JSON ì‘ë‹µ:
        {{
            "selected_agent": "agent_name",
            "reasoning": "ì„ íƒ ì´ìœ ",
            "confidence": 0.0-1.0
        }}
        """
        
        selection_result = await self.llm_client.ainvoke(agent_selection_prompt)
        return {
            "id": selection_result.get("selected_agent", "pandas_analyst"),
            "name": selection_result.get("selected_agent", "Pandas Analyst").replace("_", " ").title()
        }
```

### 2. SSE ìŠ¤íŠ¸ë¦¬ë° ê´€ë¦¬ì

```python
class StreamingManager:
    """0.001ì´ˆ ì§€ì—° ìµœì í™”ëœ SSE ìŠ¤íŠ¸ë¦¬ë° ê´€ë¦¬"""
    
    def __init__(self):
        self.active_streams = {}
        self.chunk_buffer = ChunkBuffer()
        
    async def create_sse_stream(
        self, 
        orchestrator: OptimizedA2AOrchestrator,
        query: str,
        session_id: str
    ) -> AsyncGenerator[str, None]:
        """SSE ìŠ¤íŠ¸ë¦¼ ìƒì„± with ìµœì í™”ëœ ì²­í‚¹"""
        
        try:
            async for update in orchestrator.execute_workflow(query, session_id):
                # ì²­í¬ ìµœì í™”
                optimized_chunk = self.optimize_chunk(update)
                
                # SSE í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                sse_data = f"data: {json.dumps(optimized_chunk)}\n\n"
                yield sse_data
                
                # 0.001ì´ˆ ì§€ì—°ìœ¼ë¡œ ë¶€ë“œëŸ¬ìš´ UX
                await asyncio.sleep(0.001)
                
        except Exception as e:
            error_chunk = {
                "type": "error",
                "content": str(e),
                "timestamp": datetime.now().isoformat()
            }
            yield f"data: {json.dumps(error_chunk)}\n\n"
    
    def optimize_chunk(self, update: StreamingUpdate) -> Dict:
        """ì²­í¬ ë°ì´í„° ìµœì í™”"""
        return {
            "type": update.type,
            "progress": update.progress,
            "timestamp": datetime.now().isoformat(),
            "content": update.content[:1000],  # í¬ê¸° ì œí•œ
            "agent_info": str(update.agent_info) if update.agent_info else None
        }
```

### 3. ì—ì´ì „íŠ¸ ê¸°ëŠ¥ ê²€ì¦ ì‹œìŠ¤í…œ

```python
class AgentValidator:
    """ëª¨ë“  ì—ì´ì „íŠ¸ì˜ 88ê°œ ê¸°ëŠ¥ ì™„ì „ ê²€ì¦ ì‹œìŠ¤í…œ"""
    
    def __init__(self, agent: A2AAgent):
        self.agent = agent
        self.test_data = TestDataGenerator()
    
    async def validate_all_functions(self) -> AgentValidationResult:
        """ëª¨ë“  ì—ì´ì „íŠ¸ì˜ ëª¨ë“  ê¸°ëŠ¥ ê²€ì¦"""
        
        results = {}
        
        # ì—ì´ì „íŠ¸ë³„ ê¸°ëŠ¥ ë§¤í•‘
        function_map = {
            "data_cleaning": self.validate_data_cleaning_functions,
            "data_loader": self.validate_data_loader_functions,
            "data_visualization": self.validate_visualization_functions,
            "data_wrangling": self.validate_wrangling_functions,
            "feature_engineering": self.validate_feature_engineering_functions,
            "sql_database": self.validate_sql_functions,
            "eda_tools": self.validate_eda_functions,
            "h2o_ml": self.validate_ml_functions,
            "mlflow_tools": self.validate_mlflow_functions,
            "pandas_analyst": self.validate_pandas_functions,
            "report_generator": self.validate_report_functions
        }
        
        validator_func = function_map.get(self.agent.agent_id)
        if validator_func:
            results[self.agent.agent_id] = await validator_func()
        
        return AgentValidationResult(
            agent_id=self.agent.agent_id,
            total_functions=len(results),
            passed_functions=sum(1 for r in results.values() if r.passed),
            failed_functions=sum(1 for r in results.values() if not r.passed),
            results=results
        )
    
    async def validate_data_cleaning_functions(self) -> Dict[str, FunctionTestResult]:
        """Data Cleaning Agent 8ê°œ ê¸°ëŠ¥ ê²€ì¦"""
        
        results = {}
        
        # 1. ëˆ„ë½ê°’ ê°ì§€
        results["missing_value_detection"] = await self.test_function(
            function_name="detect_missing_values",
            test_data={"data": self.test_data.create_dirty_data()},
            expected_output_type=dict,
            validation_func=lambda x: "null_count" in x and "missing_count" in x
        )
        
        # 2. ëˆ„ë½ê°’ ì²˜ë¦¬
        results["missing_value_handling"] = await self.test_function(
            function_name="handle_missing_values",
            test_data={"data": test_data, "strategy": "mean"},
            expected_output_type=pd.DataFrame,
            validation_func=lambda x: x.isnull().sum().sum() == 0
        )
        
        # 3. ì´ìƒì¹˜ ê°ì§€
        results["outlier_detection"] = await self.test_function(
            function_name="detect_outliers",
            test_data={"data": test_data, "method": "iqr"},
            expected_output_type=dict,
            validation_func=lambda x: "outlier_indices" in x
        )
        
        # 4. ì´ìƒì¹˜ ì²˜ë¦¬
        results["outlier_treatment"] = await self.test_function(
            function_name="treat_outliers",
            test_data=test_data,
            expected_output_type=pd.DataFrame,
            validation_func=lambda x: len(x) <= len(test_data)
        )
        
        # 5. ë°ì´í„° íƒ€ì… ê²€ì¦
        results["data_type_validation"] = await self.test_function(
            function_name="validate_data_types",
            test_data=test_data,
            expected_output_type=dict,
            validation_func=lambda x: "type_issues" in x
        )
        
        # 6. ì¤‘ë³µ ê°ì§€
        results["duplicate_detection"] = await self.test_function(
            function_name="detect_duplicates",
            test_data=test_data,
            expected_output_type=dict,
            validation_func=lambda x: "duplicate_count" in x
        )
        
        # 7. ë°ì´í„° í‘œì¤€í™”
        results["data_standardization"] = await self.test_function(
            function_name="standardize_data",
            test_data=test_data,
            expected_output_type=pd.DataFrame,
            validation_func=lambda x: len(x.columns) == len(test_data.columns)
        )
        
        # 8. ë°ì´í„° ê²€ì¦ ê·œì¹™
        results["data_validation_rules"] = await self.test_function(
            function_name="apply_validation_rules",
            test_data={"data": test_data, "rules": {"age": {"min": 0, "max": 120}}},
            expected_output_type=dict,
            validation_func=lambda x: "validation_results" in x
        )
        
        return results
    
    async def test_function(
        self,
        function_name: str,
        test_data: Any,
        expected_output_type: type,
        validation_func: callable
    ) -> FunctionTestResult:
        """ê°œë³„ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
        
        try:
            # A2A í”„ë¡œí† ì½œë¡œ ì—ì´ì „íŠ¸ í˜¸ì¶œ
            response = await self.agent.call_function(function_name, test_data)
            
            # ì¶œë ¥ íƒ€ì… ê²€ì¦
            if not isinstance(response, expected_output_type):
                return FunctionTestResult(
                    function_name=function_name,
                    passed=False,
                    error=f"Expected {expected_output_type}, got {type(response)}"
                )
            
            # ì»¤ìŠ¤í…€ ê²€ì¦ í•¨ìˆ˜ ì‹¤í–‰
            if not validation_func(response):
                return FunctionTestResult(
                    function_name=function_name,
                    passed=False,
                    error="Custom validation failed"
                )
            
            return FunctionTestResult(
                function_name=function_name,
                passed=True,
                response=response
            )
            
        except Exception as e:
            return FunctionTestResult(
                function_name=function_name,
                passed=False,
                error=str(e)
            )
```

### 4. Langfuse v2 í†µí•© ì‹œìŠ¤í…œ

```python
class LangfuseIntegration:
    """EMP_NO=2055186 ê¸°ë°˜ Langfuse v2 ì™„ì „ í†µí•©"""
    
    def __init__(self):
        self.user_id = "2055186"  # EMP_NO
        self.client = Langfuse(
            public_key=os.getenv("LANGFUSE_PUBLIC_KEY"),
            secret_key=os.getenv("LANGFUSE_SECRET_KEY"),
            host=os.getenv("LANGFUSE_HOST", "http://localhost:3000")
        )
    
    async def start_session(
        self, 
        session_id: str,
        user_query: str,
        metadata: Dict = None
    ) -> LangfuseTrace:
        """ì‚¬ìš©ì ì„¸ì…˜ ì‹œì‘"""
        
        trace = self.client.trace(
            name="CherryAI_Analysis_Session",
            session_id=session_id,
            user_id=self.user_id,
            metadata={
                "query": user_query,
                "timestamp": datetime.now().isoformat(),
                "system": "CherryAI_v2",
                **(metadata or {})
            }
        )
        
        return trace
    
    async def trace_agent_execution(
        self,
        trace: LangfuseTrace,
        agent_id: str,
        function_name: str,
        input_data: Any,
        output_data: Any,
        execution_time: float
    ):
        """ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¶”ì """
        
        span = trace.span(
            name=f"A2A_Agent_{agent_id}_{function_name}",
            input={"data": str(input_data)[:1000]},  # í¬ê¸° ì œí•œ
            output={"data": str(output_data)[:1000]},  # í¬ê¸° ì œí•œ
            metadata={
                "agent_id": agent_id,
                "function": function_name,
                "execution_time": execution_time,
                "timestamp": datetime.now().isoformat()
            }
        )
        
        # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê¸°ë¡
        span.score(
            name="execution_time",
            value=execution_time,
            comment=f"{agent_id} execution performance"
        )
    
    async def trace_llm_call(
        self,
        trace: LangfuseTrace,
        prompt: str,
        response: str,
        model: str = "qwen3-4b-fast",
        tokens_used: int = None
    ):
        """LLM í˜¸ì¶œ ì¶”ì """
        
        generation = trace.generation(
            name="LLM_Call",
            model=model,
            input=prompt,
            output=response,
            metadata={
                "model_provider": "ollama",
                "tokens_used": tokens_used,
            }
        )
        
        return generation
    
    async def end_session(
        self,
        trace: LangfuseTrace,
        final_result: Any,
        performance_metrics: Dict
    ):
        """ì„¸ì…˜ ì¢…ë£Œ ë° ìµœì¢… ë©”íŠ¸ë¦­ ê¸°ë¡"""
        
        trace.update(
            output=str(final_result)[:2000],  # í¬ê¸° ì œí•œ
            metadata={
                "session_completed": datetime.now().isoformat(),
                "total_execution_time": performance_metrics.get("total_time"),
                "agents_used": performance_metrics.get("agents_used"),
                "functions_called": performance_metrics.get("functions_called"),
                "success": performance_metrics.get("success", True)
            }
        )
        
        # ì„¸ì…˜ í’ˆì§ˆ ì ìˆ˜ ê¸°ë¡
        if "quality_score" in performance_metrics:
            trace.score(
                name="analysis_quality",
                value=performance_metrics["quality_score"],
                comment="Overall analysis quality assessment"
            )
```

### 5. Universal Domain Adaptation System

```python
class UniversalDomainAdaptationSystem:
    """LLM-First ë²”ìš© ë„ë©”ì¸ ì ì‘ ì‹œìŠ¤í…œ - Zero Hardcoding"""
    
    def __init__(self):
        self.llm_client = LLMFactory.create_llm_client()
        self.universal_engine = UniversalQueryProcessor()
        self.context_discovery = DynamicContextDiscovery()
        self.meta_reasoning = MetaReasoningEngine()
    
    async def process_any_domain_data(
        self,
        data: Any,
        user_query: str,
        user_context: Dict = None
    ) -> UniversalAnalysisResult:
        """
        ì™„ì „í•œ LLM-First ë²”ìš© ë„ë©”ì¸ ë°ì´í„° ì²˜ë¦¬
        - í•˜ë“œì½”ë”©ëœ ë„ë©”ì¸ ë¡œì§ ì—†ìŒ
        - LLMì´ ëª¨ë“  ë„ë©”ì¸ íŠ¹ì„± ìë™ ê°ì§€
        - ë™ì  ë¶„ì„ ì „ëµ ìˆ˜ë¦½
        """
        
        analysis_result = {
            "analysis_id": f"universal_analysis_{int(datetime.now().timestamp())}",
            "query": user_query,
            "domain_detection": {},
            "analysis_strategy": {},
            "execution_results": {},
            "quality_assessment": {},
            "adaptive_insights": {}
        }
        
        try:
            # 1. LLM ê¸°ë°˜ ë„ë©”ì¸ ìë™ ê°ì§€ (Zero Hardcoding)
            domain_detection = await self.context_discovery.detect_domain(data, user_query)
            analysis_result["domain_detection"] = domain_detection
            
            # 2. LLM ê¸°ë°˜ ë¶„ì„ ì „ëµ ë™ì  ìˆ˜ë¦½
            strategy_prompt = f"""
            ë°ì´í„°ì™€ ì¿¼ë¦¬ë¥¼ ë¶„ì„í•˜ì—¬ ìµœì ì˜ ë¶„ì„ ì „ëµì„ ìˆ˜ë¦½í•´ì£¼ì„¸ìš”:
            
            ë°ì´í„° íŠ¹ì„±: {await self.context_discovery.analyze_data_characteristics(data)}
            ì‚¬ìš©ì ì¿¼ë¦¬: {user_query}
            ë„ë©”ì¸ ê°ì§€ ê²°ê³¼: {domain_detection}
            ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸: {user_context or {}}
            
            ë‹¤ìŒì„ í¬í•¨í•œ ë¶„ì„ ì „ëµì„ JSONìœ¼ë¡œ ì œì•ˆí•´ì£¼ì„¸ìš”:
            1. ë¶„ì„ ì ‘ê·¼ë²• (í†µê³„ì , ì‹œê°ì , ë¨¸ì‹ ëŸ¬ë‹ ë“±)
            2. ì¤‘ì  ë¶„ì„ ì˜ì—­
            3. ì˜ˆìƒ ì¸ì‚¬ì´íŠ¸ ìœ í˜•
            4. ì‚¬ìš©ì ìˆ˜ì¤€ë³„ ì„¤ëª… ì „ëµ
            5. ì¶”ì²œ í›„ì† ë¶„ì„
            
            ì–´ë–¤ ë„ë©”ì¸ì´ë“  ì ì‘í•  ìˆ˜ ìˆëŠ” ë²”ìš©ì  ì ‘ê·¼ë²•ì„ ì‚¬ìš©í•˜ì„¸ìš”.
            """
            
            analysis_strategy = await self._call_llm_for_strategy(strategy_prompt)
            analysis_result["analysis_strategy"] = analysis_strategy
            
            # 3. Universal Engineì„ í†µí•œ ë™ì  ì‹¤í–‰
            execution_results = await self.universal_engine.process_query(
                query=user_query,
                context={
                    "data": data,
                    "domain_detection": domain_detection,
                    "analysis_strategy": analysis_strategy,
                    "user_context": user_context
                }
            )
            analysis_result["execution_results"] = execution_results
            
            # 4. ë©”íƒ€ ì¶”ë¡  ê¸°ë°˜ í’ˆì§ˆ í‰ê°€
            quality_assessment = await self.meta_reasoning.assess_analysis_quality(
                execution_results
            )
            analysis_result["quality_assessment"] = quality_assessment
            
            # 5. LLM ê¸°ë°˜ ì ì‘í˜• ì¸ì‚¬ì´íŠ¸ ìƒì„±
            adaptive_insights = await self._generate_adaptive_insights(
                analysis_result, user_context
            )
            analysis_result["adaptive_insights"] = adaptive_insights
            
            return UniversalAnalysisResult(**analysis_result)
            
        except Exception as e:
            analysis_result["error"] = str(e)
            analysis_result["status"] = "failed"
            return UniversalAnalysisResult(**analysis_result)
    
    async def _generate_adaptive_insights(
        self, 
        analysis_result: Dict, 
        user_context: Dict
    ) -> Dict[str, Any]:
        """
        LLM ê¸°ë°˜ ì ì‘í˜• ì¸ì‚¬ì´íŠ¸ ìƒì„±
        ì‚¬ìš©ì ìˆ˜ì¤€ê³¼ ë„ë©”ì¸ì— ê´€ê³„ì—†ì´ ë™ì ìœ¼ë¡œ ì ì‘
        """
        
        insights_prompt = f"""
        ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ ë§ëŠ” ì¸ì‚¬ì´íŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”:
        
        ë¶„ì„ ê²°ê³¼: {json.dumps(analysis_result, indent=2)}
        ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸: {user_context or {}}
        
        ë‹¤ìŒì„ í¬í•¨í•œ ì ì‘í˜• ì¸ì‚¬ì´íŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”:
        1. í•µì‹¬ ë°œê²¬ì‚¬í•­ (ì‚¬ìš©ì ìˆ˜ì¤€ì— ë§ê²Œ)
        2. ì‹¤ìš©ì  ê¶Œì¥ì‚¬í•­
        3. ì£¼ì˜ì‚¬í•­ ë° í•œê³„ì 
        4. í›„ì† ë¶„ì„ ì œì•ˆ
        5. ë„ë©”ì¸ë³„ íŠ¹í™” í•´ì„ (í•„ìš”ì‹œ)
        
        í•˜ë“œì½”ë”©ëœ íŒ¨í„´ ì—†ì´ ìˆœìˆ˜í•˜ê²Œ ë¶„ì„ ê²°ê³¼ì— ê¸°ë°˜í•˜ì—¬ ìƒì„±í•˜ì„¸ìš”.
        """
        
        return await self._call_llm_for_insights(insights_prompt)
    
    async def _call_llm_for_strategy(self, prompt: str) -> Dict[str, Any]:
        """LLM í˜¸ì¶œì„ í†µí•œ ë¶„ì„ ì „ëµ ìˆ˜ë¦½"""
        try:
            response = await self.llm_client.ainvoke(prompt)
            # JSON íŒŒì‹± ì‹œë„
            import json
            return json.loads(response.content if hasattr(response, 'content') else str(response))
        except:
            # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì „ëµ ë°˜í™˜
            return {
                "approach": "comprehensive_analysis",
                "focus_areas": ["statistical_summary", "pattern_detection"],
                "explanation_level": "adaptive"
            }
    
    async def _call_llm_for_insights(self, prompt: str) -> Dict[str, Any]:
        """LLM í˜¸ì¶œì„ í†µí•œ ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        try:
            response = await self.llm_client.ainvoke(prompt)
            return {
                "insights": response.content if hasattr(response, 'content') else str(response),
                "generated_at": datetime.now().isoformat(),
                "approach": "llm_first_adaptive"
            }
        except Exception as e:
            return {
                "insights": "ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œ ì¸ì‚¬ì´íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                "error": str(e),
                "approach": "fallback"
            }
```

## ğŸ¤– ì—ì´ì „íŠ¸ë³„ ìƒì„¸ ê¸°ëŠ¥ ì„¤ê³„

### 1. Data Cleaning Agent (í¬íŠ¸ 8306) - 8ê°œ ê¸°ëŠ¥

```python
class DataCleaningAgent:
    """ë°ì´í„° í’ˆì§ˆ ë³´ì¥ì„ ìœ„í•œ ì™„ì „í•œ ë°ì´í„° ì •ë¦¬ ì—ì´ì „íŠ¸"""
    
    async def detect_missing_values(self, data: pd.DataFrame) -> Dict:
        """1. ëˆ„ë½ê°’ ê°ì§€ - null, NaN, ë¹ˆ ë¬¸ìì—´ ì‹ë³„"""
        return {
            "null_count": data.isnull().sum().to_dict(),
            "missing_count": data.isna().sum().to_dict(),
            "empty_strings": (data == "").sum().to_dict(),
            "total_missing_percentage": (data.isnull().sum() / len(data) * 100).to_dict()
        }
    
    async def handle_missing_values(self, data: pd.DataFrame, strategy: str) -> pd.DataFrame:
        """2. ëˆ„ë½ê°’ ì²˜ë¦¬ - ë‹¤ì–‘í•œ ì „ëµ ì œê³µ"""
        strategies = {
            "drop": data.dropna(),
            "mean": data.fillna(data.mean(numeric_only=True)),
            "median": data.fillna(data.median(numeric_only=True)),
            "mode": data.fillna(data.mode().iloc[0]),
            "forward_fill": data.fillna(method='ffill'),
            "backward_fill": data.fillna(method='bfill'),
            "interpolation": data.interpolate()
        }
        return strategies.get(strategy, data)
    
    async def detect_outliers(self, data: pd.DataFrame, method: str) -> Dict:
        """3. ì´ìƒì¹˜ ê°ì§€ - IQR, Z-score, Isolation Forest"""
        outlier_indices = {}
        if method == "iqr":
            for col in data.select_dtypes(include=[np.number]).columns:
                Q1, Q3 = data[col].quantile([0.25, 0.75])
                IQR = Q3 - Q1
                outliers = data[(data[col] < Q1 - 1.5*IQR) | (data[col] > Q3 + 1.5*IQR)].index
                outlier_indices[col] = outliers.tolist()
        return {"outlier_indices": outlier_indices, "method": method}
    
    async def treat_outliers(self, data: pd.DataFrame, method: str) -> pd.DataFrame:
        """4. ì´ìƒì¹˜ ì²˜ë¦¬ - ì œê±°, ìº¡í•‘, ë³€í™˜"""
        # êµ¬í˜„ ë¡œì§
        return data
    
    async def validate_data_types(self, data: pd.DataFrame) -> Dict:
        """5. ë°ì´í„° íƒ€ì… ê²€ì¦ ë° ìˆ˜ì •"""
        return {"type_issues": data.dtypes.to_dict()}
    
    async def detect_duplicates(self, data: pd.DataFrame) -> Dict:
        """6. ì¤‘ë³µ ë°ì´í„° ê°ì§€"""
        return {"duplicate_count": data.duplicated().sum()}
    
    async def standardize_data(self, data: pd.DataFrame) -> pd.DataFrame:
        """7. ë°ì´í„° í‘œì¤€í™”"""
        return data
    
    async def apply_validation_rules(self, data: pd.DataFrame, rules: Dict) -> Dict:
        """8. ë°ì´í„° ê²€ì¦ ê·œì¹™ ì ìš©"""
        return {"validation_results": rules}
```

### 2. Data Loader Agent (í¬íŠ¸ 8307) - 8ê°œ ê¸°ëŠ¥

```python
class DataLoaderAgent:
    """ëª¨ë“  ë°ì´í„° ì†ŒìŠ¤ì™€ í˜•ì‹ì„ ì™„ë²½ ì§€ì›í•˜ëŠ” ë°ì´í„° ë¡œë”"""
    
    async def load_csv_files(self, file_path: str, encoding: str = "utf-8") -> pd.DataFrame:
        """1. CSV íŒŒì¼ ë¡œë”© - ë‹¤ì–‘í•œ ì¸ì½”ë”© ì§€ì›"""
        return pd.read_csv(file_path, encoding=encoding)
    
    async def load_excel_files(self, file_path: str, sheet_name: str = None) -> pd.DataFrame:
        """2. Excel íŒŒì¼ ë¡œë”© - ë‹¤ì¤‘ ì‹œíŠ¸, ë³‘í•© ì…€ ì²˜ë¦¬"""
        return pd.read_excel(file_path, sheet_name=sheet_name)
    
    async def load_json_files(self, file_path: str, flatten: bool = False) -> pd.DataFrame:
        """3. JSON íŒŒì¼ ë¡œë”© - ì¤‘ì²© êµ¬ì¡° í‰ë©´í™”"""
        data = pd.read_json(file_path)
        return pd.json_normalize(data) if flatten else data
    
    async def connect_database(self, connection_string: str, query: str) -> pd.DataFrame:
        """4. ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° - MySQL, PostgreSQL, SQLite, SQL Server"""
        # êµ¬í˜„ ë¡œì§
        return pd.DataFrame()
    
    async def load_large_files(self, file_path: str, chunk_size: int = 10000) -> Iterator[pd.DataFrame]:
        """5. ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬ - ì²­í‚¹ ë° ìŠ¤íŠ¸ë¦¬ë°"""
        for chunk in pd.read_csv(file_path, chunksize=chunk_size):
            yield chunk
    
    async def handle_parsing_errors(self, file_path: str) -> Dict:
        """6. íŒŒì¼ íŒŒì‹± ì˜¤ë¥˜ ì²˜ë¦¬"""
        return {"error_details": "íŒŒì‹± ì˜¤ë¥˜ ì •ë³´"}
    
    async def preview_data(self, file_path: str, rows: int = 5) -> Dict:
        """7. ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°"""
        data = pd.read_csv(file_path, nrows=rows)
        return {"preview": data.to_dict(), "info": str(data.info())}
    
    async def infer_schema(self, data: pd.DataFrame) -> Dict:
        """8. ë°ì´í„° ìŠ¤í‚¤ë§ˆ ìë™ ì¶”ë¡ """
        return {"schema": data.dtypes.to_dict(), "suggestions": {}}
```

### 3. Data Visualization Agent (í¬íŠ¸ 8308) - 8ê°œ ê¸°ëŠ¥

```python
class DataVisualizationAgent:
    """ëª¨ë“  ìœ í˜•ì˜ ì°¨íŠ¸ì™€ í”Œë¡¯ì„ ì™„ë²½ ìƒì„±í•˜ëŠ” ì‹œê°í™” ì—ì´ì „íŠ¸"""
    
    async def create_basic_plots(self, data: pd.DataFrame, plot_type: str) -> str:
        """1. ê¸°ë³¸ í”Œë¡¯ ìƒì„± - line, bar, scatter, histogram, box"""
        # Plotly/Matplotlib êµ¬í˜„
        return "plot_path.png"
    
    async def create_advanced_plots(self, data: pd.DataFrame, plot_type: str) -> str:
        """2. ê³ ê¸‰ í”Œë¡¯ ìƒì„± - heatmap, violin, pair plots, correlation matrix"""
        return "advanced_plot_path.png"
    
    async def create_interactive_plots(self, data: pd.DataFrame) -> str:
        """3. ì¸í„°ë™í‹°ë¸Œ í”Œë¡¯ - Plotly ê¸°ë°˜ ì¤Œ, í˜¸ë²„, ì„ íƒ ê¸°ëŠ¥"""
        return "interactive_plot.html"
    
    async def create_statistical_plots(self, data: pd.DataFrame) -> str:
        """4. í†µê³„ í”Œë¡¯ - ë¶„í¬ë„, Q-Q plot, íšŒê·€ í”Œë¡¯"""
        return "statistical_plot.png"
    
    async def create_timeseries_plots(self, data: pd.DataFrame, date_col: str) -> str:
        """5. ì‹œê³„ì—´ í”Œë¡¯ - ì‹œê°„ì¶•, ê³„ì ˆì„± ë¶„í•´, íŠ¸ë Œë“œ ë¶„ì„"""
        return "timeseries_plot.png"
    
    async def create_multidimensional_plots(self, data: pd.DataFrame) -> str:
        """6. ë‹¤ì°¨ì› í”Œë¡¯ - 3D í”Œë¡¯, ì„œë¸Œí”Œë¡¯, íŒ¨ì‹¯ ì°¨íŠ¸"""
        return "3d_plot.png"
    
    async def apply_custom_styling(self, plot_config: Dict) -> str:
        """7. ì»¤ìŠ¤í…€ ìŠ¤íƒ€ì¼ë§ - í…Œë§ˆ, ìƒ‰ìƒ, ì£¼ì„, ì œëª©, ë²”ë¡€"""
        return "styled_plot.png"
    
    async def export_plots(self, plot_object: Any, format: str) -> str:
        """8. í”Œë¡¯ ë‚´ë³´ë‚´ê¸° - PNG, SVG, HTML, PDF"""
        return f"exported_plot.{format}"
```

### 4. Data Wrangling Agent (í¬íŠ¸ 8309) - 8ê°œ ê¸°ëŠ¥

```python
class DataWranglingAgent:
    """ë°ì´í„° ë³€í™˜ ë° ì¡°ì‘ì„ ìœ„í•œ ì™„ì „í•œ ë°ì´í„° ë­ê¸€ë§ ì—ì´ì „íŠ¸"""
    
    async def filter_data(self, data: pd.DataFrame, conditions: Dict) -> pd.DataFrame:
        """1. ë°ì´í„° í•„í„°ë§ - ë³µì¡í•œ ì¡°ê±´, ë‹¤ì¤‘ ê¸°ì¤€, ë‚ ì§œ ë²”ìœ„"""
        return data.query(conditions.get("query", ""))
    
    async def sort_data(self, data: pd.DataFrame, columns: List[str], ascending: bool = True) -> pd.DataFrame:
        """2. ë°ì´í„° ì •ë ¬ - ë‹¨ì¼/ë‹¤ì¤‘ ì»¬ëŸ¼, ì»¤ìŠ¤í…€ ìˆœì„œ, null ì²˜ë¦¬"""
        return data.sort_values(columns, ascending=ascending)
    
    async def group_data(self, data: pd.DataFrame, group_by: List[str]) -> pd.DataFrameGroupBy:
        """3. ë°ì´í„° ê·¸ë£¹í™” - ì¹´í…Œê³ ë¦¬, ì‹œê°„ ì£¼ê¸°, ì»¤ìŠ¤í…€ í•¨ìˆ˜"""
        return data.groupby(group_by)
    
    async def aggregate_data(self, grouped_data: pd.DataFrameGroupBy, agg_funcs: Dict) -> pd.DataFrame:
        """4. ë°ì´í„° ì§‘ê³„ - sum, mean, count, min, max, percentiles, ì»¤ìŠ¤í…€ í•¨ìˆ˜"""
        return grouped_data.agg(agg_funcs)
    
    async def merge_data(self, left: pd.DataFrame, right: pd.DataFrame, how: str, on: str) -> pd.DataFrame:
        """5. ë°ì´í„° ë³‘í•© - inner, outer, left, right ì¡°ì¸"""
        return pd.merge(left, right, how=how, on=on)
    
    async def reshape_data(self, data: pd.DataFrame, operation: str) -> pd.DataFrame:
        """6. ë°ì´í„° ì¬êµ¬ì„± - pivot, melt, transpose, stack, unstack"""
        operations = {
            "pivot": data.pivot_table,
            "melt": pd.melt,
            "transpose": data.transpose
        }
        return operations.get(operation, lambda: data)()
    
    async def sample_data(self, data: pd.DataFrame, method: str, size: int) -> pd.DataFrame:
        """7. ë°ì´í„° ìƒ˜í”Œë§ - random, stratified, systematic"""
        if method == "random":
            return data.sample(n=size)
        return data
    
    async def split_data(self, data: pd.DataFrame, ratios: List[float]) -> List[pd.DataFrame]:
        """8. ë°ì´í„° ë¶„í•  - train/test/validation ë¶„í• """
        return [data.sample(frac=ratio) for ratio in ratios]
```

### 5. Feature Engineering Agent (í¬íŠ¸ 8310) - 8ê°œ ê¸°ëŠ¥

```python
class FeatureEngineeringAgent:
    """ë¨¸ì‹ ëŸ¬ë‹ì„ ìœ„í•œ ì™„ì „í•œ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ì—ì´ì „íŠ¸"""
    
    async def create_numerical_features(self, data: pd.DataFrame, feature_types: List[str]) -> pd.DataFrame:
        """1. ìˆ˜ì¹˜í˜• í”¼ì²˜ ìƒì„± - polynomial, interaction, ratio, log"""
        return data  # êµ¬í˜„ ë¡œì§
    
    async def encode_categorical_features(self, data: pd.DataFrame, encoding_type: str) -> pd.DataFrame:
        """2. ë²”ì£¼í˜• í”¼ì²˜ ì¸ì½”ë”© - one-hot, label, target, binary"""
        return data  # êµ¬í˜„ ë¡œì§
    
    async def extract_text_features(self, data: pd.DataFrame, text_column: str) -> pd.DataFrame:
        """3. í…ìŠ¤íŠ¸ í”¼ì²˜ ì¶”ì¶œ - TF-IDF, word counts, n-grams, embeddings"""
        return data  # êµ¬í˜„ ë¡œì§
    
    async def extract_datetime_features(self, data: pd.DataFrame, date_column: str) -> pd.DataFrame:
        """4. ë‚ ì§œì‹œê°„ í”¼ì²˜ ì¶”ì¶œ - year, month, day, hour, weekday, season"""
        return data  # êµ¬í˜„ ë¡œì§
    
    async def scale_features(self, data: pd.DataFrame, scaling_method: str) -> pd.DataFrame:
        """5. í”¼ì²˜ ìŠ¤ì¼€ì¼ë§ - standardization, normalization, robust scaling"""
        return data  # êµ¬í˜„ ë¡œì§
    
    async def select_features(self, data: pd.DataFrame, target: str, method: str) -> List[str]:
        """6. í”¼ì²˜ ì„ íƒ - correlation, mutual info, chi-square, recursive elimination"""
        return data.columns.tolist()  # êµ¬í˜„ ë¡œì§
    
    async def reduce_dimensionality(self, data: pd.DataFrame, method: str, n_components: int) -> pd.DataFrame:
        """7. ì°¨ì› ì¶•ì†Œ - PCA, t-SNE, UMAP, factor analysis"""
        return data  # êµ¬í˜„ ë¡œì§
    
    async def calculate_feature_importance(self, data: pd.DataFrame, target: str, method: str) -> Dict:
        """8. í”¼ì²˜ ì¤‘ìš”ë„ ê³„ì‚° - permutation, SHAP, tree-based importance"""
        return {"importance_scores": {}}  # êµ¬í˜„ ë¡œì§
```

### 6. SQL Database Agent (í¬íŠ¸ 8311) - 8ê°œ ê¸°ëŠ¥

```python
class SQLDatabaseAgent:
    """ë°ì´í„°ë² ì´ìŠ¤ ë¶„ì„ì„ ìœ„í•œ ì™„ì „í•œ SQL ì—ì´ì „íŠ¸"""
    
    async def connect_to_database(self, connection_params: Dict) -> bool:
        """1. ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° - ë‹¤ì¤‘ DB íƒ€ì…, ì¸ì¦"""
        return True  # êµ¬í˜„ ë¡œì§
    
    async def execute_sql_queries(self, query: str, operation_type: str) -> Any:
        """2. SQL ì¿¼ë¦¬ ì‹¤í–‰ - SELECT, INSERT, UPDATE, DELETE"""
        return {}  # êµ¬í˜„ ë¡œì§
    
    async def create_complex_queries(self, query_spec: Dict) -> str:
        """3. ë³µì¡í•œ ì¿¼ë¦¬ ìƒì„± - JOINs, subqueries, CTEs, window functions"""
        return "SELECT * FROM table"  # êµ¬í˜„ ë¡œì§
    
    async def optimize_queries(self, query: str) -> Dict:
        """4. ì¿¼ë¦¬ ìµœì í™” - ì¸ë±ìŠ¤ ì œì•ˆ, ì¿¼ë¦¬ ì¬ì‘ì„±, ì‹¤í–‰ ê³„íš"""
        return {"optimized_query": query, "suggestions": []}
    
    async def analyze_database_schema(self, database_name: str) -> Dict:
        """5. ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ë¶„ì„ - í…Œì´ë¸”, ì»¬ëŸ¼, ê´€ê³„, ì œì•½ì¡°ê±´"""
        return {"schema_info": {}}
    
    async def profile_database_data(self, table_name: str) -> Dict:
        """6. ë°ì´í„° í”„ë¡œíŒŒì¼ë§ - ë¶„í¬, ì¹´ë””ë„ë¦¬í‹°, null ë¹„ìœ¨, íŒ¨í„´"""
        return {"profile_results": {}}
    
    async def handle_large_results(self, query: str, chunk_size: int) -> Iterator[Dict]:
        """7. ëŒ€ìš©ëŸ‰ ê²°ê³¼ ì²˜ë¦¬ - í˜ì´ì§€ë„¤ì´ì…˜, ìŠ¤íŠ¸ë¦¬ë°"""
        yield {"chunk": []}  # êµ¬í˜„ ë¡œì§
    
    async def handle_database_errors(self, error: Exception) -> Dict:
        """8. ë°ì´í„°ë² ì´ìŠ¤ ì˜¤ë¥˜ ì²˜ë¦¬ - ì˜ë¯¸ìˆëŠ” ì˜¤ë¥˜ ë©”ì‹œì§€, ë³µêµ¬ ì œì•ˆ"""
        return {"error_message": str(error), "recovery_suggestions": []}
```

### 7. EDA Tools Agent (í¬íŠ¸ 8312) - 8ê°œ ê¸°ëŠ¥

```python
class EDAToolsAgent:
    """íƒìƒ‰ì  ë°ì´í„° ë¶„ì„ì„ ìœ„í•œ ì™„ì „í•œ EDA ì—ì´ì „íŠ¸"""
    
    async def compute_descriptive_statistics(self, data: pd.DataFrame) -> Dict:
        """1. ê¸°ìˆ í†µê³„ ê³„ì‚° - mean, median, mode, std, skewness, kurtosis"""
        return {
            "mean": data.mean(numeric_only=True).to_dict(),
            "median": data.median(numeric_only=True).to_dict(),
            "std": data.std(numeric_only=True).to_dict(),
            "skewness": data.skew(numeric_only=True).to_dict(),
            "kurtosis": data.kurtosis(numeric_only=True).to_dict()
        }
    
    async def analyze_correlations(self, data: pd.DataFrame, method: str) -> Dict:
        """2. ìƒê´€ê´€ê³„ ë¶„ì„ - Pearson, Spearman, Kendall correlations with significance"""
        return {"correlation_matrix": data.corr(method=method).to_dict()}
    
    async def analyze_distributions(self, data: pd.DataFrame) -> Dict:
        """3. ë¶„í¬ ë¶„ì„ - ì •ê·œì„± ê²€ì •, ë¶„í¬ ì í•©, Q-Q plots"""
        return {"distribution_tests": {}}
    
    async def analyze_categorical_data(self, data: pd.DataFrame, cat_columns: List[str]) -> Dict:
        """4. ë²”ì£¼í˜• ë°ì´í„° ë¶„ì„ - ë¹ˆë„í‘œ, ì¹´ì´ì œê³± ê²€ì •, CramÃ©r's V"""
        return {"categorical_analysis": {}}
    
    async def analyze_timeseries(self, data: pd.DataFrame, date_column: str) -> Dict:
        """5. ì‹œê³„ì—´ ë¶„ì„ - íŠ¸ë Œë“œ, ê³„ì ˆì„±, ì •ìƒì„±, ìê¸°ìƒê´€"""
        return {"timeseries_analysis": {}}
    
    async def detect_anomalies(self, data: pd.DataFrame, method: str) -> Dict:
        """6. ì´ìƒ íƒì§€ - ì´ìƒì¹˜, ë³€í™”ì , ë¹„ì •ìƒ íŒ¨í„´"""
        return {"anomalies": {}}
    
    async def assess_data_quality(self, data: pd.DataFrame) -> Dict:
        """7. ë°ì´í„° í’ˆì§ˆ í‰ê°€ - ì™„ì „ì„±, ì¼ê´€ì„±, ìœ íš¨ì„±, ìœ ì¼ì„±"""
        return {"quality_assessment": {}}
    
    async def generate_automated_insights(self, data: pd.DataFrame) -> Dict:
        """8. ìë™í™”ëœ ì¸ì‚¬ì´íŠ¸ ìƒì„± - ì£¼ìš” ë°œê²¬ì‚¬í•­ì˜ ì„œìˆ ì  ìš”ì•½"""
        return {"automated_insights": "ë°ì´í„° ë¶„ì„ ê²°ê³¼ ìš”ì•½"}
```

### 8. H2O ML Agent (í¬íŠ¸ 8313) - 8ê°œ ê¸°ëŠ¥

```python
class H2OMLAgent:
    """ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ ê°œë°œì„ ìœ„í•œ ì™„ì „í•œ H2O ML ì—ì´ì „íŠ¸"""
    
    async def run_automl(self, data: pd.DataFrame, target: str, max_models: int = 20) -> Dict:
        """1. AutoML ì‹¤í–‰ - ë‹¤ì¤‘ ì•Œê³ ë¦¬ì¦˜ í›ˆë ¨ ë° ìµœì  ëª¨ë¸ ì„ íƒ"""
        return {"best_model": "GBM", "leaderboard": []}
    
    async def train_classification_models(self, data: pd.DataFrame, target: str, algorithms: List[str]) -> Dict:
        """2. ë¶„ë¥˜ ëª¨ë¸ í›ˆë ¨ - Random Forest, GBM, XGBoost, Neural Networks"""
        return {"trained_models": algorithms, "performance": {}}
    
    async def train_regression_models(self, data: pd.DataFrame, target: str, algorithms: List[str]) -> Dict:
        """3. íšŒê·€ ëª¨ë¸ í›ˆë ¨ - Linear, GLM, GBM, Deep Learning"""
        return {"trained_models": algorithms, "performance": {}}
    
    async def evaluate_models(self, model_ids: List[str], test_data: pd.DataFrame) -> Dict:
        """4. ëª¨ë¸ í‰ê°€ - accuracy, precision, recall, F1, AUC, RMSE, MAE"""
        return {"evaluation_metrics": {}}
    
    async def tune_hyperparameters(self, model_type: str, param_grid: Dict, data: pd.DataFrame) -> Dict:
        """5. í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ - grid search, random search, Bayesian optimization"""
        return {"best_params": param_grid, "best_score": 0.95}
    
    async def explain_model_features(self, model_id: str, method: str) -> Dict:
        """6. í”¼ì²˜ ì¤‘ìš”ë„ ë¶„ì„ - SHAP values, permutation importance, variable importance"""
        return {"feature_importance": {}, "shap_values": []}
    
    async def interpret_model_predictions(self, model_id: str, data: pd.DataFrame) -> Dict:
        """7. ëª¨ë¸ í•´ì„ - partial dependence plots, LIME explanations"""
        return {"interpretation_results": {}}
    
    async def deploy_model(self, model_id: str, format: str) -> Dict:
        """8. ëª¨ë¸ ë°°í¬ - MOJO, POJO, pickle í˜•ì‹ìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°"""
        return {"deployment_path": f"model.{format}", "model_info": {}}
```

### 9. MLflow Tools Agent (í¬íŠ¸ 8314) - 8ê°œ ê¸°ëŠ¥

```python
class MLflowToolsAgent:
    """ML ë¼ì´í”„ì‚¬ì´í´ ê´€ë¦¬ë¥¼ ìœ„í•œ ì™„ì „í•œ MLflow ì—ì´ì „íŠ¸"""
    
    async def track_experiments(self, experiment_name: str, params: Dict, metrics: Dict, artifacts: List[str]) -> Dict:
        """1. ì‹¤í—˜ ì¶”ì  - íŒŒë¼ë¯¸í„°, ë©”íŠ¸ë¦­, ì•„í‹°íŒ©íŠ¸, ëª¨ë¸ ë²„ì „ ë¡œê¹…"""
        return {"run_id": "run_123", "experiment_id": "exp_456"}
    
    async def manage_model_registry(self, model_name: str, action: str, stage: str = None) -> Dict:
        """2. ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ê´€ë¦¬ - ë“±ë¡, ë²„ì „ ê´€ë¦¬, ìŠ¤í…Œì´ì§€, ì „í™˜"""
        return {"model_version": 1, "stage": stage or "None"}
    
    async def serve_models(self, model_uri: str, port: int = 5000) -> Dict:
        """3. ëª¨ë¸ ì„œë¹™ - REST APIë¡œ ëª¨ë¸ ë°°í¬"""
        return {"serving_url": f"http://localhost:{port}", "status": "running"}
    
    async def compare_experiments(self, experiment_ids: List[str], metrics: List[str]) -> Dict:
        """4. ì‹¤í—˜ ë¹„êµ - ëŸ°, ë©”íŠ¸ë¦­, íŒŒë¼ë¯¸í„° ê°„ ë¹„êµ"""
        return {"comparison_results": {}, "best_run": "run_123"}
    
    async def manage_artifacts(self, run_id: str, action: str, artifact_path: str = None) -> Dict:
        """5. ì•„í‹°íŒ©íŠ¸ ê´€ë¦¬ - ë°ì´í„°ì…‹, ëª¨ë¸, í”Œë¡¯, ë¦¬í¬íŠ¸ ì €ì¥/ê²€ìƒ‰"""
        return {"artifact_uri": artifact_path, "status": "success"}
    
    async def monitor_model_performance(self, model_name: str, data: pd.DataFrame) -> Dict:
        """6. ëª¨ë¸ ëª¨ë‹ˆí„°ë§ - ì„±ëŠ¥ ì¶”ì , ë“œë¦¬í”„íŠ¸, ë°ì´í„° í’ˆì§ˆ"""
        return {"performance_metrics": {}, "drift_detected": False}
    
    async def orchestrate_pipelines(self, pipeline_config: Dict) -> Dict:
        """7. íŒŒì´í”„ë¼ì¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ - ML ì›Œí¬í”Œë¡œìš° ìƒì„± ë° ê´€ë¦¬"""
        return {"pipeline_id": "pipeline_789", "status": "running"}
    
    async def manage_collaboration(self, project_name: str, action: str, user_permissions: Dict = None) -> Dict:
        """8. í˜‘ì—… ê¸°ëŠ¥ - íŒ€ ì•¡ì„¸ìŠ¤, ê¶Œí•œ, ê³µìœ """
        return {"project_id": project_name, "permissions": user_permissions or {}}
```

### 10. Pandas Analyst Agent (í¬íŠ¸ 8210) - 8ê°œ ê¸°ëŠ¥

```python
class PandasAnalystAgent:
    """ë°ì´í„° ì¡°ì‘ ë° ë¶„ì„ì„ ìœ„í•œ ì™„ì „í•œ Pandas ì—ì´ì „íŠ¸"""
    
    async def load_and_inspect_data(self, file_path: str, format: str) -> Dict:
        """1. ë°ì´í„° ë¡œë”© ë° ê²€ì‚¬ - ë‹¤ì–‘í•œ í˜•ì‹, íŒŒì‹± ì˜µì…˜"""
        data = pd.read_csv(file_path) if format == "csv" else pd.read_excel(file_path)
        return {
            "shape": data.shape,
            "dtypes": data.dtypes.to_dict(),
            "head": data.head().to_dict(),
            "info": str(data.info())
        }
    
    async def perform_data_inspection(self, data: pd.DataFrame) -> Dict:
        """2. ë°ì´í„° ê²€ì‚¬ - info, describe, head, tail, shape, dtypes"""
        return {
            "describe": data.describe().to_dict(),
            "info": str(data.info()),
            "shape": data.shape,
            "dtypes": data.dtypes.to_dict(),
            "head": data.head().to_dict(),
            "tail": data.tail().to_dict()
        }
    
    async def select_and_filter_data(self, data: pd.DataFrame, conditions: Dict) -> pd.DataFrame:
        """3. ë°ì´í„° ì„ íƒ ë° í•„í„°ë§ - í–‰ í•„í„°, ì»¬ëŸ¼ ì„ íƒ, ë³µì¡í•œ ì¡°ê±´"""
        if "query" in conditions:
            return data.query(conditions["query"])
        if "columns" in conditions:
            return data[conditions["columns"]]
        return data
    
    async def manipulate_data(self, data: pd.DataFrame, operations: List[Dict]) -> pd.DataFrame:
        """4. ë°ì´í„° ì¡°ì‘ - apply, map, transform, replace, rename"""
        result = data.copy()
        for op in operations:
            if op["type"] == "rename":
                result = result.rename(columns=op["mapping"])
            elif op["type"] == "replace":
                result = result.replace(op["old"], op["new"])
        return result
    
    async def aggregate_and_group_data(self, data: pd.DataFrame, group_by: List[str], agg_funcs: Dict) -> pd.DataFrame:
        """5. ë°ì´í„° ì§‘ê³„ - groupby, pivot_table, crosstab, resample"""
        if group_by:
            return data.groupby(group_by).agg(agg_funcs)
        return data
    
    async def merge_and_join_data(self, left: pd.DataFrame, right: pd.DataFrame, merge_config: Dict) -> pd.DataFrame:
        """6. ë°ì´í„° ë³‘í•© - merge, join, concat, append with ë‹¤ì–‘í•œ ì „ëµ"""
        return pd.merge(
            left, right,
            how=merge_config.get("how", "inner"),
            on=merge_config.get("on"),
            left_on=merge_config.get("left_on"),
            right_on=merge_config.get("right_on")
        )
    
    async def clean_data(self, data: pd.DataFrame, cleaning_config: Dict) -> pd.DataFrame:
        """7. ë°ì´í„° ì •ë¦¬ - ëˆ„ë½ê°’, ì¤‘ë³µê°’, ë°ì´í„° íƒ€ì… ì²˜ë¦¬"""
        result = data.copy()
        if cleaning_config.get("drop_na"):
            result = result.dropna()
        if cleaning_config.get("drop_duplicates"):
            result = result.drop_duplicates()
        return result
    
    async def perform_statistical_analysis(self, data: pd.DataFrame, analysis_type: str) -> Dict:
        """8. í†µê³„ ë¶„ì„ - ìƒê´€ê´€ê³„, ë¶„í¬, ê°€ì„¤ ê²€ì •"""
        if analysis_type == "correlation":
            return {"correlation_matrix": data.corr().to_dict()}
        elif analysis_type == "describe":
            return {"statistics": data.describe().to_dict()}
        return {"analysis_results": {}}
```

### 11. Report Generator Agent (í¬íŠ¸ 8316) - 8ê°œ ê¸°ëŠ¥

```python
class ReportGeneratorAgent:
    """ë¶„ì„ ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„±ì„ ìœ„í•œ ì™„ì „í•œ ë¦¬í¬íŠ¸ ì—ì´ì „íŠ¸"""
    
    async def generate_executive_summary(self, analysis_results: Dict, key_findings: List[str]) -> Dict:
        """1. ê²½ì˜ì§„ ìš”ì•½ ìƒì„± - í•µì‹¬ ì¸ì‚¬ì´íŠ¸ì™€ ì£¼ìš” ë°œê²¬ì‚¬í•­"""
        return {
            "executive_summary": "ë¶„ì„ ê²°ê³¼ ìš”ì•½",
            "key_findings": key_findings,
            "recommendations": []
        }
    
    async def create_detailed_analysis_report(self, data: pd.DataFrame, analysis_config: Dict) -> Dict:
        """2. ìƒì„¸ ë¶„ì„ ë¦¬í¬íŠ¸ - ë°©ë²•ë¡ , ê²°ê³¼, ê²°ë¡  í¬í•¨"""
        return {
            "methodology": analysis_config.get("methodology", ""),
            "results": "ìƒì„¸ ë¶„ì„ ê²°ê³¼",
            "conclusions": "ë¶„ì„ ê²°ë¡ ",
            "limitations": "ë¶„ì„ í•œê³„ì "
        }
    
    async def assess_data_quality_report(self, data: pd.DataFrame) -> Dict:
        """3. ë°ì´í„° í’ˆì§ˆ ë¦¬í¬íŠ¸ - ì™„ì „ì„±, ì •í™•ì„±, ì¼ê´€ì„± í‰ê°€"""
        return {
            "completeness": (1 - data.isnull().sum().sum() / (len(data) * len(data.columns))) * 100,
            "accuracy_indicators": {},
            "consistency_checks": {},
            "quality_score": 85.5
        }
    
    async def generate_statistical_report(self, data: pd.DataFrame, tests_config: List[Dict]) -> Dict:
        """4. í†µê³„ ë¦¬í¬íŠ¸ - ê¸°ìˆ í†µê³„, ê²€ì •, ì‹ ë¢°êµ¬ê°„ í¬í•¨"""
        return {
            "descriptive_statistics": data.describe().to_dict(),
            "statistical_tests": {},
            "confidence_intervals": {},
            "significance_levels": {}
        }
    
    async def create_visualization_report(self, plots: List[str], descriptions: List[str]) -> Dict:
        """5. ì‹œê°í™” ë¦¬í¬íŠ¸ - ì°¨íŠ¸, í…Œì´ë¸”, ì¸í„°ë™í‹°ë¸Œ ìš”ì†Œ í¬í•¨"""
        return {
            "visualizations": plots,
            "descriptions": descriptions,
            "interactive_elements": [],
            "chart_insights": []
        }
    
    async def perform_comparative_analysis(self, datasets: List[pd.DataFrame], comparison_config: Dict) -> Dict:
        """6. ë¹„êµ ë¶„ì„ - ë°ì´í„°ì…‹, ì‹œê°„ ì£¼ê¸°, ì„¸ê·¸ë¨¼íŠ¸ ê°„ ë¹„êµ"""
        return {
            "comparison_results": {},
            "differences": [],
            "similarities": [],
            "trend_analysis": {}
        }
    
    async def generate_recommendations(self, analysis_results: Dict, business_context: Dict) -> Dict:
        """7. ê¶Œì¥ì‚¬í•­ ë¦¬í¬íŠ¸ - ì‹¤í–‰ ê°€ëŠ¥í•œ ì¸ì‚¬ì´íŠ¸ì™€ ë‹¤ìŒ ë‹¨ê³„"""
        return {
            "recommendations": [],
            "action_items": [],
            "next_steps": [],
            "expected_outcomes": []
        }
    
    async def export_report(self, report_content: Dict, format: str, styling_config: Dict = None) -> str:
        """8. ë¦¬í¬íŠ¸ ë‚´ë³´ë‚´ê¸° - PDF, HTML, Word, PowerPoint í˜•ì‹"""
        export_path = f"report.{format}"
        # ì‹¤ì œ ë‚´ë³´ë‚´ê¸° ë¡œì§ êµ¬í˜„
        return export_path
```meseries_plot.png"
    
    async def create_multidimensional_plots(self, data: pd.DataFrame) -> str:
        """6. ë‹¤ì°¨ì› í”Œë¡¯ - 3D í”Œë¡¯, ì„œë¸Œí”Œë¡¯, íŒ¨ì‹¯ ì°¨íŠ¸"""
        return "3d_plot.png"
    
    async def apply_custom_styling(self, plot_config: Dict) -> str:
        """7. ì»¤ìŠ¤í…€ ìŠ¤íƒ€ì¼ë§ - í…Œë§ˆ, ìƒ‰ìƒ, ì£¼ì„, ì œëª©, ë²”ë¡€"""
        return "styled_plot.png"
    
    async def export_plots(self, plot_object: Any, format: str) -> str:
        """8. í”Œë¡¯ ë‚´ë³´ë‚´ê¸° - PNG, SVG, HTML, PDF"""
        return f"exported_plot.{format}"
```

### 4. Data Wrangling Agent (í¬íŠ¸ 8309) - 8ê°œ ê¸°ëŠ¥

```python
class DataWranglingAgent:
    """ë°ì´í„° ë³€í™˜ ë° ì¡°ì‘ì„ ìœ„í•œ ì™„ì „í•œ ë°ì´í„° ë­ê¸€ë§ ì—ì´ì „íŠ¸"""
    
    async def filter_data(self, data: pd.DataFrame, conditions: Dict) -> pd.DataFrame:
        """1. ë°ì´í„° í•„í„°ë§ - ë³µì¡í•œ ì¡°ê±´, ë‹¤ì¤‘ ê¸°ì¤€, ë‚ ì§œ ë²”ìœ„"""
        return data.query(conditions.get("query", ""))
    
    async def sort_data(self, data: pd.DataFrame, columns: List[str], ascending: bool = True) -> pd.DataFrame:
        """2. ë°ì´í„° ì •ë ¬ - ë‹¨ì¼/ë‹¤ì¤‘ ì»¬ëŸ¼, ì»¤ìŠ¤í…€ ìˆœì„œ, null ì²˜ë¦¬"""
        return data.sort_values(columns, ascending=ascending)
    
    async def group_data(self, data: pd.DataFrame, group_by: List[str]) -> pd.DataFrameGroupBy:
        """3. ë°ì´í„° ê·¸ë£¹í™” - ì¹´í…Œê³ ë¦¬, ì‹œê°„ ì£¼ê¸°, ì»¤ìŠ¤í…€ í•¨ìˆ˜"""
        return data.groupby(group_by)
    
    async def aggregate_data(self, grouped_data: pd.DataFrameGroupBy, agg_funcs: Dict) -> pd.DataFrame:
        """4. ë°ì´í„° ì§‘ê³„ - sum, mean, count, min, max, percentiles, ì»¤ìŠ¤í…€ í•¨ìˆ˜"""
        return grouped_data.agg(agg_funcs)
    
    async def merge_data(self, left: pd.DataFrame, right: pd.DataFrame, how: str, on: str) -> pd.DataFrame:
        """5. ë°ì´í„° ë³‘í•© - inner, outer, left, right ì¡°ì¸"""
        return pd.merge(left, right, how=how, on=on)
    
    async def reshape_data(self, data: pd.DataFrame, operation: str) -> pd.DataFrame:
        """6. ë°ì´í„° ì¬êµ¬ì„± - pivot, melt, transpose, stack, unstack"""
        operations = {
            "pivot": data.pivot_table,
            "melt": pd.melt,
            "transpose": data.transpose
        }
        return operations.get(operation, lambda: data)()
    
    async def sample_data(self, data: pd.DataFrame, method: str, size: int) -> pd.DataFrame:
        """7. ë°ì´í„° ìƒ˜í”Œë§ - random, stratified, systematic"""
        if method == "random":
            return data.sample(n=size)
        return data
    
    async def split_data(self, data: pd.DataFrame, ratios: List[float]) -> List[pd.DataFrame]:
        """8. ë°ì´í„° ë¶„í•  - train/test/validation ë¶„í• """
        return [data.sample(frac=ratio) for ratio in ratios]
```

## ğŸ§ª í…ŒìŠ¤íŒ… ì „ëµ

### Playwright MCP ê¸°ë°˜ E2E í…ŒìŠ¤íŠ¸

**MCP ì„œë²„**: `playwright-mcp-server`

```python
class PlaywrightE2ETestSuite:
    """playwright-mcp-server ê¸°ë°˜ ì¢…í•© E2E í…ŒìŠ¤íŠ¸"""
    
    def __init__(self):
        self.playwright = None
        self.browser = None
        self.page = None
    
    async def setup_test_environment(self):
        """í…ŒìŠ¤íŠ¸ í™˜ê²½ ì„¤ì •"""
        self.playwright = await playwright().start()
        self.browser = await self.playwright.chromium.launch(headless=False)
        self.page = await self.browser.new_page()
    
    async def test_novice_scenario(self) -> TestResult:
        """ì¼ë°˜ì¸ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸"""
        
        try:
            # 1. ì• í”Œë¦¬ì¼€ì´ì…˜ ì ‘ì†
            await self.page.goto("http://localhost:8501")
            
            # 2. íŒŒì¼ ì—…ë¡œë“œ
            file_input = await self.page.wait_for_selector('input[type="file"]')
            await file_input.set_input_files("data/sample_data.csv")
            
            # 3. ê°„ë‹¨í•œ ì§ˆë¬¸ ì…ë ¥
            chat_input = await self.page.wait_for_selector('[data-testid="stChatInput"]')
            await chat_input.fill("ì´ ë°ì´í„°ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”")
            await chat_input.press("Enter")
            
            # 4. ì‘ë‹µ ëŒ€ê¸° ë° ê²€ì¦
            response = await self.page.wait_for_selector(
                '[data-testid="stChatMessage"]',
                timeout=300000
            )
            response_text = await response.inner_text()
            
            # 5. ê²°ê³¼ ê²€ì¦
            assert len(response_text) > 100
            assert "ë¶„ì„" in response_text
            
            return TestResult(
                test_name="novice_scenario",
                passed=True,
                execution_time=time.time() - start_time
            )
            
        except Exception as e:
            return TestResult(
                test_name="novice_scenario",
                passed=False,
                error=str(e)
            )
    
    async def test_universal_domain_scenario(self) -> TestResult:
        """ë²”ìš© ë„ë©”ì¸ ì ì‘ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸"""
        
        try:
            # 1. ì• í”Œë¦¬ì¼€ì´ì…˜ ì ‘ì†
            await self.page.goto("http://localhost:8501")
            
            # 2. ë‹¤ì–‘í•œ ë„ë©”ì¸ ë°ì´í„° í…ŒìŠ¤íŠ¸
            test_datasets = [
                "data/financial_data.csv",
                "data/healthcare_data.csv", 
                "data/manufacturing_data.csv",
                "data/sales_data.csv"
            ]
            
            for dataset in test_datasets:
                # ë°ì´í„° ì—…ë¡œë“œ
                file_input = await self.page.wait_for_selector('input[type="file"]')
                await file_input.set_input_files(dataset)
                
                # LLMì´ ë„ë©”ì¸ì„ ìë™ ê°ì§€í•˜ë„ë¡ ë²”ìš© ì§ˆë¬¸
                chat_input = await self.page.wait_for_selector('[data-testid="stChatInput"]')
                await chat_input.fill("ì´ ë°ì´í„°ì˜ íŠ¹ì„±ì„ ë¶„ì„í•˜ê³  ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”")
                await chat_input.press("Enter")
                
                # ì‘ë‹µ ëŒ€ê¸°
                response_elements = await self.page.wait_for_selector_all(
                    '[data-testid="stChatMessage"]',
                    timeout=300000
                )
                latest_response = response_elements[-1]
                response_text = await latest_response.inner_text()
                
                # Universal Engine ë™ì‘ ê²€ì¦
                universal_indicators = [
                    "ë„ë©”ì¸", "íŠ¹ì„±", "ë¶„ì„", "ì¸ì‚¬ì´íŠ¸", 
                    "íŒ¨í„´", "ì¶”ì²œ", "ê²°ê³¼", "í•´ì„"
                ]
                found_indicators = sum(
                    1 for indicator in universal_indicators 
                    if indicator in response_text
                )
                
                # LLMì´ ë„ë©”ì¸ì„ ê°ì§€í•˜ê³  ì ì ˆí•œ ë¶„ì„ ì œê³µ
                assert found_indicators >= 4
                assert len(response_text) > 200
            
            return TestResult(
                test_name="universal_domain_scenario",
                passed=True,
                scenario="universal"
            )
            
        except Exception as e:
            return TestResult(
                test_name="universal_domain_scenario",
                passed=False,
                error=str(e)
            )
    
    async def test_complex_domain_adaptation_scenario(self) -> TestResult:
        """ë³µì¡í•œ ë„ë©”ì¸ ì ì‘ ê²€ì¦ ì‹œë‚˜ë¦¬ì˜¤ (ë°˜ë„ì²´ ë°ì´í„°ë¡œ ë²”ìš©ì„± í…ŒìŠ¤íŠ¸)"""
        
        try:
            # 1. ì• í”Œë¦¬ì¼€ì´ì…˜ ì ‘ì†
            await self.page.goto("http://localhost:8501")
            
            # 2. ë³µì¡í•œ ë„ë©”ì¸ ë°ì´í„° ì—…ë¡œë“œ (ë°˜ë„ì²´)
            file_input = await self.page.wait_for_selector('input[type="file"]')
            await file_input.set_input_files("ion_implant_3lot_dataset.csv")
            
            # 3. ë³µì¡í•œ ë„ë©”ì¸ ì§€ì‹ ì¿¼ë¦¬ ì…ë ¥ (query.txt ë‚´ìš©)
            with open("query.txt", "r", encoding="utf-8") as f:
                complex_query = f.read()
            
            chat_input = await self.page.wait_for_selector('[data-testid="stChatInput"]')
            await chat_input.fill(complex_query)
            await chat_input.press("Enter")
            
            # 4. LLM First Universal Engine ì‘ë‹µ ëŒ€ê¸°
            response_elements = await self.page.wait_for_selector_all(
                '[data-testid="stChatMessage"]',
                timeout=600000  # ë³µì¡í•œ ë¶„ì„ì€ ë” ì˜¤ë˜ ê±¸ë¦¼
            )
            latest_response = response_elements[-1]
            response_text = await latest_response.inner_text()
            
            # 5. Universal Engineì˜ ë„ë©”ì¸ ì ì‘ ëŠ¥ë ¥ ê²€ì¦
            adaptation_indicators = [
                "ë„ë©”ì¸", "íŠ¹ì„±", "ë¶„ì„", "íŒ¨í„´", "ì¸ì‚¬ì´íŠ¸",
                "ìˆ˜ì¹˜", "ê²°ê³¼", "í•´ì„", "ê¶Œì¥", "í‰ê°€"
            ]
            found_indicators = sum(
                1 for indicator in adaptation_indicators 
                if indicator in response_text
            )
            
            # LLMì´ ë³µì¡í•œ ë„ë©”ì¸ì„ ìë™ ê°ì§€í•˜ê³  ì „ë¬¸ ë¶„ì„ ì œê³µ
            assert found_indicators >= 6  # ë” ë†’ì€ ê¸°ì¤€
            assert len(response_text) > 500  # ë” ìƒì„¸í•œ ë¶„ì„
            
            # Zero-Hardcoding ê²€ì¦: í•˜ë“œì½”ë”© ì—†ì´ LLMë§Œìœ¼ë¡œ ì „ë¬¸ ë¶„ì„ ë‹¬ì„±
            assert "ë¶„ì„" in response_text or "ê²°ê³¼" in response_text
            
            return TestResult(
                test_name="complex_domain_adaptation_scenario",
                passed=True,
                scenario="complex_domain_adaptation",
                notes="LLM First Universal Engine successfully adapted to complex domain without hardcoding"
            )
            
        except Exception as e:
            return TestResult(
                test_name="complex_domain_adaptation_scenario",
                passed=False,
                error=str(e)
            )
```

## ğŸ¯ ì„±ê³µ ê¸°ì¤€

### ê¸°ìˆ ì  ì„±ê³µ ê¸°ì¤€
- **ê¸°ëŠ¥ ì™„ì„±ë„**: ëª¨ë“  ì—ì´ì „íŠ¸ì˜ 88ê°œ ê¸°ëŠ¥ 100% ë™ì‘
- **ì„±ëŠ¥ ìµœì í™”**: qwen3-4b-fast ê¸°ë°˜ ì‹¤ìš©ì  ì‘ë‹µ ì†ë„ (í‰ê·  120ì´ˆ ì´ë‚´)
- **UI/UX í’ˆì§ˆ**: ChatGPT ìˆ˜ì¤€ì˜ ì§ê´€ì  ì‚¬ìš©ì ê²½í—˜
- **ê²€ì¦ ì™„ì„±ë„**: Playwright MCP ê¸°ë°˜ ì™„ì „ ìë™í™” í…ŒìŠ¤íŠ¸

### ì‚¬ìš©ì ê²½í—˜ ê¸°ì¤€
- **ì§ê´€ì  ì¸í„°í˜ì´ìŠ¤**: í•™ìŠµ ì—†ì´ ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥
- **ì‹¤ì‹œê°„ í”¼ë“œë°±**: 0.001ì´ˆ ì§€ì—°ì˜ ë¶€ë“œëŸ¬ìš´ ìŠ¤íŠ¸ë¦¬ë°
- **ë²”ìš© ë„ë©”ì¸ ì§€ì›**: ëª¨ë“  ë„ë©”ì¸ ìë™ ì ì‘ ë° ì „ë¬¸ ë¶„ì„
- **ì‹ ë¢°ì„±**: 99.9% ì‹œìŠ¤í…œ ê°€ìš©ì„±

### LLM First Universal Engine ë‹¬ì„± ê¸°ì¤€
- **Zero-Hardcoding**: 100% í•˜ë“œì½”ë”© íŒ¨í„´ ì œê±° ë‹¬ì„±
- **ë²”ìš© ë„ë©”ì¸ ì ì‘**: LLMì´ ëª¨ë“  ë„ë©”ì¸ ìë™ ê°ì§€ ë° ë¶„ì„
- **ë™ì  ì „ë¬¸ì„±**: ì‚¬ìš©ì ìˆ˜ì¤€ê³¼ ë„ë©”ì¸ì— ê´€ê³„ì—†ì´ ì ì‘í˜• ì‘ë‹µ ì œê³µ
- **ì™„ì „ ììœ¨ì„±**: íŒ¨í„´ ë§¤ì¹­ ì—†ì´ ìˆœìˆ˜ LLM ê¸°ë°˜ ì˜ì‚¬ê²°ì •

ì´ ì„¤ê³„ë¥¼ í†µí•´ í˜„ì¬ CherryAI ì‹œìŠ¤í…œì„ ChatGPT Data Analyst ìˆ˜ì¤€ìœ¼ë¡œ ì™„ì „íˆ ìµœì í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.