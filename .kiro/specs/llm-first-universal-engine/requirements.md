# ğŸ§  LLM First ë²”ìš© ë„ë©”ì¸ ë¶„ì„ ì—”ì§„ ìš”êµ¬ì‚¬í•­ ëª…ì„¸ì„œ

## ğŸ“‹ ê°œìš”

ì´ ë¬¸ì„œëŠ” ì§„ì •í•œ LLM First ë²”ìš© ë„ë©”ì¸ ë¶„ì„ ì—”ì§„ êµ¬í˜„ì„ ìœ„í•œ ìƒì„¸ ìš”êµ¬ì‚¬í•­ì„ ì •ì˜í•©ë‹ˆë‹¤. ì´ ì‹œìŠ¤í…œì€ í•˜ë“œì½”ë”©ëœ íŒ¨í„´, ì¹´í…Œê³ ë¦¬, ê·œì¹™ ì—†ì´ ëª¨ë“  ë„ë©”ì¸(ë°˜ë„ì²´, ê¸ˆìœµ, ì˜ë£Œ ë“±)ê³¼ ëª¨ë“  ì‚¬ìš©ì ìˆ˜ì¤€(ì´ˆë³´ì~ì „ë¬¸ê°€)ì— ë™ì ìœ¼ë¡œ ì ì‘í•˜ëŠ” ì™„ì „í•œ ë²”ìš© ë¶„ì„ ì—”ì§„ì…ë‹ˆë‹¤.

### í•µì‹¬ ì² í•™
- **Zero Hardcoding**: ì‚¬ì „ ì •ì˜ëœ íŒ¨í„´, ì¹´í…Œê³ ë¦¬, ê·œì¹™ ì¼ì²´ ì—†ìŒ
- **Zero Assumptions**: ë„ë©”ì¸, ì‚¬ìš©ì ìˆ˜ì¤€, ì¿¼ë¦¬ ìœ í˜•ì— ëŒ€í•œ ê°€ì • ì—†ìŒ  
- **Self-Discovering**: LLMì´ ìŠ¤ìŠ¤ë¡œ ëª¨ë“  ì»¨í…ìŠ¤íŠ¸ì™€ ìš”êµ¬ì‚¬í•­ì„ íŒŒì•…
- **Universal Adaptability**: ëª¨ë“  ë„ë©”ì¸, ëª¨ë“  ì‚¬ìš©ì ìˆ˜ì¤€ì— ë™ì  ì ì‘

### ì„¤ê³„ ëª©í‘œ
1. **ì™„ì „í•œ ë²”ìš©ì„±**: ë°˜ë„ì²´ë¶€í„° ê¸ˆìœµ, ì˜ë£Œê¹Œì§€ ëª¨ë“  ë„ë©”ì¸ ì§€ì›
2. **ì‚¬ìš©ì ì ì‘ì„±**: ì´ˆë³´ìë¶€í„° ì „ë¬¸ê°€ê¹Œì§€ ìë™ ìˆ˜ì¤€ ì¡°ì ˆ
3. **ì§„ì •í•œ ì§€ëŠ¥**: íŒ¨í„´ ë§¤ì¹­ì´ ì•„ë‹Œ ì‹¤ì œ ì´í•´ì™€ ì¶”ë¡ 
4. **ì§€ì†ì  í•™ìŠµ**: ìƒí˜¸ì‘ìš©ì„ í†µí•œ ì‹¤ì‹œê°„ ê°œì„ 

## ğŸ” ê¸°ì¡´ ë¬¸ì œì  ë¶„ì„ ë° í•´ê²° ìš”êµ¬ì‚¬í•­

### âŒ ì œê±°í•´ì•¼ í•  ì˜ëª»ëœ ì ‘ê·¼ë²•ë“¤

#### í•˜ë“œì½”ë”©ëœ ë¶„ë¥˜ ì²´ê³„ ì œê±°
```python
# ì œê±°í•´ì•¼ í•  ì˜ëª»ëœ íŒ¨í„´ë“¤
if "ë„ì¦ˆ" in query or "ê· ì¼ì„±" in query:
    process_type = "ion_implantation"
    analysis_category = "dose_uniformity"

domain_categories = {
    "semiconductor": ["ion_implantation", "lithography"],
    "finance": ["risk_analysis", "portfolio"],
    "healthcare": ["diagnosis", "treatment"]
}

if user_type == "expert":
    use_technical_language()
elif user_type == "beginner":
    use_simple_language()
```

## Requirements

### Requirement 1: Zero Hardcoding Architecture Implementation

**User Story:** As a system architect, I want to completely eliminate all hardcoded patterns, categories, and domain-specific logic, so that the system can truly adapt to any domain without predefined limitations.

#### Acceptance Criteria

1. WHEN processing any query THEN the system SHALL NOT use predefined domain categories like `if "ë„ì¦ˆ" in query or "ê· ì¼ì„±" in query: process_type = "ion_implantation"`
2. WHEN analyzing data THEN the system SHALL NOT rely on hardcoded classification systems like `domain_categories = {"semiconductor": ["ion_implantation", "lithography"]}`
3. WHEN determining user expertise THEN the system SHALL NOT use fixed persona categories like `if user_type == "expert": use_technical_language()`
4. WHEN implementing UniversalQueryProcessor THEN the system SHALL use the architecture:
   ```python
   class UniversalQueryProcessor:
       """ì™„ì „ ë²”ìš© ì¿¼ë¦¬ ì²˜ë¦¬ê¸° - ì–´ë–¤ ê°€ì •ë„ í•˜ì§€ ì•ŠìŒ"""
       
       async def process_query(self, query: str, data: Any, context: Dict = None):
           """
           ìˆœìˆ˜ LLM ê¸°ë°˜ìœ¼ë¡œ ì¿¼ë¦¬ ì²˜ë¦¬
           - íŒ¨í„´ ë§¤ì¹­ ì—†ìŒ
           - ì‚¬ì „ ë¶„ë¥˜ ì—†ìŒ  
           - ì™„ì „í•œ ë™ì  ë¶„ì„
           """
   ```
5. WHEN encountering new domains THEN the system SHALL adapt without requiring code changes or configuration updates

### Requirement 2: Meta-Reasoning Engine with DeepSeek-R1 Inspired Patterns

**User Story:** As a user, I want the system to think about its own thinking process using 2024-2025 ìµœì‹  ì—°êµ¬ ê¸°ë°˜ meta-reasoning, so that I receive increasingly sophisticated and accurate analysis.

#### Acceptance Criteria

1. WHEN analyzing any query THEN the system SHALL implement MetaReasoningEngine with methods:
   ```python
   class MetaReasoningEngine:
       """ë©”íƒ€ ì¶”ë¡  ì—”ì§„ - ìƒê°ì— ëŒ€í•´ ìƒê°í•˜ê¸°"""
       
       async def analyze_query_intent(self, query: str, data: Any):
           """ì¿¼ë¦¬ ì˜ë„ë¥¼ ìŠ¤ìŠ¤ë¡œ íŒŒì•…"""
           
       async def detect_domain_context(self, query: str, data: Any):
           """ë„ë©”ì¸ ì»¨í…ìŠ¤íŠ¸ë¥¼ ìŠ¤ìŠ¤ë¡œ ë°œê²¬"""
           
       async def estimate_user_expertise(self, interaction_history: List):
           """ì‚¬ìš©ì ì „ë¬¸ì„±ì„ ìƒí˜¸ì‘ìš©ìœ¼ë¡œ ì¶”ì •"""
           
       async def select_response_strategy(self, intent, context, expertise):
           """ìµœì  ì‘ë‹µ ì „ëµì„ ìŠ¤ìŠ¤ë¡œ ì„ íƒ"""
   ```

2. WHEN performing self-reflection THEN the system SHALL use the exact prompt pattern:
   ```
   # ìê°€ ë°˜ì„± ì¶”ë¡  íŒ¨í„´
   ë‹¹ì‹ ì€ ì£¼ì–´ì§„ ì¿¼ë¦¬ì™€ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

   ë‹¨ê³„ 1: ì´ˆê¸° ê´€ì°°
   - ë°ì´í„°ë¥¼ ë³´ê³  ë¬´ì—‡ì„ ë°œê²¬í•˜ëŠ”ê°€?
   - ì‚¬ìš©ì ì¿¼ë¦¬ì˜ ì§„ì •í•œ ì˜ë„ëŠ”?
   - ë‚´ê°€ ë†“ì¹˜ê³  ìˆëŠ” ê²ƒì€ ì—†ëŠ”ê°€?

   ë‹¨ê³„ 2: ë‹¤ê°ë„ ë¶„ì„
   - ì´ ë¬¸ì œë¥¼ ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ ì ‘ê·¼í•œë‹¤ë©´?
   - ì‚¬ìš©ìê°€ ì „ë¬¸ê°€ë¼ë©´ ì–´ë–¤ ë‹µì„ ì›í• ê¹Œ?
   - ì‚¬ìš©ìê°€ ì´ˆë³´ìë¼ë©´ ì–´ë–¤ ë„ì›€ì´ í•„ìš”í• ê¹Œ?

   ë‹¨ê³„ 3: ìê°€ ê²€ì¦
   - ë‚´ ë¶„ì„ì´ ë…¼ë¦¬ì ìœ¼ë¡œ ì¼ê´€ì„±ì´ ìˆëŠ”ê°€?
   - ì‚¬ìš©ìì—ê²Œ ì‹¤ì œë¡œ ë„ì›€ì´ ë˜ëŠ”ê°€?
   - í™•ì‹ ì´ ì—†ëŠ” ë¶€ë¶„ì€ ë¬´ì—‡ì¸ê°€?

   ë‹¨ê³„ 4: ì ì‘ì  ì‘ë‹µ
   - í™•ì‹¤í•œ ë¶€ë¶„ì€ ëª…í™•íˆ ì œì‹œ
   - ë¶ˆí™•ì‹¤í•œ ë¶€ë¶„ì€ ëª…í™•í™” ì§ˆë¬¸
   - ì‚¬ìš©ì ìˆ˜ì¤€ì— ë§ëŠ” ì„¤ëª… ê¹Šì´ ì¡°ì ˆ
   ```

3. WHEN evaluating analysis quality THEN the system SHALL use meta-rewarding pattern:
   ```
   # ìê°€ í‰ê°€ ë° ê°œì„  íŒ¨í„´
   ë‚´ ë¶„ì„ì„ ìŠ¤ìŠ¤ë¡œ í‰ê°€í•´ë³´ê² ìŠµë‹ˆë‹¤:

   í‰ê°€ ê¸°ì¤€:
   1. ì •í™•ì„±: ë¶„ì„ì´ ë°ì´í„°ë¥¼ ì˜¬ë°”ë¥´ê²Œ í•´ì„í–ˆëŠ”ê°€?
   2. ì™„ì „ì„±: ì¤‘ìš”í•œ ì¸ì‚¬ì´íŠ¸ë¥¼ ë†“ì¹˜ì§€ ì•Šì•˜ëŠ”ê°€?
   3. ì ì ˆì„±: ì‚¬ìš©ì ìˆ˜ì¤€ê³¼ ìš”êµ¬ì— ë§ëŠ”ê°€?
   4. ëª…í™•ì„±: ì„¤ëª…ì´ ì´í•´í•˜ê¸° ì‰¬ìš´ê°€?
   5. ì‹¤ìš©ì„±: ì‹¤ì œë¡œ ë„ì›€ì´ ë˜ëŠ” ì¡°ì¹˜ë¥¼ ì œì•ˆí–ˆëŠ”ê°€?

   ê°œì„ ì :
   - ë¶€ì¡±í•œ ë¶€ë¶„ì€ ë¬´ì—‡ì¸ê°€?
   - ì–´ë–»ê²Œ ë” ë‚˜ì€ ë¶„ì„ì„ í•  ìˆ˜ ìˆëŠ”ê°€?
   - ì‚¬ìš©ìì—ê²Œ ì¶”ê°€ë¡œ í•„ìš”í•œ ì •ë³´ëŠ”?

   ì´ í‰ê°€ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ë‹µì„ ê°œì„ í•˜ê² ìŠµë‹ˆë‹¤.
   ```

4. WHEN uncertainty exists THEN the system SHALL explicitly state "í™•ì‹ ì´ ì—†ëŠ” ë¶€ë¶„ì€ ë¬´ì—‡ì¸ê°€?" and seek clarification
5. WHEN receiving user feedback THEN the system SHALL incorporate feedback into its meta-reasoning process for future improvements

### Requirement 3: Dynamic Context Discovery

**User Story:** As a user working with any type of data, I want the system to automatically discover the domain context and requirements from the data itself, so that I don't need to explain what type of analysis I need.

#### Acceptance Criteria

1. WHEN receiving data and query THEN the system SHALL analyze data characteristics, patterns, and terminology to discover domain context
2. WHEN domain context is unclear THEN the system SHALL use the pattern: "ì´ ë°ì´í„°ë¥¼ ë³´ë‹ˆ ë­”ê°€ ê³µì¥ì—ì„œ ì œí’ˆì„ ë§Œë“œëŠ” ê³¼ì •ì„ ê¸°ë¡í•œ ê²ƒ ê°™ë„¤ìš”" for intuitive explanation
3. WHEN discovering domain patterns THEN the system SHALL identify relevant methodologies and best practices without predefined knowledge bases
4. WHEN context discovery is incomplete THEN the system SHALL ask targeted clarifying questions to complete understanding
5. WHEN new domains are encountered THEN the system SHALL learn domain-specific patterns through real-time interaction

### Requirement 4: Adaptive User Understanding

**User Story:** As a user of any expertise level, I want the system to understand my knowledge level through our interaction and adapt its communication style accordingly, so that I receive appropriately tailored explanations.

#### Acceptance Criteria

1. WHEN user submits first query THEN the system SHALL analyze language usage, terminology, question complexity to estimate expertise level
2. WHEN expertise estimation is uncertain THEN the system SHALL use progressive disclosure to gauge user understanding level
3. WHEN user is identified as beginner THEN the system SHALL use patterns like "ë§ˆì¹˜ ìš”ë¦¬ ë ˆì‹œí”¼ì˜ ì¬ë£Œ ë¶„ëŸ‰ì„ ì¸¡ì •í•œ ê¸°ë¡ì²˜ëŸ¼ ë³´ì—¬ìš”" for accessible explanations
4. WHEN user is identified as expert THEN the system SHALL provide technical analysis like "Cpk 1.2ì—ì„œ 1.33ìœ¼ë¡œ ê°œì„ í•˜ë ¤ë©´ ë³€ë™ì„±ì„ ì•½ 8.3% ê°ì†Œì‹œì¼œì•¼ í•©ë‹ˆë‹¤"
5. WHEN user expertise changes during conversation THEN the system SHALL dynamically adjust explanation depth and technical language usage

### Requirement 5: Self-Reflecting Reasoning System

**User Story:** As a user, I want the system to continuously question and improve its own analysis process, so that I can trust the quality and reliability of the insights provided.

#### Acceptance Criteria

1. WHEN performing analysis THEN the system SHALL use DeepSeek-R1 inspired reasoning with steps: ì´ˆê¸° ê´€ì°° â†’ ë‹¤ê°ë„ ë¶„ì„ â†’ ìê°€ ê²€ì¦ â†’ ì ì‘ì  ì‘ë‹µ
2. WHEN generating insights THEN the system SHALL apply meta-rewarding patterns to evaluate accuracy, completeness, appropriateness, clarity, and practicality
3. WHEN confidence is low THEN the system SHALL explicitly state "í™•ì‹ ì´ ì—†ëŠ” ë¶€ë¶„ì€ ë¬´ì—‡ì¸ê°€?" and seek clarification
4. WHEN multiple reasoning paths exist THEN the system SHALL use chain-of-thought with self-consistency to validate conclusions
5. WHEN analysis is complete THEN the system SHALL perform final self-reflection: "ì´ í‰ê°€ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ë‹µì„ ê°œì„ í•˜ê² ìŠµë‹ˆë‹¤"

### Requirement 6: Universal Intent Detection

**User Story:** As a user with various types of questions, I want the system to understand my true intent without forcing me into predefined categories, so that I can ask questions naturally and get relevant responses.

#### Acceptance Criteria

1. WHEN processing queries THEN the system SHALL use semantic routing without predefined intent categories
2. WHEN intent is unclear THEN the system SHALL apply the pattern: "ì‚¬ì „ ì •ì˜ëœ ì¹´í…Œê³ ë¦¬ë‚˜ íŒ¨í„´ì— ì˜ì¡´í•˜ì§€ ì•Šê³  ì¿¼ë¦¬ ìì²´ê°€ ë§í•˜ëŠ” ê²ƒì„ ë“¤ì–´ë³´ê² ìŠµë‹ˆë‹¤"
3. WHEN analyzing user intent THEN the system SHALL distinguish between direct intent (ëª…ì‹œì  ìš”ì²­) and implicit intent (ì•”ë¬µì  ì˜ë„)
4. WHEN multiple interpretations exist THEN the system SHALL explore semantic space navigation to find the most relevant approach
5. WHEN intent detection is complete THEN the system SHALL select response strategy based on discovered intent rather than predefined templates

### Requirement 7: Progressive Disclosure System

**User Story:** As a user, I want the system to reveal information gradually based on my interest and understanding level, so that I'm neither overwhelmed with too much detail nor left wanting more depth.

#### Acceptance Criteria

1. WHEN providing initial response THEN the system SHALL present core insights first with clear options to explore deeper
2. WHEN user shows confusion THEN the system SHALL simplify using patterns like "ì¼ë‹¨ ëª‡ ê°€ì§€ í¥ë¯¸ë¡œìš´ íŒ¨í„´ì´ ë³´ì´ëŠ”ë°ìš”" with accessible explanations
3. WHEN user demonstrates understanding THEN the system SHALL offer more technical depth and detailed analysis
4. WHEN user asks follow-up questions THEN the system SHALL adapt disclosure level based on question sophistication
5. WHEN analysis is complete THEN the system SHALL suggest relevant next steps: "ì–´ë–¤ ë¶€ë¶„ì´ ê°€ì¥ ê¶ê¸ˆí•˜ì„¸ìš”?"

### Requirement 8: Zero-Shot Adaptive Reasoning

**User Story:** As a user with unique or novel problems, I want the system to reason about my situation without relying on previous templates or examples, so that I get fresh insights tailored to my specific context.

#### Acceptance Criteria

1. WHEN encountering new problem types THEN the system SHALL use zero-shot reasoning without template matching
2. WHEN reasoning about problems THEN the system SHALL follow the pattern: ë¬¸ì œ ê³µê°„ ì •ì˜ â†’ ì¶”ë¡  ì „ëµ ìˆ˜ë¦½ â†’ ë‹¨ê³„ë³„ ì¶”ë¡  ì‹¤í–‰ â†’ ê²°ê³¼ í†µí•© ë° ê²€ì¦
3. WHEN assumptions are made THEN the system SHALL explicitly state "ê°€ì •ê³¼ ì œì•½ì‚¬í•­ ëª…ì‹œ" and "ë¶ˆí™•ì‹¤ì„±ê³¼ ì‹ ë¢°ë„ í‰ê°€"
4. WHEN multiple reasoning paths exist THEN the system SHALL validate consistency across different approaches
5. WHEN reasoning is complete THEN the system SHALL state "í…œí”Œë¦¿ì´ë‚˜ ê³µì‹ì— ì˜ì¡´í•˜ì§€ ì•Šê³  ë¬¸ì œ ìì²´ì˜ ë³¸ì§ˆì— ë§ëŠ” ì¶”ë¡ ì„ ìˆ˜í–‰í•˜ê² ìŠµë‹ˆë‹¤"

### Requirement 9: Real-time Learning and Adaptation

**User Story:** As a user, I want the system to learn from our interactions and improve its responses over time, so that the quality of analysis gets better with continued use.

#### Acceptance Criteria

1. WHEN user provides feedback THEN the system SHALL incorporate learning using the pattern: "ì´ë²ˆ ìƒí˜¸ì‘ìš©ì—ì„œ ë°°ìš´ ê²ƒì„ ì •ë¦¬í•˜ê² ìŠµë‹ˆë‹¤"
2. WHEN successful patterns are identified THEN the system SHALL generalize learnings for similar future situations
3. WHEN failures occur THEN the system SHALL analyze failure patterns and avoid similar approaches
4. WHEN user satisfaction changes THEN the system SHALL adjust its approach based on satisfaction indicators
5. WHEN knowledge is updated THEN the system SHALL maintain learning without compromising user privacy

### Requirement 10: Cherry AI UI/UX Integration and Enhancement

**User Story:** As a Cherry AI user, I want a ChatGPT-like intuitive interface that seamlessly integrates the Universal Engine with A2A agents, so that I get an enhanced multi-agent data analysis experience without losing the familiar UI/UX.

#### Acceptance Criteria

1. WHEN using Cherry AI THEN the system SHALL maintain the existing ChatGPT-style interface with these components:
   ```python
   # ê¸°ì¡´ Cherry AI UI ì»´í¬ë„ŒíŠ¸ ìœ ì§€ ë° ê°•í™”
   class CherryAI:
       def render_header(self):
           """ğŸ’ Cherry AI ë¸Œëœë”© í—¤ë” ìœ ì§€ + Universal Engine ìƒíƒœ í‘œì‹œ"""
           st.markdown("# ğŸ’ Cherry AI - LLM First Universal Engine")
           
           # Universal Engine ìƒíƒœ í‘œì‹œ
           col1, col2, col3 = st.columns([2, 1, 1])
           with col1:
               st.caption("ğŸ§  Universal Engine í™œì„±í™”")
           with col2:
               st.caption(f"ğŸ¤– {len(self.available_agents)}ê°œ A2A ì—ì´ì „íŠ¸")
           with col3:
               if st.button("âš™ï¸ ì„¤ì •"):
                   st.session_state.show_settings = True
           
       def render_chat_interface(self):
           """ğŸ’¬ ChatGPT ìŠ¤íƒ€ì¼ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ ìœ ì§€ + ë©”íƒ€ ì¶”ë¡  í‘œì‹œ"""
           # ê¸°ì¡´ ì±„íŒ… ë©”ì‹œì§€ í‘œì‹œ
           for message in st.session_state.messages:
               with st.chat_message(message["role"]):
                   st.write(message["content"])
                   
                   # Universal Engine ë©”íƒ€ ì¶”ë¡  ê²°ê³¼ í‘œì‹œ
                   if message.get("meta_reasoning"):
                       with st.expander("ğŸ§  ë©”íƒ€ ì¶”ë¡  ê³¼ì •", expanded=False):
                           st.json(message["meta_reasoning"])
                   
                   # A2A Agent ê¸°ì—¬ë„ í‘œì‹œ
                   if message.get("agent_contributions"):
                       with st.expander("ğŸ¤– ì—ì´ì „íŠ¸ í˜‘ì—…", expanded=False):
                           for agent_id, contribution in message["agent_contributions"].items():
                               st.write(f"**{agent_id}**: {contribution}")
           
       def render_file_upload(self):
           """ğŸ“ ì§ê´€ì  íŒŒì¼ ì—…ë¡œë“œ ì¸í„°í˜ì´ìŠ¤ + Universal Engine ë°ì´í„° ë¶„ì„"""
           uploaded_file = st.file_uploader(
               "ğŸ“ ë°ì´í„° íŒŒì¼ ì—…ë¡œë“œ", 
               type=['csv', 'xlsx', 'json', 'txt'],
               help="Universal Engineì´ ìë™ìœ¼ë¡œ ë°ì´í„° ìœ í˜•ê³¼ ë„ë©”ì¸ì„ ê°ì§€í•©ë‹ˆë‹¤"
           )
           
           if uploaded_file:
               # Universal Engineìœ¼ë¡œ ë°ì´í„° ì‚¬ì „ ë¶„ì„
               with st.spinner("ğŸ§  ë°ì´í„° ì»¨í…ìŠ¤íŠ¸ ë¶„ì„ ì¤‘..."):
                   context_analysis = await self.universal_engine.analyze_data_context(uploaded_file)
               
               # ê°ì§€ëœ ë„ë©”ì¸ê³¼ ì¶”ì²œ ë¶„ì„ í‘œì‹œ
               if context_analysis:
                   st.success(f"âœ… {context_analysis['domain']} ë„ë©”ì¸ ë°ì´í„°ë¡œ ê°ì§€ë¨")
                   st.info(f"ğŸ’¡ ì¶”ì²œ ë¶„ì„: {context_analysis['recommended_analysis']}")
           
       def render_sidebar(self):
           """ğŸ”§ ì—ì´ì „íŠ¸ ìƒíƒœ ë° ì„¤ì • ì‚¬ì´ë“œë°” + Universal Engine ì œì–´"""
           with st.sidebar:
               st.header("ğŸ”§ Universal Engine ì œì–´")
               
               # ë©”íƒ€ ì¶”ë¡  ì„¤ì •
               st.subheader("ğŸ§  ë©”íƒ€ ì¶”ë¡  ì„¤ì •")
               show_reasoning = st.checkbox("ì¶”ë¡  ê³¼ì • í‘œì‹œ", value=True)
               reasoning_depth = st.selectbox("ì¶”ë¡  ê¹Šì´", ["ê¸°ë³¸", "ìƒì„¸", "ì „ë¬¸ê°€"])
               
               # A2A Agent ìƒíƒœ
               st.subheader("ğŸ¤– A2A ì—ì´ì „íŠ¸ ìƒíƒœ")
               for agent in self.available_agents:
                   status_icon = "ğŸŸ¢" if agent.status == "active" else "ğŸ”´"
                   st.write(f"{status_icon} {agent.name} (:{agent.port})")
               
               # ì‚¬ìš©ì í”„ë¡œí•„ ì„¤ì •
               st.subheader("ğŸ‘¤ ì‚¬ìš©ì í”„ë¡œí•„")
               expertise_level = st.selectbox(
                   "ì „ë¬¸ì„± ìˆ˜ì¤€", 
                   ["ìë™ ê°ì§€", "ì´ˆë³´ì", "ì¤‘ê¸‰ì", "ì „ë¬¸ê°€"]
               )
               
               # Universal Engine í†µê³„
               st.subheader("ğŸ“Š ì—”ì§„ í†µê³„")
               st.metric("ì´ ë¶„ì„ ìˆ˜í–‰", st.session_state.get('total_analyses', 0))
               st.metric("í‰ê·  ì‘ë‹µ ì‹œê°„", f"{st.session_state.get('avg_response_time', 0):.1f}ì´ˆ")
               st.metric("ì‚¬ìš©ì ë§Œì¡±ë„", f"{st.session_state.get('satisfaction_score', 0):.1f}/5.0")
   ```

2. WHEN replacing hardcoded analysis logic THEN the system SHALL completely replace the execute_analysis method:
   ```python
   # ì œê±°ë˜ëŠ” ê¸°ì¡´ í•˜ë“œì½”ë”© íŒ¨í„´:
   async def execute_analysis(self, user_query: str) -> Dict[str, Any]:
       # âŒ ì œê±°í•´ì•¼ í•  í•˜ë“œì½”ë”©ëœ ë„ë©”ì¸ ìš°ì„ ìˆœìœ„
       if SEMICONDUCTOR_ENGINE_AVAILABLE:
           semiconductor_result = await analyze_semiconductor_data(...)
           if confidence > 0.7:
               return self._format_semiconductor_analysis(semiconductor_result)
       # âŒ ì œê±°í•´ì•¼ í•  ì¼ë°˜ A2A fallback
       return await self._general_agent_analysis(user_query)
   
   # âœ… ìƒˆë¡œìš´ Universal Engine + A2A í†µí•© íŒ¨í„´:
   async def execute_analysis(self, user_query: str) -> Dict[str, Any]:
       """ì™„ì „íˆ ìƒˆë¡œìš´ LLM First ë¶„ì„ ì‹¤í–‰"""
       
       # 1. Universal Engineìœ¼ë¡œ ë©”íƒ€ ì¶”ë¡  ìˆ˜í–‰
       meta_analysis = await self.universal_engine.perform_meta_reasoning(
           query=user_query,
           data=st.session_state.get('current_data'),
           user_context=self._get_user_context(),
           conversation_history=st.session_state.get('messages', [])
       )
       
       # 2. A2A Agent ë™ì  ì„ íƒ ë° í˜‘ì—…
       unified_result = await self.universal_a2a_system.process_unified_query(
           query=user_query,
           meta_analysis=meta_analysis,
           available_agents=self.available_agents,
           context=self._get_session_context()
       )
       
       # 3. ê²°ê³¼ í†µí•© ë° ì‚¬ìš©ì ìˆ˜ì¤€ë³„ ì ì‘
       adaptive_response = await self.universal_engine.generate_adaptive_response(
           analysis_result=unified_result,
           user_profile=st.session_state.get('user_profile', {}),
           meta_reasoning=meta_analysis
       )
       
       return adaptive_response
   ```

3. WHEN displaying analysis progress THEN the system SHALL show real-time Universal Engine processing:
   ```python
   # ë©”íƒ€ ì¶”ë¡  ê³¼ì • ì‹¤ì‹œê°„ í‘œì‹œ (ë” ìƒì„¸í•œ ë‹¨ê³„ë³„ í‘œì‹œ)
   async def display_analysis_progress(self, user_query: str):
       with st.chat_message("assistant"):
           # 1ë‹¨ê³„: ë©”íƒ€ ì¶”ë¡ 
           with st.spinner("ğŸ§  ë©”íƒ€ ì¶”ë¡  ì¤‘..."):
               st.caption("ì¿¼ë¦¬ ì˜ë„ ë¶„ì„, ë„ë©”ì¸ ì»¨í…ìŠ¤íŠ¸ ë°œê²¬, ì‚¬ìš©ì ìˆ˜ì¤€ ì¶”ì •")
               meta_analysis = await self.universal_engine.analyze_request(user_query)
               
           # ë©”íƒ€ ì¶”ë¡  ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°
           if st.session_state.get('show_reasoning', True):
               with st.expander("ğŸ§  ë©”íƒ€ ì¶”ë¡  ê²°ê³¼", expanded=False):
                   st.write(f"**ê°ì§€ëœ ë„ë©”ì¸**: {meta_analysis.get('domain', 'ë¶„ì„ ì¤‘')}")
                   st.write(f"**ì‚¬ìš©ì ìˆ˜ì¤€**: {meta_analysis.get('user_level', 'ì¶”ì • ì¤‘')}")
                   st.write(f"**ë¶„ì„ ì „ëµ**: {meta_analysis.get('strategy', 'ìˆ˜ë¦½ ì¤‘')}")
           
           # 2ë‹¨ê³„: A2A ì—ì´ì „íŠ¸ ì„ íƒ
           with st.spinner("ğŸ¤– A2A ì—ì´ì „íŠ¸ ì„ íƒ ì¤‘..."):
               st.caption("ë©”íƒ€ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì  ì—ì´ì „íŠ¸ ì¡°í•© ì„ íƒ")
               selected_agents = await self.agent_selector.select_agents(meta_analysis)
               
           # ì„ íƒëœ ì—ì´ì „íŠ¸ í‘œì‹œ
           if selected_agents:
               st.success(f"âœ… {len(selected_agents)}ê°œ ì—ì´ì „íŠ¸ ì„ íƒë¨")
               cols = st.columns(len(selected_agents))
               for i, agent in enumerate(selected_agents):
                   with cols[i]:
                       st.write(f"ğŸ¤– {agent.name}")
                       st.caption(f"í¬íŠ¸: {agent.port}")
           
           # 3ë‹¨ê³„: ì—ì´ì „íŠ¸ í˜‘ì—… ì‹¤í–‰
           with st.spinner("âš¡ ì—ì´ì „íŠ¸ í˜‘ì—… ì‹¤í–‰ ì¤‘..."):
               st.caption("ì„ íƒëœ ì—ì´ì „íŠ¸ë“¤ì´ í˜‘ì—…í•˜ì—¬ ë¶„ì„ ìˆ˜í–‰")
               
               # ì‹¤ì‹œê°„ ì§„í–‰ë¥  í‘œì‹œ
               progress_bar = st.progress(0)
               status_text = st.empty()
               
               async for progress_update in self.workflow_coordinator.execute_workflow_with_progress(selected_agents):
                   progress_bar.progress(progress_update['progress'] / 100)
                   status_text.text(f"ì§„í–‰ ì¤‘: {progress_update['current_task']}")
               
               agent_results = progress_update['final_results']
           
           # 4ë‹¨ê³„: ê²°ê³¼ í†µí•© ë° ì ì‘ì  ì‘ë‹µ ìƒì„±
           with st.spinner("ğŸ”„ ê²°ê³¼ í†µí•© ë° ì‘ë‹µ ìƒì„± ì¤‘..."):
               st.caption("ì—ì´ì „íŠ¸ ê²°ê³¼ë¥¼ í†µí•©í•˜ê³  ì‚¬ìš©ì ìˆ˜ì¤€ì— ë§ëŠ” ì‘ë‹µ ìƒì„±")
               final_response = await self.universal_engine.integrate_and_adapt(
                   agent_results, meta_analysis, st.session_state.get('user_profile', {})
               )
           
           return final_response
   ```

4. WHEN showing agent collaboration THEN the system SHALL provide enhanced agent status visualization:
   ```python
   # A2A Agent í˜‘ì—… ìƒíƒœ ì‹¤ì‹œê°„ í‘œì‹œ (ë” ìƒì„¸í•œ ì‹œê°í™”)
   def render_agent_collaboration_status(self, selected_agents, workflow_status):
       if st.session_state.get('show_agent_details', True):
           with st.expander("ğŸ¤– A2A ì—ì´ì „íŠ¸ í˜‘ì—… ìƒíƒœ", expanded=True):
               
               # ì „ì²´ ì›Œí¬í”Œë¡œìš° ì§„í–‰ë¥ 
               overall_progress = sum(agent.progress for agent in selected_agents) / len(selected_agents)
               st.progress(overall_progress / 100)
               st.caption(f"ì „ì²´ ì§„í–‰ë¥ : {overall_progress:.1f}%")
               
               # ê°œë³„ ì—ì´ì „íŠ¸ ìƒíƒœ
               for agent in selected_agents:
                   col1, col2, col3, col4 = st.columns([3, 1, 1, 1])
                   
                   with col1:
                       st.write(f"**{agent.name}** (Port {agent.port})")
                       st.caption(f"ì—­í• : {agent.role}")
                   
                   with col2:
                       status_color = {
                           'running': 'ğŸŸ¢ ì‹¤í–‰ì¤‘',
                           'waiting': 'ğŸŸ¡ ëŒ€ê¸°ì¤‘', 
                           'completed': 'âœ… ì™„ë£Œ',
                           'error': 'ğŸ”´ ì˜¤ë¥˜'
                       }
                       st.write(status_color.get(agent.status, 'â“ ì•Œ ìˆ˜ ì—†ìŒ'))
                   
                   with col3:
                       st.write(f"{agent.progress}%")
                       st.progress(agent.progress / 100)
                   
                   with col4:
                       if agent.status == 'error':
                           if st.button("ğŸ”„", key=f"retry_{agent.id}"):
                               # ì—ì´ì „íŠ¸ ì¬ì‹œì‘
                               await self.restart_agent(agent)
                       elif agent.status == 'completed':
                           if st.button("ğŸ“Š", key=f"details_{agent.id}"):
                               # ì—ì´ì „íŠ¸ ê²°ê³¼ ìƒì„¸ë³´ê¸°
                               st.session_state[f'show_agent_details_{agent.id}'] = True
               
               # ì—ì´ì „íŠ¸ ê°„ ë°ì´í„° íë¦„ ì‹œê°í™”
               if len(selected_agents) > 1:
                   st.subheader("ğŸ”„ ë°ì´í„° íë¦„")
                   workflow_diagram = self.generate_workflow_diagram(selected_agents, workflow_status)
                   st.graphviz_chart(workflow_diagram)
               
               # ì‹¤ì‹œê°„ ë¡œê·¸
               if st.checkbox("ì‹¤ì‹œê°„ ë¡œê·¸ í‘œì‹œ"):
                   log_container = st.container()
                   with log_container:
                       for log_entry in workflow_status.get('logs', [])[-10:]:  # ìµœê·¼ 10ê°œ
                           timestamp = log_entry['timestamp'].strftime("%H:%M:%S")
                           st.text(f"[{timestamp}] {log_entry['agent']}: {log_entry['message']}")
   ```

5. WHEN providing progressive disclosure THEN the system SHALL implement user-adaptive information revelation:
   ```python
   # ì‚¬ìš©ì ìˆ˜ì¤€ë³„ ì ì§„ì  ì •ë³´ ê³µê°œ (ë” ì •êµí•œ ì ì‘)
   async def render_progressive_disclosure(self, analysis_result, user_profile):
       expertise_level = user_profile.get('expertise', 'auto_detect')
       
       if expertise_level == 'beginner' or (expertise_level == 'auto_detect' and 
                                           self.estimate_user_level() == 'beginner'):
           # ì´ˆë³´ììš© ì¹œê·¼í•œ ì„¤ëª…
           st.write("ğŸ˜Š ì´ ë°ì´í„°ë¥¼ ë³´ë‹ˆ ë­”ê°€ ê³µì¥ì—ì„œ ì œí’ˆì„ ë§Œë“œëŠ” ê³¼ì •ì„ ê¸°ë¡í•œ ê²ƒ ê°™ë„¤ìš”.")
           st.write("ë§ˆì¹˜ ìš”ë¦¬ ë ˆì‹œí”¼ì˜ ì¬ë£Œ ë¶„ëŸ‰ì„ ì¸¡ì •í•œ ê¸°ë¡ì²˜ëŸ¼ ë³´ì—¬ìš”.")
           
           # ì ì§„ì  ì •ë³´ ê³µê°œ ë²„íŠ¼ë“¤
           col1, col2, col3 = st.columns(3)
           with col1:
               if st.button("ğŸ” ë” ìì„¸íˆ ì•Œì•„ë³´ê¸°"):
                   st.session_state.disclosure_level = 'detailed'
           with col2:
               if st.button("ğŸ“Š ìˆ«ìë¡œ ë³´ê¸°"):
                   st.session_state.disclosure_level = 'numerical'
           with col3:
               if st.button("ğŸ¯ ë¬¸ì œì  ì°¾ê¸°"):
                   st.session_state.disclosure_level = 'problem_focused'
           
           # ì„ íƒëœ ê³µê°œ ìˆ˜ì¤€ì— ë”°ë¥¸ ì¶”ê°€ ì •ë³´
           if st.session_state.get('disclosure_level') == 'detailed':
               st.write("ì¢€ ë” ìì„¸íˆ ì„¤ëª…ë“œë¦¬ë©´...")
               st.write(analysis_result.get('detailed_explanation', ''))
               
               if st.button("ğŸ“ ì „ë¬¸ê°€ ìˆ˜ì¤€ìœ¼ë¡œ ë³´ê¸°"):
                   st.session_state.user_profile['expertise'] = 'expert'
                   st.rerun()
       
       elif expertise_level == 'expert':
           # ì „ë¬¸ê°€ìš© ê¸°ìˆ ì  ë¶„ì„
           st.write("í˜„ì¬ Cpk 1.2ì—ì„œ 1.33ìœ¼ë¡œ ê°œì„ í•˜ë ¤ë©´ ë³€ë™ì„±ì„ ì•½ 8.3% ê°ì†Œì‹œì¼œì•¼ í•©ë‹ˆë‹¤.")
           
           # ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­ ì¦‰ì‹œ í‘œì‹œ
           with st.expander("ğŸ“ˆ í†µê³„ì  ë¶„ì„ ê²°ê³¼", expanded=True):
               st.json(analysis_result.get('statistical_analysis', {}))
           
           with st.expander("ğŸ”§ ê°œì„  ê¶Œì¥ì‚¬í•­", expanded=True):
               for recommendation in analysis_result.get('expert_recommendations', []):
                   st.write(f"â€¢ {recommendation}")
           
           # ì „ë¬¸ê°€ìš© ì¶”ê°€ ì˜µì…˜
           col1, col2 = st.columns(2)
           with col1:
               if st.button("ğŸ“Š ê³ ê¸‰ ì‹œê°í™”"):
                   st.session_state.show_advanced_viz = True
           with col2:
               if st.button("ğŸ”¬ ì‹¬í™” ë¶„ì„"):
                   st.session_state.request_deep_analysis = True
       
       else:  # intermediate or auto_detect
           # ì¤‘ê°„ ìˆ˜ì¤€ ì„¤ëª…
           st.write("ë°ì´í„° ë¶„ì„ ê²°ê³¼ë¥¼ ìš”ì•½í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.")
           
           # ì ì‘ì  ì„¤ëª… ê¹Šì´ ì¡°ì ˆ
           explanation_depth = st.slider("ì„¤ëª… ê¹Šì´", 1, 5, 3)
           
           if explanation_depth <= 2:
               st.write(analysis_result.get('simple_summary', ''))
           elif explanation_depth >= 4:
               st.write(analysis_result.get('detailed_analysis', ''))
           else:
               st.write(analysis_result.get('medium_summary', ''))
           
           # ì‚¬ìš©ì ë°˜ì‘ì— ë”°ë¥¸ ì ì‘
           feedback = st.radio("ì´ ì„¤ëª…ì´ ë„ì›€ì´ ë˜ì…¨ë‚˜ìš”?", 
                             ["ë„ˆë¬´ ì–´ë ¤ì›Œìš”", "ì ë‹¹í•´ìš”", "ë” ìì„¸íˆ ì•Œê³  ì‹¶ì–´ìš”"])
           
           if feedback == "ë„ˆë¬´ ì–´ë ¤ì›Œìš”":
               st.session_state.user_profile['expertise'] = 'beginner'
               st.info("ğŸ’¡ ë” ì‰¬ìš´ ì„¤ëª…ìœ¼ë¡œ ë°”ê¿”ë“œë¦¬ê² ìŠµë‹ˆë‹¤.")
           elif feedback == "ë” ìì„¸íˆ ì•Œê³  ì‹¶ì–´ìš”":
               st.session_state.user_profile['expertise'] = 'expert'
               st.info("ğŸ’¡ ë” ì „ë¬¸ì ì¸ ë¶„ì„ì„ ì œê³µí•˜ê² ìŠµë‹ˆë‹¤.")
   ```

6. WHEN handling user interactions THEN the system SHALL maintain session state and conversation flow:
   ```python
   # ì„¸ì…˜ ìƒíƒœ ê´€ë¦¬ ë° ëŒ€í™” íë¦„ ìœ ì§€ (ë” í¬ê´„ì ì¸ ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬)
   def _get_session_context(self) -> Dict:
       """Universal Engineì„ ìœ„í•œ í¬ê´„ì  ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸"""
       return {
           # ì‚¬ìš©ì í”„ë¡œí•„ ë° í•™ìŠµ ì´ë ¥
           'user_profile': {
               'expertise': st.session_state.get('user_expertise', 'auto_detect'),
               'preferred_explanation_style': st.session_state.get('explanation_style', 'adaptive'),
               'domain_familiarity': st.session_state.get('domain_familiarity', {}),
               'learning_progress': st.session_state.get('learning_progress', {}),
               'interaction_patterns': st.session_state.get('interaction_patterns', [])
           },
           
           # ëŒ€í™” ì´ë ¥ ë° ì»¨í…ìŠ¤íŠ¸
           'conversation_history': st.session_state.get('messages', []),
           'conversation_topics': st.session_state.get('topics', []),
           'conversation_sentiment': st.session_state.get('sentiment_history', []),
           
           # ë°ì´í„° ë° ë¶„ì„ ì´ë ¥
           'uploaded_files': st.session_state.get('uploaded_files', []),
           'current_data': st.session_state.get('current_data'),
           'data_context': st.session_state.get('data_context', {}),
           'previous_analyses': st.session_state.get('analysis_history', []),
           
           # A2A Agent ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸
           'agent_preferences': st.session_state.get('agent_preferences', {}),
           'successful_agent_combinations': st.session_state.get('successful_combinations', []),
           'agent_performance_history': st.session_state.get('agent_performance', {}),
           
           # Universal Engine ë©”íƒ€ ì •ë³´
           'meta_reasoning_history': st.session_state.get('meta_history', []),
           'reasoning_patterns': st.session_state.get('reasoning_patterns', {}),
           'adaptation_history': st.session_state.get('adaptation_history', []),
           
           # UI/UX ì„¤ì •
           'ui_preferences': {
               'show_reasoning': st.session_state.get('show_reasoning', True),
               'show_agent_details': st.session_state.get('show_agent_details', True),
               'disclosure_level': st.session_state.get('disclosure_level', 'adaptive'),
               'visualization_preferences': st.session_state.get('viz_preferences', {})
           },
           
           # ì„±ëŠ¥ ë° ë§Œì¡±ë„ ë©”íŠ¸ë¦­
           'performance_metrics': {
               'response_times': st.session_state.get('response_times', []),
               'satisfaction_scores': st.session_state.get('satisfaction_scores', []),
               'task_completion_rates': st.session_state.get('completion_rates', [])
           }
       }
   
   def update_session_context(self, interaction_result: Dict):
       """ìƒí˜¸ì‘ìš© ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸"""
       
       # ì‚¬ìš©ì í”„ë¡œí•„ ì—…ë°ì´íŠ¸
       if interaction_result.get('detected_expertise'):
           st.session_state.user_expertise = interaction_result['detected_expertise']
       
       # ëŒ€í™” ì´ë ¥ ì—…ë°ì´íŠ¸
       if interaction_result.get('new_topics'):
           current_topics = st.session_state.get('topics', [])
           st.session_state.topics = current_topics + interaction_result['new_topics']
       
       # ë©”íƒ€ ì¶”ë¡  ì´ë ¥ ì €ì¥
       if interaction_result.get('meta_reasoning'):
           meta_history = st.session_state.get('meta_history', [])
           meta_history.append({
               'timestamp': datetime.now(),
               'reasoning': interaction_result['meta_reasoning'],
               'effectiveness': interaction_result.get('reasoning_effectiveness', 'unknown')
           })
           st.session_state.meta_history = meta_history[-50:]  # ìµœê·¼ 50ê°œë§Œ ìœ ì§€
       
       # ì—ì´ì „íŠ¸ ì„±ëŠ¥ ì—…ë°ì´íŠ¸
       if interaction_result.get('agent_performance'):
           for agent_id, performance in interaction_result['agent_performance'].items():
               agent_perf = st.session_state.get('agent_performance', {})
               if agent_id not in agent_perf:
                   agent_perf[agent_id] = []
               agent_perf[agent_id].append(performance)
               st.session_state.agent_performance = agent_perf
   ```

7. WHEN displaying analysis results THEN the system SHALL provide enhanced result visualization:
   ```python
   def render_analysis_result(self, result: Dict[str, Any]):
       """Universal Engine ê²°ê³¼ì˜ í¬ê´„ì  ì‹œê°í™”"""
       
       # 1. ë©”ì¸ ë¶„ì„ ê²°ê³¼ (ì‚¬ìš©ì ìˆ˜ì¤€ì— ë§ê²Œ ì ì‘)
       st.subheader("ğŸ“Š ë¶„ì„ ê²°ê³¼")
       
       user_level = st.session_state.get('user_expertise', 'auto_detect')
       if user_level == 'beginner':
           st.write(result.get('beginner_summary', ''))
           
           # ì‹œê°ì  ìš”ì†Œ ê°•í™”
           if result.get('key_insights'):
               st.info("ğŸ’¡ ì£¼ìš” ë°œê²¬ì‚¬í•­")
               for insight in result['key_insights'][:3]:  # ì´ˆë³´ìëŠ” 3ê°œë§Œ
                   st.write(f"â€¢ {insight}")
       
       elif user_level == 'expert':
           st.write(result.get('expert_analysis', ''))
           
           # ì „ë¬¸ê°€ìš© ìƒì„¸ ë©”íŠ¸ë¦­
           if result.get('detailed_metrics'):
               cols = st.columns(len(result['detailed_metrics']))
               for i, (metric, value) in enumerate(result['detailed_metrics'].items()):
                   with cols[i]:
                       st.metric(metric, value)
       
       # 2. Universal Engine ë©”íƒ€ ë¶„ì„ ê²°ê³¼
       if result.get('meta_analysis') and st.session_state.get('show_reasoning', True):
           with st.expander("ğŸ§  ë©”íƒ€ ì¶”ë¡  ê²°ê³¼", expanded=False):
               meta = result['meta_analysis']
               
               col1, col2 = st.columns(2)
               with col1:
                   st.write("**ê°ì§€ëœ ì»¨í…ìŠ¤íŠ¸:**")
                   st.json({
                       'domain': meta.get('domain', 'Unknown'),
                       'user_level': meta.get('user_level', 'Unknown'),
                       'intent': meta.get('intent', 'Unknown')
                   })
               
               with col2:
                   st.write("**ì¶”ë¡  ì „ëµ:**")
                   st.write(meta.get('reasoning_strategy', 'ì „ëµ ì •ë³´ ì—†ìŒ'))
               
               # ì¶”ë¡  ê³¼ì • ì‹œê°í™”
               if meta.get('reasoning_steps'):
                   st.write("**ì¶”ë¡  ë‹¨ê³„:**")
                   for i, step in enumerate(meta['reasoning_steps'], 1):
                       st.write(f"{i}. {step}")
       
       # 3. A2A Agent ê¸°ì—¬ë„ ë° í˜‘ì—… ê²°ê³¼
       if result.get('agent_contributions'):
           with st.expander("ğŸ¤– ì—ì´ì „íŠ¸ ê¸°ì—¬ë„", expanded=False):
               
               # ê¸°ì—¬ë„ ì‹œê°í™”
               agent_scores = {}
               for agent_id, contribution in result['agent_contributions'].items():
                   agent_scores[agent_id] = contribution.get('contribution_score', 0)
               
               if agent_scores:
                   # ê¸°ì—¬ë„ ì°¨íŠ¸
                   import plotly.express as px
                   fig = px.bar(
                       x=list(agent_scores.keys()), 
                       y=list(agent_scores.values()),
                       title="ì—ì´ì „íŠ¸ë³„ ê¸°ì—¬ë„"
                   )
                   st.plotly_chart(fig, use_container_width=True)
               
               # ê°œë³„ ì—ì´ì „íŠ¸ ê²°ê³¼
               for agent_id, contribution in result['agent_contributions'].items():
                   with st.container():
                       st.write(f"**ğŸ¤– {agent_id}**")
                       st.write(f"ê¸°ì—¬ë„: {contribution.get('contribution_score', 0):.1f}%")
                       st.write(f"ìš”ì•½: {contribution.get('summary', 'ì‘ì—… ì™„ë£Œ')}")
                       
                       if contribution.get('detailed_result'):
                           if st.button(f"ìƒì„¸ ê²°ê³¼ ë³´ê¸°", key=f"detail_{agent_id}"):
                               st.json(contribution['detailed_result'])
       
       # 4. í†µí•©ëœ ì¸ì‚¬ì´íŠ¸ ë° ê¶Œì¥ì‚¬í•­
       if result.get('integrated_analysis'):
           st.subheader("ğŸ¯ í†µí•© ì¸ì‚¬ì´íŠ¸")
           st.write(result['integrated_analysis'])
       
       if result.get('recommendations'):
           st.subheader("ğŸ’¡ ê¶Œì¥ì‚¬í•­")
           for i, rec in enumerate(result['recommendations'], 1):
               st.write(f"{i}. {rec}")
       
       # 5. ëŒ€í™”í˜• í›„ì† ì§ˆë¬¸ ì œì•ˆ
       if result.get('suggested_questions'):
           st.subheader("â“ ì¶”ê°€ë¡œ ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹œë‹¤ë©´")
           cols = st.columns(min(3, len(result['suggested_questions'])))
           
           for i, question in enumerate(result['suggested_questions'][:3]):
               with cols[i]:
                   if st.button(question, key=f"followup_{i}"):
                       # í›„ì† ì§ˆë¬¸ì„ ìƒˆë¡œìš´ ë©”ì‹œì§€ë¡œ ì¶”ê°€
                       st.session_state.messages.append({
                           'role': 'user',
                           'content': question,
                           'timestamp': datetime.now(),
                           'source': 'suggested_followup'
                       })
                       st.rerun()
       
       # 6. ê²°ê³¼ í’ˆì§ˆ í”¼ë“œë°±
       st.subheader("ğŸ“ ì´ ë¶„ì„ì´ ë„ì›€ì´ ë˜ì…¨ë‚˜ìš”?")
       col1, col2, col3, col4, col5 = st.columns(5)
       
       feedback_buttons = [
           ("ğŸ˜", "ë§¤ìš° ë¶ˆë§Œì¡±", 1),
           ("ğŸ˜", "ë¶ˆë§Œì¡±", 2), 
           ("ğŸ˜Š", "ë³´í†µ", 3),
           ("ğŸ˜„", "ë§Œì¡±", 4),
           ("ğŸ¤©", "ë§¤ìš° ë§Œì¡±", 5)
       ]
       
       for i, (emoji, label, score) in enumerate(feedback_buttons):
           with [col1, col2, col3, col4, col5][i]:
               if st.button(f"{emoji} {label}", key=f"feedback_{score}"):
                   # í”¼ë“œë°±ì„ ì„¸ì…˜ì— ì €ì¥í•˜ê³  Universal Engine í•™ìŠµì— í™œìš©
                   self.record_user_feedback(result, score)
                   st.success("í”¼ë“œë°±ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
   ```

8. WHEN providing recommendations THEN the system SHALL offer intelligent follow-up suggestions:
   ```python
   # ì§€ëŠ¥ì  í›„ì† ì¶”ì²œ ì‹œìŠ¤í…œ (ë” ì •êµí•œ ì¶”ì²œ ë¡œì§)
   async def generate_intelligent_followup_recommendations(self, analysis_result, user_profile, conversation_context):
       """Universal Engine ê¸°ë°˜ ì§€ëŠ¥ì  í›„ì† ì¶”ì²œ"""
       
       # Universal Engineìœ¼ë¡œ ë§¥ë½ì  ì¶”ì²œ ìƒì„±
       followup_recs = await self.universal_engine.generate_followup_recommendations(
           analysis_result=analysis_result,
           user_profile=user_profile,
           conversation_context=conversation_context,
           available_agents=self.available_agents
       )
       
       if followup_recs:
           st.subheader("ğŸ’¡ ë‹¤ìŒ ë‹¨ê³„ ì¶”ì²œ")
           
           # ì¶”ì²œ ì¹´í…Œê³ ë¦¬ë³„ ë¶„ë¥˜
           recommendation_categories = {
               'immediate': "ğŸš€ ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥",
               'exploratory': "ğŸ” ì¶”ê°€ íƒìƒ‰",
               'deep_dive': "ğŸ¯ ì‹¬í™” ë¶„ì„",
               'related': "ğŸ”— ê´€ë ¨ ë¶„ì„"
           }
           
           for category, title in recommendation_categories.items():
               category_recs = [r for r in followup_recs if r.get('category') == category]
               
               if category_recs:
                   with st.expander(title, expanded=(category == 'immediate')):
                       cols = st.columns(min(2, len(category_recs)))
                       
                       for i, rec in enumerate(category_recs):
                           with cols[i % 2]:
                               # ì¶”ì²œ ì¹´ë“œ ìŠ¤íƒ€ì¼
                               with st.container():
                                   st.write(f"**{rec['title']}**")
                                   st.caption(rec.get('description', ''))
                                   
                                   # ì˜ˆìƒ ì†Œìš” ì‹œê°„ ë° ë³µì¡ë„ í‘œì‹œ
                                   col_time, col_complexity = st.columns(2)
                                   with col_time:
                                       st.caption(f"â±ï¸ {rec.get('estimated_time', 'ì•Œ ìˆ˜ ì—†ìŒ')}")
                                   with col_complexity:
                                       complexity_icons = {
                                           'easy': 'ğŸŸ¢ ì‰¬ì›€',
                                           'medium': 'ğŸŸ¡ ë³´í†µ', 
                                           'hard': 'ğŸ”´ ì–´ë ¤ì›€'
                                       }
                                       st.caption(complexity_icons.get(rec.get('complexity', 'medium')))
                                   
                                   # ì¶”ì²œ ì‹¤í–‰ ë²„íŠ¼
                                   if st.button(f"â–¶ï¸ ì‹¤í–‰", key=f"rec_{rec['id']}"):
                                       # ì¶”ì²œ í´ë¦­ ì‹œ Universal Engineìœ¼ë¡œ ì²˜ë¦¬
                                       new_message = {
                                           'role': 'user',
                                           'content': rec['query'],
                                           'timestamp': datetime.now(),
                                           'source': 'recommendation',
                                           'recommendation_id': rec['id']
                                       }
                                       st.session_state.messages.append(new_message)
                                       
                                       # ì¶”ì²œ í´ë¦­ ì´ë²¤íŠ¸ ê¸°ë¡ (í•™ìŠµìš©)
                                       self.record_recommendation_click(rec, user_profile)
                                       st.rerun()
           
           # ì‚¬ìš©ì ë§ì¶¤ ì¶”ì²œ í•™ìŠµ
           st.subheader("ğŸ¯ ë§ì¶¤ ì¶”ì²œ ê°œì„ ")
           col1, col2 = st.columns(2)
           
           with col1:
               if st.button("ğŸ‘ ì´ëŸ° ì¶”ì²œì´ ì¢‹ì•„ìš”"):
                   self.learn_recommendation_preferences(followup_recs, 'positive')
                   st.success("ì¶”ì²œ ì„ í˜¸ë„ê°€ í•™ìŠµë˜ì—ˆìŠµë‹ˆë‹¤!")
           
           with col2:
               if st.button("ğŸ‘ ë‹¤ë¥¸ ì¢…ë¥˜ ì¶”ì²œ ì›í•´ìš”"):
                   self.learn_recommendation_preferences(followup_recs, 'negative')
                   st.info("ì¶”ì²œ ë°©ì‹ì„ ì¡°ì •í•˜ê² ìŠµë‹ˆë‹¤!")
   ```

9. WHEN handling errors THEN the system SHALL provide user-friendly error messages and recovery options:
   ```python
   # ì‚¬ìš©ì ì¹œí™”ì  ì˜¤ë¥˜ ì²˜ë¦¬ (ë” í¬ê´„ì ì¸ ì˜¤ë¥˜ ì²˜ë¦¬ ë° ë³µêµ¬)
   async def handle_analysis_errors(self, user_query: str):
       """Universal Engine + A2A í†µí•© ì‹œìŠ¤í…œì˜ í¬ê´„ì  ì˜¤ë¥˜ ì²˜ë¦¬"""
       
       try:
           result = await self.universal_a2a_system.process_unified_query(
               query=user_query,
               data=st.session_state.get('current_data'),
               context=self._get_session_context()
           )
           return result
           
       except A2AAgentError as e:
           # A2A Agent ê´€ë ¨ ì˜¤ë¥˜
           st.error(f"ğŸ¤– ì—ì´ì „íŠ¸ ì˜¤ë¥˜: {e.agent_id}ê°€ ì¼ì‹œì ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
           
           # êµ¬ì²´ì  ì˜¤ë¥˜ ìœ í˜•ë³„ ì²˜ë¦¬
           if e.error_type == 'connection_timeout':
               st.info("ğŸ’¡ ë„¤íŠ¸ì›Œí¬ ì—°ê²° ë¬¸ì œë¡œ ë³´ì…ë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
           elif e.error_type == 'agent_overload':
               st.info("ğŸ’¡ ì—ì´ì „íŠ¸ê°€ ê³¼ë¶€í•˜ ìƒíƒœì…ë‹ˆë‹¤. ë‹¤ë¥¸ ì—ì´ì „íŠ¸ë¡œ ë¶„ì„ì„ ê³„ì†í•˜ì‹œê² ìŠµë‹ˆê¹Œ?")
           elif e.error_type == 'data_format_error':
               st.info("ğŸ’¡ ë°ì´í„° í˜•ì‹ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. ë°ì´í„°ë¥¼ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.")
           
           # ë³µêµ¬ ì˜µì…˜ ì œê³µ
           col1, col2, col3 = st.columns(3)
           
           with col1:
               if st.button("ğŸ”„ ì¬ì‹œë„"):
                   st.rerun()
           
           with col2:
               if st.button("ğŸ¤– ë‹¤ë¥¸ ì—ì´ì „íŠ¸ ì‚¬ìš©"):
                   # ë¬¸ì œê°€ ìˆëŠ” ì—ì´ì „íŠ¸ ì œì™¸í•˜ê³  ì¬ì‹œë„
                   st.session_state.excluded_agents = st.session_state.get('excluded_agents', [])
                   st.session_state.excluded_agents.append(e.agent_id)
                   st.rerun()
           
           with col3:
               if st.button("ğŸ“ ì§€ì› ìš”ì²­"):
                   st.session_state.show_support_form = True
           
           # ëŒ€ì•ˆ ë¶„ì„ ì œì•ˆ
           st.subheader("ğŸ”„ ëŒ€ì•ˆ ë¶„ì„ ë°©ë²•")
           alternative_approaches = await self.universal_engine.suggest_alternative_approaches(
               original_query=user_query,
               failed_agent=e.agent_id,
               available_agents=[a for a in self.available_agents if a.id != e.agent_id]
           )
           
           for approach in alternative_approaches:
               if st.button(f"ğŸ’¡ {approach['title']}", key=f"alt_{approach['id']}"):
                   st.session_state.messages.append({
                       'role': 'user',
                       'content': approach['modified_query'],
                       'timestamp': datetime.now(),
                       'source': 'error_recovery'
                   })
                   st.rerun()
       
       except UniversalEngineError as e:
           # Universal Engine ê´€ë ¨ ì˜¤ë¥˜
           st.error(f"ğŸ§  ë¶„ì„ ì—”ì§„ ì˜¤ë¥˜: {str(e)}")
           
           # ì˜¤ë¥˜ ìœ í˜•ë³„ ì‚¬ìš©ì ì¹œí™”ì  ë©”ì‹œì§€
           if e.error_type == 'context_analysis_failed':
               st.info("ğŸ’¡ ë°ì´í„° ì»¨í…ìŠ¤íŠ¸ ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë°ì´í„°ì— ëŒ€í•´ ë” êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì‹œë©´ ë„ì›€ì´ ë©ë‹ˆë‹¤.")
               
               # ì»¨í…ìŠ¤íŠ¸ ëª…í™•í™” ë„ì›€
               st.subheader("ğŸ“ ë°ì´í„° ì •ë³´ ì…ë ¥")
               data_description = st.text_area(
                   "ë°ì´í„°ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”:",
                   placeholder="ì˜ˆ: ë°˜ë„ì²´ ê³µì • ë°ì´í„°, ë§¤ì¶œ ë°ì´í„°, ê³ ê° ì„¤ë¬¸ì¡°ì‚¬ ë“±"
               )
               
               if data_description and st.button("ğŸ”„ ë‹¤ì‹œ ë¶„ì„"):
                   st.session_state.user_provided_context = data_description
                   st.rerun()
           
           elif e.error_type == 'meta_reasoning_failed':
               st.info("ğŸ’¡ ë©”íƒ€ ì¶”ë¡ ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì§ˆë¬¸ì„ ë” êµ¬ì²´ì ìœ¼ë¡œ ë°”ê¿”ì„œ ë‹¤ì‹œ ì‹œë„í•´ë³´ì„¸ìš”.")
               
               # ì§ˆë¬¸ ê°œì„  ë„ì›€
               st.subheader("â“ ì§ˆë¬¸ ê°œì„  ë„ì›€")
               question_suggestions = [
                   "ì´ ë°ì´í„°ì—ì„œ ì–´ë–¤ íŒ¨í„´ì„ ì°¾ì„ ìˆ˜ ìˆë‚˜ìš”?",
                   "ë°ì´í„°ì— ë¬¸ì œê°€ ìˆëŠ” ë¶€ë¶„ì´ ìˆë‚˜ìš”?",
                   "ì´ ê²°ê³¼ë¥¼ ì–´ë–»ê²Œ í•´ì„í•´ì•¼ í•˜ë‚˜ìš”?",
                   "ë‹¤ìŒì— ë¬´ì—‡ì„ í•´ì•¼ í•˜ë‚˜ìš”?"
               ]
               
               for suggestion in question_suggestions:
                   if st.button(f"ğŸ’¡ {suggestion}", key=f"suggest_{hash(suggestion)}"):
                       st.session_state.messages.append({
                           'role': 'user',
                           'content': suggestion,
                           'timestamp': datetime.now(),
                           'source': 'error_recovery_suggestion'
                       })
                       st.rerun()
           
           elif e.error_type == 'user_level_detection_failed':
               st.info("ğŸ’¡ ì‚¬ìš©ì ìˆ˜ì¤€ ê°ì§€ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ìˆ˜ë™ìœ¼ë¡œ ì„¤ì •í•´ì£¼ì„¸ìš”.")
               
               # ìˆ˜ë™ ì‚¬ìš©ì ìˆ˜ì¤€ ì„¤ì •
               manual_level = st.selectbox(
                   "ì „ë¬¸ì„± ìˆ˜ì¤€ì„ ì„ íƒí•´ì£¼ì„¸ìš”:",
                   ["ì´ˆë³´ì - ì‰¬ìš´ ì„¤ëª… ì›í•¨", "ì¤‘ê¸‰ì - ì ë‹¹í•œ ì„¤ëª…", "ì „ë¬¸ê°€ - ê¸°ìˆ ì  ë¶„ì„ ì›í•¨"]
               )
               
               if st.button("âœ… ì„¤ì • ì™„ë£Œ"):
                   level_mapping = {
                       "ì´ˆë³´ì - ì‰¬ìš´ ì„¤ëª… ì›í•¨": "beginner",
                       "ì¤‘ê¸‰ì - ì ë‹¹í•œ ì„¤ëª…": "intermediate", 
                       "ì „ë¬¸ê°€ - ê¸°ìˆ ì  ë¶„ì„ ì›í•¨": "expert"
                   }
                   st.session_state.user_expertise = level_mapping[manual_level]
                   st.success("ì‚¬ìš©ì ìˆ˜ì¤€ì´ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤!")
                   st.rerun()
       
       except DataProcessingError as e:
           # ë°ì´í„° ì²˜ë¦¬ ì˜¤ë¥˜
           st.error(f"ğŸ“Š ë°ì´í„° ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
           
           # ë°ì´í„° ë¬¸ì œ ì§„ë‹¨ ë° í•´ê²°ì±… ì œì•ˆ
           st.subheader("ğŸ” ë°ì´í„° ë¬¸ì œ ì§„ë‹¨")
           
           diagnostic_results = await self.diagnose_data_issues(st.session_state.get('current_data'))
           
           for issue in diagnostic_results:
               st.warning(f"âš ï¸ {issue['problem']}")
               st.info(f"ğŸ’¡ í•´ê²°ì±…: {issue['solution']}")
               
               if issue.get('auto_fix_available'):
                   if st.button(f"ğŸ”§ ìë™ ìˆ˜ì •", key=f"fix_{issue['id']}"):
                       fixed_data = await self.auto_fix_data_issue(issue)
                       st.session_state.current_data = fixed_data
                       st.success("ë°ì´í„°ê°€ ìˆ˜ì •ë˜ì—ˆìŠµë‹ˆë‹¤!")
                       st.rerun()
       
       except Exception as e:
           # ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜
           st.error("ğŸ˜µ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
           
           # ì˜¤ë¥˜ ë³´ê³  ë° ë³µêµ¬
           with st.expander("ğŸ”§ ì˜¤ë¥˜ ì„¸ë¶€ ì •ë³´", expanded=False):
               st.code(str(e))
           
           st.info("ğŸ’¡ ì´ ì˜¤ë¥˜ë¥¼ ê°œë°œíŒ€ì— ë³´ê³ í•˜ì—¬ ì‹œìŠ¤í…œì„ ê°œì„ í•˜ëŠ”ë° ë„ì›€ì„ ì£¼ì„¸ìš”.")
           
           col1, col2 = st.columns(2)
           with col1:
               if st.button("ğŸ“§ ì˜¤ë¥˜ ë³´ê³ "):
                   self.send_error_report(e, user_query, st.session_state.get('current_data'))
                   st.success("ì˜¤ë¥˜ê°€ ë³´ê³ ë˜ì—ˆìŠµë‹ˆë‹¤!")
           
           with col2:
               if st.button("ğŸ  í™ˆìœ¼ë¡œ ëŒì•„ê°€ê¸°"):
                   # ì„¸ì…˜ ì´ˆê¸°í™”í•˜ê³  í™ˆìœ¼ë¡œ
                   for key in list(st.session_state.keys()):
                       if key not in ['user_profile', 'user_expertise']:  # ì‚¬ìš©ì ì„¤ì •ì€ ìœ ì§€
                           del st.session_state[key]
                   st.rerun()
   ```

10. WHEN system loads THEN the system SHALL initialize all components seamlessly:
    ```python
    async def initialize(self):
        """Universal Engine + A2A í†µí•© ì‹œìŠ¤í…œì˜ ì™„ì „í•œ ì´ˆê¸°í™”"""
        
        # ì´ˆê¸°í™” ì§„í–‰ ìƒíƒœ í‘œì‹œ
        initialization_container = st.container()
        
        with initialization_container:
            st.info("ğŸ’ Cherry AI Universal Engine ì´ˆê¸°í™” ì¤‘...")
            
            # ì§„í–‰ë¥  í‘œì‹œ
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            try:
                # 1ë‹¨ê³„: Universal Engine ì´ˆê¸°í™” (20%)
                status_text.text("ğŸ§  Universal Engine ì´ˆê¸°í™” ì¤‘...")
                self.universal_engine = UniversalEngine()
                await self.universal_engine.initialize()
                progress_bar.progress(20)
                
                # 2ë‹¨ê³„: A2A Agent ë°œê²¬ (40%)
                status_text.text("ğŸ¤– A2A ì—ì´ì „íŠ¸ ë°œê²¬ ì¤‘...")
                self.available_agents = await self.discover_a2a_agents()
                progress_bar.progress(40)
                
                # 3ë‹¨ê³„: Universal Engine + A2A í†µí•© ì‹œìŠ¤í…œ ì´ˆê¸°í™” (60%)
                status_text.text("ğŸ”— í†µí•© ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
                self.universal_a2a_system = UniversalEngineA2AIntegration(
                    universal_engine=self.universal_engine,
                    available_agents=self.available_agents
                )
                await self.universal_a2a_system.initialize()
                progress_bar.progress(60)
                
                # 4ë‹¨ê³„: Agent ìƒíƒœ í™•ì¸ (80%)
                status_text.text("âœ… ì—ì´ì „íŠ¸ ìƒíƒœ í™•ì¸ ì¤‘...")
                active_agents = []
                for agent in self.available_agents:
                    try:
                        status = await self.check_agent_status(agent)
                        if status == 'active':
                            active_agents.append(agent)
                    except Exception as e:
                        st.warning(f"âš ï¸ {agent.name} (í¬íŠ¸ {agent.port}) ì—°ê²° ì‹¤íŒ¨: {str(e)}")
                
                self.available_agents = active_agents
                progress_bar.progress(80)
                
                # 5ë‹¨ê³„: UI ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” (100%)
                status_text.text("ğŸ¨ UI ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì¤‘...")
                await self.initialize_ui_components()
                progress_bar.progress(100)
                
                # ì´ˆê¸°í™” ì™„ë£Œ ë©”ì‹œì§€
                status_text.empty()
                progress_bar.empty()
                
                if len(self.available_agents) > 0:
                    st.success(f"âœ… Cherry AI Universal Engine ì´ˆê¸°í™” ì™„ë£Œ!")
                    st.info(f"ğŸ¤– {len(self.available_agents)}ê°œ A2A ì—ì´ì „íŠ¸ì™€ ì—°ê²°ë¨")
                    
                    # ì—°ê²°ëœ ì—ì´ì „íŠ¸ ëª©ë¡ í‘œì‹œ
                    with st.expander("ğŸ¤– ì—°ê²°ëœ ì—ì´ì „íŠ¸ ëª©ë¡", expanded=False):
                        for agent in self.available_agents:
                            col1, col2, col3 = st.columns([2, 1, 1])
                            with col1:
                                st.write(f"**{agent.name}**")
                            with col2:
                                st.write(f"í¬íŠ¸: {agent.port}")
                            with col3:
                                st.write("ğŸŸ¢ í™œì„±")
                else:
                    st.warning("âš ï¸ A2A ì—ì´ì „íŠ¸ ì—°ê²° ì‹¤íŒ¨ - ê¸°ë³¸ Universal Engine ê¸°ëŠ¥ë§Œ ì‚¬ìš© ê°€ëŠ¥")
                    st.info("ğŸ’¡ ì—ì´ì „íŠ¸ ì„œë²„ë¥¼ ì‹œì‘í•œ í›„ í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•´ì£¼ì„¸ìš”.")
                
                # ì´ˆê¸°í™” ì„±ê³µ ì‹œ í™˜ì˜ ë©”ì‹œì§€
                if not st.session_state.get('welcome_shown', False):
                    self.show_welcome_message()
                    st.session_state.welcome_shown = True
                
                return True
                
            except Exception as e:
                # ì´ˆê¸°í™” ì‹¤íŒ¨ ì²˜ë¦¬
                progress_bar.empty()
                status_text.empty()
                
                st.error(f"âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
                
                # ë¶€ë¶„ ì´ˆê¸°í™” ì˜µì…˜ ì œê³µ
                st.subheader("ğŸ”„ ë³µêµ¬ ì˜µì…˜")
                
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    if st.button("ğŸ”„ ë‹¤ì‹œ ì‹œë„"):
                        st.rerun()
                
                with col2:
                    if st.button("ğŸ§  Universal Engineë§Œ ì‚¬ìš©"):
                        # A2A ì—†ì´ Universal Engineë§Œ ì´ˆê¸°í™”
                        try:
                            self.universal_engine = UniversalEngine()
                            await self.universal_engine.initialize()
                            self.available_agents = []
                            st.success("âœ… Universal Engine ê¸°ë³¸ ëª¨ë“œë¡œ ì‹œì‘ë¨")
                            return True
                        except Exception as e2:
                            st.error(f"ê¸°ë³¸ ëª¨ë“œ ì´ˆê¸°í™”ë„ ì‹¤íŒ¨: {str(e2)}")
                
                with col3:
                    if st.button("ğŸ“ ì§€ì› ìš”ì²­"):
                        st.session_state.show_support_form = True
                
                return False
    
    def show_welcome_message(self):
        """ì‚¬ìš©ì í™˜ì˜ ë©”ì‹œì§€ ë° ì‹œì‘ ê°€ì´ë“œ"""
        st.balloons()  # ì¶•í•˜ íš¨ê³¼
        
        st.success("ğŸ‰ Cherry AI Universal Engineì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤!")
        
        with st.expander("ğŸš€ ì‹œì‘í•˜ê¸° ê°€ì´ë“œ", expanded=True):
            st.markdown("""
            ### ğŸ’ Cherry AI Universal Engine íŠ¹ì§•
            
            - **ğŸ§  LLM First ì ‘ê·¼**: í•˜ë“œì½”ë”© ì—†ëŠ” ì§„ì •í•œ ì§€ëŠ¥í˜• ë¶„ì„
            - **ğŸ¤– A2A Agent í†µí•©**: 10ê°œ ì „ë¬¸ ì—ì´ì „íŠ¸ì™€ ìë™ í˜‘ì—…
            - **ğŸ¯ ì‚¬ìš©ì ì ì‘**: ì´ˆë³´ìë¶€í„° ì „ë¬¸ê°€ê¹Œì§€ ìë™ ìˆ˜ì¤€ ì¡°ì ˆ
            - **ğŸ” ë©”íƒ€ ì¶”ë¡ **: ìƒê°ì— ëŒ€í•´ ìƒê°í•˜ëŠ” ê³ ê¸‰ ì¶”ë¡ 
            - **ğŸ“Š ë²”ìš© ë¶„ì„**: ëª¨ë“  ë„ë©”ì¸, ëª¨ë“  ë°ì´í„° ìœ í˜• ì§€ì›
            
            ### ğŸ“ ì‚¬ìš© ë°©ë²•
            
            1. **ğŸ“ ë°ì´í„° ì—…ë¡œë“œ**: ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ íŒŒì¼ ì—…ë¡œë“œ
            2. **ğŸ’¬ ìì—°ì–´ ì§ˆë¬¸**: "ì´ ë°ì´í„°ê°€ ë­˜ ë§í•˜ëŠ”ì§€ ëª¨ë¥´ê² ì–´ìš”" ê°™ì€ ìì—°ìŠ¤ëŸ¬ìš´ ì§ˆë¬¸
            3. **ğŸ” ì ì§„ì  íƒìƒ‰**: ì‹œìŠ¤í…œì´ ì œì•ˆí•˜ëŠ” í›„ì† ì§ˆë¬¸ìœ¼ë¡œ ê¹Šì´ ìˆëŠ” ë¶„ì„
            4. **âš™ï¸ ê°œì¸í™”**: ì‹œìŠ¤í…œì´ ìë™ìœ¼ë¡œ ë‹¹ì‹ ì˜ ìˆ˜ì¤€ì— ë§ì¶° ì„¤ëª… ì¡°ì ˆ
            
            ### ğŸ’¡ ì‹œì‘ ì˜ˆì‹œ
            """)
            
            # ì˜ˆì‹œ ì§ˆë¬¸ ë²„íŠ¼ë“¤
            example_questions = [
                "ì´ ë°ì´í„° íŒŒì¼ì´ ë­˜ ë§í•˜ëŠ”ì§€ ì „í˜€ ëª¨ë¥´ê² ì–´ìš”. ë„ì›€ ì£¼ì„¸ìš”.",
                "ë°ì´í„°ì—ì„œ ì´ìƒí•œ íŒ¨í„´ì´ë‚˜ ë¬¸ì œì ì„ ì°¾ì•„ì£¼ì„¸ìš”.",
                "ì´ ê²°ê³¼ë¥¼ ì–´ë–»ê²Œ í•´ì„í•˜ê³  ë‹¤ìŒì— ë­˜ í•´ì•¼ í•˜ë‚˜ìš”?",
                "ì „ë¬¸ê°€ ìˆ˜ì¤€ì˜ ìƒì„¸í•œ í†µê³„ ë¶„ì„ì„ ì›í•©ë‹ˆë‹¤."
            ]
            
            st.write("**ğŸ¯ ì˜ˆì‹œ ì§ˆë¬¸ (í´ë¦­í•˜ë©´ ë°”ë¡œ ì‹œì‘):**")
            
            for i, question in enumerate(example_questions):
                if st.button(f"ğŸ’¡ {question}", key=f"example_{i}"):
                    st.session_state.messages.append({
                        'role': 'user',
                        'content': question,
                        'timestamp': datetime.now(),
                        'source': 'welcome_example'
                    })
                    st.rerun()
    ```

### Requirement 11: Performance and Scalability

**User Story:** As a system administrator, I want the universal engine to perform efficiently at scale while maintaining response quality, so that it can serve multiple users simultaneously without degradation.

#### Acceptance Criteria

1. WHEN processing queries THEN the system SHALL maintain response times under 10 seconds for typical analysis requests
2. WHEN multiple users access simultaneously THEN the system SHALL handle concurrent requests without performance degradation
3. WHEN learning from interactions THEN the system SHALL update knowledge efficiently without blocking other operations
4. WHEN system load increases THEN the system SHALL gracefully scale processing capacity
5. WHEN monitoring performance THEN the system SHALL provide metrics on response time, accuracy, user satisfaction, and resource utilization
### 
Requirement 12: Semantic Routing & Intent Recognition (2025 ì—°êµ¬ ê¸°ë°˜)

**User Story:** As a user, I want the system to understand my intent through semantic analysis rather than keyword matching, so that I get relevant responses even when my questions are ambiguous or use non-standard terminology.

#### Acceptance Criteria

1. WHEN processing queries THEN the system SHALL implement Universal Intent Detection using the exact pattern:
   ```
   # ë²”ìš© ì˜ë„ ë¶„ì„ íŒ¨í„´
   ì‚¬ì „ ì •ì˜ëœ ì¹´í…Œê³ ë¦¬ë‚˜ íŒ¨í„´ì— ì˜ì¡´í•˜ì§€ ì•Šê³ 
   ì¿¼ë¦¬ ìì²´ê°€ ë§í•˜ëŠ” ê²ƒì„ ë“¤ì–´ë³´ê² ìŠµë‹ˆë‹¤:

   1. ì§ì ‘ì  ì˜ë„ ë¶„ì„:
      - ì‚¬ìš©ìê°€ ëª…ì‹œì ìœ¼ë¡œ ìš”ì²­í•œ ê²ƒì€?
      - ì‚¬ìš©ëœ ì–¸ì–´ì˜ í†¤ê³¼ ìŠ¤íƒ€ì¼ì€?
      - ê¸°ëŒ€í•˜ëŠ” ì‘ë‹µì˜ í˜•íƒœëŠ”?

   2. ì•”ë¬µì  ì˜ë„ ì¶”ë¡ :
      - í‘œë©´ì  ì§ˆë¬¸ ë’¤ì˜ ì§„ì •í•œ ê´€ì‹¬ì‚¬ëŠ”?
      - í˜„ì¬ ìƒí™©ì´ë‚˜ ë¬¸ì œ ìƒí™©ì˜ ë§¥ë½ì€?
      - ê¶ê·¹ì ìœ¼ë¡œ í•´ê²°í•˜ê³ ì í•˜ëŠ” ê²ƒì€?

   3. ë™ì  ë¶„ë¥˜:
      - ì´ ì¿¼ë¦¬ëŠ” ì–´ë–¤ ì¢…ë¥˜ì˜ ë„ì›€ì´ í•„ìš”í•œê°€?
      - íƒìƒ‰ì  ë¶„ì„? ë¬¸ì œ í•´ê²°? í•™ìŠµ? ê²€ì¦?
      - ì¦‰ì‹œ ë‹µë³€? ë‹¨ê³„ë³„ ê°€ì´ë“œ? ì‹¬í™” ë¶„ì„?

   ì¹´í…Œê³ ë¦¬ì— ë§ì¶”ë ¤ í•˜ì§€ ë§ê³ , 
   ì¿¼ë¦¬ê°€ ìì—°ìŠ¤ëŸ½ê²Œ ì´ë„ëŠ” ë°©í–¥ì„ ë”°ë¥´ê² ìŠµë‹ˆë‹¤.
   ```

2. WHEN exploring semantic space THEN the system SHALL use Semantic Space Navigation pattern:
   ```
   # ì˜ë¯¸ ê³µê°„ íƒìƒ‰ íŒ¨í„´
   ì´ ì¿¼ë¦¬ì™€ ë°ì´í„°ê°€ ìœ„ì¹˜í•œ ì˜ë¯¸ ê³µê°„ì„ íƒìƒ‰í•´ë³´ê² ìŠµë‹ˆë‹¤:

   1. ì˜ë¯¸ì  ê·¼ì ‘ì„± ë¶„ì„:
      - ì–´ë–¤ ê°œë…ë“¤ì´ ì—°ê´€ë˜ì–´ ìˆëŠ”ê°€?
      - ë‹¤ë¥¸ ìœ ì‚¬í•œ ìƒí™©ë“¤ì€ ì–´ë–»ê²Œ ì²˜ë¦¬ë˜ì—ˆëŠ”ê°€?
      - ê´€ë ¨ ë„ë©”ì¸ ì§€ì‹ì€ ë¬´ì—‡ì¸ê°€?

   2. ë§¥ë½ì  ì—°ê²° íƒìƒ‰:
      - ì´ ë¬¸ì œì™€ ê´€ë ¨ëœ ë‹¤ë¥¸ ì¸¡ë©´ë“¤ì€?
      - ìƒìœ„ ê°œë…ì´ë‚˜ í•˜ìœ„ ì„¸ë¶€ì‚¬í•­ë“¤ì€?
      - ì¸ê³¼ê´€ê³„ë‚˜ ìƒê´€ê´€ê³„ëŠ”?

   3. ë™ì  ì§€ì‹ ì—°ê²°:
      - ì‹¤ì‹œê°„ìœ¼ë¡œ ê´€ë ¨ ì§€ì‹ ê²€ìƒ‰
      - ë‹¤ì–‘í•œ ê´€ì ì—ì„œì˜ ì ‘ê·¼ë²• ê³ ë ¤
      - ìµœì‹  ì—°êµ¬ë‚˜ ëª¨ë²” ì‚¬ë¡€ í†µí•©

   ì˜ë¯¸ ê³µê°„ì—ì„œ ìì—°ìŠ¤ëŸ½ê²Œ í˜•ì„±ë˜ëŠ” ì—°ê²°ì„ ë”°ë¼
   ìµœì ì˜ ë¶„ì„ ê²½ë¡œë¥¼ ì°¾ê² ìŠµë‹ˆë‹¤.
   ```

3. WHEN intent is ambiguous THEN the system SHALL distinguish between direct intent (ëª…ì‹œì  ìš”ì²­) and implicit intent (ì•”ë¬µì  ì˜ë„)
4. WHEN multiple interpretations exist THEN the system SHALL explore all semantic possibilities before selecting the most relevant approach
5. WHEN intent detection is complete THEN the system SHALL select response strategy based on discovered intent rather than predefined templates

### Requirement 13: Chain-of-Thought with Self-Consistency

**User Story:** As a user, I want the system to use multiple reasoning paths and validate consistency across them, so that I can trust the reliability of complex analysis results.

#### Acceptance Criteria

1. WHEN analyzing complex problems THEN the system SHALL use the exact Chain-of-Thought pattern:
   ```
   # ë‹¤ì¤‘ ì¶”ë¡  ê²½ë¡œ íŒ¨í„´
   ì´ ë¬¸ì œë¥¼ ì—¬ëŸ¬ ê´€ì ì—ì„œ ë¶„ì„í•´ë³´ê² ìŠµë‹ˆë‹¤:

   ì¶”ë¡  ê²½ë¡œ 1: ë°ì´í„° ì¤‘ì‹¬ ì ‘ê·¼
   - ë°ì´í„°ê°€ ë³´ì—¬ì£¼ëŠ” íŒ¨í„´ì€?
   - í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ íŠ¹ì§•ì€?
   - ë°ì´í„°ë§Œìœ¼ë¡œ ë„ì¶œí•  ìˆ˜ ìˆëŠ” ê²°ë¡ ì€?

   ì¶”ë¡  ê²½ë¡œ 2: ë„ë©”ì¸ ì§€ì‹ ì¤‘ì‹¬ ì ‘ê·¼  
   - ì´ ë¶„ì•¼ì˜ ì¼ë°˜ì ì¸ ì›ë¦¬ëŠ”?
   - ì „ë¬¸ê°€ë“¤ì´ ì£¼ë¡œ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì€?
   - ì—…ê³„ ëª¨ë²” ì‚¬ë¡€ëŠ”?

   ì¶”ë¡  ê²½ë¡œ 3: ì‚¬ìš©ì ë§¥ë½ ì¤‘ì‹¬ ì ‘ê·¼
   - ì‚¬ìš©ìì˜ ìƒí™©ê³¼ ì œì•½ì‚¬í•­ì€?
   - ì‹¤ì œ ì ìš© ê°€ëŠ¥ì„±ì€?
   - ìš°ì„ ìˆœìœ„ì™€ ëª©í‘œëŠ”?

   ì¼ê´€ì„± ê²€ì¦:
   - ê° ì¶”ë¡  ê²½ë¡œì˜ ê²°ë¡ ì´ ì¼ì¹˜í•˜ëŠ”ê°€?
   - ì°¨ì´ê°€ ìˆë‹¤ë©´ ê·¸ ì´ìœ ëŠ”?
   - ê°€ì¥ ì‹ ë¢°í•  ë§Œí•œ ê²°ë¡ ì€?

   ìµœì¢…ì ìœ¼ë¡œ ê°€ì¥ ì¼ê´€ì„± ìˆê³  ì‹ ë¢°í•  ë§Œí•œ ë¶„ì„ì„ ì œì‹œí•˜ê² ìŠµë‹ˆë‹¤.
   ```

2. WHEN reasoning paths conflict THEN the system SHALL explicitly identify and explain the differences
3. WHEN consistency is achieved THEN the system SHALL present the validated conclusion with confidence level
4. WHEN consistency cannot be achieved THEN the system SHALL present multiple valid interpretations with their respective strengths
5. WHEN final analysis is complete THEN the system SHALL state confidence level and areas of remaining uncertainty

### Requirement 14: Zero-Shot Adaptive Reasoning Without Templates

**User Story:** As a user with novel or unique problems, I want the system to reason from first principles without relying on templates, so that I get fresh insights tailored to my specific situation.

#### Acceptance Criteria

1. WHEN encountering novel problems THEN the system SHALL use the exact Zero-Shot Adaptive Reasoning pattern:
   ```
   # ë¬´ì‘ì • ì ì‘ì  ì¶”ë¡  íŒ¨í„´
   ì´ì „ ì‚¬ë¡€ë‚˜ í…œí”Œë¦¿ ì—†ì´ ìˆœìˆ˜í•˜ê²Œ ì¶”ë¡ í•´ë³´ê² ìŠµë‹ˆë‹¤:

   1. ë¬¸ì œ ê³µê°„ ì •ì˜:
      - ì´ ë¬¸ì œì˜ ë³¸ì§ˆì€ ë¬´ì—‡ì¸ê°€?
      - ì–´ë–¤ ì¢…ë¥˜ì˜ ì¶”ë¡ ì´ í•„ìš”í•œê°€?
      - í•´ê²°í•´ì•¼ í•  í•µì‹¬ ì§ˆë¬¸ë“¤ì€?

   2. ì¶”ë¡  ì „ëµ ìˆ˜ë¦½:
      - ì–´ë–¤ ìˆœì„œë¡œ ì ‘ê·¼í•  ê²ƒì¸ê°€?
      - ì–´ë–¤ ì •ë³´ê°€ ì¶”ê°€ë¡œ í•„ìš”í•œê°€?
      - ì–´ë–¤ ë°©ë²•ë¡ ì´ ê°€ì¥ ì í•©í•œê°€?

   3. ë‹¨ê³„ë³„ ì¶”ë¡  ì‹¤í–‰:
      - ê° ë‹¨ê³„ì—ì„œ ë…¼ë¦¬ì  íƒ€ë‹¹ì„± í™•ì¸
      - ê°€ì •ê³¼ ì œì•½ì‚¬í•­ ëª…ì‹œ
      - ë¶ˆí™•ì‹¤ì„±ê³¼ ì‹ ë¢°ë„ í‰ê°€

   4. ê²°ê³¼ í†µí•© ë° ê²€ì¦:
      - ë¶€ë¶„ ê²°ë¡ ë“¤ì´ ì „ì²´ì ìœ¼ë¡œ ì¼ê´€ì„± ìˆëŠ”ê°€?
      - ëŒ€ì•ˆì  í•´ì„ì´ë‚˜ ì„¤ëª…ì´ ê°€ëŠ¥í•œê°€?
      - ê²°ë¡ ì˜ í•œê³„ì™€ ì ìš© ë²”ìœ„ëŠ”?

   í…œí”Œë¦¿ì´ë‚˜ ê³µì‹ì— ì˜ì¡´í•˜ì§€ ì•Šê³ 
   ë¬¸ì œ ìì²´ì˜ ë³¸ì§ˆì— ë§ëŠ” ì¶”ë¡ ì„ ìˆ˜í–‰í•˜ê² ìŠµë‹ˆë‹¤.
   ```

2. WHEN making assumptions THEN the system SHALL explicitly state "ê°€ì •ê³¼ ì œì•½ì‚¬í•­ ëª…ì‹œ"
3. WHEN evaluating uncertainty THEN the system SHALL provide "ë¶ˆí™•ì‹¤ì„±ê³¼ ì‹ ë¢°ë„ í‰ê°€"
4. WHEN reasoning is complete THEN the system SHALL validate that no templates or formulas were used
5. WHEN presenting results THEN the system SHALL clearly indicate the reasoning approach was tailored to the specific problem

### Requirement 15: ì‹¤ì œ ì‘ë™ ì‹œë‚˜ë¦¬ì˜¤ êµ¬í˜„

**User Story:** As a user, I want the system to handle real-world scenarios with the same quality as demonstrated in the specification examples, so that I can rely on consistent performance across different use cases.

#### Acceptance Criteria

1. WHEN user is complete beginner THEN the system SHALL handle the exact scenario:
   ```
   ì…ë ¥: "ì´ ë°ì´í„° íŒŒì¼ì´ ë­˜ ë§í•˜ëŠ”ì§€ ì „í˜€ ëª¨ë¥´ê² ì–´ìš”. ë„ì›€ ì£¼ì„¸ìš”."
   ë°ì´í„°: [ë³µì¡í•œ ë°˜ë„ì²´ ê³µì • ë°ì´í„°]
   
   ì‘ë‹µ íŒ¨í„´:
   ì•ˆë…•í•˜ì„¸ìš”! ğŸ˜Š 
   
   ì´ ë°ì´í„°ë¥¼ ë³´ë‹ˆ ë­”ê°€ ê³µì¥ì—ì„œ ì œí’ˆì„ ë§Œë“œëŠ” ê³¼ì •ì„ ê¸°ë¡í•œ ê²ƒ ê°™ë„¤ìš”. 
   ë§ˆì¹˜ ìš”ë¦¬ ë ˆì‹œí”¼ì˜ ì¬ë£Œ ë¶„ëŸ‰ì„ ì¸¡ì •í•œ ê¸°ë¡ì²˜ëŸ¼ ë³´ì—¬ìš”.
   
   ì¼ë‹¨ ëª‡ ê°€ì§€ í¥ë¯¸ë¡œìš´ íŒ¨í„´ì´ ë³´ì´ëŠ”ë°ìš”:
   1. ìˆ«ìë“¤ì´ ì¼ì •í•œ ë²”ìœ„ ì•ˆì—ì„œ ì›€ì§ì´ê³  ìˆì–´ìš”
   2. ì‹œê°„ì— ë”°ë¼ ë³€í™”í•˜ëŠ” ëª¨ìŠµì´ ìˆì–´ìš”
   3. ëª‡ ê°œì˜ ì£¼ìš” ì¸¡ì •ê°’ë“¤ì´ ìˆëŠ” ê²ƒ ê°™ì•„ìš”
   
   ì–´ë–¤ ë¶€ë¶„ì´ ê°€ì¥ ê¶ê¸ˆí•˜ì„¸ìš”? 
   - ì´ ìˆ«ìë“¤ì´ ë¬´ì—‡ì„ ì˜ë¯¸í•˜ëŠ”ì§€?
   - ì¢‹ì€ ê±´ì§€ ë‚˜ìœ ê±´ì§€?
   - ë­”ê°€ ë¬¸ì œê°€ ìˆëŠ” ê±´ì§€?
   
   í•˜ë‚˜ì”© ì²œì²œíˆ ì•Œì•„ê°€ë´ìš”! ğŸ”
   ```

2. WHEN user is expert THEN the system SHALL handle the exact scenario:
   ```
   ì…ë ¥: "ê³µì • ëŠ¥ë ¥ ì§€ìˆ˜ê°€ 1.2ì¸ë° íƒ€ê²Ÿì„ 1.33ìœ¼ë¡œ ì˜¬ë¦¬ë ¤ë©´ ì–´ë–¤ íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì •í•´ì•¼ í• ê¹Œ? íŠ¹íˆ ë„ì¦ˆ ê· ì¼ì„± ì¸¡ë©´ì—ì„œ ë¶„ì„ ë¶€íƒí•´."
   
   ì‘ë‹µ íŒ¨í„´:
   í˜„ì¬ Cpk 1.2ì—ì„œ 1.33ìœ¼ë¡œ ê°œì„ í•˜ë ¤ë©´ ë³€ë™ì„±ì„ ì•½ 8.3% ê°ì†Œì‹œì¼œì•¼ í•©ë‹ˆë‹¤.
   
   ## ë„ì¦ˆ ê· ì¼ì„± ë¶„ì„ ê²°ê³¼
   
   **í˜„ì¬ ìƒíƒœ:**
   - ë„ì¦ˆ ê· ì¼ì„±: Â±1.8% (3Ïƒ)
   - ì£¼ìš” ë³€ë™ ìš”ì¸: ì›¨ì´í¼ ì¤‘ì‹¬ë¶€ ê³¼ë„ì¦ˆ (1.2% í¸ì°¨)
   - ì—ì§€ ì˜ì—­ ë„ì¦ˆ ë¶€ì¡±: í‰ê·  ëŒ€ë¹„ -2.1%
   
   **Cpk 1.33 ë‹¬ì„±ì„ ìœ„í•œ í•µì‹¬ íŒŒë¼ë¯¸í„° ì¡°ì •:**
   
   1. **ë¹” ìŠ¤ìº” ìµœì í™”** (ì˜ˆìƒ ê°œì„ : 40%)
      - ìŠ¤ìº” ì†ë„: í˜„ì¬ ëŒ€ë¹„ 5-7% ê°ì†Œ
      - ìŠ¤ìº” íŒ¨í„´: Raster â†’ Serpentine ë³€ê²½ ê²€í† 
      - ì˜ˆìƒ ê· ì¼ì„± ê°œì„ : Â±1.8% â†’ Â±1.4%
   
   [ìƒì„¸ ê¸°ìˆ  ë¶„ì„ ê³„ì†...]
   ```

3. WHEN user has ambiguous question THEN the system SHALL handle the exact scenario:
   ```
   ì…ë ¥: "ë­”ê°€ ì´ìƒí•œë°ìš”? í‰ì†Œë‘ ë‹¤ë¥¸ ê²ƒ ê°™ì•„ìš”."
   
   ì‘ë‹µ íŒ¨í„´:
   ë„¤, ë­”ê°€ í‰ì†Œì™€ ë‹¤ë¥´ë‹¤ëŠ” ëŠë‚Œì´ ë“œì‹œëŠ”êµ°ìš”. í•¨ê»˜ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤! ğŸ”
   
   ì¼ë‹¨ ë°ì´í„°ë¥¼ ë¹ ë¥´ê²Œ ìŠ¤ìº”í•´ë³´ë‹ˆ ëª‡ ê°€ì§€ ëˆˆì— ë„ëŠ” ë¶€ë¶„ì´ ìˆì–´ìš”:
   
   **ì¦‰ì‹œ ë°œê²¬ëœ ì´ìƒ ì§•í›„:**
   1. ğŸ“ˆ ì¸¡ì •ê°’ #3ì´ í‰ì†Œë³´ë‹¤ 15% ë†’ìŒ (ë§ˆì§€ë§‰ 2ì‹œê°„)
   2. ğŸ“Š ë³€ë™í­ì´ í‰ì†Œì˜ 2ë°°ë¡œ ì¦ê°€ (ì˜¤í›„ 2ì‹œ ì´í›„)
   3. âš ï¸ ì„¼ì„œ #7ì—ì„œ ê°„í—ì  ìŠ¤íŒŒì´í¬ ë°œìƒ
   
   **ëª…í™•í™”ê°€ í•„ìš”í•œ ë¶€ë¶„:**
   - "í‰ì†Œ"ë¼ê³  í•˜ì‹  ê²ƒì€ ì–¸ì œì™€ ë¹„êµí•˜ì‹  ê±´ê°€ìš”?
   - íŠ¹ë³„íˆ ì–´ë–¤ ë¶€ë¶„ì´ ì´ìƒí•˜ê²Œ ëŠê»´ì§€ì…¨ë‚˜ìš”?
   
   ì¼ë‹¨ ê°€ì¥ ëˆˆì— ë„ëŠ” ê²ƒë¶€í„° ë³´ì—¬ë“œë¦´ê¹Œìš”?
   ```

4. WHEN adapting to user responses THEN the system SHALL dynamically adjust explanation depth and technical language
5. WHEN scenarios evolve THEN the system SHALL maintain consistency with the demonstrated interaction patterns

### Requirement 16: Dynamic Knowledge Orchestrator Implementation

**User Story:** As a user, I want the system to dynamically integrate knowledge from multiple sources and reasoning approaches, so that I get comprehensive analysis that considers all relevant aspects.

#### Acceptance Criteria

1. WHEN implementing knowledge orchestration THEN the system SHALL use the exact architecture:
   ```python
   class DynamicKnowledgeOrchestrator:
       """ë™ì  ì§€ì‹ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° - ì‹¤ì‹œê°„ ì§€ì‹ í†µí•©"""
       
       async def retrieve_relevant_knowledge(self, context: Dict):
           """ì»¨í…ìŠ¤íŠ¸ì— ë§ëŠ” ì§€ì‹ ì‹¤ì‹œê°„ ê²€ìƒ‰"""
           
       async def reason_with_context(self, knowledge: Dict, query: str):
           """ë§¥ë½ì„ ê³ ë ¤í•œ ì¶”ë¡  ìˆ˜í–‰"""
           
       async def collaborate_with_agents(self, reasoning_result: Dict):
           """ë‹¤ì¤‘ ì—ì´ì „íŠ¸ì™€ í˜‘ì—…"""
           
       async def self_reflect_and_refine(self, result: Dict):
           """ê²°ê³¼ë¥¼ ìê°€ ê²€í† í•˜ê³  ê°œì„ """
   ```

2. WHEN retrieving knowledge THEN the system SHALL search contextually relevant information without predefined categories
3. WHEN reasoning with context THEN the system SHALL integrate domain knowledge, user context, and data patterns
4. WHEN collaborating with agents THEN the system SHALL coordinate multiple analysis approaches
5. WHEN refining results THEN the system SHALL apply self-reflection to improve analysis quality

### Requirement 17: Adaptive Response Generator with Progressive Disclosure

**User Story:** As a user, I want responses that adapt to my understanding level and provide information progressively, so that I can learn and explore at my own pace.

#### Acceptance Criteria

1. WHEN implementing response generation THEN the system SHALL use the exact architecture:
   ```python
   class AdaptiveResponseGenerator:
       """ì ì‘í˜• ì‘ë‹µ ìƒì„±ê¸° - ì‚¬ìš©ì ë§ì¶¤ ì‘ë‹µ"""
       
       async def generate_expertise_aware_explanation(self, analysis: Dict, user_level: str):
           """ì‚¬ìš©ì ìˆ˜ì¤€ì— ë§ëŠ” ì„¤ëª… ìƒì„±"""
           
       async def progressive_disclosure(self, information: Dict, user_response: str):
           """ì ì§„ì  ì •ë³´ ê³µê°œ"""
           
       async def interactive_clarification(self, uncertainty: Dict):
           """ëŒ€í™”í˜• ëª…í™•í™” ì§ˆë¬¸"""
           
       async def recommend_followup(self, current_analysis: Dict, user_interest: Dict):
           """í›„ì† ë¶„ì„ ì¶”ì²œ"""
   ```

2. WHEN generating explanations THEN the system SHALL adapt language complexity based on estimated user expertise
3. WHEN providing progressive disclosure THEN the system SHALL reveal information based on user interest and comprehension
4. WHEN uncertainty exists THEN the system SHALL ask interactive clarification questions
5. WHEN analysis is complete THEN the system SHALL recommend relevant follow-up analyses or explorations

### Requirement 18: Real-time Learning System Implementation

**User Story:** As a user, I want the system to learn from our interactions and continuously improve, so that the analysis quality gets better over time.

#### Acceptance Criteria

1. WHEN implementing learning system THEN the system SHALL use the exact pattern:
   ```python
   class RealTimeLearningSystem:
       def __init__(self):
           self.user_feedback_history = []
           self.successful_patterns = {}
           self.failure_patterns = {}
           
       async def learn_from_interaction(self, interaction: Dict):
           learning_prompt = f"""
           ì´ë²ˆ ìƒí˜¸ì‘ìš©ì—ì„œ ë°°ìš´ ê²ƒì„ ì •ë¦¬í•˜ê² ìŠµë‹ˆë‹¤:
           
           ìƒí˜¸ì‘ìš©: {interaction}
           ì‚¬ìš©ì ë§Œì¡±ë„: {interaction.get('satisfaction', 'unknown')}
           
           í•™ìŠµ í¬ì¸íŠ¸:
           1. ì„±ê³µí•œ ë¶€ë¶„: ë¬´ì—‡ì´ íš¨ê³¼ì ì´ì—ˆëŠ”ê°€?
           2. ê°œì„  í•„ìš”: ë¬´ì—‡ì´ ë¶€ì¡±í–ˆëŠ”ê°€?
           3. ì¼ë°˜í™” ê°€ëŠ¥: ë‹¤ë¥¸ ìƒí™©ì—ë„ ì ìš©í•  ìˆ˜ ìˆëŠ” íŒ¨í„´ì€?
           4. ì£¼ì˜ì‚¬í•­: í”¼í•´ì•¼ í•  ì ‘ê·¼ë²•ì€?
           
           ì´ í•™ìŠµì„ í–¥í›„ ìœ ì‚¬í•œ ìƒí™©ì—ì„œ í™œìš©í•˜ê² ìŠµë‹ˆë‹¤.
           """
   ```

2. WHEN user provides feedback THEN the system SHALL analyze and incorporate learning points
3. WHEN successful patterns are identified THEN the system SHALL generalize for future similar situations
4. WHEN failures occur THEN the system SHALL identify and avoid similar approaches
5. WHEN knowledge is updated THEN the system SHALL maintain privacy while preserving learning

### Requirement 19: Performance Metrics and Validation

**User Story:** As a system administrator, I want comprehensive metrics to validate the system's performance against the specification goals, so that I can ensure it meets the LLM First Universal Engine requirements.

#### Acceptance Criteria

1. WHEN measuring user satisfaction THEN the system SHALL track the exact metrics:
   - **ì‘ë‹µ ì ì ˆì„±**: ì‚¬ìš©ì í”¼ë“œë°± ê¸°ë°˜ 1-5ì  í‰ê°€
   - **ì´í•´ë„ í–¥ìƒ**: í›„ì† ì§ˆë¬¸ ê°ì†Œìœ¨
   - **ë¬¸ì œ í•´ê²°ë¥ **: ì‚¬ìš©ì ëª©í‘œ ë‹¬ì„± ë¹„ìœ¨
   - **ì¬ì‚¬ìš©ë¥ **: ë™ì¼ ì‚¬ìš©ìì˜ ë°˜ë³µ ì‚¬ìš© ë¹ˆë„

2. WHEN measuring system performance THEN the system SHALL track:
   - **ì ì‘ ì†ë„**: ì‚¬ìš©ì ìˆ˜ì¤€ íŒŒì•…ì— í•„ìš”í•œ ìƒí˜¸ì‘ìš© ìˆ˜
   - **ì •í™•ë„**: ë„ë©”ì¸ ê°ì§€ ë° ì˜ë„ ë¶„ì„ ì •í™•ë„
   - **íš¨ìœ¨ì„±**: í‰ê·  ì‘ë‹µ ì‹œê°„ ë° ì²˜ë¦¬ ì†ë„
   - **í™•ì¥ì„±**: ìƒˆë¡œìš´ ë„ë©”ì¸ ì ì‘ ì†ë„

3. WHEN conducting A/B testing THEN the system SHALL compare against hardcoded baseline systems
4. WHEN validating scenarios THEN the system SHALL test all specification examples exactly as documented
5. WHEN reporting metrics THEN the system SHALL provide comprehensive performance dashboards

### Requirement 20: A2A Agent Integration and Dynamic Orchestration

**User Story:** As a system user, I want the Universal Engine to intelligently coordinate with existing A2A agents to leverage their specialized capabilities, so that I get comprehensive analysis without losing the benefits of specialized tools.

#### Acceptance Criteria

1. WHEN processing queries THEN the system SHALL dynamically discover and integrate with available A2A agents:
   - **Data Cleaning Server (Port 8306)**: ğŸ§¹ LLM ê¸°ë°˜ ì§€ëŠ¥í˜• ë°ì´í„° ì •ë¦¬, ë¹ˆ ë°ì´í„° ì²˜ë¦¬, 7ë‹¨ê³„ í‘œì¤€ ì •ë¦¬ í”„ë¡œì„¸ìŠ¤
   - **Data Loader Server (Port 8307)**: ğŸ“ í†µí•© ë°ì´í„° ë¡œë”©, UTF-8 ì¸ì½”ë”© ë¬¸ì œ í•´ê²°, ë‹¤ì–‘í•œ íŒŒì¼ í˜•ì‹ ì§€ì›
   - **Data Visualization Server (Port 8308)**: ğŸ“Š Interactive ì‹œê°í™”, Plotly ê¸°ë°˜ ì°¨íŠ¸ ìƒì„±
   - **Data Wrangling Server (Port 8309)**: ğŸ”§ ë°ì´í„° ë³€í™˜, ì¡°ì‘, êµ¬ì¡° ë³€ê²½
   - **Feature Engineering Server (Port 8310)**: âš™ï¸ í”¼ì²˜ ìƒì„±, ë³€í™˜, ì„ íƒ, ì°¨ì› ì¶•ì†Œ
   - **SQL Database Server (Port 8311)**: ğŸ—„ï¸ SQL ì¿¼ë¦¬ ì‹¤í–‰, ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
   - **EDA Tools Server (Port 8312)**: ğŸ” íƒìƒ‰ì  ë°ì´í„° ë¶„ì„, í†µê³„ ê³„ì‚°, íŒ¨í„´ ë°œê²¬
   - **H2O ML Server (Port 8313)**: ğŸ¤– ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ë§, AutoML, ì˜ˆì¸¡ ë¶„ì„
   - **MLflow Tools Server (Port 8314)**: ğŸ“ˆ ëª¨ë¸ ê´€ë¦¬, ì‹¤í—˜ ì¶”ì , ë²„ì „ ê´€ë¦¬
   - **Pandas Collaboration Hub (Port 8315)**: ğŸ¼ íŒë‹¤ìŠ¤ ê¸°ë°˜ ë°ì´í„° ì¡°ì‘ ë° ë¶„ì„

2. WHEN selecting A2A agents THEN the system SHALL use LLM-based dynamic agent selection without hardcoded rules:
   ```python
   # ì œê±°í•´ì•¼ í•  í•˜ë“œì½”ë”© íŒ¨í„´:
   if "clean" in query:
       use_data_cleaning_agent()
   elif "visualize" in query:
       use_visualization_agent()
   
   # ëŒ€ì‹  ì‚¬ìš©í•  LLM ê¸°ë°˜ ë™ì  ì„ íƒ:
   agent_selection_prompt = f"""
   ì‚¬ìš©ì ìš”ì²­: {query}
   ë°ì´í„° íŠ¹ì„±: {data_characteristics}
   
   ë‹¤ìŒ A2A ì—ì´ì „íŠ¸ë“¤ ì¤‘ ì´ ìš”ì²­ì„ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ í•„ìš”í•œ ì—ì´ì „íŠ¸ë“¤ì„ ì„ íƒí•˜ì„¸ìš”:
   - data_cleaning: ë°ì´í„° ì •ì œ, ê²°ì¸¡ì¹˜ ì²˜ë¦¬, ì´ìƒì¹˜ ì œê±°
   - data_loader: íŒŒì¼ ë¡œë”©, ë°ì´í„° íŒŒì‹±, ì¸ì½”ë”© ì²˜ë¦¬
   - eda_tools: íƒìƒ‰ì  ë¶„ì„, ê¸°ì´ˆ í†µê³„, íŒ¨í„´ ë°œê²¬
   [... ëª¨ë“  ì—ì´ì „íŠ¸ ì„¤ëª…]
   
   ìš”ì²­ì˜ ë³¸ì§ˆì„ íŒŒì•…í•˜ì—¬ ìµœì ì˜ ì—ì´ì „íŠ¸ ì¡°í•©ê³¼ ì‹¤í–‰ ìˆœì„œë¥¼ ê²°ì •í•˜ì„¸ìš”.
   """
   ```

3. WHEN coordinating A2A agents THEN the system SHALL implement intelligent workflow orchestration:
   ```python
   class A2AWorkflowOrchestrator:
       async def execute_agent_workflow(self, selected_agents: List, query: str, data: Any) -> Dict:
           """
           A2A ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš° ë™ì  ì‹¤í–‰
           - ìˆœì°¨ ì‹¤í–‰: data_loader â†’ data_cleaning â†’ eda_tools â†’ feature_engineering â†’ h2o_ml
           - ë³‘ë ¬ ì‹¤í–‰: visualization + sql_database (ë…ë¦½ì  ë¶„ì„)
           - ê²°ê³¼ í†µí•©: pandas_collaboration_hubê°€ ìµœì¢… í†µí•©
           """
   ```

4. WHEN integrating with A2A agents THEN the system SHALL maintain A2A SDK 0.2.9 standard compliance:
   - TaskUpdater ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì§€ì›
   - AgentCard, AgentSkill, AgentCapabilities í‘œì¤€ ì¤€ìˆ˜
   - RequestContext ë° EventQueue í™œìš©
   - UnifiedDataInterface íŒ¨í„´ ì‚¬ìš©

5. WHEN A2A agents return results THEN the system SHALL synthesize results using Universal Engine meta-reasoning:
   ```python
   synthesis_prompt = f"""
   A2A ì—ì´ì „íŠ¸ ì‹¤í–‰ ê²°ê³¼ë“¤ì„ í†µí•© ë¶„ì„í•˜ê² ìŠµë‹ˆë‹¤:
   
   Data Cleaning ê²°ê³¼: {cleaning_result}
   EDA Tools ê²°ê³¼: {eda_result}
   Visualization ê²°ê³¼: {viz_result}
   ML ê²°ê³¼: {ml_result}
   
   ì‚¬ìš©ì í”„ë¡œí•„: {user_profile}
   ì›ë³¸ ì¿¼ë¦¬: {original_query}
   
   ê° ì—ì´ì „íŠ¸ì˜ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬:
   1. í•µì‹¬ ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ
   2. ì‚¬ìš©ì ìˆ˜ì¤€ì— ë§ëŠ” ì„¤ëª… ìƒì„±
   3. ì‹¤í–‰ ê°€ëŠ¥í•œ ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ
   4. ê²°ê³¼ ê°„ ì¼ê´€ì„± ê²€ì¦
   
   í†µí•©ëœ ë¶„ì„ ê²°ê³¼ë¥¼ ì œì‹œí•˜ì„¸ìš”.
   """
   ```

### Requirement 21: A2A Agent Discovery and Health Monitoring

**User Story:** As a system administrator, I want the Universal Engine to automatically discover available A2A agents and monitor their health, so that the system can adapt to agent availability changes without manual configuration.

#### Acceptance Criteria

1. WHEN system starts THEN it SHALL automatically discover available A2A agents by checking standard ports:
   ```python
   AGENT_PORTS = {
       "data_cleaning": 8306,
       "data_loader": 8307,
       "data_visualization": 8308,
       "data_wrangling": 8309,
       "feature_engineering": 8310,
       "sql_database": 8311,
       "eda_tools": 8312,
       "h2o_ml": 8313,
       "mlflow_tools": 8314,
       "pandas_collaboration_hub": 8315
   }
   ```

2. WHEN discovering agents THEN the system SHALL validate A2A agent capabilities through /.well-known/agent.json endpoint
3. WHEN agents become unavailable THEN the system SHALL gracefully adapt workflow without those agents
4. WHEN agents return errors THEN the system SHALL implement intelligent fallback strategies
5. WHEN monitoring agent health THEN the system SHALL track response times, success rates, and availability metrics

### Requirement 22: A2A Agent Result Integration and Quality Assurance

**User Story:** As a user, I want the system to intelligently combine results from multiple A2A agents into coherent insights, so that I get comprehensive analysis rather than fragmented outputs.

#### Acceptance Criteria

1. WHEN multiple A2A agents execute THEN the system SHALL validate result consistency across agents
2. WHEN agent results conflict THEN the system SHALL use meta-reasoning to resolve conflicts:
   ```python
   conflict_resolution_prompt = f"""
   A2A ì—ì´ì „íŠ¸ ê²°ê³¼ ì¶©ëŒ í•´ê²°:
   
   Data Cleaning Agent: "ë°ì´í„°ì— {cleaning_issues}ê°œ ë¬¸ì œ ë°œê²¬"
   EDA Tools Agent: "ë°ì´í„° í’ˆì§ˆì´ {eda_quality_score}ì "
   
   ì¶©ëŒ ë¶„ì„:
   1. ê° ì—ì´ì „íŠ¸ì˜ ë¶„ì„ ë°©ë²•ê³¼ ê¸°ì¤€ì´ ë‹¤ë¥¸ê°€?
   2. ì–´ë–¤ ê²°ê³¼ê°€ ë” ì‹ ë¢°í•  ë§Œí•œê°€?
   3. ì‚¬ìš©ìì—ê²Œ ì–´ë–»ê²Œ ì„¤ëª…í•  ê²ƒì¸ê°€?
   
   ì¼ê´€ëœ í•´ì„ì„ ì œì‹œí•˜ì„¸ìš”.
   """
   ```

3. WHEN integrating agent outputs THEN the system SHALL create unified data artifacts that combine all agent contributions
4. WHEN presenting results THEN the system SHALL attribute insights to specific agents while maintaining narrative coherence
5. WHEN agent results are incomplete THEN the system SHALL identify gaps and suggest additional analysis

### Requirement 23: A2A Agent Performance Optimization and Caching

**User Story:** As a system user, I want fast response times even when multiple A2A agents are involved, so that complex analysis doesn't become prohibitively slow.

#### Acceptance Criteria

1. WHEN executing A2A workflows THEN the system SHALL implement intelligent caching of agent results
2. WHEN similar queries are processed THEN the system SHALL reuse cached A2A agent outputs when appropriate
3. WHEN agents can run in parallel THEN the system SHALL execute them concurrently to minimize total processing time
4. WHEN agents have dependencies THEN the system SHALL optimize execution order to minimize waiting time
5. WHEN system load is high THEN the system SHALL implement load balancing across available agent instances

### Requirement 24: A2A Agent Error Handling and Resilience

**User Story:** As a user, I want the system to handle A2A agent failures gracefully, so that one failing agent doesn't break the entire analysis.

#### Acceptance Criteria

1. WHEN A2A agents fail THEN the system SHALL continue analysis with available agents and inform user of limitations
2. WHEN agent timeouts occur THEN the system SHALL implement progressive timeout strategies (5s â†’ 15s â†’ 30s)
3. WHEN agent responses are malformed THEN the system SHALL attempt to parse partial results and request clarification
4. WHEN critical agents fail THEN the system SHALL suggest alternative approaches or manual steps
5. WHEN agents recover THEN the system SHALL automatically reintegrate them into future workflows

### Requirement 25: A2A Agent Capability Enhancement

**User Story:** As a developer, I want the Universal Engine to enhance A2A agent capabilities through intelligent prompting and context provision, so that agents perform better than they would in isolation.

#### Acceptance Criteria

1. WHEN calling A2A agents THEN the system SHALL provide enhanced context from meta-reasoning analysis:
   ```python
   enhanced_agent_request = {
       'query': original_query,
       'data': processed_data,
       'context': {
           'user_expertise_level': user_profile.expertise,
           'domain_context': meta_analysis.domain_context,
           'analysis_goals': meta_analysis.inferred_goals,
           'previous_agent_results': workflow_results,
           'quality_requirements': meta_analysis.quality_expectations
       }
   }
   ```

2. WHEN agents need clarification THEN the system SHALL use Universal Engine reasoning to provide intelligent responses
3. WHEN agents produce suboptimal results THEN the system SHALL provide feedback and request improvements
4. WHEN agents suggest follow-up actions THEN the system SHALL evaluate suggestions through meta-reasoning
5. WHEN agents learn from interactions THEN the system SHALL coordinate learning across the agent ecosystem

### Requirement 26: Security and Privacy Protection

**User Story:** As a user concerned about data privacy, I want assurance that the learning system protects my data while still improving the service, so that I can use the system with confidence.

#### Acceptance Criteria

1. WHEN processing user data THEN the system SHALL ensure all data remains secure and is not shared inappropriately
2. WHEN learning from interactions THEN the system SHALL extract patterns without storing personally identifiable information
3. WHEN user requests data deletion THEN the system SHALL remove all associated data while preserving general learning
4. WHEN providing analysis THEN the system SHALL not reference other users' specific data or queries
5. WHEN system updates occur THEN privacy protections SHALL be maintained throughout the learning process