#!/usr/bin/env python3
"""
Cherry AI ì¢…í•© í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
- ëª¨ë“  í•µì‹¬ ì»´í¬ë„ŒíŠ¸ ê²€ì¦
- A2A ì—ì´ì „íŠ¸ ì—°ê²° í…ŒìŠ¤íŠ¸
- UI ê¸°ëŠ¥ ê²€ì¦
"""

import asyncio
import sys
import logging
from pathlib import Path
import json

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì„¤ì •
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

async def test_agent_config_loader():
    """ì—ì´ì „íŠ¸ ì„¤ì • ë¡œë” í…ŒìŠ¤íŠ¸"""
    logger.info("ğŸ§ª Testing AgentConfigLoader...")
    
    try:
        from config.agents_config import AgentConfigLoader
        
        loader = AgentConfigLoader("config/agents.json")
        agents = loader.get_all_agents()
        
        assert len(agents) > 0, "No agents found in configuration"
        logger.info(f"âœ… Found {len(agents)} agents in configuration")
        
        # íŠ¹ì • ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸
        orchestrator = loader.get_agent_by_id("orchestrator")
        assert orchestrator is not None, "Orchestrator agent not found"
        logger.info(f"âœ… Orchestrator agent found: {orchestrator.name}")
        
        # ì¹´í…Œê³ ë¦¬ë³„ ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸
        analysis_agents = loader.get_agents_by_category("analysis")
        logger.info(f"âœ… Found {len(analysis_agents)} analysis agents")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ AgentConfigLoader test failed: {e}")
        return False

async def test_planning_engine():
    """ê³„íš ì—”ì§„ í…ŒìŠ¤íŠ¸"""
    logger.info("ğŸ§ª Testing PlanningEngine...")
    
    try:
        from core.orchestrator.planning_engine import PlanningEngine
        from config.agents_config import AgentConfigLoader
        
        engine = PlanningEngine()
        loader = AgentConfigLoader("config/agents.json")
        
        # ì‚¬ìš©ì ì˜ë„ ë¶„ì„ í…ŒìŠ¤íŠ¸
        test_query = "ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ì‹œê°í™”í•´ì£¼ì„¸ìš”"
        intent = await engine.analyze_user_intent(test_query)
        
        assert intent.primary_goal is not None, "Primary goal not extracted"
        logger.info(f"âœ… Intent analysis: {intent.primary_goal}")
        logger.info(f"âœ… Analysis types: {intent.analysis_type}")
        logger.info(f"âœ… Complexity: {intent.complexity_level}")
        
        # ì—ì´ì „íŠ¸ ì„ íƒ í…ŒìŠ¤íŠ¸
        available_agents = list(loader.get_enabled_agents().values())
        selected_agents = await engine.select_optimal_agents(intent, available_agents)
        
        assert len(selected_agents) > 0, "No agents selected"
        logger.info(f"âœ… Selected {len(selected_agents)} agents")
        
        for agent in selected_agents:
            logger.info(f"  - {agent.agent_id}: {agent.confidence:.2f} ({agent.reasoning})")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ PlanningEngine test failed: {e}")
        return False

async def test_a2a_orchestrator():
    """A2A ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° í…ŒìŠ¤íŠ¸"""
    logger.info("ğŸ§ª Testing A2AOrchestrator...")
    
    try:
        from core.orchestrator.a2a_orchestrator import A2AOrchestrator
        
        orchestrator = A2AOrchestrator("config/agents.json")
        
        # ì„¤ì • ë¡œë“œ í…ŒìŠ¤íŠ¸
        await orchestrator.reload_agents_config()
        assert len(orchestrator.agents) > 0, "No agents loaded"
        logger.info(f"âœ… Loaded {len(orchestrator.agents)} agents")
        
        # ì—ì´ì „íŠ¸ ìƒíƒœ í™•ì¸ (ì‹¤ì œ ì—°ê²°ì€ í•˜ì§€ ì•ŠìŒ)
        logger.info("âœ… Orchestrator initialization successful")
        
        # ë¶„ì„ ê³„íš ìƒì„± í…ŒìŠ¤íŠ¸
        test_query = "CSV íŒŒì¼ì˜ ê¸°ë³¸ í†µê³„ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”"
        data_context = {
            'data_shape': (100, 5),
            'columns': ['col1', 'col2', 'col3', 'col4', 'col5'],
            'file_type': 'csv'
        }
        
        plan = await orchestrator.create_analysis_plan(test_query, data_context)
        assert plan is not None, "Analysis plan not created"
        logger.info(f"âœ… Analysis plan created: {plan.id}")
        logger.info(f"  - Selected agents: {plan.selected_agents}")
        logger.info(f"  - Steps: {len(plan.execution_sequence)}")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ A2AOrchestrator test failed: {e}")
        return False

async def test_config_file_integrity():
    """ì„¤ì • íŒŒì¼ ë¬´ê²°ì„± í…ŒìŠ¤íŠ¸"""
    logger.info("ğŸ§ª Testing config file integrity...")
    
    try:
        config_path = Path("config/agents.json")
        assert config_path.exists(), "Config file does not exist"
        
        with open(config_path, 'r', encoding='utf-8') as f:
            config_data = json.load(f)
        
        assert 'agents' in config_data, "Missing 'agents' section in config"
        assert 'global_settings' in config_data, "Missing 'global_settings' section in config"
        
        agents = config_data['agents']
        expected_agents = [
            'orchestrator', 'data_loader', 'data_cleaning', 'eda_tools',
            'data_visualization', 'data_wrangling', 'feature_engineering',
            'sql_database', 'h2o_ml', 'mlflow_tools', 'pandas_agent', 'report_generator'
        ]
        
        for agent_id in expected_agents:
            assert agent_id in agents, f"Missing agent: {agent_id}"
            agent_config = agents[agent_id]
            
            required_fields = ['id', 'name', 'port', 'host', 'endpoint', 'capabilities', 'enabled']
            for field in required_fields:
                assert field in agent_config, f"Missing field '{field}' in agent {agent_id}"
        
        logger.info(f"âœ… Config file integrity verified: {len(agents)} agents")
        return True
        
    except Exception as e:
        logger.error(f"âŒ Config file integrity test failed: {e}")
        return False

def test_import_structure():
    """ëª¨ë“ˆ ì„í¬íŠ¸ êµ¬ì¡° í…ŒìŠ¤íŠ¸"""
    logger.info("ğŸ§ª Testing import structure...")
    
    try:
        # í•µì‹¬ ëª¨ë“ˆ ì„í¬íŠ¸ í…ŒìŠ¤íŠ¸
        from config.agents_config import AgentConfigLoader, AgentConfig, AgentStatus
        logger.info("âœ… Config module imports successful")
        
        from core.orchestrator.a2a_orchestrator import A2AOrchestrator
        from core.orchestrator.planning_engine import PlanningEngine
        logger.info("âœ… Orchestrator module imports successful")
        
        # Cherry AI ë©”ì¸ ëª¨ë“ˆ ì„í¬íŠ¸ í…ŒìŠ¤íŠ¸ (Streamlit ì—†ì´)
        import importlib.util
        spec = importlib.util.spec_from_file_location("cherry_ai", "cherry_ai.py")
        cherry_ai_module = importlib.util.module_from_spec(spec)
        # spec.loader.exec_module(cherry_ai_module)  # Streamlit ë•Œë¬¸ì— ì‹¤í–‰í•˜ì§€ ì•ŠìŒ
        logger.info("âœ… Cherry AI main module structure verified")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ Import structure test failed: {e}")
        return False

async def run_all_tests():
    """ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    logger.info("ğŸ’ Starting Cherry AI Comprehensive Tests")
    logger.info("=" * 50)
    
    test_results = []
    
    # ë™ê¸° í…ŒìŠ¤íŠ¸
    test_results.append(("Import Structure", test_import_structure()))
    test_results.append(("Config File Integrity", await test_config_file_integrity()))
    
    # ë¹„ë™ê¸° í…ŒìŠ¤íŠ¸
    test_results.append(("AgentConfigLoader", await test_agent_config_loader()))
    test_results.append(("PlanningEngine", await test_planning_engine()))
    test_results.append(("A2AOrchestrator", await test_a2a_orchestrator()))
    
    # ê²°ê³¼ ìš”ì•½
    logger.info("=" * 50)
    logger.info("ğŸ’ Cherry AI Test Results Summary")
    logger.info("=" * 50)
    
    passed = 0
    failed = 0
    
    for test_name, result in test_results:
        status = "âœ… PASSED" if result else "âŒ FAILED"
        logger.info(f"{test_name}: {status}")
        if result:
            passed += 1
        else:
            failed += 1
    
    logger.info("=" * 50)
    logger.info(f"Total Tests: {len(test_results)}")
    logger.info(f"Passed: {passed}")
    logger.info(f"Failed: {failed}")
    
    if failed == 0:
        logger.info("ğŸ‰ All tests passed! Cherry AI is ready to run.")
        return True
    else:
        logger.error(f"ğŸ’¥ {failed} test(s) failed. Please check the errors above.")
        return False

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    try:
        success = asyncio.run(run_all_tests())
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        logger.info("Test interrupted by user")
        sys.exit(1)
    except Exception as e:
        logger.error(f"Unexpected error during testing: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()