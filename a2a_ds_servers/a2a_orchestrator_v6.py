#!/usr/bin/env python3
"""
A2A Orchestrator v6.0 Stable - LLM Enhanced Orchestrator (Based on v5)
ì•ˆì •ì ì¸ LLM ê°•í™” ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° (v5 ê¸°ë°˜)
"""

import asyncio
import json
import logging
import os
import time
from typing import Any, Dict, List, Optional

import httpx
import uvicorn
from openai import AsyncOpenAI

# A2A SDK 0.2.9 í‘œì¤€ ì„í¬íŠ¸
from a2a.server.apps import A2AStarletteApplication
from a2a.server.request_handlers import DefaultRequestHandler
from a2a.server.tasks import InMemoryTaskStore, TaskUpdater
from a2a.server.agent_execution import AgentExecutor, RequestContext
from a2a.server.events import EventQueue
from a2a.types import (
    AgentCard,
    AgentSkill,
    AgentCapabilities,
    TaskState,
    TextPart
)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# AI DS Team ì—ì´ì „íŠ¸ í¬íŠ¸ ë§¤í•‘
AGENT_PORTS = {
    "data_cleaning": 8306,
    "data_loader": 8307, 
    "data_visualization": 8308,
    "data_wrangling": 8309,
    "feature_engineering": 8310,
    "sql_database": 8311,
    "eda_tools": 8312,
    "h2o_ml": 8313,
    "mlflow_tools": 8314,
}


class LLMEnhancedOrchestratorExecutor(AgentExecutor):
    """LLM ê°•í™” ì•ˆì •ì ì¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° (v5 ê¸°ë°˜)"""
    
    def __init__(self):
        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (ì˜µì…˜)
        try:
            api_key = os.getenv("OPENAI_API_KEY")
            if api_key and api_key.strip():
                self.openai_client = AsyncOpenAI(api_key=api_key)
                logger.info("ğŸ¤– LLM Enhanced Orchestrator v6 with OpenAI integration")
            else:
                self.openai_client = None
                logger.info("ğŸ“Š Standard Orchestrator v6 (OpenAI API key not found)")
        except Exception as e:
            logger.warning(f"OpenAI client initialization failed: {e}")
            self.openai_client = None
    
    async def _enhance_context_with_llm(self, user_input: str, agent_name: str) -> str:
        """LLMì„ ì‚¬ìš©í•˜ì—¬ ì—ì´ì „íŠ¸ë³„ ì»¨í…ìŠ¤íŠ¸ ê°•í™” (ì˜µì…˜)"""
        
        if not self.openai_client:
            return user_input
            
        try:
            prompt = f"""ë‹¤ìŒ ìš”ì²­ì„ {agent_name} ì—ì´ì „íŠ¸ì—ê²Œ ìµœì í™”í•˜ì—¬ ì „ë‹¬í•˜ì„¸ìš”:

ì›ë³¸ ìš”ì²­: {user_input}

{agent_name} ì—ì´ì „íŠ¸ì˜ ì—­í• ì— ë§ê²Œ êµ¬ì²´ì ì´ê³  ëª…í™•í•œ ì§€ì‹œì‚¬í•­ìœ¼ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”.
ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­ê³¼ ê¸°ëŒ€í•˜ëŠ” ê²°ê³¼ë¬¼ì„ í¬í•¨í•˜ì„¸ìš”."""

            response = await self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3,
                max_tokens=500
            )
            
            enhanced_input = response.choices[0].message.content.strip()
            logger.info(f"âœ¨ Enhanced context for {agent_name}")
            return enhanced_input
            
        except Exception as e:
            logger.warning(f"Context enhancement failed for {agent_name}: {e}")
            return user_input
    
    async def execute(self, context: RequestContext, event_queue: EventQueue) -> None:
        """A2A í‘œì¤€ ì¤€ìˆ˜ ì‹¤í–‰ - Artifactë¡œ ê³„íš ë°˜í™˜"""
        task_updater = TaskUpdater(event_queue, context.task_id, context.context_id)
        
        try:
            await task_updater.submit()
            await task_updater.start_work()
            
            user_query = context.get_user_input()
            logger.info(f"ğŸ“¥ Processing orchestration query: {user_query}")
            
            if not user_query:
                user_query = "Please provide an analysis request."
            
            # ì—ì´ì „íŠ¸ ë°œê²¬
            available_agents = await self._discover_agents()
            
            if not available_agents:
                await task_updater.update_status(
                    TaskState.failed,
                    message=task_updater.new_agent_message(parts=[TextPart(text="âŒ ì‚¬ìš© ê°€ëŠ¥í•œ A2A ì—ì´ì „íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")])
                )
                return
            
            # ì‹¤ì œ ì‹¤í–‰ ê³„íš ìƒì„±
            execution_plan = await self._generate_execution_plan(user_query, available_agents)
            
            if not execution_plan:
                execution_plan = self._create_fallback_plan(available_agents)
            
            # A2A í‘œì¤€: ì‹¤í–‰ ê³„íšì„ Artifactë¡œ ë°˜í™˜
            await task_updater.add_artifact(
                parts=[TextPart(text=json.dumps(execution_plan, ensure_ascii=False, indent=2))],
                name="execution_plan",
                metadata={
                    "content_type": "application/json",
                    "plan_type": "ai_ds_team_orchestration"
                }
            )
            
            # ì™„ë£Œ ë©”ì‹œì§€
            completion_message = f"""âœ… AI DS Team ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ê³„íš ìƒì„± ì™„ë£Œ

ğŸ¤– **ë°œê²¬ëœ ì—ì´ì „íŠ¸**: {len(available_agents)}ê°œ
ğŸ“ **ë¶„ì„ ëª©í‘œ**: {execution_plan.get('objective', 'ë°ì´í„° ë¶„ì„ ìˆ˜í–‰')}
ğŸ”„ **ì‹¤í–‰ ë‹¨ê³„**: {len(execution_plan.get('steps', []))}ê°œ

ì‹¤í–‰ ê³„íšì´ Artifactë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤."""
            
            await task_updater.update_status(
                TaskState.completed,
                message=task_updater.new_agent_message(parts=[TextPart(text=completion_message)])
            )
            
        except Exception as e:
            logger.error(f"Error in execute: {e}", exc_info=True)
            await task_updater.update_status(
                TaskState.failed,
                message=task_updater.new_agent_message(parts=[TextPart(text=f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}")])
            )

    async def cancel(self, context: RequestContext, event_queue: EventQueue) -> None:
        """Cancel the operation"""
        task_updater = TaskUpdater(event_queue, context.task_id, context.context_id)
        await task_updater.reject()
        logger.info(f"Operation cancelled for context {context.context_id}")

    async def _discover_agents(self) -> Dict[str, Dict[str, Any]]:
        """A2A í‘œì¤€ ì—ì´ì „íŠ¸ ë°œê²¬"""
        available_agents = {}
        
        async with httpx.AsyncClient(timeout=5.0) as client:
            for agent_name, port in AGENT_PORTS.items():
                try:
                    response = await client.get(f"http://localhost:{port}/.well-known/agent.json")
                    if response.status_code == 200:
                        agent_card = response.json()
                        available_agents[agent_name] = {
                            "name": agent_card.get("name", agent_name),
                            "url": f"http://localhost:{port}",
                            "port": port,
                            "description": agent_card.get("description", ""),
                            "status": "available"
                        }
                        logger.info(f"âœ… {agent_name} agent discovered on port {port}")
                except Exception as e:
                    logger.warning(f"âš ï¸ {agent_name} agent on port {port} not available: {e}")
        
        logger.info(f"ğŸ” Total discovered agents: {len(available_agents)}")
        return available_agents

    async def _generate_execution_plan(self, user_query: str, available_agents: Dict[str, Dict[str, Any]]) -> Optional[Dict[str, Any]]:
        """LLMì„ ì‚¬ìš©í•˜ì—¬ A2A í‘œì¤€ ì‹¤í–‰ ê³„íš ìƒì„±"""
        if not self.openai_client:
            logger.warning("OpenAI API key not found, using fallback plan")
            return None
        
        try:
            agent_descriptions = []
            for name, info in available_agents.items():
                agent_descriptions.append(f"- {name}: {info['description']}")
            
            agents_text = "\n".join(agent_descriptions)
            
            system_prompt = f"""ë‹¹ì‹ ì€ AI Data Science Teamì˜ A2A í‘œì¤€ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ìš”ì²­ì„ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ A2A ì—ì´ì „íŠ¸ë“¤ì„ ìˆœì„œëŒ€ë¡œ ì‹¤í–‰í•˜ëŠ” ê³„íšì„ ì„¸ìš°ì„¸ìš”.

ì‚¬ìš© ê°€ëŠ¥í•œ A2A ì—ì´ì „íŠ¸ë“¤:
{agents_text}

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
{{
    "plan_type": "ai_ds_team_orchestration",
    "objective": "ë¶„ì„ ëª©í‘œ ìš”ì•½",
    "reasoning": "ì´ ê³„íšì„ ì„ íƒí•œ ì´ìœ ",
    "steps": [
        {{
            "step_number": 1,
            "agent_name": "ì—ì´ì „íŠ¸_ì´ë¦„",
            "task_description": "êµ¬ì²´ì ì¸ ì‘ì—… ì„¤ëª…",
            "reasoning": "ì´ ë‹¨ê³„ê°€ í•„ìš”í•œ ì´ìœ "
        }}
    ]
}}"""

            user_prompt = f"""ì‚¬ìš©ì ìš”ì²­: {user_query}

ìœ„ ìš”ì²­ì— ëŒ€í•´ AI DS Team A2A ì—ì´ì „íŠ¸ë“¤ì„ í™œìš©í•œ ì‹¤í–‰ ê³„íšì„ JSON í˜•ì‹ìœ¼ë¡œ ìƒì„±í•´ì£¼ì„¸ìš”."""

            response = await self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.3,
                max_tokens=2000
            )
            
            plan_text = response.choices[0].message.content.strip()
            
            # JSON ì¶”ì¶œ
            import re
            json_match = re.search(r'```json\s*(.*?)\s*```', plan_text, re.DOTALL)
            if json_match:
                plan_text = json_match.group(1)
            elif plan_text.startswith('{'):
                pass
            else:
                start_idx = plan_text.find('{')
                end_idx = plan_text.rfind('}') + 1
                if start_idx != -1 and end_idx > start_idx:
                    plan_text = plan_text[start_idx:end_idx]
            
            execution_plan = json.loads(plan_text)
            logger.info(f"âœ… LLM ê¸°ë°˜ A2A í‘œì¤€ ì‹¤í–‰ ê³„íš ìƒì„± ì™„ë£Œ: {len(execution_plan.get('steps', []))}ê°œ ë‹¨ê³„")
            return execution_plan
            
        except Exception as e:
            logger.error(f"âŒ LLM ê³„íš ìƒì„± ì‹¤íŒ¨: {e}")
            return None

    def _create_fallback_plan(self, available_agents: Dict[str, Dict[str, Any]]) -> Dict[str, Any]:
        """A2A í‘œì¤€ í´ë°± ê³„íš ìƒì„±"""
        steps = []
        step_number = 1
        
        # ê¸°ë³¸ì ì¸ ë°ì´í„° ë¶„ì„ ì›Œí¬í”Œë¡œìš°
        basic_workflow = [
            ("data_loader", "ë°ì´í„° ë¡œë“œ ë° ê¸°ë³¸ ê²€ì¦"),
            ("data_cleaning", "ë°ì´í„° í’ˆì§ˆ í™•ì¸ ë° ì •ë¦¬"),
            ("eda_tools", "íƒìƒ‰ì  ë°ì´í„° ë¶„ì„ ìˆ˜í–‰"),
            ("data_visualization", "ë°ì´í„° ì‹œê°í™” ë° ì¸ì‚¬ì´íŠ¸ ë„ì¶œ")
        ]
        
        for agent_name, task_desc in basic_workflow:
            if agent_name in available_agents:
                steps.append({
                    "step_number": step_number,
                    "agent_name": agent_name,
                    "task_description": task_desc,
                    "reasoning": f"{available_agents[agent_name]['description']} ì „ë¬¸ ì—­ëŸ‰ í™œìš©"
                })
                step_number += 1
        
        return {
            "plan_type": "ai_ds_team_orchestration",
            "objective": "ê¸°ë³¸ ë°ì´í„° ë¶„ì„ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰",
            "reasoning": "ì‚¬ìš©ì ìš”ì²­ì— ëŒ€í•œ í¬ê´„ì ì¸ ë°ì´í„° ë¶„ì„ì„ ìˆ˜í–‰í•˜ê¸° ìœ„í•œ í‘œì¤€ A2A ë‹¨ê³„ë“¤",
            "steps": steps
        }


def create_standard_orchestrator_server():
    """A2A SDK 0.2.9 ì™„ì „ í‘œì¤€ ì¤€ìˆ˜ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì„œë²„ ìƒì„±"""
    
    agent_card = AgentCard(
        name="AI DS Team LLM Enhanced Orchestrator v6 Stable",
        description="AI Data Science Teamì˜ A2A í‘œì¤€ ì¤€ìˆ˜ ë©€í‹° ì—ì´ì „íŠ¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°",
        url="http://localhost:8100",
        version="5.0.0",
        capabilities=AgentCapabilities(
            streaming=True,
            pushNotifications=False,
            stateTransitionHistory=True
        ),
        defaultInputModes=["text/plain"],
        defaultOutputModes=["text/plain", "application/json"],
        skills=[
            AgentSkill(
                id="orchestrate_analysis",
                name="AI DS Team A2A Orchestration",
                description="AI Data Science Team A2A ì—ì´ì „íŠ¸ë“¤ì„ ì¡°ì •í•˜ì—¬ í‘œì¤€ ì¤€ìˆ˜ ë°ì´í„° ë¶„ì„ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.",
                tags=["orchestration", "multi-agent", "data-science", "a2a-standard"]
            )
        ]
    )
    
    executor = LLMEnhancedOrchestratorExecutor()
    task_store = InMemoryTaskStore()
    request_handler = DefaultRequestHandler(
        agent_executor=executor,
        task_store=task_store
    )
    
    app = A2AStarletteApplication(
        agent_card=agent_card,
        http_handler=request_handler
    )
    
    return app


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    logger.info("ğŸš€ Starting A2A Standard Orchestrator Server v5.0 (A2A SDK 0.2.9 Full Compliance)")
    
    app = create_standard_orchestrator_server()
    
    uvicorn.run(
        app.build(),
        host="localhost",
        port=8100,
        log_level="info"
    )


if __name__ == "__main__":
    main() 