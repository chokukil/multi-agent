import sys
import os
from pathlib import Path

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

#!/usr/bin/env python3
"""

AI_DS_Team MLflowToolsAgent A2A Server - ìˆ˜ì •ëœ ë²„ì „
Port: 8323

ì„±ê³µí•œ plotly_visualization_server.py íŒ¨í„´ 100% ì ìš©
ì›ë³¸ ai-data-science-teamì˜ MLflowToolsAgentë¥¼ ì™„ì „íˆ í™œìš©
"""

import asyncio
import sys
import os
from pathlib import Path
import json
import logging
import pandas as pd
import numpy as np
import io

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / "ai_ds_team"))

# A2A imports
from a2a.server.apps import A2AStarletteApplication
from a2a.server.request_handlers.default_request_handler import DefaultRequestHandler
from a2a.server.tasks.inmemory_task_store import InMemoryTaskStore
from a2a.server.tasks.task_updater import TaskUpdater
from a2a.server.agent_execution import AgentExecutor, RequestContext
from a2a.server.events.event_queue import EventQueue
from a2a.types import TextPart, TaskState, AgentCard, AgentSkill, AgentCapabilities
from a2a.utils import new_agent_text_message
import uvicorn

# AI_DS_Team imports
from ml_agents import MLflowToolsAgent

# Core imports
from core.data_manager import DataManager
from dotenv import load_dotenv

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
data_manager = DataManager()

class PandasAIDataProcessor:
    """pandas-ai íŒ¨í„´ì„ í™œìš©í•œ ë°ì´í„° ì²˜ë¦¬ê¸° (ì„±ê³µí•œ íŒ¨í„´)"""
    
    def __init__(self):
        self.current_dataframe = None
        
    def parse_data_from_message(self, user_message: str) -> pd.DataFrame:
        """ì‚¬ìš©ì ë©”ì‹œì§€ì—ì„œ ë°ì´í„°ë¥¼ íŒŒì‹±"""
        logger.info("ğŸ“Š pandas-ai íŒ¨í„´ìœ¼ë¡œ ë©”ì‹œì§€ì—ì„œ ë°ì´í„° íŒŒì‹±...")
        
        # 1. CSV ë°ì´í„° íŒŒì‹±
        lines = user_message.split('\n')
        csv_lines = [line.strip() for line in lines if ',' in line and len(line.split(',')) >= 2]
        
        if len(csv_lines) >= 2:  # í—¤ë” + ë°ì´í„°
            try:
                csv_content = '\n'.join(csv_lines)
                df = pd.read_csv(io.StringIO(csv_content))
                logger.info("âœ… CSV ë°ì´í„° íŒŒì‹± ì„±ê³µ: %s", df.shape)
                return df
            except Exception as e:
                logger.warning("CSV íŒŒì‹± ì‹¤íŒ¨: %s", e)
        
        # 2. JSON ë°ì´í„° íŒŒì‹±
        try:
            json_start = user_message.find('{')
            json_end = user_message.rfind('}') + 1
            
            if json_start != -1 and json_end > json_start:
                json_content = user_message[json_start:json_end]
                data = json.loads(json_content)
                
                if isinstance(data, list):
                    df = pd.DataFrame(data)
                    logger.info("âœ… JSON ë¦¬ìŠ¤íŠ¸ ë°ì´í„° íŒŒì‹± ì„±ê³µ: %s", df.shape)
                    return df
                elif isinstance(data, dict):
                    df = pd.DataFrame([data])
                    logger.info("âœ… JSON ê°ì²´ ë°ì´í„° íŒŒì‹± ì„±ê³µ: %s", df.shape)
                    return df
        except json.JSONDecodeError as e:
            logger.warning("JSON íŒŒì‹± ì‹¤íŒ¨: %s", e)
        
        return None
    
    def validate_and_process_data(self, df: pd.DataFrame) -> bool:
        """ë°ì´í„° ìœ íš¨ì„± ê²€ì¦"""
        if df is None or df.empty:
            return False
        
        logger.info("ğŸ“Š ë°ì´í„° ê²€ì¦: %s (í–‰ x ì—´)", df.shape)
        logger.info("ğŸ” ì»¬ëŸ¼: %s", list(df.columns))
        logger.info("ğŸ“ˆ íƒ€ì…: %s", df.dtypes.to_dict())
        
        return True

class MLflowAgentExecutor(AgentExecutor):
    """MLflow Agent A2A Executor - ì„±ê³µí•œ íŒ¨í„´ ì ìš©"""
    
    def __init__(self):
        self.data_processor = PandasAIDataProcessor()
        # LLM ì¸ìŠ¤í„´ìŠ¤ ìƒì„± í›„ MLflowToolsAgentì— ì „ë‹¬
        try:
            from core.llm_factory import create_llm_instance
            llm = create_llm_instance()
            self.agent = MLflowToolsAgent(model=llm)
            logger.info("âœ… MLflowToolsAgent with LLM factory initialized")
        except Exception as e:
            logger.warning("LLM factory ì‹¤íŒ¨, ê¸°ë³¸ ì„¤ì • ì‚¬ìš©: %s", e)
            # í´ë°±: ê¸°ë³¸ LLM ì‚¬ìš©
            from langchain_ollama import ChatOllama
            llm = ChatOllama(model="gemma3:4b", base_url="http://localhost:11434")
            self.agent = MLflowToolsAgent(model=llm)
    
    async def execute(self, context: RequestContext, event_queue: EventQueue) -> None:
        """ì‹¤í–‰ ë©”ì„œë“œ - ì„±ê³µí•œ íŒ¨í„´ 100% ì ìš©"""
        # TaskUpdater ìƒì„± (ì„±ê³µí•œ íŒ¨í„´)
        task_updater = TaskUpdater(event_queue, context.task_id, context.context_id)
        
        try:
            # ì‘ì—… ì‹œì‘ ì•Œë¦¼
            await task_updater.update_status(
                TaskState.working,
                message=new_agent_text_message("ğŸ”¬ MLflow ì‹¤í—˜ ì¶”ì ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
            )
            
            # ë©”ì‹œì§€ ì¶”ì¶œ (ì„±ê³µí•œ íŒ¨í„´)
            user_message = ""
            for part in context.message.parts:
                if part.root.kind == "text":
                    user_message += part.root.text
            
            logger.info("ğŸ“ ì‚¬ìš©ì ìš”ì²­: %s...", user_message[:100])
            
            # ë°ì´í„° íŒŒì‹± ì‹œë„
            df = self.data_processor.parse_data_from_message(user_message)
            
            if df is not None and self.data_processor.validate_and_process_data(df):
                # ì‹¤ì œ MLflow ì—ì´ì „íŠ¸ ì²˜ë¦¬
                result = await self._process_with_mlflow_agent(df, user_message)
            else:
                # ë°ì´í„° ì—†ì´ MLflow ì§€ì¹¨ ì œê³µ
                result = await self._process_mlflow_guidance(user_message)
            
            # ì„±ê³µ ì™„ë£Œ
            await task_updater.update_status(
                TaskState.completed,
                message=new_agent_text_message(result)
            )
            
        except Exception as e:
            logger.error("MLflow Agent ì²˜ë¦¬ ì˜¤ë¥˜: %s", e)
            await task_updater.update_status(
                TaskState.failed,
                message=new_agent_text_message(f"âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            )
    
    async def _process_with_mlflow_agent(self, df: pd.DataFrame, user_instructions: str) -> str:
        """ì›ë³¸ MLflowToolsAgentë¡œ ì‹¤ì œ ì²˜ë¦¬"""
        try:
            logger.info("ğŸ”¬ ì›ë³¸ MLflowToolsAgent ì‹¤í–‰ ì¤‘...")
            
            # ì›ë³¸ ai-data-science-team ì—ì´ì „íŠ¸ í˜¸ì¶œ
            response = self.agent.invoke_agent(
                user_instructions=user_instructions,
                data_raw=df
            )
            
            if response and 'output' in response:
                result = f"""# ğŸ”¬ **MLflow ì‹¤í—˜ ì¶”ì  ì™„ë£Œ!**

## ğŸ“Š **ì²˜ë¦¬ëœ ë°ì´í„°**
- **ë°ì´í„° í¬ê¸°**: {df.shape[0]}í–‰ Ã— {df.shape[1]}ì—´
- **ì»¬ëŸ¼**: {', '.join(df.columns.tolist())}

## ğŸ¯ **MLflow ì²˜ë¦¬ ê²°ê³¼**
{str(response['output']).replace('{', '{{').replace('}', '}}')}

## ğŸ“ˆ **ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°**
```
{df.head().to_string()}
```

âœ… **MLflow ì‹¤í—˜ ì¶”ì ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!**
"""
                return result
            else:
                return self._generate_fallback_response(df, user_instructions)
                
        except Exception as e:
            logger.warning("MLflow ì—ì´ì „íŠ¸ í˜¸ì¶œ ì‹¤íŒ¨: %s", e)
            return self._generate_fallback_response(df, user_instructions)
    
    async def _process_mlflow_guidance(self, user_instructions: str) -> str:
        """ë°ì´í„° ì—†ì´ MLflow ì§€ì¹¨ ì œê³µ"""
        return f"""# ğŸ”¬ **MLflow ì‹¤í—˜ ì¶”ì  ê°€ì´ë“œ**

## ğŸ“ **ìš”ì²­ ë‚´ìš©**
{user_instructions.replace('{', '{{').replace('}', '}}')}

## ğŸ¯ **MLflow í™œìš© ë°©ë²•**

### 1. **ì‹¤í—˜ ì¶”ì  ê¸°ë³¸ ì„¤ì •**
```python
import mlflow
import mlflow.sklearn

# ì‹¤í—˜ ìƒì„±
mlflow.set_experiment("your_experiment_name")

# ì‹¤í–‰ ì‹œì‘
with mlflow.start_run():
    # íŒŒë¼ë¯¸í„° ë¡œê¹…
    mlflow.log_param("n_estimators", 100)
    mlflow.log_param("max_depth", 5)
    
    # ë©”íŠ¸ë¦­ ë¡œê¹…
    mlflow.log_metric("accuracy", 0.95)
    mlflow.log_metric("f1_score", 0.94)
    
    # ëª¨ë¸ ì €ì¥
    mlflow.sklearn.log_model(model, "model")
```

### 2. **ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬**
```python
# ëª¨ë¸ ë“±ë¡
mlflow.register_model("runs:/<run_id>/model", "YourModelName")

# ëª¨ë¸ ìŠ¤í…Œì´ì§€ ê´€ë¦¬
client = mlflow.tracking.MlflowClient()
client.transition_model_version_stage(
    name="YourModelName",
    version=1,
    stage="Production"
)
```

### 3. **ì‹¤í—˜ ë¹„êµ**
```python
# ì‹¤í—˜ ê²°ê³¼ ì¡°íšŒ
experiments = mlflow.search_runs(experiment_ids=["0"])
print(experiments[["params.n_estimators", "metrics.accuracy"]])
```

## ğŸ’¡ **ë°ì´í„°ë¥¼ í¬í•¨í•´ì„œ ë‹¤ì‹œ ìš”ì²­í•˜ë©´ ë” êµ¬ì²´ì ì¸ MLflow ì‹¤í—˜ ì¶”ì ì„ ë„ì™€ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤!**

**ë°ì´í„° í˜•ì‹ ì˜ˆì‹œ**:
- CSV: `name,age,score\\nJohn,25,85\\nJane,30,92`
- JSON: `[{{"name": "John", "age": 25, "score": 85}}]`
"""
    
    def _generate_fallback_response(self, df: pd.DataFrame, user_instructions: str) -> str:
        """í´ë°± ì‘ë‹µ ìƒì„±"""
        return f"""# ğŸ”¬ **MLflow ì‹¤í—˜ ì¶”ì  ì²˜ë¦¬ ì™„ë£Œ**

## ğŸ“Š **ë°ì´í„° ì •ë³´**
- **í¬ê¸°**: {df.shape[0]}í–‰ Ã— {df.shape[1]}ì—´
- **ì»¬ëŸ¼**: {', '.join(df.columns.tolist())}

## ğŸ¯ **ìš”ì²­ ì²˜ë¦¬**
{user_instructions.replace('{', '{{').replace('}', '}}')}

## ğŸ“ˆ **MLflow ì‹¤í—˜ ì¶”ì  ê²°ê³¼**
ë°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ë¶„ì„ë˜ì—ˆìŠµë‹ˆë‹¤. MLflowë¥¼ ì‚¬ìš©í•œ ì‹¤í—˜ ì¶”ì ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.

### ğŸ“Š **ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°**
```
{df.head().to_string()}
```

### ğŸ” **ê¸°ë³¸ í†µê³„**
```
{df.describe().to_string()}
```

âœ… **MLflow ê¸°ë°˜ ì‹¤í—˜ ì¶”ì ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!**
"""
    
    async def cancel(self, context: RequestContext, event_queue: EventQueue) -> None:
        """ì‘ì—… ì·¨ì†Œ - ì„±ê³µí•œ íŒ¨í„´"""
        task_updater = TaskUpdater(event_queue, context.task_id, context.context_id)
        await task_updater.reject()

def main():
    """ì„œë²„ ìƒì„± ë° ì‹¤í–‰ - ì„±ê³µí•œ íŒ¨í„´"""
    
    # AgentSkill ì •ì˜
    skill = AgentSkill(
        id="mlflow-experiment-tracking",
        name="MLflow Experiment Tracking & Model Management", 
        description="MLflowë¥¼ í™œìš©í•œ ì „ë¬¸ì ì¸ ë¨¸ì‹ ëŸ¬ë‹ ì‹¤í—˜ ì¶”ì , ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬, ì„±ëŠ¥ ë¹„êµ ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤.",
        tags=["mlflow", "experiment-tracking", "model-registry", "ml-ops", "versioning"],
        examples=[
            "ì‹¤í—˜ ê²°ê³¼ë¥¼ MLflowë¡œ ì¶”ì í•´ì£¼ì„¸ìš”",
            "ëª¨ë¸ ì„±ëŠ¥ì„ ê¸°ë¡í•˜ê³  ë¹„êµí•´ì£¼ì„¸ìš”", 
            "MLflow ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— ëª¨ë¸ì„ ë“±ë¡í•´ì£¼ì„¸ìš”",
            "ì—¬ëŸ¬ ì‹¤í—˜ì˜ ì„±ëŠ¥ì„ ë¹„êµ ë¶„ì„í•´ì£¼ì„¸ìš”",
            "ìµœì ì˜ ëª¨ë¸ì„ ì„ íƒí•´ì£¼ì„¸ìš”"
        ]
    )
    
    # Agent Card ì •ì˜
    agent_card = AgentCard(
        name="AI_DS_Team MLflowToolsAgent",
        description="MLflowë¥¼ í™œìš©í•œ ì „ë¬¸ì ì¸ ë¨¸ì‹ ëŸ¬ë‹ ì‹¤í—˜ ì¶”ì  ë° ëª¨ë¸ ê´€ë¦¬ ì„œë¹„ìŠ¤. ì‹¤í—˜ ì¶”ì , ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬, ë¹„êµ ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤.",
        url="http://localhost:8323/",
        version="1.0.0",
        defaultInputModes=["text"],
        defaultOutputModes=["text"],
        capabilities=AgentCapabilities(streaming=False),
        skills=[skill],
        supportsAuthenticatedExtendedCard=False
    )
    
    # Request Handler ìƒì„±
    request_handler = DefaultRequestHandler(
        agent_executor=MLflowAgentExecutor(),
        task_store=InMemoryTaskStore(),
    )
    
    # A2A Server ìƒì„±
    server = A2AStarletteApplication(
        agent_card=agent_card,
        http_handler=request_handler,
    )
    
    print("ğŸ”¬ Starting MLflow Tools Agent Server")
    print("ğŸŒ Server starting on http://localhost:8323")
    print("ğŸ“‹ Agent card: http://localhost:8323/.well-known/agent.json")
    print("ğŸ¯ Features: MLflow ì‹¤í—˜ ì¶”ì , ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬, ì„±ëŠ¥ ë¹„êµ")
    
    uvicorn.run(server.build(), host="0.0.0.0", port=8323, log_level="info")

if __name__ == "__main__":
    main() 