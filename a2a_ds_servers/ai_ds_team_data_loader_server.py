from a2a.utils import new_agent_text_message#!/usr/bin/env python3
"""
AI_DS_Team DataLoaderToolsAgent A2A Server
Port: 8307

AI_DS_Teamì˜ DataLoaderToolsAgentë¥¼ A2A í”„ë¡œí† ì½œë¡œ ë˜í•‘í•˜ì—¬ ì œê³µí•©ë‹ˆë‹¤.
ë‹¤ì–‘í•œ ë°ì´í„° ì†ŒìŠ¤ ë¡œë”© ë° ì „ì²˜ë¦¬ ì „ë¬¸
"""

import asyncio
import sys
import os
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / "ai_ds_team"))

from a2a.server.apps import A2AStarletteApplication
from a2a.server.request_handlers.default_request_handler import DefaultRequestHandler
from a2a.server.tasks.inmemory_task_store import InMemoryTaskStore
from a2a.server.tasks.task_updater import TaskUpdater
from a2a.server.agent_execution import AgentExecutor, RequestContext
from a2a.types import TextPart, TaskState, AgentCard, AgentSkill, AgentCapabilities
import uvicorn
import logging

# AI_DS_Team imports
from ai_data_science_team.tools.dataframe import get_dataframe_summary
from ai_data_science_team.agents import DataLoaderToolsAgent
import pandas as pd
import json
from core.data_manager import DataManager
from core.session_data_manager import SessionDataManager

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def get_dataframe_summary(df, n_sample=5):
    """ê°„ë‹¨í•œ ë°ì´í„°í”„ë ˆì„ ìš”ì•½ ìƒì„±"""
    try:
        summary = f"""
**Shape**: {df.shape[0]:,} rows Ã— {df.shape[1]:,} columns

**Columns**: {', '.join(df.columns.tolist())}

**Data Types**:
{df.dtypes.to_string()}

**Sample Data**:
{df.head(n_sample).to_string()}

**Missing Values**:
{df.isnull().sum().to_string()}
"""
        return [summary]
    except Exception as e:
        return [f"ë°ì´í„° ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}"]


class DataLoaderToolsAgentExecutor(AgentExecutor):
    """AI_DS_Team DataLoaderToolsAgentë¥¼ A2A í”„ë¡œí† ì½œë¡œ ë˜í•‘"""
    
    def __init__(self):
        # LLM ì„¤ì •
        from core.llm_factory import create_llm_instance
        self.llm = create_llm_instance()
        self.agent = DataLoaderToolsAgent(model=self.llm)
        logger.info("DataLoaderToolsAgent initialized")
    
    async def execute(self, context: RequestContext, event_queue) -> None:
        """A2A í”„ë¡œí† ì½œì— ë”°ë¥¸ ì‹¤í–‰"""
        # event_queue passed as parameter
        task_updater = TaskUpdater(event_queue, context.task_id, context.context_id)
        
        try:
            # ì‘ì—… ì‹œì‘
            await task_updater.submit()
            await task_updater.start_work()
            
            # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ì¶œ
            user_instructions = ""
            data_reference = None
            
            if context.message and context.message.parts:
                for part in context.message.parts:
                    if part.root.kind == "text":
                        user_instructions += part.root.text + " "
                    elif part.root.kind == "data" and hasattr(part.root, 'data'):
                        data_reference = part.root.data.get('data_reference', {})
                
                user_instructions = user_instructions.strip()
                logger.info(f"Processing data loading request: {user_instructions}")
                
                # DataManagerë¥¼ í†µí•œ ë°ì´í„° ê´€ë¦¬
                data_manager = DataManager()
                available_data_ids = data_manager.list_dataframes()
                
                response_text = ""
                
                # ìš”ì²­ëœ ë°ì´í„° í™•ì¸
                if data_reference and 'data_id' in data_reference:
                    requested_data_id = data_reference['data_id']
                    logger.info(f"Requested data: {requested_data_id}")
                    
                    if requested_data_id in available_data_ids:
                        # ìš”ì²­ëœ ë°ì´í„°ê°€ ì´ë¯¸ ë¡œë“œë˜ì–´ ìˆìŒ
                        df = data_manager.get_dataframe(requested_data_id)
                        if df is not None:
                            response_text = f"""## ğŸ“ ë°ì´í„° ë¡œë”© ì™„ë£Œ
âœ… ìš”ì²­í•˜ì‹  ë°ì´í„°ê°€ ì´ë¯¸ ë¡œë“œë˜ì–´ ìˆìŠµë‹ˆë‹¤.

**ìš”ì²­**: {user_instructions}

### ğŸ“Š ë¡œë“œëœ ë°ì´í„° ì •ë³´
- **ë°ì´í„° ID**: `{requested_data_id}`
- **ë°ì´í„° í¬ê¸°**: {df.shape[0]:,} í–‰ Ã— {df.shape[1]:,} ì—´
- **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰**: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB

### ğŸ“‹ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
```
{df.head().to_string()}
```

### ğŸ” ë°ì´í„° ì •ë³´
```
{df.info()}
```
"""
                        else:
                            response_text = f"""## âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨

ìš”ì²­í•˜ì‹  ë°ì´í„° '{requested_data_id}'ë¥¼ DataManagerì—ì„œ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.

**í•´ê²° ë°©ë²•**: 
1. UIì—ì„œ íŒŒì¼ì„ ë‹¤ì‹œ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”
2. ë‹¤ë¥¸ ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”
"""
                    else:
                        # ìš”ì²­ëœ ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš°
                        if available_data_ids:
                            response_text = f"""## âŒ ìš”ì²­ëœ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ

ìš”ì²­í•˜ì‹  ë°ì´í„° íŒŒì¼ '{requested_data_id}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.

### ğŸ“ ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°
{chr(10).join([f"- {data_id}" for data_id in available_data_ids])}

**í•´ê²° ë°©ë²•**:
1. ìœ„ì˜ ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„° ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ì—¬ ìš”ì²­í•˜ì„¸ìš”
2. ì›í•˜ëŠ” íŒŒì¼ì„ ë¨¼ì € ì—…ë¡œë“œí•´ì£¼ì„¸ìš”

**ìš”ì²­**: {user_instructions}
"""
                        else:
                            response_text = f"""## âŒ ë°ì´í„° ì—†ìŒ

ë°ì´í„° ë¡œë”©ì„ ìˆ˜í–‰í•˜ë ¤ë©´ ë¨¼ì € ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•´ì•¼ í•©ë‹ˆë‹¤.

**ìš”ì²­**: {user_instructions}

### ğŸ“¤ ë°ì´í„° ì—…ë¡œë“œ ë°©ë²•
1. **UIì—ì„œ íŒŒì¼ ì—…ë¡œë“œ**: ë©”ì¸ í˜ì´ì§€ì—ì„œ CSV, Excel íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”
2. **íŒŒì¼ëª… ëª…ì‹œ**: ìì—°ì–´ë¡œ "{requested_data_id} íŒŒì¼ë¡œ ë¶„ì„í•´ì¤˜"ì™€ ê°™ì´ ìš”ì²­í•˜ì„¸ìš”
3. **ì§€ì› í˜•ì‹**: CSV, Excel (.xlsx, .xls), JSON, Pickle

**í˜„ì¬ ìƒíƒœ**: ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.
"""
                else:
                    # ë°ì´í„° ì°¸ì¡°ê°€ ì—†ëŠ” ê²½ìš° - ì¼ë°˜ì ì¸ ë°ì´í„° ë¡œë”© ê°€ì´ë“œ
                    if available_data_ids:
                        # ì²« ë²ˆì§¸ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì§€ ë§ê³  ì‚¬ìš©ìì—ê²Œ ì„ íƒí•˜ë„ë¡ ì•ˆë‚´
                        response_text = f"""## ğŸ“ ë°ì´í„° ë¡œë”© ê°€ì´ë“œ

**ìš”ì²­**: {user_instructions}

### ğŸ“ ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°
{chr(10).join([f"- {data_id}" for data_id in available_data_ids])}

### ğŸ’¡ ë°ì´í„° ë¡œë”© ë°©ë²•
êµ¬ì²´ì ì¸ íŒŒì¼ëª…ì„ ëª…ì‹œí•˜ì—¬ ìš”ì²­í•´ì£¼ì„¸ìš”:

**ì˜ˆì‹œ**:
- "sales_data.csv íŒŒì¼ì„ ë¡œë“œí•´ì£¼ì„¸ìš”"
- "employee_data.csvë¡œ ë¶„ì„ì„ ì‹œì‘í•´ì£¼ì„¸ìš”"

### ğŸ› ï¸ Data Loader Tools ê¸°ëŠ¥
- **íŒŒì¼ ë¡œë”©**: CSV, Excel, JSON, Parquet ë“± ë‹¤ì–‘í•œ í˜•ì‹ ì§€ì›
- **ë°ì´í„° ê²€ì¦**: ë¡œë“œëœ ë°ì´í„°ì˜ í’ˆì§ˆ ë° í˜•ì‹ ê²€ì¦
- **ìë™ íƒ€ì… ì¶”ë¡ **: ì»¬ëŸ¼ íƒ€ì… ìë™ ê°ì§€ ë° ë³€í™˜
"""
                    else:
                        response_text = f"""## ğŸ“ ë°ì´í„° ë¡œë”© ê°€ì´ë“œ

**ìš”ì²­**: {user_instructions}

### âŒ ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤

### ğŸ“¤ ë°ì´í„° ì—…ë¡œë“œ ë°©ë²•
1. **UIì—ì„œ íŒŒì¼ ì—…ë¡œë“œ**: ë©”ì¸ í˜ì´ì§€ì—ì„œ CSV, Excel íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”
2. **íŒŒì¼ëª… ëª…ì‹œ**: ìì—°ì–´ë¡œ "data.xlsx íŒŒì¼ì„ ë¡œë“œí•´ì¤˜"ì™€ ê°™ì´ ìš”ì²­í•˜ì„¸ìš”
3. **ì§€ì› í˜•ì‹**: CSV, Excel (.xlsx, .xls), JSON, Pickle

### ğŸ› ï¸ Data Loader Tools ê¸°ëŠ¥
- **íŒŒì¼ ë¡œë”©**: CSV, Excel, JSON, Parquet ë“± ë‹¤ì–‘í•œ í˜•ì‹ ì§€ì›
- **ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°**: SQL ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ë° ì¿¼ë¦¬
- **API í†µí•©**: REST APIë¥¼ í†µí•œ ë°ì´í„° ìˆ˜ì§‘
- **ë°ì´í„° ê²€ì¦**: ë¡œë“œëœ ë°ì´í„°ì˜ í’ˆì§ˆ ë° í˜•ì‹ ê²€ì¦
- **ìë™ íƒ€ì… ì¶”ë¡ **: ì»¬ëŸ¼ íƒ€ì… ìë™ ê°ì§€ ë° ë³€í™˜
"""
                
                # ì‘ì—… ì™„ë£Œ
                await task_updater.update_status(
                    TaskState.completed,
                    message=new_agent_text_message(response_text)
                )
                
            else:
                # ë©”ì‹œì§€ê°€ ì—†ëŠ” ê²½ìš°
                await task_updater.update_status(
                    TaskState.completed,
                    message=new_agent_text_message("ë°ì´í„° ë¡œë”© ìš”ì²­ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ë¡œë“œí•  ë°ì´í„° íŒŒì¼ì´ë‚˜ ì†ŒìŠ¤ë¥¼ ì§€ì •í•´ì£¼ì„¸ìš”.")
                )
                
        except Exception as e:
            logger.error(f"Error in DataLoaderToolsAgent execution: {e}")
            await task_updater.update_status(
                TaskState.failed,
                message=new_agent_text_message(f"ë°ì´í„° ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            )
    
    async def cancel(self, context: RequestContext) -> None:
        """ì‘ì—… ì·¨ì†Œ"""
        logger.info(f"DataLoaderToolsAgent task cancelled: {context.task_id}")


def main():
    """A2A ì„œë²„ ìƒì„± ë° ì‹¤í–‰"""
    
    # AgentSkill ì •ì˜
    skill = AgentSkill(
        id="data_loading",
        name="Data Loading & File Processing",
        description="ë‹¤ì–‘í•œ ë°ì´í„° ì†ŒìŠ¤ ë¡œë”© ë° ì „ì²˜ë¦¬ ì „ë¬¸ê°€. íŒŒì¼, ë°ì´í„°ë² ì´ìŠ¤, API ë“±ì—ì„œ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  DataFrameìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.",
        tags=["data-loading", "etl", "file-processing", "database", "api-integration"],
        examples=[
            "CSV íŒŒì¼ì„ ë¡œë“œí•´ì£¼ì„¸ìš”",
            "ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê³ ê° í…Œì´ë¸”ì„ ê°€ì ¸ì™€ì£¼ì„¸ìš”",
            "APIì—ì„œ ì‹¤ì‹œê°„ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•´ì£¼ì„¸ìš”",
            "Excel íŒŒì¼ì˜ íŠ¹ì • ì‹œíŠ¸ë¥¼ ì½ì–´ì£¼ì„¸ìš”",
            "ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„° íŒŒì¼ë“¤ì„ ë³´ì—¬ì£¼ì„¸ìš”"
        ]
    )
    
    # Agent Card ì •ì˜
    agent_card = AgentCard(
        name="AI_DS_Team DataLoaderToolsAgent",
        description="ë‹¤ì–‘í•œ ë°ì´í„° ì†ŒìŠ¤ ë¡œë”© ë° ì „ì²˜ë¦¬ ì „ë¬¸ê°€. íŒŒì¼, ë°ì´í„°ë² ì´ìŠ¤, API ë“±ì—ì„œ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  DataFrameìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.",
        url="http://localhost:8307/",
        version="1.0.0",
        defaultInputModes=["text"],
        defaultOutputModes=["text"],
        capabilities=AgentCapabilities(streaming=False),
        skills=[skill],
        supportsAuthenticatedExtendedCard=False
    )
    
    # Request Handler ìƒì„±
    request_handler = DefaultRequestHandler(
        agent_executor=DataLoaderToolsAgentExecutor(),
        task_store=InMemoryTaskStore(),
    )
    
    # A2A Server ìƒì„±
    server = A2AStarletteApplication(
        agent_card=agent_card,
        http_handler=request_handler,
    )
    
    print("ğŸ“ Starting AI_DS_Team DataLoaderToolsAgent Server")
    print("ğŸŒ Server starting on http://localhost:8307")
    print("ğŸ“‹ Agent card: http://localhost:8307/.well-known/agent.json")
    print("ğŸ› ï¸ Features: Data loading, file processing, database integration")
    
    uvicorn.run(server.build(), host="0.0.0.0", port=8307, log_level="info")


if __name__ == "__main__":
    main() 