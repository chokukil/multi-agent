#!/usr/bin/env python3
"""
ğŸ” Enhanced AI_DS_Team EDA Tools Server v2 with Smart Fallback
Port: 8312

ì´ ì„œë²„ëŠ” ë‹¤ìŒ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤:
- AI-Data-Science-Team EDAToolsAgent ë‚´ë¶€ ì²˜ë¦¬ ê³¼ì • ì™„ì „ ì¶”ì 
- AI-DS-Teamì´ Noneì„ ë°˜í™˜í•˜ëŠ” ê²½ìš° ì§€ëŠ¥í˜• ëŒ€ì²´ ë¶„ì„ ì œê³µ
- LLM ê¸°ë°˜ EDA ë¶„ì„ ë° ì‹œê°í™” ìƒì„±
- Langfuse ì„¸ì…˜ ê¸°ë°˜ ê³„ì¸µì  ì¶”ì 
"""

import asyncio
import sys
import os
import time
import traceback
import json
import numpy as np
import pandas as pd
from pathlib import Path
from typing import Dict, Any, Optional

# matplotlib í•œê¸€ í°íŠ¸ ì„¤ì • (ë§¨ ì²˜ìŒì— ì„¤ì •)
try:
    import matplotlib.pyplot as plt
    import matplotlib.font_manager as fm
    import platform
    
    # macOSì—ì„œ ìµœì  í•œê¸€ í°íŠ¸ ì„¤ì •
    if platform.system() == 'Darwin':  # macOS
        available_fonts = [f.name for f in fm.fontManager.ttflist]
        korean_fonts = ['Apple SD Gothic Neo', 'AppleGothic']
        
        selected_font = None
        for font in korean_fonts:
            if font in available_fonts:
                selected_font = font
                break
        
        if selected_font:
            plt.rcParams['font.family'] = selected_font
            plt.rcParams['axes.unicode_minus'] = False
            print(f"âœ… matplotlib í•œê¸€ í°íŠ¸ ì„¤ì •: {selected_font}")
        else:
            plt.rcParams['font.family'] = ['Arial Unicode MS']
            print("âš ï¸ ê¸°ë³¸ ìœ ë‹ˆì½”ë“œ í°íŠ¸ ì‚¬ìš©")
    else:
        # ë‹¤ë¥¸ OSëŠ” ê¸°ë³¸ ì„¤ì • ì‚¬ìš©
        plt.rcParams['axes.unicode_minus'] = False
        
except ImportError:
    print("âš ï¸ matplotlibë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / "ai_ds_team"))

from a2a.server.apps import A2AStarletteApplication
from a2a.server.request_handlers.default_request_handler import DefaultRequestHandler
from a2a.server.tasks.inmemory_task_store import InMemoryTaskStore
from a2a.server.tasks.task_updater import TaskUpdater
from a2a.server.agent_execution import AgentExecutor, RequestContext
from a2a.types import TextPart, TaskState, AgentCard, AgentSkill, AgentCapabilities
from a2a.utils import new_agent_text_message
import uvicorn
import logging

# AI_DS_Team imports
from ai_data_science_team.ds_agents import EDAToolsAgent

# CherryAI Enhanced tracking imports
from core.data_manager import DataManager
from core.session_data_manager import SessionDataManager

try:
    from core.langfuse_session_tracer import get_session_tracer
    from core.langfuse_ai_ds_team_wrapper import LangfuseAIDataScienceTeamWrapper
    ENHANCED_TRACKING_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ Enhanced tracking not available: {e}")
    ENHANCED_TRACKING_AVAILABLE = False

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# .env íŒŒì¼ì—ì„œ ë¡œê¹… ì„¤ì • ë¡œë“œ
from dotenv import load_dotenv
load_dotenv()

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
data_manager = DataManager()
session_data_manager = SessionDataManager()


class SmartEDAAnalyzer:
    """AI-DS-Teamì´ ì‹¤íŒ¨í•  ë•Œ ì‚¬ìš©í•˜ëŠ” ì§€ëŠ¥í˜• EDA ë¶„ì„ê¸°"""
    
    def __init__(self, llm):
        self.llm = llm
        # matplotlib ì„¤ì • í™•ì¸
        try:
            current_font = plt.rcParams['font.family']
            print(f"ğŸ“Š SmartEDAAnalyzer ì´ˆê¸°í™” - ì‚¬ìš© í°íŠ¸: {current_font}")
        except:
            print("âš ï¸ matplotlib í°íŠ¸ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    
    def generate_comprehensive_eda(self, df: pd.DataFrame, user_instructions: str) -> Dict[str, Any]:
        """í¬ê´„ì ì¸ EDA ë¶„ì„ ìƒì„±"""
        try:
            # 1. ê¸°ë³¸ ë°ì´í„° ì •ë³´
            basic_info = self._get_basic_info(df)
            
            # 2. í†µê³„ì  ë¶„ì„
            statistical_analysis = self._get_statistical_analysis(df)
            
            # 3. ë°ì´í„° í’ˆì§ˆ ë¶„ì„
            quality_analysis = self._get_quality_analysis(df)
            
            # 4. ì‹œê°í™” ìƒì„± (í•œê¸€ í°íŠ¸ ì ìš©)
            visualization_info = self._generate_visualizations(df)
            
            # 5. LLMì„ í†µí•œ ì¸ì‚¬ì´íŠ¸ ìƒì„±
            llm_insights = self._generate_llm_insights(df, user_instructions, basic_info, statistical_analysis)
            
            # 6. ê¶Œì¥ì‚¬í•­ ìƒì„±
            recommendations = self._generate_recommendations(df, basic_info, quality_analysis)
            
            return {
                "success": True,
                "basic_info": basic_info,
                "statistical_analysis": statistical_analysis,
                "quality_analysis": quality_analysis,
                "visualization_info": visualization_info,
                "llm_insights": llm_insights,
                "recommendations": recommendations,
                "analysis_method": "Smart EDA Analyzer (AI-DS-Team Fallback)"
            }
            
        except Exception as e:
            logger.error(f"Smart EDA Analyzer failed: {e}")
            return {
                "success": False,
                "error": str(e),
                "analysis_method": "Smart EDA Analyzer (Failed)"
            }
    
    def _get_basic_info(self, df: pd.DataFrame) -> Dict[str, Any]:
        """ê¸°ë³¸ ë°ì´í„° ì •ë³´ ìˆ˜ì§‘"""
        return {
            "shape": df.shape,
            "columns": list(df.columns),
            "dtypes": dict(df.dtypes.astype(str)),
            "memory_usage": f"{df.memory_usage(deep=True).sum() / 1024:.2f} KB",
            "sample_data": df.head(3).to_dict('records')
        }
    
    def _get_statistical_analysis(self, df: pd.DataFrame) -> Dict[str, Any]:
        """í†µê³„ì  ë¶„ì„"""
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()
        
        analysis = {
            "numeric_columns": numeric_cols,
            "categorical_columns": categorical_cols,
            "numeric_stats": {},
            "categorical_stats": {}
        }
        
        # ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ í†µê³„
        if numeric_cols:
            analysis["numeric_stats"] = df[numeric_cols].describe().to_dict()
            
            # ìƒê´€ê´€ê³„ ë¶„ì„
            if len(numeric_cols) > 1:
                corr_matrix = df[numeric_cols].corr()
                # ê°•í•œ ìƒê´€ê´€ê³„ ì°¾ê¸°
                strong_correlations = []
                for i in range(len(corr_matrix.columns)):
                    for j in range(i+1, len(corr_matrix.columns)):
                        corr_val = corr_matrix.iloc[i, j]
                        if abs(corr_val) > 0.5:
                            strong_correlations.append({
                                "var1": corr_matrix.columns[i],
                                "var2": corr_matrix.columns[j],
                                "correlation": round(corr_val, 3)
                            })
                analysis["strong_correlations"] = strong_correlations
        
        # ë²”ì£¼í˜• ì»¬ëŸ¼ í†µê³„
        if categorical_cols:
            for col in categorical_cols[:5]:  # ì²˜ìŒ 5ê°œë§Œ
                value_counts = df[col].value_counts().head(10)
                analysis["categorical_stats"][col] = {
                    "unique_count": df[col].nunique(),
                    "top_values": value_counts.to_dict()
                }
        
        return analysis
    
    def _get_quality_analysis(self, df: pd.DataFrame) -> Dict[str, Any]:
        """ë°ì´í„° í’ˆì§ˆ ë¶„ì„"""
        total_rows = len(df)
        
        quality = {
            "missing_values": {},
            "duplicate_rows": df.duplicated().sum(),
            "data_quality_score": 0
        }
        
        # ê²°ì¸¡ê°’ ë¶„ì„
        missing_counts = df.isnull().sum()
        for col in df.columns:
            missing_count = missing_counts[col]
            if missing_count > 0:
                quality["missing_values"][col] = {
                    "count": int(missing_count),
                    "percentage": round((missing_count / total_rows) * 100, 2)
                }
        
        # ë°ì´í„° í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±)
        missing_percentage = (df.isnull().sum().sum() / (total_rows * len(df.columns))) * 100
        duplicate_percentage = (quality["duplicate_rows"] / total_rows) * 100
        
        quality_score = max(0, 100 - missing_percentage - duplicate_percentage)
        quality["data_quality_score"] = round(quality_score, 1)
        
        return quality
    
    def _generate_visualizations(self, df: pd.DataFrame) -> Dict[str, Any]:
        """ì‹œê°í™” ì •ë³´ ìƒì„± (í•œê¸€ í°íŠ¸ ì ìš©)"""
        viz_info = {
            "charts_generated": 0,
            "chart_types": [],
            "font_used": plt.rcParams['font.family']
        }
        
        try:
            numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
            categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()
            
            # íˆìŠ¤í† ê·¸ë¨ ì •ë³´
            if numeric_cols:
                viz_info["chart_types"].append("íˆìŠ¤í† ê·¸ë¨")
                viz_info["histogram_columns"] = numeric_cols[:5]  # ì²˜ìŒ 5ê°œ ì»¬ëŸ¼
                viz_info["charts_generated"] += len(numeric_cols[:5])
            
            # ë§‰ëŒ€ê·¸ë˜í”„ ì •ë³´
            if categorical_cols:
                viz_info["chart_types"].append("ë§‰ëŒ€ê·¸ë˜í”„")
                viz_info["bar_chart_columns"] = categorical_cols[:3]  # ì²˜ìŒ 3ê°œ ì»¬ëŸ¼
                viz_info["charts_generated"] += len(categorical_cols[:3])
            
            # ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ ì •ë³´
            if len(numeric_cols) > 1:
                viz_info["chart_types"].append("ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ")
                viz_info["correlation_matrix_size"] = f"{len(numeric_cols)}x{len(numeric_cols)}"
                viz_info["charts_generated"] += 1
            
            viz_info["korean_font_ready"] = True
            viz_info["visualization_note"] = f"í•œê¸€ í°íŠ¸ ({plt.rcParams['font.family']}) ì ìš©ìœ¼ë¡œ í•œê¸€ ì œëª©/ë ˆì´ë¸” í‘œì‹œ ê°€ëŠ¥"
            
        except Exception as e:
            viz_info["error"] = str(e)
            viz_info["korean_font_ready"] = False
        
        return viz_info
    
    def _generate_llm_insights(self, df: pd.DataFrame, user_instructions: str, 
                             basic_info: Dict, statistical_analysis: Dict) -> str:
        """LLMì„ í†µí•œ ë°ì´í„° ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        try:
            prompt = f"""ë°ì´í„° ê³¼í•™ìë¡œì„œ ë‹¤ìŒ ë°ì´í„°ì— ëŒ€í•œ ì „ë¬¸ì ì¸ íƒìƒ‰ì  ë°ì´í„° ë¶„ì„ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”:

## ë°ì´í„° ì •ë³´
- í¬ê¸°: {basic_info['shape'][0]:,}í–‰ Ã— {basic_info['shape'][1]:,}ì—´
- ì»¬ëŸ¼: {', '.join(basic_info['columns'][:10])}{'...' if len(basic_info['columns']) > 10 else ''}
- ìˆ˜ì¹˜í˜• ë³€ìˆ˜: {len(statistical_analysis['numeric_columns'])}ê°œ
- ë²”ì£¼í˜• ë³€ìˆ˜: {len(statistical_analysis['categorical_columns'])}ê°œ

## ì‚¬ìš©ì ìš”ì²­
{user_instructions}

## ë¶„ì„ ê²°ê³¼ ìš”ì•½
- ê°•í•œ ìƒê´€ê´€ê³„: {len(statistical_analysis.get('strong_correlations', []))}ê°œ ë°œê²¬
- ê²°ì¸¡ê°’ íŒ¨í„´: {"ìˆìŒ" if any(df.isnull().any()) else "ì—†ìŒ"}
- ì¤‘ë³µ ë°ì´í„°: {df.duplicated().sum()}ê°œ

ë‹¤ìŒ í˜•íƒœë¡œ ë¶„ì„ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”:

### ğŸ“Š ì£¼ìš” ë°œê²¬ì‚¬í•­
- [í•µì‹¬ íŒ¨í„´ì´ë‚˜ íŠ¹ì´ì‚¬í•­]

### ğŸ” ìƒì„¸ ë¶„ì„
- [ìˆ˜ì¹˜í˜• ë³€ìˆ˜ë“¤ì˜ ë¶„í¬ íŠ¹ì„±]
- [ë²”ì£¼í˜• ë³€ìˆ˜ë“¤ì˜ ë¶„í¬ íŠ¹ì„±]
- [ë³€ìˆ˜ ê°„ ê´€ê³„ ë¶„ì„]

### ğŸ’¡ ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸
- [ì‹¤ë¬´ì  ê´€ì ì—ì„œì˜ í•´ì„]
- [ì£¼ëª©í•  ë§Œí•œ íŒ¨í„´]

### âš ï¸ ë°ì´í„° í’ˆì§ˆ ì´ìŠˆ
- [ë°œê²¬ëœ í’ˆì§ˆ ë¬¸ì œ]
- [ê°œì„  ê¶Œì¥ì‚¬í•­]

ì „ë¬¸ì ì´ê³  ì‹¤ìš©ì ì¸ ê´€ì ì—ì„œ ë¶„ì„í•´ì£¼ì„¸ìš”."""

            if self.llm:
                response = self.llm.invoke(prompt)
                if hasattr(response, 'content'):
                    return response.content
                return str(response)
            else:
                return "LLMì„ ì‚¬ìš©í•  ìˆ˜ ì—†ì–´ ìë™ ì¸ì‚¬ì´íŠ¸ ìƒì„±ì„ ê±´ë„ˆëœë‹ˆë‹¤."
                
        except Exception as e:
            logger.error(f"LLM insights generation failed: {e}")
            return f"ì¸ì‚¬ì´íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
    
    def _generate_recommendations(self, df: pd.DataFrame, basic_info: Dict, 
                                quality_analysis: Dict) -> list:
        """ë¶„ì„ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        # ë°ì´í„° í¬ê¸° ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
        if basic_info['shape'][0] < 100:
            recommendations.append("âš ï¸ ë°ì´í„° í¬ê¸°ê°€ ì‘ìŠµë‹ˆë‹¤. ë” ë§ì€ ë°ì´í„° ìˆ˜ì§‘ì„ ê³ ë ¤í•´ë³´ì„¸ìš”.")
        
        # ê²°ì¸¡ê°’ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
        if quality_analysis['missing_values']:
            high_missing_cols = [col for col, info in quality_analysis['missing_values'].items() 
                               if info['percentage'] > 50]
            if high_missing_cols:
                recommendations.append(f"ğŸ” ë‹¤ìŒ ì»¬ëŸ¼ë“¤ì˜ ê²°ì¸¡ê°’ ë¹„ìœ¨ì´ 50% ì´ìƒì…ë‹ˆë‹¤: {', '.join(high_missing_cols)}")
        
        # ì¤‘ë³µ ë°ì´í„° ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
        if quality_analysis['duplicate_rows'] > 0:
            recommendations.append(f"ğŸ”„ {quality_analysis['duplicate_rows']}ê°œì˜ ì¤‘ë³µ í–‰ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. ì œê±°ë¥¼ ê³ ë ¤í•´ë³´ì„¸ìš”.")
        
        # ë°ì´í„° í’ˆì§ˆ ì ìˆ˜ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
        if quality_analysis['data_quality_score'] < 80:
            recommendations.append(f"ğŸ“Š ë°ì´í„° í’ˆì§ˆ ì ìˆ˜: {quality_analysis['data_quality_score']}/100. ë°ì´í„° ì „ì²˜ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        
        # ê¸°ë³¸ ê¶Œì¥ì‚¬í•­
        recommendations.extend([
            "ğŸ“ˆ ìˆ˜ì¹˜í˜• ë³€ìˆ˜ë“¤ì˜ ë¶„í¬ë¥¼ íˆìŠ¤í† ê·¸ë¨ìœ¼ë¡œ í™•ì¸í•´ë³´ì„¸ìš”.",
            "ğŸ”— ì£¼ìš” ë³€ìˆ˜ë“¤ ê°„ì˜ ì‚°ì ë„ë¥¼ ê·¸ë ¤ ê´€ê³„ë¥¼ ì‹œê°í™”í•´ë³´ì„¸ìš”.",
            "ğŸ“Š ë²”ì£¼í˜• ë³€ìˆ˜ë“¤ì˜ ë¹ˆë„ë¥¼ ë§‰ëŒ€ê·¸ë˜í”„ë¡œ í™•ì¸í•´ë³´ì„¸ìš”."
        ])
        
        return recommendations


class EnhancedEDAToolsAgentExecutorV2(AgentExecutor):
    """Enhanced EDA Tools Agent v2 with Smart Fallback"""
    
    def __init__(self):
        # LLM ì„¤ì •
        from core.llm_factory import create_llm_instance
        self.llm = create_llm_instance()
        
        # AI-Data-Science-Team ì—ì´ì „íŠ¸ ì´ˆê¸°í™”
        self.agent = EDAToolsAgent(model=self.llm)
        
        # Smart EDA Analyzer ì´ˆê¸°í™”
        self.smart_analyzer = SmartEDAAnalyzer(self.llm)
        
        # Enhanced tracking wrapper
        self.tracking_wrapper = None
        if ENHANCED_TRACKING_AVAILABLE:
            session_tracer = get_session_tracer()
            if session_tracer and hasattr(session_tracer, 'trace_client') and session_tracer.trace_client:
                self.tracking_wrapper = LangfuseAIDataScienceTeamWrapper(
                    session_tracer, 
                    "Enhanced EDA Tools Agent v2"
                )
                logger.info("âœ… Enhanced tracking wrapper v2 initialized")
            else:
                logger.warning("âš ï¸ Session tracer not available or incomplete")
                self.tracking_wrapper = None
        else:
            logger.warning("âš ï¸ Enhanced tracking not available")
        
        logger.info("ğŸ” Enhanced EDA Tools Agent v2 initialized with smart fallback")
    
    def extract_data_reference_from_message(self, context: RequestContext) -> Dict[str, Any]:
        """A2A ë©”ì‹œì§€ì—ì„œ ë°ì´í„° ì°¸ì¡° ì •ë³´ ì¶”ì¶œ"""
        data_reference = None
        user_instructions = ""
        
        if context.message and context.message.parts:
            for part in context.message.parts:
                if hasattr(part, 'text'):
                    user_instructions += part['text'] + " "
                elif hasattr(part, 'root'):
                    if hasattr(part.root, 'text'):
                        user_instructions += part.root.text + " "
                    elif hasattr(part.root, 'data') and 'data_reference' in part.root.data:
                        data_reference = part.root.data['data_reference']
        
        return {
            "user_instructions": user_instructions.strip(),
            "data_reference": data_reference
        }
    
    async def execute_enhanced_eda_v2(self, user_instructions: str, df: pd.DataFrame, 
                                    data_source: str, session_id: str, task_updater: TaskUpdater):
        """Enhanced tracking v2ë¥¼ ì ìš©í•œ EDA ì‹¤í–‰"""
        
        logger.info("ğŸ” Starting Enhanced EDA v2 with smart fallback...")
        
        # ë©”ì¸ agent span ìƒì„±
        operation_data = {
            "operation": "enhanced_eda_analysis_v2",
            "user_request": user_instructions,
            "data_source": data_source,
            "data_shape": df.shape,
            "session_id": session_id
        }
        
        main_span = None
        if self.tracking_wrapper:
            main_span = self.tracking_wrapper.create_agent_span("Enhanced EDA Analysis v2", operation_data)
        
        try:
            # 1. ì›Œí¬í”Œë¡œìš° ì‹œì‘ ì¶”ì 
            if self.tracking_wrapper:
                self.tracking_wrapper.trace_ai_ds_workflow_start("eda_analysis_v2", operation_data)
            
            # 2. ë°ì´í„° ë¶„ì„ ë‹¨ê³„
            await task_updater.update_status(
                TaskState.working,
                message=new_agent_text_message("ğŸ” ë°ì´í„° êµ¬ì¡° ë¶„ì„ ì¤‘...")
            )
            
            data_summary = f"""EDA v2 ë°ì´í„° ë¶„ì„:
- ë°ì´í„° ì†ŒìŠ¤: {data_source}
- í˜•íƒœ: {df.shape[0]:,} í–‰ Ã— {df.shape[1]:,} ì—´
- ì»¬ëŸ¼: {list(df.columns)}
- ë°ì´í„° íƒ€ì…: {dict(df.dtypes)}
- ê²°ì¸¡ê°’: {dict(df.isnull().sum())}
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {df.memory_usage(deep=True).sum() / 1024:.2f} KB
"""
            
            if self.tracking_wrapper:
                self.tracking_wrapper.trace_data_analysis_step(data_summary, "initial_data_inspection_v2")
            
            # 3. AI-DS-Team ì—ì´ì „íŠ¸ ì‹œë„
            await task_updater.update_status(
                TaskState.working,
                message=new_agent_text_message("âš¡ AI-Data-Science-Team EDA ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¤‘...")
            )
            
            ai_ds_result = None
            ai_ds_execution_time = 0
            
            try:
                start_time = time.time()
                ai_ds_result = self.agent.invoke_agent(
                    user_instructions=user_instructions,
                    data_raw=df
                )
                ai_ds_execution_time = time.time() - start_time
                
                logger.info(f"AI-DS-Team result: {type(ai_ds_result)} = {ai_ds_result}")
                
            except Exception as ai_ds_error:
                logger.error(f"AI-DS-Team agent failed: {ai_ds_error}")
                ai_ds_result = None
            
            # 4. Smart Fallback ë¶„ì„ ì‹¤í–‰
            await task_updater.update_status(
                TaskState.working,
                message=new_agent_text_message("ğŸ§  Smart EDA ë¶„ì„ ì‹¤í–‰ ì¤‘...")
            )
            
            smart_start_time = time.time()
            smart_result = self.smart_analyzer.generate_comprehensive_eda(df, user_instructions)
            smart_execution_time = time.time() - smart_start_time
            
            # 5. ê²°ê³¼ í†µí•© ë° ì¶”ì 
            if self.tracking_wrapper:
                # AI-DS-Team ê²°ê³¼ ì¶”ì 
                ai_ds_code = f"""# AI-Data-Science-Team EDA ì‹¤í–‰
eda_agent = EDAToolsAgent(model=llm)
result = eda_agent.invoke_agent(
    user_instructions="{user_instructions[:100]}...",
    data_raw=data_frame  # shape: {df.shape}
)
# Result: {type(ai_ds_result).__name__}"""
                
                self.tracking_wrapper.trace_code_execution_step(
                    ai_ds_code,
                    {"ai_ds_result": str(ai_ds_result), "execution_time": ai_ds_execution_time},
                    ai_ds_execution_time
                )
                
                # Smart Analyzer ê²°ê³¼ ì¶”ì 
                smart_code = f"""# Smart EDA Analyzer (Fallback)
smart_analyzer = SmartEDAAnalyzer(llm)
smart_result = smart_analyzer.generate_comprehensive_eda(
    df=data_frame,  # shape: {df.shape}
    user_instructions="{user_instructions[:100]}..."
)
# Generated: {len(str(smart_result))} characters of analysis"""
                
                self.tracking_wrapper.trace_code_execution_step(
                    smart_code,
                    smart_result,
                    smart_execution_time
                )
            
            # 6. ìµœì¢… ê²°ê³¼ ìƒì„±
            await task_updater.update_status(
                TaskState.working,
                message=new_agent_text_message("ğŸ“Š ë¶„ì„ ê²°ê³¼ ìƒì„± ì¤‘...")
            )
            
            # ê²°ê³¼ í†µí•©
            final_result = self._create_final_response(
                ai_ds_result, smart_result, df, data_source, session_id,
                ai_ds_execution_time, smart_execution_time, user_instructions
            )
            
            # ì›Œí¬í”Œë¡œìš° ì™„ë£Œ ì¶”ì 
            if self.tracking_wrapper:
                workflow_summary = f"""# Enhanced EDA v2 ì›Œí¬í”Œë¡œìš° ì™„ë£Œ

## ì²˜ë¦¬ ìš”ì•½
- **ìš”ì²­**: {user_instructions}
- **AI-DS-Team ê²°ê³¼**: {"ì„±ê³µ" if ai_ds_result else "ì‹¤íŒ¨ (None)"}
- **Smart Analyzer ê²°ê³¼**: {"ì„±ê³µ" if smart_result.get('success') else "ì‹¤íŒ¨"}
- **ì´ ì‹¤í–‰ ì‹œê°„**: {ai_ds_execution_time + smart_execution_time:.2f}ì´ˆ

## ë°ì´í„° ì •ë³´
- **ì†ŒìŠ¤**: {data_source}
- **í˜•íƒœ**: {df.shape[0]:,} í–‰ Ã— {df.shape[1]:,} ì—´
- **ì„¸ì…˜**: {session_id}

## Enhanced Tracking v2 ê²°ê³¼
- âœ… ë°ì´í„° êµ¬ì¡° ë¶„ì„ ì™„ë£Œ
- âœ… AI-DS-Team ì—ì´ì „íŠ¸ ì‹¤í–‰ ì™„ë£Œ (ê²°ê³¼: {type(ai_ds_result).__name__})
- âœ… Smart Fallback ë¶„ì„ ì™„ë£Œ
- âœ… ê²°ê³¼ í†µí•© ë° ì¶”ì  ì™„ë£Œ
"""
                
                self.tracking_wrapper.trace_workflow_completion(final_result, workflow_summary)
            
            return final_result
            
        except Exception as e:
            logger.error(f"Enhanced EDA v2 execution failed: {e}")
            logger.error(f"Traceback: {traceback.format_exc()}")
            return f"Enhanced EDA v2 ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        
        finally:
            # Agent span ì™„ë£Œ
            if main_span and self.tracking_wrapper:
                self.tracking_wrapper.finalize_agent_span(
                    final_result="Enhanced EDA v2 analysis completed",
                    success=True
                )
    
    def _create_final_response(self, ai_ds_result, smart_result, df, data_source, 
                             session_id, ai_ds_time, smart_time, user_instructions):
        """ìµœì¢… ì‘ë‹µ ìƒì„±"""
        
        # Smart Analyzer ê²°ê³¼ í¬ë§·íŒ…
        if smart_result.get('success'):
            basic_info = smart_result['basic_info']
            statistical_analysis = smart_result['statistical_analysis']
            quality_analysis = smart_result['quality_analysis']
            llm_insights = smart_result['llm_insights']
            recommendations = smart_result['recommendations']
            
            response = f"""## ğŸ” Enhanced EDA ë¶„ì„ ì™„ë£Œ (v2)

âœ… **ì„¸ì…˜ ID**: {session_id}
âœ… **ë°ì´í„° ì†ŒìŠ¤**: {data_source}  
âœ… **ë°ì´í„° í˜•íƒœ**: {df.shape[0]:,} í–‰ Ã— {df.shape[1]:,} ì—´
âœ… **ë¶„ì„ ë°©ë²•**: Hybrid (AI-DS-Team + Smart Analyzer)

### ğŸ“Š ë¶„ì„ ì‹¤í–‰ ê²°ê³¼

**AI-Data-Science-Team**: {"âœ… ì •ìƒ ì‹¤í–‰" if ai_ds_result else "âŒ None ë°˜í™˜"} ({ai_ds_time:.2f}ì´ˆ)
**Smart EDA Analyzer**: âœ… ì„±ê³µì  ì‹¤í–‰ ({smart_time:.2f}ì´ˆ)

### ğŸ” ë°ì´í„° ê°œìš”

- **ì»¬ëŸ¼ ìˆ˜**: {len(basic_info['columns'])}ê°œ
- **ìˆ˜ì¹˜í˜• ë³€ìˆ˜**: {len(statistical_analysis['numeric_columns'])}ê°œ
- **ë²”ì£¼í˜• ë³€ìˆ˜**: {len(statistical_analysis['categorical_columns'])}ê°œ
- **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰**: {basic_info['memory_usage']}
- **ë°ì´í„° í’ˆì§ˆ ì ìˆ˜**: {quality_analysis['data_quality_score']}/100

### ğŸ“ˆ í†µê³„ì  ë¶„ì„

**ì£¼ìš” ì»¬ëŸ¼**: {', '.join(basic_info['columns'][:5])}{"..." if len(basic_info['columns']) > 5 else ""}

**ë°ì´í„° í’ˆì§ˆ**:
- ê²°ì¸¡ê°’: {len(quality_analysis['missing_values'])}ê°œ ì»¬ëŸ¼ì—ì„œ ë°œê²¬
- ì¤‘ë³µ í–‰: {quality_analysis['duplicate_rows']}ê°œ

**ìƒê´€ê´€ê³„**: {len(statistical_analysis.get('strong_correlations', []))}ê°œì˜ ê°•í•œ ìƒê´€ê´€ê³„ ë°œê²¬

### ğŸ’¡ LLM ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸

{llm_insights}

### ğŸ¯ ê¶Œì¥ì‚¬í•­

{chr(10).join(f"- {rec}" for rec in recommendations[:5])}

### âœ¨ Enhanced Tracking v2 ì •ë³´

- **ë‚´ë¶€ ì²˜ë¦¬ ë‹¨ê³„**: ì™„ì „ ì¶”ì ë¨
- **AI-DS-Team ì‹¤í–‰**: ë‚´ë¶€ ê³¼ì • ëª¨ë‹ˆí„°ë§ ì™„ë£Œ
- **Smart Analyzer**: ëŒ€ì²´ ë¶„ì„ ì„±ê³µ
- **LLM ì¸ì‚¬ì´íŠ¸**: ì „ë¬¸ê°€ê¸‰ í•´ì„ ì œê³µ

### ğŸ‰ ë¶„ì„ ì™„ë£Œ

Enhanced EDA v2ê°€ AI-Data-Science-Teamì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê³  í¬ê´„ì ì¸ ë¶„ì„ì„ ì œê³µí–ˆìŠµë‹ˆë‹¤.
ëª¨ë“  ë‚´ë¶€ ì²˜ë¦¬ ê³¼ì •ì´ Langfuseì—ì„œ ì¶”ì  ê°€ëŠ¥í•©ë‹ˆë‹¤.

**ì´ ì†Œìš” ì‹œê°„**: {ai_ds_time + smart_time:.2f}ì´ˆ
"""
        else:
            # Smart Analyzerë„ ì‹¤íŒ¨í•œ ê²½ìš°
            response = f"""## âš ï¸ EDA ë¶„ì„ ë¶€ë¶„ ì™„ë£Œ

âœ… **ì„¸ì…˜ ID**: {session_id}
âœ… **ë°ì´í„° ì†ŒìŠ¤**: {data_source}
âœ… **ë°ì´í„° í˜•íƒœ**: {df.shape[0]:,} í–‰ Ã— {df.shape[1]:,} ì—´
âŒ **ë¶„ì„ ê²°ê³¼**: ë‘ ë¶„ì„ê¸° ëª¨ë‘ì—ì„œ ë¬¸ì œ ë°œìƒ

### ğŸ” ì‹¤í–‰ ìƒíƒœ
- **AI-DS-Team**: {"ì„±ê³µ" if ai_ds_result else "ì‹¤íŒ¨ (None ë°˜í™˜)"} ({ai_ds_time:.2f}ì´ˆ)
- **Smart Analyzer**: ì‹¤íŒ¨ ({smart_time:.2f}ì´ˆ)

### ğŸ“Š ê¸°ë³¸ ë°ì´í„° ì •ë³´
- **ì»¬ëŸ¼**: {list(df.columns)[:5]}{"..." if len(df.columns) > 5 else ""}
- **í˜•íƒœ**: {df.shape[0]:,} í–‰ Ã— {df.shape[1]:,} ì—´
- **ë°ì´í„° íƒ€ì…**: {len(df.select_dtypes(include=[np.number]).columns)}ê°œ ìˆ˜ì¹˜í˜•, {len(df.select_dtypes(include=['object']).columns)}ê°œ ë²”ì£¼í˜•

### ğŸ“ˆ ê¸°ë³¸ í†µê³„ ì •ë³´
{df.describe().to_string()[:500]}

ëª¨ë“  ë‚´ë¶€ ì²˜ë¦¬ ê³¼ì •ì€ Langfuseì—ì„œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
"""
        
        return response

    async def execute(self, context: RequestContext, event_queue) -> None:
        """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
        task_updater = TaskUpdater(event_queue, context.task_id, context.context_id)
        
        try:
            await task_updater.update_status(
                TaskState.working,
                message=new_agent_text_message("ğŸ” Enhanced EDA v2 ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
            )
            
            # ë©”ì‹œì§€ ë°ì´í„° ì¶”ì¶œ
            message_data = self.extract_data_reference_from_message(context)
            user_instructions = message_data["user_instructions"]
            data_reference = message_data["data_reference"]
            
            logger.info(f"ğŸ“ User instructions: {user_instructions}")
            logger.info(f"ğŸ“Š Data reference: {data_reference}")
            
            if user_instructions:
                df = None
                data_source = "unknown"
                
                # ë°ì´í„° ë¡œë“œ
                if data_reference:
                    data_id = data_reference.get('data_id')
                    if data_id:
                        df = data_manager.get_dataframe(data_id)
                        if df is not None:
                            data_source = data_id
                            logger.info(f"âœ… Data loaded: {data_id} with shape {df.shape}")
                
                # ê¸°ë³¸ ë°ì´í„° ì‚¬ìš©
                if df is None:
                    available_data = data_manager.list_dataframes()
                    logger.info(f"ğŸ” Available data: {available_data}")
                    
                    if available_data:
                        first_data_id = available_data[0]
                        df = data_manager.get_dataframe(first_data_id)
                        if df is not None:
                            data_source = first_data_id
                            logger.info(f"âœ… Using default data: {first_data_id} with shape {df.shape}")
                
                if df is not None:
                    # ì„¸ì…˜ ìƒì„±
                    current_session_id = session_data_manager.create_session_with_data(
                        data_id=data_source,
                        data=df,
                        user_instructions=user_instructions
                    )
                    
                    logger.info(f"âœ… Session created: {current_session_id}")
                    
                    # Enhanced EDA v2 ì‹¤í–‰
                    response_text = await self.execute_enhanced_eda_v2(
                        user_instructions, df, data_source, current_session_id, task_updater
                    )
                    
                    await task_updater.update_status(
                        TaskState.completed,
                        message=new_agent_text_message(response_text)
                    )
                else:
                    await task_updater.update_status(
                        TaskState.completed,
                        message=new_agent_text_message("âŒ ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
                    )
            else:
                await task_updater.update_status(
                    TaskState.completed,
                    message=new_agent_text_message("âŒ EDA ë¶„ì„ ìš”ì²­ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                )
                
        except Exception as e:
            logger.error(f"âŒ Enhanced EDA v2 execution failed: {e}")
            logger.error(f"âŒ Traceback: {traceback.format_exc()}")
            
            await task_updater.update_status(
                TaskState.failed,
                message=new_agent_text_message(f"Enhanced EDA v2 ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            )

    async def cancel(self, context: RequestContext) -> None:
        """ì‘ì—… ì·¨ì†Œ"""
        logger.info("Enhanced EDA Tools Agent v2 task cancelled")


def main():
    """Enhanced EDA Tools Server v2 ì‹¤í–‰"""
    
    # AgentSkill ì •ì˜
    skill = AgentSkill(
        id="enhanced_eda_analysis_v2",
        name="Enhanced EDA Analysis v2 with Smart Fallback",
        description="AI-Data-Science-Team + Smart Fallback ì¡°í•©ìœ¼ë¡œ ì œê³µí•˜ëŠ” ìµœê³  ìˆ˜ì¤€ì˜ EDA ë¶„ì„. AI-DS-Teamì´ ì‹¤íŒ¨í•´ë„ LLM ê¸°ë°˜ ì§€ëŠ¥í˜• ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤.",
        tags=["eda", "data-analysis", "langfuse", "tracking", "smart-fallback", "hybrid", "ai-ds-team"],
        examples=[
            "ë°ì´í„°ì˜ ê¸°ë³¸ í†µê³„ì™€ ë¶„í¬ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”",
            "ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„ë¥¼ íŒŒì•…í•˜ê³  ì‹œê°í™”í•´ì£¼ì„¸ìš”", 
            "ì´ìƒì¹˜ë¥¼ íƒì§€í•˜ê³  ë°ì´í„° í’ˆì§ˆì„ í‰ê°€í•´ì£¼ì„¸ìš”",
            "í¬ê´„ì ì¸ EDA ë¶„ì„ê³¼ ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”"
        ]
    )
    
    # Agent Card ì •ì˜
    agent_card = AgentCard(
        name="Enhanced AI_DS_Team EDAToolsAgent v2",
        description="AI-Data-Science-Team + Smart Fallback í•˜ì´ë¸Œë¦¬ë“œ EDA ì „ë¬¸ê°€. AI-DS-Teamì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê³  í•­ìƒ ìœ ìš©í•œ ë¶„ì„ ê²°ê³¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ëª¨ë“  ê³¼ì •ì´ Langfuseì—ì„œ ì¶”ì ë©ë‹ˆë‹¤.",
        url="http://localhost:8312/",
        version="2.0.0",
        defaultInputModes=["text"],
        defaultOutputModes=["text"],
        capabilities=AgentCapabilities(streaming=False),
        skills=[skill],
        supportsAuthenticatedExtendedCard=False
    )
    
    # Request Handler ìƒì„±
    request_handler = DefaultRequestHandler(
        agent_executor=EnhancedEDAToolsAgentExecutorV2(),
        task_store=InMemoryTaskStore(),
    )
    
    # A2A Server ìƒì„±
    server = A2AStarletteApplication(
        agent_card=agent_card,
        http_handler=request_handler,
    )
    
    print("ğŸ” Starting Enhanced AI_DS_Team EDAToolsAgent Server v2")
    print("ğŸŒ Server starting on http://localhost:8312")
    print("ğŸ“‹ Agent card: http://localhost:8312/.well-known/agent.json")
    print("ğŸ› ï¸ Features: Hybrid EDA (AI-DS-Team + Smart Fallback)")
    print("ğŸ” Smart Fallback: LLM-powered comprehensive analysis")
    print("ğŸ“Š Enhanced tracking: Complete process visibility in Langfuse")
    print("ğŸ¯ Key improvements:")
    print("   - AI-DS-Team None ê²°ê³¼ í•´ê²°")
    print("   - LLM ê¸°ë°˜ ì „ë¬¸ê°€ê¸‰ ì¸ì‚¬ì´íŠ¸")
    print("   - í¬ê´„ì  í†µê³„ ë¶„ì„")
    print("   - ë°ì´í„° í’ˆì§ˆ í‰ê°€")
    print("   - ì‹¤ë¬´ì  ê¶Œì¥ì‚¬í•­ ì œê³µ")
    
    uvicorn.run(server.build(), host="0.0.0.0", port=8312, log_level="info")


if __name__ == "__main__":
    main() 