"""
ì¸ì½”ë”© ê°ì§€ê¸° (Encoding Detector)

UTF-8 ì¸ì½”ë”© ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ ì§€ëŠ¥í˜• ì¸ì½”ë”© ê°ì§€ ìœ í‹¸ë¦¬í‹°
pandas_agentì˜ ì•ˆì •ì„±ì„ ê¸°ì¤€ìœ¼ë¡œ ë‹¤ì¤‘ ì¸ì½”ë”© ì‹œë„ íŒ¨í„´ êµ¬í˜„
"""

import logging
import asyncio
from typing import Optional, List, Dict, Any
from pathlib import Path
import chardet

logger = logging.getLogger(__name__)


class EncodingDetector:
    """
    ì§€ëŠ¥í˜• ì¸ì½”ë”© ê°ì§€ê¸°
    
    UTF-8 ì¸ì½”ë”© ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ë‹¤ì¤‘ ì¸ì½”ë”©ì„ ì‹œë„í•˜ê³ 
    ìµœì ì˜ ì¸ì½”ë”©ì„ ìë™ìœ¼ë¡œ ê°ì§€í•˜ëŠ” ìœ í‹¸ë¦¬í‹°
    """
    
    def __init__(self):
        # ìš°ì„ ìˆœìœ„ ê¸°ë°˜ ì¸ì½”ë”© ë¦¬ìŠ¤íŠ¸ (í•œêµ­ì–´ í™˜ê²½ ìµœì í™”)
        self.encoding_priority = [
            'utf-8',
            'cp949',      # Windows í•œêµ­ì–´
            'euc-kr',     # Unix/Linux í•œêµ­ì–´
            'utf-8-sig',  # BOMì´ ìˆëŠ” UTF-8
            'latin1',     # ì„œìœ ëŸ½
            'iso-8859-1', # ë¼í‹´-1
            'ascii',      # ê¸°ë³¸ ASCII
            'utf-16',     # Unicode 16ë¹„íŠ¸
            'utf-32'      # Unicode 32ë¹„íŠ¸
        ]
        
        logger.info("âœ… EncodingDetector ì´ˆê¸°í™” ì™„ë£Œ")
    
    async def detect_encoding(self, file_path: str, sample_size: int = 8192) -> str:
        """
        íŒŒì¼ ì¸ì½”ë”© ìë™ ê°ì§€
        
        Args:
            file_path: íŒŒì¼ ê²½ë¡œ
            sample_size: ìƒ˜í”Œë§í•  ë°”ì´íŠ¸ í¬ê¸°
            
        Returns:
            str: ê°ì§€ëœ ì¸ì½”ë”© (ê¸°ë³¸: utf-8)
        """
        try:
            # 1ë‹¨ê³„: chardet ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•œ ìë™ ê°ì§€
            detected_encoding = await self._detect_with_chardet(file_path, sample_size)
            
            if detected_encoding:
                # ê°ì§€ëœ ì¸ì½”ë”©ìœ¼ë¡œ ì‹¤ì œ ì½ê¸° í…ŒìŠ¤íŠ¸
                if await self._test_encoding(file_path, detected_encoding):
                    logger.info(f"âœ… ì¸ì½”ë”© ìë™ ê°ì§€ ì„±ê³µ: {detected_encoding}")
                    return detected_encoding
            
            # 2ë‹¨ê³„: ìš°ì„ ìˆœìœ„ ê¸°ë°˜ ìˆœì°¨ ì‹œë„
            for encoding in self.encoding_priority:
                if await self._test_encoding(file_path, encoding):
                    logger.info(f"âœ… ì¸ì½”ë”© ìˆœì°¨ ì‹œë„ ì„±ê³µ: {encoding}")
                    return encoding
            
            # 3ë‹¨ê³„: í´ë°± - UTF-8 ê°•ì œ ì‚¬ìš©
            logger.warning(f"âš ï¸ ì¸ì½”ë”© ê°ì§€ ì‹¤íŒ¨, UTF-8 í´ë°± ì‚¬ìš©: {file_path}")
            return 'utf-8'
            
        except Exception as e:
            logger.error(f"âŒ ì¸ì½”ë”© ê°ì§€ ì¤‘ ì˜¤ë¥˜: {e}")
            return 'utf-8'
    
    async def _detect_with_chardet(self, file_path: str, sample_size: int) -> Optional[str]:
        """chardet ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•œ ì¸ì½”ë”© ê°ì§€"""
        try:
            with open(file_path, 'rb') as file:
                # íŒŒì¼ ìƒ˜í”Œ ì½ê¸°
                sample = file.read(sample_size)
                
                if not sample:
                    return None
                
                # chardetìœ¼ë¡œ ì¸ì½”ë”© ê°ì§€
                result = chardet.detect(sample)
                
                if result and result.get('confidence', 0) > 0.7:
                    encoding = result['encoding']
                    
                    # ì¼ë°˜ì ì¸ ì¸ì½”ë”© ì´ë¦„ìœ¼ë¡œ ì •ê·œí™”
                    encoding = self._normalize_encoding_name(encoding)
                    
                    logger.info(f"ğŸ” chardet ê°ì§€: {encoding} (ì‹ ë¢°ë„: {result['confidence']:.2f})")
                    return encoding
                
        except Exception as e:
            logger.debug(f"chardet ê°ì§€ ì‹¤íŒ¨: {e}")
            
        return None
    
    def _normalize_encoding_name(self, encoding: str) -> str:
        """ì¸ì½”ë”© ì´ë¦„ ì •ê·œí™”"""
        if not encoding:
            return 'utf-8'
        
        encoding_lower = encoding.lower()
        
        # ì¼ë°˜ì ì¸ ì¸ì½”ë”© ì´ë¦„ ë§¤í•‘
        encoding_mapping = {
            'cp949': 'cp949',
            'euc-kr': 'euc-kr',
            'ks_c_5601-1987': 'cp949',
            'windows-1252': 'latin1',
            'iso-8859-1': 'latin1',
            'ascii': 'ascii',
            'utf-8': 'utf-8',
            'utf-16': 'utf-16',
            'utf-32': 'utf-32'
        }
        
        for key, value in encoding_mapping.items():
            if key in encoding_lower:
                return value
        
        return encoding
    
    async def _test_encoding(self, file_path: str, encoding: str, test_lines: int = 10) -> bool:
        """íŠ¹ì • ì¸ì½”ë”©ìœ¼ë¡œ íŒŒì¼ ì½ê¸° í…ŒìŠ¤íŠ¸"""
        try:
            with open(file_path, 'r', encoding=encoding) as file:
                # ì²˜ìŒ ëª‡ ì¤„ë§Œ ì½ì–´ì„œ í…ŒìŠ¤íŠ¸
                for i, line in enumerate(file):
                    if i >= test_lines:
                        break
                    
                    # ì½ê¸° ì„±ê³µí•˜ë©´ True
                    if line:
                        pass
            
            return True
            
        except (UnicodeDecodeError, UnicodeError, LookupError):
            return False
        except Exception as e:
            logger.debug(f"ì¸ì½”ë”© í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ {encoding}: {e}")
            return False
    
    async def get_encoding_candidates(self, file_path: str) -> List[Dict[str, Any]]:
        """
        ê°€ëŠ¥í•œ ì¸ì½”ë”© í›„ë³´ë“¤ê³¼ ì‹ ë¢°ë„ ë°˜í™˜
        
        Args:
            file_path: íŒŒì¼ ê²½ë¡œ
            
        Returns:
            List[Dict]: ì¸ì½”ë”© í›„ë³´ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        """
        candidates = []
        
        # chardetìœ¼ë¡œ ê°ì§€ëœ ì¸ì½”ë”© ì¶”ê°€
        detected = await self._detect_with_chardet(file_path, 8192)
        if detected:
            candidates.append({
                "encoding": detected,
                "method": "chardet",
                "confidence": 0.8,
                "tested": await self._test_encoding(file_path, detected)
            })
        
        # ìš°ì„ ìˆœìœ„ ê¸°ë°˜ ì¸ì½”ë”©ë“¤ í…ŒìŠ¤íŠ¸
        for encoding in self.encoding_priority:
            if encoding != detected:  # ì¤‘ë³µ ì œê±°
                tested = await self._test_encoding(file_path, encoding)
                candidates.append({
                    "encoding": encoding,
                    "method": "priority",
                    "confidence": 0.6 if tested else 0.2,
                    "tested": tested
                })
        
        # ì‹ ë¢°ë„ ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
        candidates.sort(key=lambda x: x["confidence"], reverse=True)
        
        return candidates
    
    async def detect_with_fallback(self, file_path: str, preferred_encodings: List[str] = None) -> str:
        """
        í´ë°± ì „ëµì„ í¬í•¨í•œ ì¸ì½”ë”© ê°ì§€
        
        Args:
            file_path: íŒŒì¼ ê²½ë¡œ
            preferred_encodings: ìš°ì„  ì‹œë„í•  ì¸ì½”ë”©ë“¤
            
        Returns:
            str: ê°ì§€ëœ ì¸ì½”ë”©
        """
        try:
            # ì‚¬ìš©ì ì§€ì • ì¸ì½”ë”© ìš°ì„  ì‹œë„
            if preferred_encodings:
                for encoding in preferred_encodings:
                    if await self._test_encoding(file_path, encoding):
                        logger.info(f"âœ… ì„ í˜¸ ì¸ì½”ë”© ì„±ê³µ: {encoding}")
                        return encoding
            
            # ê¸°ë³¸ ê°ì§€ ë¡œì§ ì‹¤í–‰
            return await self.detect_encoding(file_path)
            
        except Exception as e:
            logger.error(f"âŒ í´ë°± ì¸ì½”ë”© ê°ì§€ ì‹¤íŒ¨: {e}")
            return 'utf-8'
    
    async def analyze_file_encoding_issues(self, file_path: str) -> Dict[str, Any]:
        """
        íŒŒì¼ì˜ ì¸ì½”ë”© ë¬¸ì œ ë¶„ì„
        
        Args:
            file_path: íŒŒì¼ ê²½ë¡œ
            
        Returns:
            Dict: ì¸ì½”ë”© ë¶„ì„ ê²°ê³¼
        """
        try:
            analysis = {
                "file_path": file_path,
                "detected_encoding": None,
                "working_encodings": [],
                "failed_encodings": [],
                "has_bom": False,
                "file_size": 0,
                "recommendations": []
            }
            
            # íŒŒì¼ í¬ê¸° í™•ì¸
            file_obj = Path(file_path)
            if file_obj.exists():
                analysis["file_size"] = file_obj.stat().st_size
            
            # BOM í™•ì¸
            analysis["has_bom"] = await self._check_bom(file_path)
            
            # ëª¨ë“  ì¸ì½”ë”© í…ŒìŠ¤íŠ¸
            for encoding in self.encoding_priority:
                if await self._test_encoding(file_path, encoding):
                    analysis["working_encodings"].append(encoding)
                else:
                    analysis["failed_encodings"].append(encoding)
            
            # ìµœì  ì¸ì½”ë”© ê°ì§€
            analysis["detected_encoding"] = await self.detect_encoding(file_path)
            
            # ê¶Œì¥ì‚¬í•­ ìƒì„±
            analysis["recommendations"] = self._generate_encoding_recommendations(analysis)
            
            return analysis
            
        except Exception as e:
            logger.error(f"âŒ ì¸ì½”ë”© ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                "file_path": file_path,
                "error": str(e),
                "recommendations": ["íŒŒì¼ì„ UTF-8ë¡œ ë‹¤ì‹œ ì €ì¥í•´ë³´ì„¸ìš”."]
            }
    
    async def _check_bom(self, file_path: str) -> bool:
        """BOM(Byte Order Mark) í™•ì¸"""
        try:
            with open(file_path, 'rb') as file:
                # BOM ì‹œê·¸ë‹ˆì²˜ í™•ì¸
                bom_signatures = [
                    b'\xef\xbb\xbf',      # UTF-8 BOM
                    b'\xff\xfe',          # UTF-16 LE BOM
                    b'\xfe\xff',          # UTF-16 BE BOM
                    b'\xff\xfe\x00\x00',  # UTF-32 LE BOM
                    b'\x00\x00\xfe\xff'   # UTF-32 BE BOM
                ]
                
                first_bytes = file.read(4)
                
                for bom in bom_signatures:
                    if first_bytes.startswith(bom):
                        return True
                
                return False
                
        except Exception:
            return False
    
    def _generate_encoding_recommendations(self, analysis: Dict[str, Any]) -> List[str]:
        """ì¸ì½”ë”© ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        working_count = len(analysis.get("working_encodings", []))
        
        if working_count == 0:
            recommendations.append("âš ï¸ ì§€ì›ë˜ëŠ” ì¸ì½”ë”©ì´ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì´ ì†ìƒë˜ì—ˆì„ ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤.")
            recommendations.append("ğŸ’¡ íŒŒì¼ì„ í…ìŠ¤íŠ¸ ì—ë””í„°ì—ì„œ UTF-8ë¡œ ë‹¤ì‹œ ì €ì¥í•´ë³´ì„¸ìš”.")
        
        elif working_count == 1:
            encoding = analysis["working_encodings"][0]
            recommendations.append(f"âœ… {encoding} ì¸ì½”ë”©ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì•ˆì „í•©ë‹ˆë‹¤.")
        
        elif working_count > 1:
            recommendations.append("âš ï¸ ì—¬ëŸ¬ ì¸ì½”ë”©ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤. ë°ì´í„° ì •í™•ì„±ì„ ìœ„í•´ ê²€ì¦ì´ í•„ìš”í•©ë‹ˆë‹¤.")
            recommendations.append(f"ğŸ’¡ ê¶Œì¥ ì¸ì½”ë”©: {analysis.get('detected_encoding', 'utf-8')}")
        
        if analysis.get("has_bom"):
            recommendations.append("ğŸ“ íŒŒì¼ì— BOMì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. utf-8-sig ì¸ì½”ë”©ì„ ê³ ë ¤í•´ë³´ì„¸ìš”.")
        
        file_size_mb = analysis.get("file_size", 0) / (1024 * 1024)
        if file_size_mb > 100:
            recommendations.append(f"ğŸ“Š ëŒ€ìš©ëŸ‰ íŒŒì¼({file_size_mb:.1f}MB)ì…ë‹ˆë‹¤. ì²­í¬ ë‹¨ìœ„ ì½ê¸°ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.")
        
        return recommendations
    
    def get_encoding_priority(self) -> List[str]:
        """ì¸ì½”ë”© ìš°ì„ ìˆœìœ„ ë°˜í™˜"""
        return self.encoding_priority.copy()
    
    async def convert_file_encoding(self, source_path: str, target_path: str, 
                                  source_encoding: str, target_encoding: str = 'utf-8') -> bool:
        """
        íŒŒì¼ ì¸ì½”ë”© ë³€í™˜ (ì£¼ì˜: ì›ë³¸ íŒŒì¼ ìˆ˜ì •ë¨)
        
        Args:
            source_path: ì›ë³¸ íŒŒì¼ ê²½ë¡œ
            target_path: ëŒ€ìƒ íŒŒì¼ ê²½ë¡œ
            source_encoding: ì›ë³¸ ì¸ì½”ë”©
            target_encoding: ëŒ€ìƒ ì¸ì½”ë”©
            
        Returns:
            bool: ë³€í™˜ ì„±ê³µ ì—¬ë¶€
        """
        try:
            # ì›ë³¸ íŒŒì¼ ì½ê¸°
            with open(source_path, 'r', encoding=source_encoding) as source_file:
                content = source_file.read()
            
            # ëŒ€ìƒ ì¸ì½”ë”©ìœ¼ë¡œ ì €ì¥
            with open(target_path, 'w', encoding=target_encoding) as target_file:
                target_file.write(content)
            
            logger.info(f"âœ… ì¸ì½”ë”© ë³€í™˜ ì™„ë£Œ: {source_encoding} â†’ {target_encoding}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ì¸ì½”ë”© ë³€í™˜ ì‹¤íŒ¨: {e}")
            return False 