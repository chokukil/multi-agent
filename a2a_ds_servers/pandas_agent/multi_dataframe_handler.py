"""
ğŸ”„ Multi-DataFrame Handler

ë©€í‹° ë°ì´í„°í”„ë ˆì„ ì²˜ë¦¬ ë° ê´€ë¦¬ ì‹œìŠ¤í…œ
A2A SDKë¥¼ í†µí•œ ì—ì´ì „íŠ¸ê°„ ë°ì´í„° êµí™˜ ì§€ì›

Author: CherryAI Team  
License: MIT License
"""

import pandas as pd
import numpy as np
import logging
from typing import Dict, List, Optional, Any, Tuple, Union
from datetime import datetime
import json
import uuid

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class DataFrameRegistry:
    """ë°ì´í„°í”„ë ˆì„ ì¤‘ì•™ ë ˆì§€ìŠ¤íŠ¸ë¦¬"""
    
    def __init__(self):
        self.dataframes: Dict[str, pd.DataFrame] = {}
        self.metadata: Dict[str, Dict] = {}
        self.relationships: Dict[str, List[str]] = {}
        self.created_at = datetime.now()
    
    def register_dataframe(self, df: pd.DataFrame, name: str = None, 
                          description: str = None, source: str = None) -> str:
        """ë°ì´í„°í”„ë ˆì„ ë“±ë¡"""
        df_id = name or f"df_{uuid.uuid4().hex[:8]}"
        
        # ë©”íƒ€ë°ì´í„° ìƒì„±
        metadata = {
            "id": df_id,
            "name": name or df_id,
            "description": description or f"ë°ì´í„°í”„ë ˆì„ {df_id}",
            "source": source or "unknown",
            "shape": df.shape,
            "columns": list(df.columns),
            "dtypes": {col: str(dtype) for col, dtype in df.dtypes.items()},
            "memory_usage": df.memory_usage(deep=True).sum(),
            "null_counts": df.isnull().sum().to_dict(),
            "created_at": datetime.now().isoformat(),
            "schema_hash": self._compute_schema_hash(df)
        }
        
        self.dataframes[df_id] = df
        self.metadata[df_id] = metadata
        self.relationships[df_id] = []
        
        logger.info(f"âœ… ë°ì´í„°í”„ë ˆì„ ë“±ë¡: {df_id} (shape: {df.shape})")
        return df_id
    
    def _compute_schema_hash(self, df: pd.DataFrame) -> str:
        """ìŠ¤í‚¤ë§ˆ í•´ì‹œ ê³„ì‚°"""
        schema_str = f"{list(df.columns)}_{list(df.dtypes)}"
        return str(hash(schema_str))
    
    def get_dataframe(self, df_id: str) -> Optional[pd.DataFrame]:
        """ë°ì´í„°í”„ë ˆì„ ì¡°íšŒ"""
        return self.dataframes.get(df_id)
    
    def get_metadata(self, df_id: str) -> Optional[Dict]:
        """ë©”íƒ€ë°ì´í„° ì¡°íšŒ"""
        return self.metadata.get(df_id)
    
    def list_dataframes(self) -> List[str]:
        """ë“±ë¡ëœ ë°ì´í„°í”„ë ˆì„ ëª©ë¡"""
        return list(self.dataframes.keys())
    
    def find_similar_schemas(self, df_id: str) -> List[str]:
        """ìœ ì‚¬í•œ ìŠ¤í‚¤ë§ˆì˜ ë°ì´í„°í”„ë ˆì„ ì°¾ê¸°"""
        if df_id not in self.metadata:
            return []
        
        target_hash = self.metadata[df_id]["schema_hash"]
        similar = []
        
        for other_id, meta in self.metadata.items():
            if other_id != df_id and meta["schema_hash"] == target_hash:
                similar.append(other_id)
        
        return similar
    
    def add_relationship(self, df_id1: str, df_id2: str, relationship_type: str = "related"):
        """ë°ì´í„°í”„ë ˆì„ ê°„ ê´€ê³„ ì¶”ê°€"""
        if df_id1 in self.relationships:
            self.relationships[df_id1].append({"target": df_id2, "type": relationship_type})
        if df_id2 in self.relationships:
            self.relationships[df_id2].append({"target": df_id1, "type": relationship_type})
        
        logger.info(f"ğŸ”— ê´€ê³„ ì¶”ê°€: {df_id1} â†” {df_id2} ({relationship_type})")


class MultiDataFrameHandler:
    """ë©€í‹° ë°ì´í„°í”„ë ˆì„ í•¸ë“¤ëŸ¬"""
    
    def __init__(self):
        self.registry = DataFrameRegistry()
        self.current_context: List[str] = []  # í˜„ì¬ ì‘ì—… ì»¨í…ìŠ¤íŠ¸ì˜ ë°ì´í„°í”„ë ˆì„ë“¤
        
    async def add_dataframe(self, df: pd.DataFrame, **kwargs) -> str:
        """ë°ì´í„°í”„ë ˆì„ ì¶”ê°€"""
        df_id = self.registry.register_dataframe(df, **kwargs)
        
        # ìë™ ê´€ê³„ ë°œê²¬
        await self._discover_relationships(df_id)
        
        return df_id
    
    async def _discover_relationships(self, df_id: str):
        """ë°ì´í„°í”„ë ˆì„ ê°„ ê´€ê³„ ìë™ ë°œê²¬"""
        try:
            df = self.registry.get_dataframe(df_id)
            if df is None:
                return
            
            # 1. ìŠ¤í‚¤ë§ˆ ìœ ì‚¬ì„± ê¸°ë°˜ ê´€ê³„
            similar_schemas = self.registry.find_similar_schemas(df_id)
            for similar_id in similar_schemas:
                self.registry.add_relationship(df_id, similar_id, "similar_schema")
            
            # 2. ì»¬ëŸ¼ëª… ê¸°ë°˜ ê´€ê³„ ë°œê²¬
            await self._discover_column_relationships(df_id, df)
            
        except Exception as e:
            logger.warning(f"âš ï¸ ê´€ê³„ ë°œê²¬ ì‹¤íŒ¨: {e}")
    
    async def _discover_column_relationships(self, df_id: str, df: pd.DataFrame):
        """ì»¬ëŸ¼ëª… ê¸°ë°˜ ê´€ê³„ ë°œê²¬"""
        df_columns = set(df.columns)
        
        for other_id in self.registry.list_dataframes():
            if other_id == df_id:
                continue
                
            other_df = self.registry.get_dataframe(other_id)
            if other_df is None:
                continue
            
            other_columns = set(other_df.columns)
            
            # ê³µí†µ ì»¬ëŸ¼ ë¹„ìœ¨ ê³„ì‚°
            common_columns = df_columns.intersection(other_columns)
            if common_columns:
                similarity_ratio = len(common_columns) / len(df_columns.union(other_columns))
                
                if similarity_ratio > 0.3:  # 30% ì´ìƒ ê³µí†µ ì»¬ëŸ¼
                    relationship_type = "high_column_overlap" if similarity_ratio > 0.7 else "medium_column_overlap"
                    self.registry.add_relationship(df_id, other_id, relationship_type)
    
    def get_context_dataframes(self) -> List[pd.DataFrame]:
        """í˜„ì¬ ì»¨í…ìŠ¤íŠ¸ì˜ ë°ì´í„°í”„ë ˆì„ë“¤ ë°˜í™˜"""
        return [self.registry.get_dataframe(df_id) for df_id in self.current_context 
                if self.registry.get_dataframe(df_id) is not None]
    
    def set_context(self, df_ids: List[str]):
        """ì‘ì—… ì»¨í…ìŠ¤íŠ¸ ì„¤ì •"""
        # ìœ íš¨í•œ ë°ì´í„°í”„ë ˆì„ IDë§Œ í•„í„°ë§
        valid_ids = [df_id for df_id in df_ids if df_id in self.registry.dataframes]
        self.current_context = valid_ids
        logger.info(f"ğŸ“‹ ì»¨í…ìŠ¤íŠ¸ ì„¤ì •: {len(valid_ids)}ê°œ ë°ì´í„°í”„ë ˆì„")
    
    def add_to_context(self, df_id: str):
        """ì»¨í…ìŠ¤íŠ¸ì— ë°ì´í„°í”„ë ˆì„ ì¶”ê°€"""
        if df_id in self.registry.dataframes and df_id not in self.current_context:
            self.current_context.append(df_id)
            logger.info(f"â• ì»¨í…ìŠ¤íŠ¸ì— ì¶”ê°€: {df_id}")
    
    def remove_from_context(self, df_id: str):
        """ì»¨í…ìŠ¤íŠ¸ì—ì„œ ë°ì´í„°í”„ë ˆì„ ì œê±°"""
        if df_id in self.current_context:
            self.current_context.remove(df_id)
            logger.info(f"â– ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì œê±°: {df_id}")
    
    async def merge_dataframes(self, df_ids: List[str], how: str = 'inner', 
                             on: Optional[Union[str, List[str]]] = None) -> str:
        """ë°ì´í„°í”„ë ˆì„ ë³‘í•©"""
        try:
            if len(df_ids) < 2:
                raise ValueError("ìµœì†Œ 2ê°œì˜ ë°ì´í„°í”„ë ˆì„ì´ í•„ìš”í•©ë‹ˆë‹¤.")
            
            dataframes = []
            for df_id in df_ids:
                df = self.registry.get_dataframe(df_id)
                if df is None:
                    raise ValueError(f"ë°ì´í„°í”„ë ˆì„ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {df_id}")
                dataframes.append(df)
            
            # ìˆœì°¨ì  ë³‘í•©
            result_df = dataframes[0]
            merge_info = [self.registry.get_metadata(df_ids[0])['name']]
            
            for i, df in enumerate(dataframes[1:], 1):
                if on is None:
                    # ê³µí†µ ì»¬ëŸ¼ ìë™ ì°¾ê¸°
                    common_cols = list(set(result_df.columns).intersection(set(df.columns)))
                    if not common_cols:
                        raise ValueError(f"ë³‘í•©í•  ê³µí†µ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {df_ids[0]} â†” {df_ids[i]}")
                    merge_on = common_cols
                else:
                    merge_on = on
                
                result_df = pd.merge(result_df, df, on=merge_on, how=how)
                merge_info.append(self.registry.get_metadata(df_ids[i])['name'])
            
            # ë³‘í•© ê²°ê³¼ ë“±ë¡
            merged_id = await self.add_dataframe(
                result_df,
                name=f"merged_{'_'.join(merge_info[:3])}",  # ì´ë¦„ ê¸¸ì´ ì œí•œ
                description=f"ë³‘í•©ëœ ë°ì´í„°í”„ë ˆì„: {' + '.join(merge_info)}",
                source="merge_operation"
            )
            
            logger.info(f"âœ… ë°ì´í„°í”„ë ˆì„ ë³‘í•© ì™„ë£Œ: {merged_id} (shape: {result_df.shape})")
            return merged_id
            
        except Exception as e:
            logger.error(f"âŒ ë°ì´í„°í”„ë ˆì„ ë³‘í•© ì‹¤íŒ¨: {e}")
            raise
    
    async def concat_dataframes(self, df_ids: List[str], axis: int = 0, 
                              ignore_index: bool = True) -> str:
        """ë°ì´í„°í”„ë ˆì„ ì—°ê²°"""
        try:
            dataframes = []
            concat_info = []
            
            for df_id in df_ids:
                df = self.registry.get_dataframe(df_id)
                if df is None:
                    raise ValueError(f"ë°ì´í„°í”„ë ˆì„ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {df_id}")
                dataframes.append(df)
                concat_info.append(self.registry.get_metadata(df_id)['name'])
            
            # ì—°ê²° ì‹¤í–‰
            result_df = pd.concat(dataframes, axis=axis, ignore_index=ignore_index)
            
            # ì—°ê²° ê²°ê³¼ ë“±ë¡
            concat_id = await self.add_dataframe(
                result_df,
                name=f"concat_{'_'.join(concat_info[:3])}",
                description=f"ì—°ê²°ëœ ë°ì´í„°í”„ë ˆì„: {' + '.join(concat_info)} (axis={axis})",
                source="concat_operation"
            )
            
            logger.info(f"âœ… ë°ì´í„°í”„ë ˆì„ ì—°ê²° ì™„ë£Œ: {concat_id} (shape: {result_df.shape})")
            return concat_id
            
        except Exception as e:
            logger.error(f"âŒ ë°ì´í„°í”„ë ˆì„ ì—°ê²° ì‹¤íŒ¨: {e}")
            raise
    
    def get_summary_report(self) -> str:
        """ë©€í‹° ë°ì´í„°í”„ë ˆì„ ìš”ì•½ ë³´ê³ ì„œ"""
        total_dfs = len(self.registry.dataframes)
        if total_dfs == 0:
            return "ğŸ“Š ë“±ë¡ëœ ë°ì´í„°í”„ë ˆì„ì´ ì—†ìŠµë‹ˆë‹¤."
        
        # í†µê³„ ê³„ì‚°
        total_rows = sum(meta['shape'][0] for meta in self.registry.metadata.values())
        total_columns = sum(meta['shape'][1] for meta in self.registry.metadata.values())
        total_memory = sum(meta['memory_usage'] for meta in self.registry.metadata.values())
        
        # ê´€ê³„ í†µê³„
        total_relationships = sum(len(rels) for rels in self.registry.relationships.values()) // 2
        
        report = f"""# ğŸ“Š **ë©€í‹° ë°ì´í„°í”„ë ˆì„ ìš”ì•½ ë³´ê³ ì„œ**

## ğŸ”¢ **ì „ì²´ í†µê³„**
- **ì´ ë°ì´í„°í”„ë ˆì„**: {total_dfs}ê°œ
- **ì´ í–‰ ìˆ˜**: {total_rows:,}í–‰
- **ì´ ì»¬ëŸ¼ ìˆ˜**: {total_columns}ê°œ
- **ì´ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰**: {total_memory / 1024**2:.1f} MB
- **ë°ì´í„°í”„ë ˆì„ ê°„ ê´€ê³„**: {total_relationships}ê°œ

## ğŸ“‹ **ë“±ë¡ëœ ë°ì´í„°í”„ë ˆì„**
"""
        
        for df_id, metadata in self.registry.metadata.items():
            in_context = "ğŸŸ¢" if df_id in self.current_context else "âšª"
            report += f"""
### {in_context} **{metadata['name']}** (`{df_id}`)
- **í¬ê¸°**: {metadata['shape'][0]:,}í–‰ Ã— {metadata['shape'][1]}ì—´
- **ë©”ëª¨ë¦¬**: {metadata['memory_usage'] / 1024**2:.1f} MB
- **ê²°ì¸¡ì¹˜**: {sum(metadata['null_counts'].values())}ê°œ
- **ìƒì„±ì¼**: {metadata['created_at'][:19]}
"""
        
        if self.current_context:
            report += f"\n## ğŸ¯ **í˜„ì¬ ì‘ì—… ì»¨í…ìŠ¤íŠ¸**\n"
            report += f"í™œì„± ë°ì´í„°í”„ë ˆì„: {len(self.current_context)}ê°œ\n"
            for df_id in self.current_context:
                meta = self.registry.get_metadata(df_id)
                if meta:
                    report += f"- **{meta['name']}** ({meta['shape'][0]:,}í–‰)\n"
        
        return report
    
    def export_metadata(self) -> Dict[str, Any]:
        """ë©”íƒ€ë°ì´í„° ë‚´ë³´ë‚´ê¸°"""
        return {
            "registry_metadata": self.registry.metadata,
            "relationships": self.registry.relationships,
            "current_context": self.current_context,
            "created_at": self.registry.created_at.isoformat(),
            "total_dataframes": len(self.registry.dataframes)
        }
    
    async def import_metadata(self, metadata: Dict[str, Any]):
        """ë©”íƒ€ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (ë°ì´í„°í”„ë ˆì„ ì œì™¸)"""
        try:
            self.registry.metadata.update(metadata.get("registry_metadata", {}))
            self.registry.relationships.update(metadata.get("relationships", {}))
            self.current_context = metadata.get("current_context", [])
            
            logger.info(f"âœ… ë©”íƒ€ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì™„ë£Œ: {len(metadata.get('registry_metadata', {}))}ê°œ")
            
        except Exception as e:
            logger.error(f"âŒ ë©”íƒ€ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
            raise 