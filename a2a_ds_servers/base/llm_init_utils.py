"""LLM ì´ˆê¸°í™” ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤

Ollama ì‚¬ìš© ì‹œ API í‚¤ ì²´í¬ë¥¼ ê±´ë„ˆë›°ëŠ” ë“±ì˜ ê³µí†µ ë¡œì§ì„ ì œê³µí•©ë‹ˆë‹¤.
"""

import os
import logging
from typing import Optional, Any

logger = logging.getLogger(__name__)

def check_llm_requirements() -> bool:
    """
    LLM ì‚¬ìš©ì„ ìœ„í•œ ìš”êµ¬ì‚¬í•­ ì²´í¬
    
    Returns:
        bool: LLM ì´ˆê¸°í™”ê°€ ê°€ëŠ¥í•œì§€ ì—¬ë¶€
        
    Raises:
        ValueError: LLM ì´ˆê¸°í™”ì— í•„ìš”í•œ ì¡°ê±´ì´ ì¶©ì¡±ë˜ì§€ ì•Šì€ ê²½ìš°
    """
    # LLM Provider í™•ì¸
    llm_provider = os.getenv('LLM_PROVIDER', 'openai').lower()
    logger.info(f"ğŸ” LLM Provider: {llm_provider}")
    
    # Ollama ì‚¬ìš© ì‹œì—ëŠ” API í‚¤ ì²´í¬ ê±´ë„ˆë›°ê¸°
    if llm_provider == 'ollama':
        logger.info("âœ… Ollama ì‚¬ìš© - API í‚¤ ì²´í¬ ê±´ë„ˆë›°ê¸°")
        return True
    
    # ë‹¤ë¥¸ Provider ì‚¬ìš© ì‹œ API í‚¤ ì²´í¬
    api_key = (
        os.getenv('OPENAI_API_KEY') or 
        os.getenv('ANTHROPIC_API_KEY') or 
        os.getenv('GOOGLE_API_KEY')
    )
    
    if not api_key:
        raise ValueError(
            f"No LLM API key found for provider '{llm_provider}'. "
            "Please set OPENAI_API_KEY, ANTHROPIC_API_KEY, or GOOGLE_API_KEY environment variable."
        )
    
    logger.info(f"âœ… API í‚¤ í™•ì¸ë¨ for provider: {llm_provider}")
    return True

def create_llm_with_fallback() -> Any:
    """
    LLM í´ë¼ì´ì–¸íŠ¸ ìƒì„± (í´ë°± í¬í•¨)
    
    Returns:
        LLM í´ë¼ì´ì–¸íŠ¸ ì¸ìŠ¤í„´ìŠ¤
        
    Raises:
        RuntimeError: LLM ì´ˆê¸°í™”ì— ì‹¤íŒ¨í•œ ê²½ìš°
    """
    try:
        # ìš”êµ¬ì‚¬í•­ ì²´í¬
        check_llm_requirements()
        
        # LLM í´ë¼ì´ì–¸íŠ¸ ìƒì„±
        from core.llm_factory import create_llm_instance
        llm = create_llm_instance()
        
        logger.info("âœ… LLM í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì„±ê³µ")
        return llm
        
    except Exception as e:
        logger.error(f"âŒ LLM ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        raise RuntimeError("LLM initialization is required for operation") from e

def safe_llm_init(agent_name: str = "Agent") -> tuple[Any, Any]:
    """
    ì•ˆì „í•œ LLM ë° ì—ì´ì „íŠ¸ ì´ˆê¸°í™”
    
    Args:
        agent_name: ì—ì´ì „íŠ¸ ì´ë¦„ (ë¡œê¹…ìš©)
        
    Returns:
        tuple: (llm_instance, agent_instance) - agent_instanceëŠ” Noneì¼ ìˆ˜ ìˆìŒ
        
    Raises:
        RuntimeError: LLM ì´ˆê¸°í™”ì— ì‹¤íŒ¨í•œ ê²½ìš°
    """
    logger.info(f"ğŸš€ {agent_name} LLM ì´ˆê¸°í™” ì‹œì‘")
    
    try:
        llm = create_llm_with_fallback()
        logger.info(f"âœ… {agent_name} LLM ì´ˆê¸°í™” ì™„ë£Œ")
        return llm, None
        
    except Exception as e:
        logger.error(f"âŒ {agent_name} LLM ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        raise