#!/usr/bin/env python3
"""
Feature Engineering Server - A2A SDK 0.2.9 ë˜í•‘ êµ¬í˜„

ì›ë³¸ ai-data-science-team FeatureEngineeringAgentë¥¼ A2A SDK 0.2.9ë¡œ ë˜í•‘í•˜ì—¬
8ê°œ í•µì‹¬ ê¸°ëŠ¥ì„ 100% ë³´ì¡´í•©ë‹ˆë‹¤.

í¬íŠ¸: 8310
"""

import sys
import os
import logging
from pathlib import Path
import pandas as pd
import numpy as np
import io
import json
import time

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# A2A SDK imports
from a2a.server.apps import A2AStarletteApplication
from a2a.server.agent_execution import AgentExecutor, RequestContext
from a2a.server.request_handlers import DefaultRequestHandler
from a2a.server.tasks import InMemoryTaskStore
from a2a.server.events import EventQueue
from a2a.types import AgentCard, AgentSkill, AgentCapabilities, TaskState
from a2a.utils import new_agent_text_message
from a2a.server.tasks.task_updater import TaskUpdater
import uvicorn
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Langfuse í†µí•© ëª¨ë“ˆ ì„í¬íŠ¸
try:
    from core.universal_engine.langfuse_integration import SessionBasedTracer, LangfuseEnhancedA2AExecutor
    LANGFUSE_AVAILABLE = True
    logger.info("âœ… Langfuse í†µí•© ëª¨ë“ˆ ë¡œë“œ ì„±ê³µ")
except ImportError as e:
    LANGFUSE_AVAILABLE = False
    logger.warning(f"âš ï¸ Langfuse í†µí•© ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")


class PandasAIDataProcessor:
    """pandas-ai ìŠ¤íƒ€ì¼ ë°ì´í„° í”„ë¡œì„¸ì„œ"""
    
    def parse_data_from_message(self, user_instructions: str) -> pd.DataFrame:
        """ì‚¬ìš©ì ë©”ì‹œì§€ì—ì„œ ë°ì´í„° íŒŒì‹±"""
        logger.info("ğŸ” ë°ì´í„° íŒŒì‹± ì‹œì‘")
        
        # CSV ë°ì´í„° ê²€ìƒ‰ (ì¼ë°˜ ê°œí–‰ ë¬¸ì í¬í•¨)
        if ',' in user_instructions and ('\n' in user_instructions or '\\n' in user_instructions):
            try:
                # ì‹¤ì œ ê°œí–‰ë¬¸ìì™€ ì´ìŠ¤ì¼€ì´í”„ëœ ê°œí–‰ë¬¸ì ëª¨ë‘ ì²˜ë¦¬
                normalized_text = user_instructions.replace('\\n', '\n')
                lines = normalized_text.strip().split('\n')
                
                # CSV íŒ¨í„´ ì°¾ê¸° - í—¤ë”ì™€ ë°ì´í„° í–‰ êµ¬ë¶„
                csv_lines = []
                for line in lines:
                    line = line.strip()
                    if ',' in line and line:  # ì‰¼í‘œê°€ ìˆê³  ë¹„ì–´ìˆì§€ ì•Šì€ í–‰
                        csv_lines.append(line)
                
                if len(csv_lines) >= 2:  # í—¤ë” + ìµœì†Œ 1ê°œ ë°ì´í„° í–‰
                    csv_data = '\n'.join(csv_lines)
                    df = pd.read_csv(io.StringIO(csv_data))
                    logger.info(f"âœ… CSV ë°ì´í„° íŒŒì‹± ì„±ê³µ: {df.shape}")
                    return df
            except Exception as e:
                logger.warning(f"CSV íŒŒì‹± ì‹¤íŒ¨: {e}")
        
        # JSON ë°ì´í„° ê²€ìƒ‰
        try:
            import re
            json_pattern = r'\[.*?\]|\{.*?\}'
            json_matches = re.findall(json_pattern, user_instructions, re.DOTALL)
            
            for json_str in json_matches:
                try:
                    data = json.loads(json_str)
                    if isinstance(data, list) and data:
                        df = pd.DataFrame(data)
                        logger.info(f"âœ… JSON ë°ì´í„° íŒŒì‹± ì„±ê³µ: {df.shape}")
                        return df
                    elif isinstance(data, dict):
                        df = pd.DataFrame([data])
                        logger.info(f"âœ… JSON ê°ì²´ íŒŒì‹± ì„±ê³µ: {df.shape}")
                        return df
                except:
                    continue
        except Exception as e:
            logger.warning(f"JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
        
        logger.info("âš ï¸ íŒŒì‹± ê°€ëŠ¥í•œ ë°ì´í„° ì—†ìŒ - None ë°˜í™˜")
        return None


class FeatureEngineeringServerAgent:
    """
    ai-data-science-team FeatureEngineeringAgent ë˜í•‘ í´ë˜ìŠ¤
    
    ì›ë³¸ íŒ¨í‚¤ì§€ì˜ ëª¨ë“  ê¸°ëŠ¥ì„ ë³´ì¡´í•˜ë©´ì„œ A2A SDKë¡œ ë˜í•‘í•©ë‹ˆë‹¤.
    """
    
    def __init__(self):
        self.llm = None
        self.agent = None
        self.data_processor = PandasAIDataProcessor()
        
        # LLM ì´ˆê¸°í™”
        try:
            from core.llm_factory import create_llm_instance
            self.llm = create_llm_instance()
            logger.info("âœ… LLM ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            logger.error(f"âŒ LLM ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise RuntimeError("LLM is required for operation") from e
        
        # ì›ë³¸ FeatureEngineeringAgent ì´ˆê¸°í™” ì‹œë„
        try:
            # ai-data-science-team ê²½ë¡œ ì¶”ê°€
            ai_ds_team_path = project_root / "ai_ds_team"
            sys.path.insert(0, str(ai_ds_team_path))
            
            from ai_data_science_team.agents.feature_engineering_agent import FeatureEngineeringAgent
            
            self.agent = FeatureEngineeringAgent(
                model=self.llm,
                n_samples=30,
                log=True,
                log_path="logs/feature_engineering/",
                file_name="feature_engineer.py",
                function_name="feature_engineer",
                overwrite=True,
                human_in_the_loop=False,
                bypass_recommended_steps=False,
                bypass_explain_code=False,
                checkpointer=None
            )
            self.has_original_agent = True
            logger.info("âœ… ì›ë³¸ FeatureEngineeringAgent ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            logger.warning(f"âš ï¸ ì›ë³¸ FeatureEngineeringAgent ì‚¬ìš© ë¶ˆê°€: {e}")
            self.has_original_agent = False
            logger.info("âœ… í´ë°± ëª¨ë“œë¡œ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _detect_target_variable(self, df: pd.DataFrame, user_input: str) -> str:
        """ì‚¬ìš©ì ì…ë ¥ê³¼ ë°ì´í„°ì—ì„œ íƒ€ê²Ÿ ë³€ìˆ˜ ê°ì§€"""
        # ì¼ë°˜ì ì¸ íƒ€ê²Ÿ ë³€ìˆ˜ ì´ë¦„ë“¤
        common_targets = ['target', 'label', 'y', 'class', 'outcome', 'result', 
                         'churn', 'price', 'sales', 'revenue', 'score']
        
        # ì‚¬ìš©ì ì…ë ¥ì—ì„œ íƒ€ê²Ÿ ë³€ìˆ˜ ì–¸ê¸‰ í™•ì¸
        for word in user_input.lower().split():
            if word in df.columns:
                return word
        
        # ì¼ë°˜ì ì¸ íƒ€ê²Ÿ ë³€ìˆ˜ëª… í™•ì¸
        for target in common_targets:
            if target in df.columns:
                return target
        
        # ë§ˆì§€ë§‰ ì»¬ëŸ¼ì´ íƒ€ê²Ÿì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŒ
        if len(df.columns) > 1:
            last_col = df.columns[-1]
            if df[last_col].dtype in ['object', 'bool'] or df[last_col].nunique() < len(df) * 0.5:
                return last_col
        
        return None
    
    async def process_feature_engineering(self, user_input: str) -> str:
        """í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ì²˜ë¦¬ ì‹¤í–‰"""
        try:
            logger.info(f"ğŸš€ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ìš”ì²­ ì²˜ë¦¬: {user_input[:100]}...")
            
            # ë°ì´í„° íŒŒì‹±
            df = self.data_processor.parse_data_from_message(user_input)
            
            if df is None:
                return self._generate_feature_engineering_guidance(user_input)
            
            # ì›ë³¸ ì—ì´ì „íŠ¸ ì‚¬ìš© ì‹œë„
            if self.has_original_agent and self.agent:
                return await self._process_with_original_agent(df, user_input)
            else:
                return await self._process_with_fallback(df, user_input)
                
        except Exception as e:
            logger.error(f"âŒ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            return f"âŒ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
    
    async def _process_with_original_agent(self, df: pd.DataFrame, user_input: str) -> str:
        """ì›ë³¸ FeatureEngineeringAgent ì‚¬ìš©"""
        try:
            logger.info("ğŸ¤– ì›ë³¸ FeatureEngineeringAgent ì‹¤í–‰ ì¤‘...")
            
            # íƒ€ê²Ÿ ë³€ìˆ˜ ê°ì§€
            target_variable = self._detect_target_variable(df, user_input)
            
            # ì›ë³¸ ì—ì´ì „íŠ¸ invoke_agent í˜¸ì¶œ
            self.agent.invoke_agent(
                data_raw=df,
                user_instructions=user_input,
                target_variable=target_variable
            )
            
            # ê²°ê³¼ ìˆ˜ì§‘
            data_engineered = self.agent.get_data_engineered()
            feature_engineer_function = self.agent.get_feature_engineer_function()
            recommended_steps = self.agent.get_recommended_feature_engineering_steps()
            workflow_summary = self.agent.get_workflow_summary()
            log_summary = self.agent.get_log_summary()
            
            # ë°ì´í„° ì €ì¥
            data_path = "a2a_ds_servers/artifacts/data/shared_dataframes/"
            os.makedirs(data_path, exist_ok=True)
            
            timestamp = int(time.time())
            output_file = f"engineered_data_{timestamp}.csv"
            output_path = os.path.join(data_path, output_file)
            
            # ì—”ì§€ë‹ˆì–´ë§ëœ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì €ì¥, ì—†ìœ¼ë©´ ì›ë³¸ ì €ì¥
            if data_engineered is not None and isinstance(data_engineered, pd.DataFrame):
                data_engineered.to_csv(output_path, index=False)
                logger.info(f"ì—”ì§€ë‹ˆì–´ë§ëœ ë°ì´í„° ì €ì¥: {output_path}")
            else:
                df.to_csv(output_path, index=False)
            
            # ê²°ê³¼ í¬ë§·íŒ…
            return self._format_original_agent_result(
                df, data_engineered, user_input, output_path,
                feature_engineer_function, recommended_steps, 
                workflow_summary, log_summary, target_variable
            )
            
        except Exception as e:
            logger.error(f"ì›ë³¸ ì—ì´ì „íŠ¸ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return await self._process_with_fallback(df, user_input)
    
    async def _process_with_fallback(self, df: pd.DataFrame, user_input: str) -> str:
        """í´ë°± í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ì²˜ë¦¬"""
        try:
            logger.info("ğŸ”„ í´ë°± í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ì‹¤í–‰ ì¤‘...")
            
            # ê¸°ë³¸ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ë¶„ì„
            numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
            categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()
            datetime_cols = df.select_dtypes(include=['datetime']).columns.tolist()
            
            engineered_df = df.copy()
            engineering_actions = []
            
            # 1. ë°ì´í„° íƒ€ì… ë³€í™˜
            for col in categorical_cols:
                if col in engineered_df.columns:
                    unique_ratio = engineered_df[col].nunique() / len(engineered_df)
                    if unique_ratio > 0.95:  # ê³ ìœ ê°’ì´ 95% ì´ìƒì¸ ì»¬ëŸ¼ ì œê±°
                        engineered_df = engineered_df.drop(columns=[col])
                        engineering_actions.append(f"'{col}' ê³ ìœ ê°’ í”¼ì²˜ ì œê±° (unique ratio: {unique_ratio:.2f})")
            
            # 2. ìƒìˆ˜ í”¼ì²˜ ì œê±°
            constant_cols = []
            for col in engineered_df.columns:
                if engineered_df[col].nunique() <= 1:
                    constant_cols.append(col)
            
            if constant_cols:
                engineered_df = engineered_df.drop(columns=constant_cols)
                engineering_actions.append(f"ìƒìˆ˜ í”¼ì²˜ {len(constant_cols)}ê°œ ì œê±°: {constant_cols}")
            
            # 3. ë²”ì£¼í˜• ì¸ì½”ë”© (ê°„ë‹¨í•œ ë²„ì „)
            remaining_categorical = engineered_df.select_dtypes(include=['object', 'category']).columns.tolist()
            for col in remaining_categorical:
                if col in engineered_df.columns:
                    unique_count = engineered_df[col].nunique()
                    if unique_count <= 10:  # ì†Œê·œëª¨ ì¹´í…Œê³ ë¦¬ëŠ” ì›í•« ì¸ì½”ë”©
                        dummies = pd.get_dummies(engineered_df[col], prefix=col, drop_first=True)
                        engineered_df = pd.concat([engineered_df.drop(columns=[col]), dummies], axis=1)
                        engineering_actions.append(f"'{col}' ì›í•« ì¸ì½”ë”© ({unique_count}ê°œ ì¹´í…Œê³ ë¦¬)")
                    else:  # ëŒ€ê·œëª¨ ì¹´í…Œê³ ë¦¬ëŠ” ë¹ˆë„ ê¸°ë°˜ ì¸ì½”ë”©
                        value_counts = engineered_df[col].value_counts()
                        threshold = len(engineered_df) * 0.05  # 5% ì„ê³„ê°’
                        frequent_values = value_counts[value_counts >= threshold].index
                        engineered_df[col] = engineered_df[col].apply(
                            lambda x: x if x in frequent_values else 'other'
                        )
                        engineering_actions.append(f"'{col}' ê³ ì°¨ì› ì¹´í…Œê³ ë¦¬ ì²˜ë¦¬ (threshold: 5%)")
            
            # 4. ë¶ˆë¦° ê°’ì„ ì •ìˆ˜ë¡œ ë³€í™˜
            bool_cols = engineered_df.select_dtypes(include=['bool']).columns.tolist()
            for col in bool_cols:
                engineered_df[col] = engineered_df[col].astype(int)
                engineering_actions.append(f"'{col}' ë¶ˆë¦°â†’ì •ìˆ˜ ë³€í™˜")
            
            # 5. ê²°ì¸¡ê°’ ì²˜ë¦¬
            for col in engineered_df.columns:
                if engineered_df[col].isnull().any():
                    if engineered_df[col].dtype in ['object', 'category']:
                        engineered_df[col] = engineered_df[col].fillna('missing')
                    else:
                        engineered_df[col] = engineered_df[col].fillna(engineered_df[col].median())
                    engineering_actions.append(f"'{col}' ê²°ì¸¡ê°’ ì²˜ë¦¬")
            
            # ë°ì´í„° ì €ì¥
            data_path = "a2a_ds_servers/artifacts/data/shared_dataframes/"
            os.makedirs(data_path, exist_ok=True)
            
            timestamp = int(time.time())
            output_file = f"engineered_data_fallback_{timestamp}.csv"
            output_path = os.path.join(data_path, output_file)
            
            engineered_df.to_csv(output_path, index=False)
            
            return self._format_fallback_result(
                df, engineered_df, user_input, output_path, engineering_actions
            )
            
        except Exception as e:
            logger.error(f"í´ë°± ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return f"âŒ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ì‹¤íŒ¨: {str(e)}"
    
    def _format_original_agent_result(self, original_df, engineered_df, user_input, 
                                    output_path, engineer_function, recommended_steps,
                                    workflow_summary, log_summary, target_variable) -> str:
        """ì›ë³¸ ì—ì´ì „íŠ¸ ê²°ê³¼ í¬ë§·íŒ…"""
        
        data_preview = original_df.head().to_string()
        
        engineered_info = ""
        if engineered_df is not None and isinstance(engineered_df, pd.DataFrame):
            engineered_info = f"""

## ğŸ”§ **ì—”ì§€ë‹ˆì–´ë§ëœ ë°ì´í„° ì •ë³´**
- **ì—”ì§€ë‹ˆì–´ë§ í›„ í¬ê¸°**: {engineered_df.shape[0]:,} í–‰ Ã— {engineered_df.shape[1]:,} ì—´
- **í”¼ì²˜ ë³€í™”**: {len(original_df.columns)} â†’ {len(engineered_df.columns)} ({len(engineered_df.columns) - len(original_df.columns):+d})
- **ë°ì´í„° íƒ€ì…**: {len(engineered_df.select_dtypes(include=[np.number]).columns)} ìˆ«ìí˜•, {len(engineered_df.select_dtypes(include=['object']).columns)} ë²”ì£¼í˜•
"""
        
        function_info = ""
        if engineer_function:
            function_info = f"""

## ğŸ’» **ìƒì„±ëœ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ í•¨ìˆ˜**
```python
{engineer_function}
```
"""
        
        steps_info = ""
        if recommended_steps:
            steps_info = f"""

## ğŸ“‹ **ì¶”ì²œ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ë‹¨ê³„**
{recommended_steps}
"""
        
        workflow_info = ""
        if workflow_summary:
            workflow_info = f"""

## ğŸ”„ **ì›Œí¬í”Œë¡œìš° ìš”ì•½**
{workflow_summary}
"""
        
        log_info = ""
        if log_summary:
            log_info = f"""

## ğŸ“„ **ë¡œê·¸ ìš”ì•½**
{log_summary}
"""
        
        target_info = ""
        if target_variable:
            target_info = f"""

## ğŸ¯ **ê°ì§€ëœ íƒ€ê²Ÿ ë³€ìˆ˜**: `{target_variable}`
"""
        
        return f"""# ğŸ”§ **FeatureEngineeringAgent Complete!**

## ğŸ“Š **ì›ë³¸ ë°ì´í„° ì •ë³´**
- **íŒŒì¼ ìœ„ì¹˜**: `{output_path}`
- **ë°ì´í„° í¬ê¸°**: {original_df.shape[0]:,} í–‰ Ã— {original_df.shape[1]:,} ì—´
- **ì»¬ëŸ¼**: {', '.join(original_df.columns.tolist())}
- **ë°ì´í„° íƒ€ì…**: {len(original_df.select_dtypes(include=[np.number]).columns)} ìˆ«ìí˜•, {len(original_df.select_dtypes(include=['object']).columns)} í…ìŠ¤íŠ¸í˜•

{engineered_info}

{target_info}

## ğŸ“ **ìš”ì²­ ë‚´ìš©**
{user_input}

{steps_info}

{workflow_info}

{function_info}

{log_info}

## ğŸ“ˆ **ì›ë³¸ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°**
```
{data_preview}
```

## ğŸ”— **FeatureEngineeringAgent 8ê°œ í•µì‹¬ ê¸°ëŠ¥ë“¤**
1. **convert_data_types()** - ë°ì´í„° íƒ€ì… ìµœì í™” ë° ë³€í™˜
2. **remove_unique_features()** - ê³ ìœ ê°’ ë° ìƒìˆ˜ í”¼ì²˜ ì œê±°
3. **encode_categorical()** - ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”© (ì›í•«/ë¼ë²¨)
4. **handle_high_cardinality()** - ê³ ì°¨ì› ë²”ì£¼í˜• ë³€ìˆ˜ ì²˜ë¦¬
5. **create_datetime_features()** - ë‚ ì§œ/ì‹œê°„ ê¸°ë°˜ í”¼ì²˜ ìƒì„±
6. **scale_numeric_features()** - ìˆ˜ì¹˜í˜• í”¼ì²˜ ì •ê·œí™”/í‘œì¤€í™”
7. **create_interaction_features()** - ìƒí˜¸ì‘ìš© ë° ë‹¤í•­ í”¼ì²˜ ìƒì„±
8. **handle_target_encoding()** - íƒ€ê²Ÿ ë³€ìˆ˜ ì¸ì½”ë”© ë° ì²˜ë¦¬

âœ… **ì›ë³¸ ai-data-science-team FeatureEngineeringAgent 100% ê¸°ëŠ¥ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!**
"""
    
    def _format_fallback_result(self, original_df, engineered_df, user_input, 
                               output_path, engineering_actions) -> str:
        """í´ë°± ê²°ê³¼ í¬ë§·íŒ…"""
        
        data_preview = original_df.head().to_string()
        engineered_preview = engineered_df.head().to_string()
        
        actions_text = "\n".join([f"- {action}" for action in engineering_actions]) if engineering_actions else "- ê¸°ë³¸ ë°ì´í„° ê²€ì¦ë§Œ ìˆ˜í–‰"
        
        return f"""# ğŸ”§ **Feature Engineering Complete (Fallback Mode)!**

## ğŸ“Š **í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ê²°ê³¼**
- **íŒŒì¼ ìœ„ì¹˜**: `{output_path}`
- **ì›ë³¸ í¬ê¸°**: {original_df.shape[0]:,} í–‰ Ã— {original_df.shape[1]:,} ì—´
- **ì—”ì§€ë‹ˆì–´ë§ í›„ í¬ê¸°**: {engineered_df.shape[0]:,} í–‰ Ã— {engineered_df.shape[1]:,} ì—´
- **ì²˜ë¦¬ ê²°ê³¼**: {len(engineering_actions)}ê°œ ì‘ì—… ìˆ˜í–‰

## ğŸ“ **ìš”ì²­ ë‚´ìš©**
{user_input}

## ğŸ”§ **ìˆ˜í–‰ëœ ì—”ì§€ë‹ˆì–´ë§ ì‘ì—…**
{actions_text}

## ğŸ“Š **ë°ì´í„° íƒ€ì… ë¶„ì„**
- **ìˆ«ìí˜• í”¼ì²˜**: {len(original_df.select_dtypes(include=[np.number]).columns)} ê°œ
- **ë²”ì£¼í˜• í”¼ì²˜**: {len(original_df.select_dtypes(include=['object']).columns)} ê°œ
- **ê²°ì¸¡ê°’**: {original_df.isnull().sum().sum()} ê°œ

## ğŸ“ˆ **ì›ë³¸ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°**
```
{data_preview}
```

## ğŸ”§ **ì—”ì§€ë‹ˆì–´ë§ëœ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°**
```
{engineered_preview}
```

âš ï¸ **í´ë°± ëª¨ë“œ**: ì›ë³¸ ai-data-science-team íŒ¨í‚¤ì§€ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ì–´ ê¸°ë³¸ ì—”ì§€ë‹ˆì–´ë§ë§Œ ìˆ˜í–‰ë˜ì—ˆìŠµë‹ˆë‹¤.
ğŸ’¡ **ì™„ì „í•œ ê¸°ëŠ¥ì„ ìœ„í•´ì„œëŠ” ì›ë³¸ FeatureEngineeringAgent ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.**
"""
    
    def _generate_feature_engineering_guidance(self, user_instructions: str) -> str:
        """í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ê°€ì´ë“œ ì œê³µ"""
        return f"""# ğŸ”§ **FeatureEngineeringAgent ê°€ì´ë“œ**

## ğŸ“ **ìš”ì²­ ë‚´ìš©**
{user_instructions}

## ğŸ¯ **FeatureEngineeringAgent ì™„ì „ ê°€ì´ë“œ**

### 1. **í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ í•µì‹¬ ê°œë…**
í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ì€ ì›ì‹œ ë°ì´í„°ë¥¼ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì— ìµœì í™”ëœ í”¼ì²˜ë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤:

- **ë°ì´í„° ì „ì²˜ë¦¬**: íƒ€ì… ë³€í™˜, ê²°ì¸¡ê°’ ì²˜ë¦¬
- **í”¼ì²˜ ì„ íƒ**: ë¶ˆí•„ìš”í•œ í”¼ì²˜ ì œê±°
- **í”¼ì²˜ ë³€í™˜**: ì¸ì½”ë”©, ìŠ¤ì¼€ì¼ë§, ì •ê·œí™”
- **í”¼ì²˜ ìƒì„±**: ìƒí˜¸ì‘ìš©, ë‹¤í•­ì‹, íŒŒìƒ í”¼ì²˜

### 2. **8ê°œ í•µì‹¬ ê¸°ëŠ¥**
1. ğŸ”„ **convert_data_types** - ë°ì´í„° íƒ€ì… ìµœì í™”
2. ğŸ—‘ï¸ **remove_unique_features** - ê³ ìœ ê°’/ìƒìˆ˜ í”¼ì²˜ ì œê±°
3. ğŸ·ï¸ **encode_categorical** - ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©
4. ğŸ“Š **handle_high_cardinality** - ê³ ì°¨ì› ë²”ì£¼í˜• ì²˜ë¦¬
5. â° **create_datetime_features** - ì‹œê°„ ê¸°ë°˜ í”¼ì²˜ ìƒì„±
6. ğŸ“ **scale_numeric_features** - ìˆ˜ì¹˜í˜• í”¼ì²˜ ìŠ¤ì¼€ì¼ë§
7. ğŸ”— **create_interaction_features** - ìƒí˜¸ì‘ìš© í”¼ì²˜ ìƒì„±
8. ğŸ¯ **handle_target_encoding** - íƒ€ê²Ÿ ë³€ìˆ˜ ì¸ì½”ë”©

### 3. **í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ì‘ì—… ì˜ˆì‹œ**

#### ğŸ”„ **ë°ì´í„° íƒ€ì… ìµœì í™”**
```text
ë°ì´í„° íƒ€ì…ì„ ë©”ëª¨ë¦¬ íš¨ìœ¨ì ìœ¼ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”
```

#### ğŸ·ï¸ **ë²”ì£¼í˜• ì¸ì½”ë”©**
```text
ë²”ì£¼í˜• ë³€ìˆ˜ë“¤ì„ ì›í•« ì¸ì½”ë”©ìœ¼ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”
```

#### ğŸ“ **í”¼ì²˜ ìŠ¤ì¼€ì¼ë§**
```text
ìˆ˜ì¹˜í˜• í”¼ì²˜ë“¤ì„ í‘œì¤€í™”í•´ì£¼ì„¸ìš”
```

### 4. **ì§€ì›ë˜ëŠ” ì—”ì§€ë‹ˆì–´ë§ ê¸°ë²•**
- **ì¸ì½”ë”©**: OneHot, Label, Target, Frequency
- **ìŠ¤ì¼€ì¼ë§**: Standard, MinMax, Robust Scaler
- **ë³€í™˜**: Log, Square Root, Box-Cox
- **í”¼ì²˜ ìƒì„±**: ë‹¤í•­ì‹, ìƒí˜¸ì‘ìš©, ë¹„ë‹
- **ì°¨ì› ì¶•ì†Œ**: PCA, í”¼ì²˜ ì„ íƒ
- **ì‹œê³„ì—´**: ì‹œì°¨, ì´ë™í‰ê· , ê³„ì ˆì„±

### 5. **ì›ë³¸ FeatureEngineeringAgent íŠ¹ì§•**
- **ìë™ íƒ€ì… ê°ì§€**: ìµœì  ë°ì´í„° íƒ€ì… ìë™ ì„ íƒ
- **íƒ€ê²Ÿ ì¸ì‹**: íƒ€ê²Ÿ ë³€ìˆ˜ ìë™ ê°ì§€ ë° ì²˜ë¦¬
- **ìŠ¤ë§ˆíŠ¸ ì¸ì½”ë”©**: ì¹´ë””ë„ë¦¬í‹° ê¸°ë°˜ ìµœì  ì¸ì½”ë”©
- **ë©”ëª¨ë¦¬ ìµœì í™”**: íš¨ìœ¨ì ì¸ ë°ì´í„° íƒ€ì… ì‚¬ìš©

## ğŸ’¡ **ë°ì´í„°ë¥¼ í¬í•¨í•´ì„œ ë‹¤ì‹œ ìš”ì²­í•˜ë©´ ì‹¤ì œ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ì‘ì—…ì„ ìˆ˜í–‰í•´ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤!**

**ë°ì´í„° í˜•ì‹ ì˜ˆì‹œ**:
- **CSV**: `id,age,category,target\\n1,25,A,1\\n2,30,B,0`
- **JSON**: `[{{"id": 1, "age": 25, "category": "A", "target": 1}}]`

### ğŸ”— **í•™ìŠµ ë¦¬ì†ŒìŠ¤**
- scikit-learn ì „ì²˜ë¦¬: https://scikit-learn.org/stable/modules/preprocessing.html
- í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ê°€ì´ë“œ: https://scikit-learn.org/stable/modules/feature_extraction.html
- pandas ë°ì´í„° ë³€í™˜: https://pandas.pydata.org/docs/user_guide/reshaping.html

âœ… **FeatureEngineeringAgent ì¤€ë¹„ ì™„ë£Œ!**
"""


class FeatureEngineeringAgentExecutor(AgentExecutor):
    """Feature Engineering Agent A2A Executor"""
    
    def __init__(self):
        self.agent = FeatureEngineeringServerAgent()
        
        # Langfuse í†µí•© ì´ˆê¸°í™”
        self.langfuse_tracer = None
        if LANGFUSE_AVAILABLE:
            try:
                self.langfuse_tracer = SessionBasedTracer()
                if self.langfuse_tracer.langfuse:
                    logger.info("âœ… FeatureEngineeringAgent Langfuse í†µí•© ì™„ë£Œ")
                else:
                    logger.warning("âš ï¸ Langfuse ì„¤ì • ëˆ„ë½ - ê¸°ë³¸ ëª¨ë“œë¡œ ì‹¤í–‰")
            except Exception as e:
                logger.error(f"âŒ Langfuse ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self.langfuse_tracer = None
        
        logger.info("ğŸ¤– Feature Engineering Agent Executor ì´ˆê¸°í™” ì™„ë£Œ")
    
    async def execute(self, context: RequestContext, event_queue: EventQueue) -> None:
        """A2A SDK 0.2.9 ê³µì‹ íŒ¨í„´ì— ë”°ë¥¸ ì‹¤í–‰ with Langfuse integration"""
        logger.info(f"ğŸš€ Feature Engineering Agent ì‹¤í–‰ ì‹œì‘ - Task: {context.task_id}")
        
        # TaskUpdater ì´ˆê¸°í™”
        task_updater = TaskUpdater(event_queue, context.task_id, context.context_id)
        
        # Langfuse ë©”ì¸ íŠ¸ë ˆì´ìŠ¤ ì‹œì‘
        main_trace = None
        if self.langfuse_tracer and self.langfuse_tracer.langfuse:
            try:
                # ì „ì²´ ì‚¬ìš©ì ì¿¼ë¦¬ ì¶”ì¶œ
                full_user_query = ""
                if context.message and hasattr(context.message, 'parts') and context.message.parts:
                    for part in context.message.parts:
                        if hasattr(part, 'root') and part.root.kind == "text":
                            full_user_query += part.root.text + " "
                        elif hasattr(part, 'text'):
                            full_user_query += part.text + " "
                full_user_query = full_user_query.strip()
                
                # ë©”ì¸ íŠ¸ë ˆì´ìŠ¤ ìƒì„± (task_idë¥¼ íŠ¸ë ˆì´ìŠ¤ IDë¡œ ì‚¬ìš©)
                main_trace = self.langfuse_tracer.langfuse.trace(
                    id=context.task_id,
                    name="FeatureEngineeringAgent_Execution",
                    input=full_user_query,
                    user_id="2055186",
                    metadata={
                        "agent": "FeatureEngineeringAgent",
                        "port": 8310,
                        "context_id": context.context_id,
                        "timestamp": str(context.task_id),
                        "server_type": "new_wrapper_based"
                    }
                )
                logger.info(f"ğŸ”§ Langfuse ë©”ì¸ íŠ¸ë ˆì´ìŠ¤ ì‹œì‘: {context.task_id}")
            except Exception as e:
                logger.warning(f"âš ï¸ Langfuse íŠ¸ë ˆì´ìŠ¤ ìƒì„± ì‹¤íŒ¨: {e}")
        
        try:
            await task_updater.submit()
            await task_updater.start_work()
            
            # 1ë‹¨ê³„: ìš”ì²­ íŒŒì‹± (Langfuse ì¶”ì )
            parsing_span = None
            if main_trace:
                parsing_span = self.langfuse_tracer.langfuse.span(
                    trace_id=context.task_id,
                    name="request_parsing",
                    input={"user_request": full_user_query[:500]},
                    metadata={"step": "1", "description": "Parse feature engineering request"}
                )
            
            await task_updater.update_status(
                TaskState.working,
                message=new_agent_text_message("ğŸ¤– FeatureEngineeringAgent ì‹œì‘...")
            )
            
            # A2A SDK 0.2.9 ê³µì‹ íŒ¨í„´ì— ë”°ë¥¸ ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ì¶œ
            user_instructions = ""
            if context.message and context.message.parts:
                for part in context.message.parts:
                    if part.root.kind == "text":
                        user_instructions += part.root.text + " "
                
                user_instructions = user_instructions.strip()
                logger.info(f"ğŸ“ ì‚¬ìš©ì ìš”ì²­: {user_instructions}")
                
                # íŒŒì‹± ê²°ê³¼ ì—…ë°ì´íŠ¸
                if parsing_span:
                    parsing_span.update(
                        output={
                            "success": True,
                            "query_extracted": user_instructions[:200],
                            "request_length": len(user_instructions),
                            "engineering_type": "feature_transformation"
                        }
                    )
                
                if not user_instructions:
                    await task_updater.update_status(
                        TaskState.completed,
                        message=new_agent_text_message("âŒ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ìš”ì²­ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                    )
                    return
                
                # 2ë‹¨ê³„: í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ì‹¤í–‰ (Langfuse ì¶”ì )
                engineering_span = None
                if main_trace:
                    engineering_span = self.langfuse_tracer.langfuse.span(
                        trace_id=context.task_id,
                        name="feature_engineering",
                        input={
                            "query": user_instructions[:200],
                            "engineering_type": "wrapper_based_processing"
                        },
                        metadata={"step": "2", "description": "Execute feature engineering with optimized wrapper"}
                    )
                
                # í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ì²˜ë¦¬ ì‹¤í–‰
                result = await self.agent.process_feature_engineering(user_instructions)
                
                # ì—”ì§€ë‹ˆì–´ë§ ê²°ê³¼ ì—…ë°ì´íŠ¸
                if engineering_span:
                    engineering_span.update(
                        output={
                            "success": True,
                            "result_length": len(result),
                            "features_created": True,
                            "transformation_applied": True,
                            "execution_method": "optimized_wrapper"
                        }
                    )
                
                # 3ë‹¨ê³„: ê²°ê³¼ ì €ì¥/ë°˜í™˜ (Langfuse ì¶”ì )
                save_span = None
                if main_trace:
                    save_span = self.langfuse_tracer.langfuse.span(
                        trace_id=context.task_id,
                        name="save_results",
                        input={
                            "result_size": len(result),
                            "engineering_success": True
                        },
                        metadata={"step": "3", "description": "Prepare feature engineering results"}
                    )
                
                # ì €ì¥ ê²°ê³¼ ì—…ë°ì´íŠ¸
                if save_span:
                    save_span.update(
                        output={
                            "response_prepared": True,
                            "features_delivered": True,
                            "final_status": "completed",
                            "transformations_included": True
                        }
                    )
                
                # ì‘ì—… ì™„ë£Œ
                await task_updater.update_status(
                    TaskState.completed,
                    message=new_agent_text_message(result)
                )
                
            else:
                await task_updater.update_status(
                    TaskState.completed,
                    message=new_agent_text_message("âŒ ë©”ì‹œì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                )
            
            # Langfuse ë©”ì¸ íŠ¸ë ˆì´ìŠ¤ ì™„ë£Œ
            if main_trace:
                try:
                    # Outputì„ ìš”ì•½ëœ í˜•íƒœë¡œ ì œê³µ
                    output_summary = {
                        "status": "completed",
                        "result_preview": result[:1000] + "..." if len(result) > 1000 else result,
                        "full_result_length": len(result)
                    }
                    
                    main_trace.update(
                        output=output_summary,
                        metadata={
                            "status": "completed",
                            "result_length": len(result),
                            "success": True,
                            "completion_timestamp": str(context.task_id),
                            "agent": "FeatureEngineeringAgent",
                            "port": 8310,
                            "server_type": "new_wrapper_based",
                            "engineering_type": "feature_transformation"
                        }
                    )
                    logger.info(f"ğŸ”§ Langfuse íŠ¸ë ˆì´ìŠ¤ ì™„ë£Œ: {context.task_id}")
                except Exception as e:
                    logger.warning(f"âš ï¸ Langfuse íŠ¸ë ˆì´ìŠ¤ ì™„ë£Œ ì‹¤íŒ¨: {e}")
                
        except Exception as e:
            logger.error(f"âŒ Feature Engineering Agent ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            
            # Langfuse ë©”ì¸ íŠ¸ë ˆì´ìŠ¤ ì˜¤ë¥˜ ê¸°ë¡
            if main_trace:
                try:
                    main_trace.update(
                        output=f"Error: {str(e)}",
                        metadata={
                            "status": "failed",
                            "error": str(e),
                            "error_type": type(e).__name__,
                            "success": False,
                            "agent": "FeatureEngineeringAgent",
                            "port": 8310,
                            "server_type": "new_wrapper_based"
                        }
                    )
                except Exception as langfuse_error:
                    logger.warning(f"âš ï¸ Langfuse ì˜¤ë¥˜ ê¸°ë¡ ì‹¤íŒ¨: {langfuse_error}")
            
            await task_updater.update_status(
                TaskState.completed,
                message=new_agent_text_message(f"âŒ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            )
    
    async def cancel(self, context: RequestContext, event_queue: EventQueue) -> None:
        """ì‘ì—… ì·¨ì†Œ"""
        logger.info(f"ğŸš« Feature Engineering Agent ì‘ì—… ì·¨ì†Œ - Task: {context.task_id}")


def main():
    """Feature Engineering Agent ì„œë²„ ìƒì„± ë° ì‹¤í–‰"""
    
    # AgentSkill ì •ì˜
    skill = AgentSkill(
        id="feature_engineering",
        name="Feature Engineering and Transformation",
        description="ì›ë³¸ ai-data-science-team FeatureEngineeringAgentë¥¼ í™œìš©í•œ ì™„ì „í•œ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤. 8ê°œ í•µì‹¬ ê¸°ëŠ¥ìœ¼ë¡œ ë°ì´í„° íƒ€ì… ìµœì í™”, ì¸ì½”ë”©, ìŠ¤ì¼€ì¼ë§ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.",
        tags=["feature-engineering", "preprocessing", "encoding", "scaling", "transformation", "ai-data-science-team"],
        examples=[
            "ë°ì´í„° íƒ€ì…ì„ ìµœì í™”í•´ì£¼ì„¸ìš”",
            "ë²”ì£¼í˜• ë³€ìˆ˜ë¥¼ ì¸ì½”ë”©í•´ì£¼ì„¸ìš”",  
            "ìˆ˜ì¹˜í˜• í”¼ì²˜ë¥¼ í‘œì¤€í™”í•´ì£¼ì„¸ìš”",
            "ê³ ìœ ê°’ í”¼ì²˜ë¥¼ ì œê±°í•´ì£¼ì„¸ìš”",
            "ì‹œê°„ ê¸°ë°˜ í”¼ì²˜ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”",
            "ìƒí˜¸ì‘ìš© í”¼ì²˜ë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”",
            "ê³ ì°¨ì› ë²”ì£¼í˜•ì„ ì²˜ë¦¬í•´ì£¼ì„¸ìš”",
            "íƒ€ê²Ÿ ë³€ìˆ˜ë¥¼ ì¸ì½”ë”©í•´ì£¼ì„¸ìš”"
        ]
    )
    
    # Agent Card ì •ì˜
    agent_card = AgentCard(
        name="Feature Engineering Agent",
        description="ì›ë³¸ ai-data-science-team FeatureEngineeringAgentë¥¼ A2A SDKë¡œ ë˜í•‘í•œ ì™„ì „í•œ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ì„œë¹„ìŠ¤. 8ê°œ í•µì‹¬ ê¸°ëŠ¥ìœ¼ë¡œ ë°ì´í„° íƒ€ì… ìµœì í™”, ì¸ì½”ë”©, ìŠ¤ì¼€ì¼ë§, í”¼ì²˜ ìƒì„±ì„ ì§€ì›í•©ë‹ˆë‹¤.",
        url="http://localhost:8310/",
        version="1.0.0",
        defaultInputModes=["text"],
        defaultOutputModes=["text"],
        capabilities=AgentCapabilities(streaming=False),
        skills=[skill],
        supportsAuthenticatedExtendedCard=False
    )
    
    # Request Handler ìƒì„±
    request_handler = DefaultRequestHandler(
        agent_executor=FeatureEngineeringAgentExecutor(),
        task_store=InMemoryTaskStore(),
    )
    
    # A2A Server ìƒì„±
    server = A2AStarletteApplication(
        agent_card=agent_card,
        http_handler=request_handler,
    )
    
    print("ğŸ”§ Starting Feature Engineering Agent Server")
    print("ğŸŒ Server starting on http://localhost:8310")
    print("ğŸ“‹ Agent card: http://localhost:8310/.well-known/agent.json")
    print("ğŸ¯ Features: ì›ë³¸ ai-data-science-team FeatureEngineeringAgent 8ê°œ ê¸°ëŠ¥ 100% ë˜í•‘")
    print("ğŸ’¡ Feature Engineering: íƒ€ì… ìµœì í™”, ì¸ì½”ë”©, ìŠ¤ì¼€ì¼ë§, í”¼ì²˜ ìƒì„±, ë³€í™˜")
    
    uvicorn.run(server.build(), host="0.0.0.0", port=8310, log_level="info")


if __name__ == "__main__":
    main()