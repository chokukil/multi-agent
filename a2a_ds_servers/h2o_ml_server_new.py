#!/usr/bin/env python3
"""
H2OMLServerAgent - A2A SDK 0.2.9 ê¸°ë°˜ H2O ë¨¸ì‹ ëŸ¬ë‹ ì„œë²„

ì›ë³¸ ai-data-science-team H2OMLAgentë¥¼ A2A í”„ë¡œí† ì½œë¡œ ë˜í•‘í•œ ì„œë²„ì…ë‹ˆë‹¤.
H2O AutoMLì„ í™œìš©í•œ ìë™ ë¨¸ì‹ ëŸ¬ë‹ ë° ëª¨ë¸ í•™ìŠµ/ë°°í¬ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.

Port: 8313
Agent: H2OMLAgent
Functions: 8ê°œ (run_automl, train_classification_models, train_regression_models, 
           evaluate_models, tune_hyperparameters, analyze_feature_importance,
           interpret_models, deploy_models)
"""

import asyncio
import logging
import uvicorn
import sys
import os
from pathlib import Path
from typing import Dict, Any

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# A2A SDK ì„í¬íŠ¸
from a2a.server.apps import A2AStarletteApplication
from a2a.server.request_handlers import DefaultRequestHandler
from a2a.server.tasks import InMemoryTaskStore, TaskUpdater
from a2a.server.agent_execution import AgentExecutor, RequestContext
from a2a.server.events import EventQueue
from a2a.types import AgentCard, AgentSkill, AgentCapabilities, TaskState
from a2a.utils import new_agent_text_message

# ë¡œì»¬ ëª¨ë“ˆ ì„í¬íŠ¸
from a2a_ds_servers.base.h2o_ml_a2a_wrapper import H2OMLA2AExecutor

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Langfuse í†µí•© ëª¨ë“ˆ ì„í¬íŠ¸
try:
    from core.universal_engine.langfuse_integration import SessionBasedTracer, LangfuseEnhancedA2AExecutor
    LANGFUSE_AVAILABLE = True
    logger.info("âœ… Langfuse í†µí•© ëª¨ë“ˆ ë¡œë“œ ì„±ê³µ")
except ImportError as e:
    LANGFUSE_AVAILABLE = False
    logger.warning(f"âš ï¸ Langfuse í†µí•© ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")


class H2OMLServerAgent(AgentExecutor):
    """H2O ë¨¸ì‹ ëŸ¬ë‹ A2A ì„œë²„ ì—ì´ì „íŠ¸"""
    
    def __init__(self):
        self.executor = H2OMLA2AExecutor()
        
        # Langfuse í†µí•© ì´ˆê¸°í™”
        self.langfuse_tracer = None
        if LANGFUSE_AVAILABLE:
            try:
                self.langfuse_tracer = SessionBasedTracer()
                if self.langfuse_tracer.langfuse:
                    logger.info("âœ… H2OMLAgent Langfuse í†µí•© ì™„ë£Œ")
                else:
                    logger.warning("âš ï¸ Langfuse ì„¤ì • ëˆ„ë½ - ê¸°ë³¸ ëª¨ë“œë¡œ ì‹¤í–‰")
            except Exception as e:
                logger.error(f"âŒ Langfuse ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self.langfuse_tracer = None
        
        logger.info("ğŸ¤– H2OMLServerAgent ì´ˆê¸°í™” ì™„ë£Œ")
        logger.info("ğŸ”¬ H2O AutoML ê¸°ë°˜ ë¨¸ì‹ ëŸ¬ë‹ ì„œë²„ ì‹œì‘")
        logger.info("âš¡ 8ê°œ í•µì‹¬ ML ê¸°ëŠ¥ í™œì„±í™”")
    
    async def process_h2o_ml_analysis(self, user_input: str) -> str:
        """H2O ML ë¶„ì„ ì²˜ë¦¬ ì‹¤í–‰ (í…ŒìŠ¤íŠ¸ìš© í—¬í¼ ë©”ì„œë“œ)"""
        try:
            logger.info(f"ğŸš€ H2O ML ë¶„ì„ ìš”ì²­ ì²˜ë¦¬: {user_input[:100]}...")
            
            # wrapper agentê°€ ìˆëŠ”ì§€ í™•ì¸
            if hasattr(self.executor, 'agent') and self.executor.agent:
                # wrapper agentì˜ process_request ë©”ì„œë“œ í˜¸ì¶œ
                result = await self.executor.agent.process_request(user_input)
                return result
            else:
                # í´ë°± ì‘ë‹µ
                return self._generate_h2o_ml_guidance(user_input)
                
        except Exception as e:
            logger.error(f"H2O ML ë¶„ì„ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return f"H2O ML ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    def _generate_h2o_ml_guidance(self, user_input: str) -> str:
        """H2O ML ê°€ì´ë“œ ìƒì„± (í´ë°±ìš©)"""
        return f"""# ğŸ¤– **H2OMLAgent ê°€ì´ë“œ**

## ğŸ“ **ìš”ì²­ ë‚´ìš©**
{user_input}

## ğŸ¯ **H2O AutoML ì™„ì „ ê°€ì´ë“œ**

### 1. **H2O AutoML í•µì‹¬ ê°œë…**
H2O AutoMLì€ ìë™ìœ¼ë¡œ ì—¬ëŸ¬ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì„ í•™ìŠµí•˜ê³  ìµœì ì˜ ëª¨ë¸ì„ ì°¾ì•„ì£¼ëŠ” ë„êµ¬ì…ë‹ˆë‹¤:
- **ìë™ ëª¨ë¸ ì„ íƒ**: GBM, Random Forest, Deep Learning, GLM, XGBoost ë“±
- **ìë™ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹**: Grid Search, Random Search
- **ì•™ìƒë¸” ìƒì„±**: Stackingì„ í†µí•œ ëª¨ë¸ ê²°í•©
- **ë¦¬ë”ë³´ë“œ**: ëª¨ë“  ëª¨ë¸ì˜ ì„±ëŠ¥ ë¹„êµ

### 2. **8ê°œ í•µì‹¬ ê¸°ëŠ¥**
1. **run_automl()** - ìë™ ë¨¸ì‹ ëŸ¬ë‹ ì‹¤í–‰
2. **train_classification_models()** - ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ
3. **train_regression_models()** - íšŒê·€ ëª¨ë¸ í•™ìŠµ
4. **evaluate_models()** - ëª¨ë¸ í‰ê°€ ë° ì„±ëŠ¥ ì§€í‘œ
5. **tune_hyperparameters()** - í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
6. **analyze_feature_importance()** - í”¼ì²˜ ì¤‘ìš”ë„ ë¶„ì„
7. **interpret_models()** - ëª¨ë¸ í•´ì„ ë° ì„¤ëª…
8. **deploy_models()** - ëª¨ë¸ ë°°í¬ ë° ì €ì¥

âœ… **H2OMLAgent ì¤€ë¹„ ì™„ë£Œ!**
"""
    
    async def execute(self, context: RequestContext, event_queue: EventQueue) -> None:
        """H2O ML ìš”ì²­ ì²˜ë¦¬ ë° ì‹¤í–‰ with Langfuse integration"""
        task_updater = TaskUpdater(event_queue, context.task_id, context.context_id)
        
        # Langfuse ë©”ì¸ íŠ¸ë ˆì´ìŠ¤ ì‹œì‘
        main_trace = None
        if self.langfuse_tracer and self.langfuse_tracer.langfuse:
            try:
                # ì „ì²´ ì‚¬ìš©ì ì¿¼ë¦¬ ì¶”ì¶œ
                full_user_query = ""
                if context.message and hasattr(context.message, 'parts') and context.message.parts:
                    for part in context.message.parts:
                        if hasattr(part, 'root') and part.root.kind == "text":
                            full_user_query += part.root.text + " "
                        elif hasattr(part, 'text'):
                            full_user_query += part.text + " "
                full_user_query = full_user_query.strip()
                
                # ë©”ì¸ íŠ¸ë ˆì´ìŠ¤ ìƒì„± (task_idë¥¼ íŠ¸ë ˆì´ìŠ¤ IDë¡œ ì‚¬ìš©)
                main_trace = self.langfuse_tracer.langfuse.trace(
                    id=context.task_id,
                    name="H2OMLAgent_Execution",
                    input=full_user_query,
                    user_id="2055186",
                    metadata={
                        "agent": "H2OMLAgent",
                        "port": 8313,
                        "context_id": context.context_id,
                        "timestamp": str(context.task_id),
                        "server_type": "wrapper_based"
                    }
                )
                logger.info(f"ğŸ”§ Langfuse ë©”ì¸ íŠ¸ë ˆì´ìŠ¤ ì‹œì‘: {context.task_id}")
            except Exception as e:
                logger.warning(f"âš ï¸ Langfuse íŠ¸ë ˆì´ìŠ¤ ìƒì„± ì‹¤íŒ¨: {e}")
        
        try:
            # ì‘ì—… ì‹œì‘
            await task_updater.submit()
            await task_updater.start_work()
            
            # 1ë‹¨ê³„: ìš”ì²­ íŒŒì‹± (Langfuse ì¶”ì )
            parsing_span = None
            if main_trace:
                parsing_span = self.langfuse_tracer.langfuse.span(
                    trace_id=context.task_id,
                    name="request_parsing",
                    input={"user_request": full_user_query[:500]},
                    metadata={"step": "1", "description": "Parse H2O ML request"}
                )
            
            # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ì¶œ
            user_message = ""
            if context.message and context.message.parts:
                for part in context.message.parts:
                    if part.root.kind == "text":
                        user_message += part.root.text
            
            logger.info(f"ğŸ“ H2O ML ìš”ì²­: {user_message[:100]}...")
            
            # íŒŒì‹± ê²°ê³¼ ì—…ë°ì´íŠ¸
            if parsing_span:
                parsing_span.update(
                    output={
                        "success": True,
                        "query_extracted": user_message[:200],
                        "request_length": len(user_message),
                        "ml_type": "h2o_automl"
                    }
                )
            
            # 2ë‹¨ê³„: H2O ML ë¶„ì„ ì‹¤í–‰ (Langfuse ì¶”ì )
            ml_span = None
            if main_trace:
                ml_span = self.langfuse_tracer.langfuse.span(
                    trace_id=context.task_id,
                    name="h2o_ml_analysis",
                    input={
                        "query": user_message[:200],
                        "ml_type": "h2o_automl_analysis"
                    },
                    metadata={"step": "2", "description": "Execute H2O AutoML analysis"}
                )
            
            # H2O ML ë¶„ì„ ì‹¤í–‰ (wrapper agentë¥¼ í†µí•´ ì ‘ê·¼)
            result = await self.executor.agent.process_request(user_message)
            
            # ML ë¶„ì„ ê²°ê³¼ ì—…ë°ì´íŠ¸
            if ml_span:
                ml_span.update(
                    output={
                        "success": True,
                        "result_length": len(result),
                        "models_created": True,
                        "analysis_completed": True,
                        "execution_method": "h2o_wrapper"
                    }
                )
            
            # 3ë‹¨ê³„: ê²°ê³¼ ì €ì¥/ë°˜í™˜ (Langfuse ì¶”ì )
            save_span = None
            if main_trace:
                save_span = self.langfuse_tracer.langfuse.span(
                    trace_id=context.task_id,
                    name="save_results",
                    input={
                        "result_size": len(result),
                        "ml_success": True
                    },
                    metadata={"step": "3", "description": "Prepare H2O ML results"}
                )
            
            # ì €ì¥ ê²°ê³¼ ì—…ë°ì´íŠ¸
            if save_span:
                save_span.update(
                    output={
                        "response_prepared": True,
                        "models_delivered": True,
                        "final_status": "completed",
                        "ml_analysis_included": True
                    }
                )
            
            # ì„±ê³µ ì‘ë‹µ
            await task_updater.update_status(
                TaskState.completed,
                message=new_agent_text_message(result)
            )
            
            logger.info("âœ… H2O ML ë¶„ì„ ì™„ë£Œ")
            
            # Langfuse ë©”ì¸ íŠ¸ë ˆì´ìŠ¤ ì™„ë£Œ
            if main_trace:
                try:
                    # Outputì„ ìš”ì•½ëœ í˜•íƒœë¡œ ì œê³µ
                    output_summary = {
                        "status": "completed",
                        "result_preview": result[:1000] + "..." if len(result) > 1000 else result,
                        "full_result_length": len(result)
                    }
                    
                    main_trace.update(
                        output=output_summary,
                        metadata={
                            "status": "completed",
                            "result_length": len(result),
                            "success": True,
                            "completion_timestamp": str(context.task_id),
                            "agent": "H2OMLAgent",
                            "port": 8313,
                            "server_type": "wrapper_based",
                            "ml_type": "h2o_automl"
                        }
                    )
                    logger.info(f"ğŸ”§ Langfuse íŠ¸ë ˆì´ìŠ¤ ì™„ë£Œ: {context.task_id}")
                except Exception as e:
                    logger.warning(f"âš ï¸ Langfuse íŠ¸ë ˆì´ìŠ¤ ì™„ë£Œ ì‹¤íŒ¨: {e}")
            
        except Exception as e:
            error_msg = f"H2O ML ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            logger.error(f"âŒ {error_msg}")
            
            # Langfuse ë©”ì¸ íŠ¸ë ˆì´ìŠ¤ ì˜¤ë¥˜ ê¸°ë¡
            if main_trace:
                try:
                    main_trace.update(
                        output=f"Error: {str(e)}",
                        metadata={
                            "status": "failed",
                            "error": str(e),
                            "error_type": type(e).__name__,
                            "success": False,
                            "agent": "H2OMLAgent",
                            "port": 8313,
                            "server_type": "wrapper_based"
                        }
                    )
                except Exception as langfuse_error:
                    logger.warning(f"âš ï¸ Langfuse ì˜¤ë¥˜ ê¸°ë¡ ì‹¤íŒ¨: {langfuse_error}")
            
            await task_updater.update_status(
                TaskState.failed,
                message=new_agent_text_message(error_msg)
            )
    
    async def cancel(self, context: RequestContext, event_queue: EventQueue) -> None:
        """ì‘ì—… ì·¨ì†Œ ì²˜ë¦¬"""
        task_updater = TaskUpdater(event_queue, context.task_id, context.context_id)
        await task_updater.reject()
        logger.info("ğŸš« H2O ML ì‘ì—…ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤")


def create_agent_card() -> AgentCard:
    """H2OMLAgentìš© Agent Card ìƒì„±"""
    
    # H2O ML ìŠ¤í‚¬ ì •ì˜
    h2o_ml_skill = AgentSkill(
        id="h2o_ml_analysis",
        name="H2O AutoML Analysis",
        description="H2O.ai AutoMLì„ í™œìš©í•œ ê³ ê¸‰ ë¨¸ì‹ ëŸ¬ë‹ ë¶„ì„ ë° ëª¨ë¸ ê°œë°œ",
        tags=["machine-learning", "automl", "h2o", "classification", "regression", "model-training"],
        examples=[
            "H2O AutoMLë¡œ ë¶„ë¥˜ ëª¨ë¸ì„ í•™ìŠµí•´ì£¼ì„¸ìš”",
            "íšŒê·€ ëª¨ë¸ë“¤ì„ í•™ìŠµí•˜ê³  ì„±ëŠ¥ì„ ë¹„êµí•´ì£¼ì„¸ìš”", 
            "í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ íŠœë‹í•´ì£¼ì„¸ìš”",
            "í”¼ì²˜ ì¤‘ìš”ë„ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”",
            "í•™ìŠµëœ ëª¨ë¸ì„ í•´ì„í•˜ê³  ì„¤ëª…í•´ì£¼ì„¸ìš”",
            "ëª¨ë¸ì„ í”„ë¡œë•ì…˜ ë°°í¬ ì¤€ë¹„í•´ì£¼ì„¸ìš”"
        ]
    )
    
    # Agent Card ìƒì„±
    agent_card = AgentCard(
        name="H2O Machine Learning Agent",
        description="H2O AutoMLì„ í™œìš©í•œ ìë™ ë¨¸ì‹ ëŸ¬ë‹ ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤. ë¶„ë¥˜/íšŒê·€ ëª¨ë¸ í•™ìŠµ, í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹, í”¼ì²˜ ì¤‘ìš”ë„ ë¶„ì„, ëª¨ë¸ í•´ì„ ë° ë°°í¬ê¹Œì§€ ì „ì²´ ML íŒŒì´í”„ë¼ì¸ì„ ì§€ì›í•©ë‹ˆë‹¤.",
        url="http://localhost:8313/",
        version="1.0.0",
        defaultInputModes=["text"],
        defaultOutputModes=["text"],
        capabilities=AgentCapabilities(streaming=False),
        skills=[h2o_ml_skill],
        supportsAuthenticatedExtendedCard=False
    )
    
    return agent_card


def main():
    """ë©”ì¸ ì„œë²„ ì‹¤í–‰ í•¨ìˆ˜"""
    # Agent Card ìƒì„±
    agent_card = create_agent_card()
    
    # Request Handler ìƒì„±  
    request_handler = DefaultRequestHandler(
        agent_executor=H2OMLServerAgent(),
        task_store=InMemoryTaskStore(),
    )
    
    # A2A Server ìƒì„±
    server = A2AStarletteApplication(
        agent_card=agent_card,
        http_handler=request_handler,
    )
    
    # ì„œë²„ ì‹œì‘ ë©”ì‹œì§€
    print("ğŸš€ H2O ML Server ì‹œì‘ ì¤‘...")
    print("ğŸ¤– Agent: H2OMLAgent (H2O AutoML)")
    print("ğŸ”¬ ê¸°ëŠ¥: ìë™ ë¨¸ì‹ ëŸ¬ë‹, ëª¨ë¸ í•™ìŠµ/í‰ê°€/ë°°í¬")
    print("ğŸ“¡ Port: 8313")
    print("ğŸ¯ 8ê°œ í•µì‹¬ ê¸°ëŠ¥:")
    print("   1. run_automl() - ìë™ ë¨¸ì‹ ëŸ¬ë‹ ì‹¤í–‰")
    print("   2. train_classification_models() - ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ")
    print("   3. train_regression_models() - íšŒê·€ ëª¨ë¸ í•™ìŠµ")  
    print("   4. evaluate_models() - ëª¨ë¸ í‰ê°€")
    print("   5. tune_hyperparameters() - í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹")
    print("   6. analyze_feature_importance() - í”¼ì²˜ ì¤‘ìš”ë„ ë¶„ì„")
    print("   7. interpret_models() - ëª¨ë¸ í•´ì„")
    print("   8. deploy_models() - ëª¨ë¸ ë°°í¬")
    print("âœ… H2O ML ì„œë²„ ì¤€ë¹„ ì™„ë£Œ!")
    
    # Uvicorn ì„œë²„ ì‹¤í–‰
    uvicorn.run(
        server.build(),
        host="0.0.0.0", 
        port=8313,
        log_level="info"
    )


if __name__ == "__main__":
    main()