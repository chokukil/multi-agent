#!/usr/bin/env python3
"""
A2A Orchestrator v8.0 - Universal Intelligent Orchestrator
A2A SDK 0.2.9 표준 기능 극대화 + 실시간 스트리밍 혁신
"""

import asyncio
import json
import logging
import os
import re
import time
from datetime import datetime
from typing import Any, Dict, List, Optional, AsyncGenerator, Set

import httpx
import uvicorn
from openai import AsyncOpenAI

# A2A SDK 0.2.9 표준 임포트
from a2a.server.apps import A2AStarletteApplication
from a2a.server.request_handlers import DefaultRequestHandler
from a2a.server.tasks import InMemoryTaskStore, TaskUpdater
from a2a.server.agent_execution import AgentExecutor, RequestContext
from a2a.server.events import EventQueue
from a2a.types import (
    AgentCard,
    AgentSkill,
    AgentCapabilities,
    TaskState,
    TextPart,
    Message,
    Part,
    SendMessageRequest,
    MessageSendParams
)

# A2A 클라이언트 및 디스커버리
from a2a.client import A2ACardResolver, A2AClient

# 로깅 설정
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class RealTimeStreamingTaskUpdater(TaskUpdater):
    """실시간 문자 단위 스트리밍을 지원하는 향상된 TaskUpdater"""
    
    def __init__(self, event_queue: EventQueue, task_id: str, context_id: str):
        super().__init__(event_queue, task_id, context_id)
        self._buffer = ""
        self._last_update_time = 0
        self._min_update_interval = 0.05  # 50ms 최소 간격
    
    async def stream_character(self, char: str):
        """단일 문자 스트리밍 (버퍼링 포함)"""
        self._buffer += char
        current_time = time.time()
        
        # 최소 간격이 지났거나 특정 문자인 경우 즉시 전송
        if (current_time - self._last_update_time >= self._min_update_interval or
            char in ['\n', '.', '!', '?', ':', ';']):
            await self._flush_buffer()
    
    async def stream_chunk(self, chunk: str):
        """청크 단위 스트리밍"""
        for char in chunk:
            await self.stream_character(char)
    
    async def stream_line(self, line: str):
        """라인 단위 스트리밍 (즉시 플러시)"""
        self._buffer += line + '\n'
        await self._flush_buffer()
    
    async def _flush_buffer(self):
        """버퍼 플러시"""
        if self._buffer:
            await self.update_status(
                TaskState.working,
                message=self.new_agent_message(parts=[TextPart(text=self._buffer)])
            )
            self._buffer = ""
            self._last_update_time = time.time()
    
    async def stream_markdown_section(self, section_type: str, content: str):
        """Markdown 섹션별 스트리밍"""
        if section_type == "header":
            await self.stream_line(f"\n{content}\n")
        elif section_type == "bullet":
            await self.stream_line(f"- {content}")
        elif section_type == "code":
            await self.stream_line(f"```\n{content}\n```")
        elif section_type == "quote":
            await self.stream_line(f"> {content}")
        else:
            await self.stream_chunk(content)
    
    async def stream_final_response(self, response: str):
        """최종 응답 완료 (버퍼 플러시 후)"""
        await self._flush_buffer()
        await self.update_status(
            TaskState.completed,
            message=self.new_agent_message(parts=[TextPart(text=response)])
        )
    
    async def stream_from_llm(self, stream: AsyncGenerator):
        """LLM 스트림 직접 연동"""
        try:
            async for chunk in stream:
                if chunk.choices[0].delta.content:
                    await self.stream_chunk(chunk.choices[0].delta.content)
            await self._flush_buffer()
        except Exception as e:
            logger.error(f"LLM streaming error: {e}")
            await self._flush_buffer()


class DynamicAgentDiscovery:
    """A2A CardResolver를 활용한 동적 에이전트 발견 시스템"""
    
    def __init__(self):
        self.discovered_agents = {}
        self.agent_health_status = {}
        self.last_discovery_time = {}
        self.discovery_interval = 60  # 60초마다 재발견
    
    async def discover_all_agents(self, base_ports: List[int] = None) -> Dict[str, Dict]:
        """모든 에이전트 동적 발견"""
        if base_ports is None:
            # AI DS Team 표준 포트 + 추가 스캔 범위
            base_ports = list(range(8300, 8320))
        
        discovered = {}
        
        async with httpx.AsyncClient(timeout=5.0) as client:
            for port in base_ports:
                agent_url = f"http://localhost:{port}"
                
                try:
                    # A2A 표준 에이전트 카드 조회
                    card_resolver = A2ACardResolver(
                        httpx_client=client,
                        base_url=agent_url
                    )
                    agent_card = await card_resolver.get_agent_card()
                    
                    if agent_card:
                        agent_name = agent_card.name
                        
                        discovered[agent_name] = {
                            'url': agent_url,
                            'port': port,
                            'card': agent_card,
                            'skills': [skill.model_dump() for skill in agent_card.skills],
                            'capabilities': agent_card.capabilities.model_dump() if agent_card.capabilities else {},
                            'description': agent_card.description,
                            'version': agent_card.version,
                            'discovered_at': datetime.now().isoformat()
                        }
                        
                        # 헬스 체크
                        health = await self._check_agent_health(agent_url)
                        self.agent_health_status[agent_name] = health
                        
                        logger.info(f"✅ Discovered: {agent_name} on port {port} (Health: {health['status']})")
                        
                except Exception as e:
                    logger.debug(f"Port {port} scan failed: {e}")
        
        self.discovered_agents = discovered
        self.last_discovery_time[datetime.now()] = len(discovered)
        
        logger.info(f"🔍 Total discovered agents: {len(discovered)}")
        return discovered
    
    async def _check_agent_health(self, agent_url: str) -> Dict:
        """에이전트 헬스 체크"""
        try:
            async with httpx.AsyncClient(timeout=3.0) as client:
                start_time = time.time()
                
                # 간단한 헬스 체크 - Agent Card 조회로 대체
                card_resolver = A2ACardResolver(
                    httpx_client=client,
                    base_url=agent_url
                )
                agent_card = await card_resolver.get_agent_card()
                
                response_time = (time.time() - start_time) * 1000  # ms
                
                if agent_card:
                    return {
                        'status': 'healthy',
                        'response_time_ms': round(response_time, 2),
                        'last_check': datetime.now().isoformat()
                    }
                else:
                    return {
                        'status': 'unhealthy',
                        'error': 'No agent card',
                        'last_check': datetime.now().isoformat()
                    }
                    
        except Exception as e:
            return {
                'status': 'unreachable',
                'error': str(e),
                'last_check': datetime.now().isoformat()
            }
    
    async def find_best_agent_for_task(self, task_description: str, required_skills: List[str]) -> Optional[str]:
        """작업에 가장 적합한 에이전트 찾기"""
        best_match = None
        best_score = 0
        
        for agent_name, agent_info in self.discovered_agents.items():
            # 헬스 체크
            if self.agent_health_status.get(agent_name, {}).get('status') != 'healthy':
                continue
            
            score = 0
            
            # 스킬 매칭
            agent_skills = {skill.get('id', '') for skill in agent_info.get('skills', [])}
            for required_skill in required_skills:
                if required_skill in agent_skills:
                    score += 10
            
            # 설명 매칭
            description = agent_info.get('description', '').lower()
            task_lower = task_description.lower()
            
            # 키워드 매칭
            keywords = task_lower.split()
            for keyword in keywords:
                if len(keyword) > 3 and keyword in description:
                    score += 1
            
            if score > best_score:
                best_score = score
                best_match = agent_name
        
        return best_match
    
    async def get_healthy_agents(self) -> List[str]:
        """건강한 에이전트 목록 반환"""
        healthy = []
        for agent_name, health in self.agent_health_status.items():
            if health.get('status') == 'healthy':
                healthy.append(agent_name)
        return healthy


class StandardA2ACommunicator:
    """A2A Client를 활용한 표준 통신 시스템"""
    
    def __init__(self):
        self.clients = {}  # 에이전트별 클라이언트 캐시
    
    async def get_client(self, agent_url: str) -> A2AClient:
        """에이전트별 A2A 클라이언트 획득 (캐싱)"""
        if agent_url not in self.clients:
            async with httpx.AsyncClient() as client:
                self.clients[agent_url] = A2AClient(
                    httpx_client=client,
                    url=agent_url
                )
        return self.clients[agent_url]
    
    async def send_message(self, agent_url: str, message: str, 
                          stream_callback=None) -> Dict:
        """표준 A2A 메시지 전송"""
        try:
            async with httpx.AsyncClient() as client:
                a2a_client = A2AClient(
                    httpx_client=client,
                    url=agent_url
                )
                
                # 메시지 생성
                msg = Message(
                    messageId=f"orchestrator_{int(time.time() * 1000)}",
                    role="user",
                    parts=[TextPart(text=message)]
                )
                
                # SendMessageRequest 생성
                params = MessageSendParams(message=msg)
                request = SendMessageRequest(
                    id=f"req_{int(time.time() * 1000)}",
                    jsonrpc="2.0",
                    method="message/send",
                    params=params
                )
                
                # 스트리밍 콜백이 있으면 스트리밍 모드
                if stream_callback:
                    result = await self._handle_streaming_response(
                        a2a_client, request, stream_callback
                    )
                else:
                    # 일반 전송
                    response = await a2a_client.send_message(request)
                    result = self._parse_a2a_response(response)
                
                return result
            
        except Exception as e:
            logger.error(f"A2A communication error with {agent_url}: {e}")
            return {
                'status': 'failed',
                'error': str(e),
                'summary': f'통신 오류: {str(e)}'
            }
    
    async def _handle_streaming_response(self, client: A2AClient, 
                                       request: SendMessageRequest, 
                                       stream_callback) -> Dict:
        """스트리밍 응답 처리"""
        try:
            # A2A 스트리밍 응답 처리 - send_message_streaming 사용
            full_response = ""
            async for chunk in client.send_message_streaming(request):
                if isinstance(chunk, dict):
                    content = chunk.get('content', '')
                    if content:
                        full_response += content
                        await stream_callback(content)
                elif hasattr(chunk, 'content'):
                    content = chunk.content
                    if content:
                        full_response += content
                        await stream_callback(content)
            
            return {
                'status': 'success',
                'result': {'content': full_response},
                'summary': '스트리밍 완료'
            }
            
        except Exception as e:
            logger.error(f"Streaming error: {e}")
            return {
                'status': 'failed',
                'error': str(e),
                'summary': '스트리밍 오류'
            }
    
    def _parse_a2a_response(self, response: Any) -> Dict:
        """A2A 응답 파싱"""
        try:
            if hasattr(response, 'status'):
                return {
                    'status': 'success' if response.status.state == 'completed' else 'partial',
                    'result': response,
                    'summary': '작업 완료'
                }
            else:
                return {
                    'status': 'success',
                    'result': response,
                    'summary': '작업 완료'
                }
        except Exception as e:
            return {
                'status': 'failed',
                'error': str(e),
                'summary': '응답 파싱 오류'
            }


class UniversalIntelligentOrchestratorV8(AgentExecutor):
    """v8.0 - A2A SDK 극대화 + 실시간 스트리밍 혁신"""
    
    def __init__(self):
        # OpenAI 클라이언트
        try:
            api_key = os.getenv("OPENAI_API_KEY")
            if api_key and api_key.strip():
                self.openai_client = AsyncOpenAI(api_key=api_key)
                logger.info("🤖 Universal Intelligent Orchestrator v8.0 with LLM")
            else:
                self.openai_client = None
                logger.info("📊 Universal Orchestrator v8.0 (No LLM)")
        except Exception as e:
            logger.warning(f"OpenAI client initialization failed: {e}")
            self.openai_client = None
        
        # A2A 시스템 초기화
        self.agent_discovery = DynamicAgentDiscovery()
        self.a2a_communicator = StandardA2ACommunicator()
        
        # 상태 관리
        self.available_agents = {}
        self.agent_capabilities = {}
        self.execution_monitor = None
        self.replanning_engine = None
        
        # 백그라운드 태스크
        self._discovery_task = None
    
    async def initialize(self):
        """시스템 초기화 및 첫 발견"""
        logger.info("🚀 Initializing Universal Orchestrator v8.0...")
        
        # 초기 에이전트 발견
        self.available_agents = await self.agent_discovery.discover_all_agents()
        
        # 백그라운드 발견 태스크 시작
        if not self._discovery_task:
            self._discovery_task = asyncio.create_task(
                self._periodic_agent_discovery()
            )
        
        logger.info(f"✅ Initialization complete with {len(self.available_agents)} agents")
    
    async def _periodic_agent_discovery(self):
        """주기적 에이전트 재발견"""
        while True:
            await asyncio.sleep(60)  # 60초마다
            try:
                new_agents = await self.agent_discovery.discover_all_agents()
                if len(new_agents) != len(self.available_agents):
                    logger.info(f"🔄 Agent landscape changed: {len(new_agents)} agents")
                    self.available_agents = new_agents
            except Exception as e:
                logger.error(f"Periodic discovery error: {e}")
    
    async def execute(self, context: RequestContext, event_queue: EventQueue) -> None:
        """메인 실행 - 실시간 스트리밍 강화"""
        # 실시간 스트리밍 업데이터 사용
        task_updater = RealTimeStreamingTaskUpdater(
            event_queue, context.task_id, context.context_id
        )
        
        try:
            await task_updater.submit()
            await task_updater.start_work()
            
            # 초기화 확인
            if not self.available_agents:
                await self.initialize()
            
            user_input = context.get_user_input()
            logger.info(f"🎯 Processing: {user_input}")
            
            if not user_input:
                user_input = "Please provide an analysis request."
            
            # 실시간 피드백 시작
            await task_updater.stream_markdown_section(
                "header", "## 🧠 Universal Intelligent Orchestrator v8.0"
            )
            await task_updater.stream_line("분석을 시작합니다...")
            
            # Step 1: 복잡도 평가 (스트리밍)
            await task_updater.stream_markdown_section(
                "header", "### 📊 요청 분석 중..."
            )
            
            complexity = await self._assess_request_complexity_streaming(
                user_input, task_updater
            )
            
            # Step 2: 복잡도 기반 적응적 처리
            if complexity['level'] == 'simple':
                await self._handle_simple_request_streaming(
                    user_input, task_updater
                )
                
            elif complexity['level'] == 'single_agent':
                await self._handle_single_agent_streaming(
                    user_input,
                    complexity.get('recommended_agent'),
                    task_updater
                )
                
            else:  # complex
                await self._handle_complex_request_streaming(
                    user_input, task_updater
                )
                
        except Exception as e:
            error_msg = f"Orchestrator error: {str(e)}"
            logger.error(error_msg, exc_info=True)
            await task_updater.stream_line(f"\n❌ 오류 발생: {error_msg}")
            await task_updater.update_status(
                TaskState.failed,
                message=task_updater.new_agent_message(
                    parts=[TextPart(text=error_msg)]
                )
            )
    
    async def cancel(self, context: RequestContext, event_queue: EventQueue) -> None:
        """작업 취소"""
        task_updater = TaskUpdater(event_queue, context.task_id, context.context_id)
        await task_updater.reject()
        logger.info(f"Operation cancelled for context {context.context_id}")
    
    async def _assess_request_complexity_streaming(self, 
                                                 user_input: str,
                                                 task_updater: RealTimeStreamingTaskUpdater) -> Dict:
        """요청 복잡도 평가 (스트리밍)"""
        
        if not self.openai_client:
            await task_updater.stream_line("- LLM 없이 기본 복잡도로 처리합니다.")
            return {'level': 'complex', 'reasoning': 'No LLM available'}
        
        assessment_prompt = f"""
        다음 사용자 요청의 복잡도를 평가하세요:
        "{user_input}"
        
        평가 기준:
        1. **simple**: 즉답 가능 (정의, 개념 설명, 간단한 사실 확인)
        2. **single_agent**: 한 에이전트로 충분 (단일 작업)
        3. **complex**: 여러 에이전트 협업 필요 (다단계 분석)
        
        JSON 응답:
        {{
            "level": "simple/single_agent/complex",
            "reasoning": "판단 근거",
            "recommended_agent": "single_agent인 경우 추천 에이전트",
            "key_requirements": ["핵심 요구사항들"]
        }}
        """
        
        try:
            await task_updater.stream_line("- AI가 요청을 분석하고 있습니다...")
            
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": assessment_prompt}],
                response_format={"type": "json_object"},
                temperature=0.2,
                timeout=30.0
            )
            
            complexity = json.loads(response.choices[0].message.content)
            
            # 결과 스트리밍
            level_emoji = {
                'simple': '💬',
                'single_agent': '🤖', 
                'complex': '🎯'
            }
            
            await task_updater.stream_line(
                f"- 복잡도: {level_emoji.get(complexity['level'], '📊')} "
                f"**{complexity['level'].upper()}**"
            )
            await task_updater.stream_line(f"- 판단 근거: {complexity['reasoning']}")
            
            return complexity
            
        except Exception as e:
            logger.warning(f"Complexity assessment failed: {e}")
            await task_updater.stream_line("- 복잡도 평가 실패, 기본 모드로 진행")
            return {'level': 'complex', 'reasoning': 'Assessment failed'}
    
    async def _handle_simple_request_streaming(self,
                                             user_input: str,
                                             task_updater: RealTimeStreamingTaskUpdater):
        """간단한 요청 즉답 (스트리밍)"""
        await task_updater.stream_markdown_section(
            "header", "### 💬 즉시 답변"
        )
        
        if self.openai_client:
            try:
                # 스트리밍 응답
                stream = await self.openai_client.chat.completions.create(
                    model="gpt-4o",
                    messages=[{
                        "role": "system",
                        "content": "당신은 도움이 되는 AI 어시스턴트입니다. 간결하고 정확하게 답변하세요."
                    }, {
                        "role": "user",
                        "content": user_input
                    }],
                    temperature=0.3,
                    max_tokens=1000,
                    stream=True
                )
                
                await task_updater.stream_line("")
                full_response = ""
                
                async for chunk in stream:
                    if chunk.choices[0].delta.content:
                        content = chunk.choices[0].delta.content
                        full_response += content
                        await task_updater.stream_chunk(content)
                
                await task_updater._flush_buffer()
                
                # 완료
                await task_updater.update_status(
                    TaskState.completed,
                    message=task_updater.new_agent_message(
                        parts=[TextPart(text=full_response)]
                    )
                )
                
            except Exception as e:
                logger.error(f"Simple request streaming failed: {e}")
                await task_updater.stream_line(f"\n❌ 오류: {str(e)}")
                await task_updater.update_status(
                    TaskState.failed,
                    message=task_updater.new_agent_message(
                        parts=[TextPart(text=f"오류 발생: {str(e)}")]
                    )
                )
        else:
            response = "죄송합니다. LLM이 설정되지 않아 즉답을 제공할 수 없습니다."
            await task_updater.stream_line(response)
            await task_updater.update_status(
                TaskState.completed,
                message=task_updater.new_agent_message(
                    parts=[TextPart(text=response)]
                )
            )
    
    async def _handle_single_agent_streaming(self,
                                           user_input: str,
                                           agent_name: str,
                                           task_updater: RealTimeStreamingTaskUpdater):
        """단일 에이전트 처리 (스트리밍)"""
        await task_updater.stream_markdown_section(
            "header", f"### 🤖 {agent_name} 에이전트 실행"
        )
        
        # 에이전트 확인
        if agent_name not in self.available_agents:
            # 대체 에이전트 찾기
            await task_updater.stream_line("- 지정된 에이전트를 찾을 수 없어 대체 에이전트를 검색합니다...")
            
            agent_name = await self._find_alternative_agent_streaming(
                user_input, task_updater
            )
            
            if not agent_name:
                await task_updater.stream_line("❌ 적합한 에이전트를 찾을 수 없습니다.")
                await task_updater.update_status(
                    TaskState.failed,
                    message=task_updater.new_agent_message(
                        parts=[TextPart(text="에이전트 없음")]
                    )
                )
                return
        
        # 에이전트 정보
        agent_info = self.available_agents[agent_name]
        agent_url = agent_info['url']
        
        await task_updater.stream_line(f"- 에이전트: **{agent_name}**")
        await task_updater.stream_line(f"- 상태: ✅ {agent_info.get('version', 'unknown')}")
        
        # 사용자 의도 추출
        await task_updater.stream_line("- 요청 내용을 분석하고 있습니다...")
        user_intent = await self._extract_user_intent_precisely(user_input)
        
        # 정밀한 지시 생성
        await task_updater.stream_line("- 최적의 작업 지시를 생성하고 있습니다...")
        instruction = await self._create_precise_instruction_for_agent(
            agent_name, user_intent, agent_info
        )
        
        # A2A 표준 통신으로 실행 (스트리밍)
        await task_updater.stream_line(f"\n**실행 중...**")
        
        # 스트리밍 콜백
        async def stream_callback(content: str):
            await task_updater.stream_chunk(content)
        
        result = await self.a2a_communicator.send_message(
            agent_url,
            instruction,
            stream_callback=stream_callback
        )
        
        # 결과 검증
        if result['status'] == 'success':
            await task_updater.stream_line(f"\n✅ {agent_name} 작업 완료")
            
            # 최종 응답 생성
            final_response = await self._create_final_response_single(
                user_input, agent_name, result, user_intent
            )
            
            await task_updater.update_status(
                TaskState.completed,
                message=task_updater.new_agent_message(
                    parts=[TextPart(text=final_response)]
                )
            )
        else:
            await task_updater.stream_line(f"\n❌ 실행 실패: {result.get('error', 'Unknown')}")
            await task_updater.update_status(
                TaskState.failed,
                message=task_updater.new_agent_message(
                    parts=[TextPart(text=f"에이전트 실행 실패: {result.get('error')}")]
                )
            )
    
    async def _handle_complex_request_streaming(self,
                                              user_input: str,
                                              task_updater: RealTimeStreamingTaskUpdater):
        """복잡한 요청 처리 (스트리밍)"""
        await task_updater.stream_markdown_section(
            "header", "### 🎯 복잡한 분석 시작"
        )
        
        # Phase 1: 깊이 있는 분석
        await task_updater.stream_line("\n**1단계: 요청 심층 분석**")
        
        request_analysis = await self._analyze_request_depth(user_input)
        user_intent = await self._extract_user_intent_precisely(user_input)
        
        await task_updater.stream_line(f"- 주요 목표: {user_intent['main_goal']}")
        await task_updater.stream_line(f"- 액션 타입: {user_intent['action_type']}")
        
        # Phase 2: 에이전트 준비
        await task_updater.stream_line("\n**2단계: AI 에이전트 준비**")
        
        # 건강한 에이전트만 사용
        healthy_agents = await self.agent_discovery.get_healthy_agents()
        await task_updater.stream_line(f"- 사용 가능한 에이전트: {len(healthy_agents)}개")
        
        for agent_name in healthy_agents[:5]:  # 상위 5개만 표시
            health = self.agent_discovery.agent_health_status.get(agent_name, {})
            response_time = health.get('response_time_ms', 'N/A')
            await task_updater.stream_line(f"  - ✅ {agent_name} ({response_time}ms)")
        
        # Phase 3: 실행 계획 수립
        await task_updater.stream_line("\n**3단계: 최적 실행 계획 수립**")
        
        plan = await self._create_streaming_execution_plan(
            user_input, user_intent, healthy_agents, task_updater
        )
        
        if not plan or not plan.get('steps'):
            await task_updater.stream_line("❌ 실행 계획 수립 실패")
            await task_updater.update_status(
                TaskState.failed,
                message=task_updater.new_agent_message(
                    parts=[TextPart(text="계획 수립 실패")]
                )
            )
            return
        
        # 계획 표시
        await task_updater.stream_line(f"\n📋 **실행 계획** ({len(plan['steps'])}단계)")
        for i, step in enumerate(plan['steps']):
            await task_updater.stream_line(
                f"{i+1}. **{step['agent']}**: {step['purpose']}"
            )
        
        # Phase 4: 적응적 실행
        await task_updater.stream_line("\n**4단계: 실행 시작**")
        
        execution_result = await self._execute_with_streaming_and_replanning(
            plan, user_intent, task_updater
        )
        
        # Phase 5: 결과 종합
        await task_updater.stream_line("\n**5단계: 결과 종합**")
        
        final_response = await self._create_comprehensive_response_streaming(
            user_input, user_intent, execution_result, task_updater
        )
        
        # 완료
        await task_updater.stream_line("\n🎉 **분석 완료!**")
        
        await task_updater.update_status(
            TaskState.completed,
            message=task_updater.new_agent_message(
                parts=[TextPart(text=final_response)]
            )
        )
    
    async def _find_alternative_agent_streaming(self,
                                              user_input: str,
                                              task_updater: RealTimeStreamingTaskUpdater) -> Optional[str]:
        """대체 에이전트 찾기 (스트리밍)"""
        
        # 태스크 설명에서 키워드 추출
        keywords = []
        if 'data' in user_input.lower():
            keywords.extend(['data', 'analysis', 'processing'])
        if 'visual' in user_input.lower() or 'chart' in user_input.lower():
            keywords.append('visualization')
        if 'clean' in user_input.lower():
            keywords.append('cleaning')
        
        # A2A Discovery로 최적 에이전트 찾기
        best_agent = await self.agent_discovery.find_best_agent_for_task(
            user_input, keywords
        )
        
        if best_agent:
            await task_updater.stream_line(f"- 대체 에이전트 발견: **{best_agent}**")
            return best_agent
        
        # 폴백: 첫 번째 건강한 에이전트
        healthy = await self.agent_discovery.get_healthy_agents()
        if healthy:
            await task_updater.stream_line(f"- 기본 에이전트 사용: **{healthy[0]}**")
            return healthy[0]
        
        return None
    
    async def _create_streaming_execution_plan(self,
                                             user_input: str,
                                             user_intent: Dict,
                                             healthy_agents: List[str],
                                             task_updater: RealTimeStreamingTaskUpdater) -> Dict:
        """실행 계획 수립 (스트리밍 피드백)"""
        
        if not self.openai_client or not healthy_agents:
            return self._create_basic_plan(healthy_agents)
        
        await task_updater.stream_line("- AI가 최적의 실행 경로를 설계하고 있습니다...")
        
        # 에이전트 정보 수집
        agent_details = {}
        for agent_name in healthy_agents:
            if agent_name in self.available_agents:
                info = self.available_agents[agent_name]
                agent_details[agent_name] = {
                    'description': info.get('description', ''),
                    'skills': [s.get('name', '') for s in info.get('skills', [])]
                }
        
        planning_prompt = f"""
        사용자 요청: {user_input}
        사용자 의도: {json.dumps(user_intent, ensure_ascii=False)}
        
        사용 가능한 에이전트:
        {json.dumps(agent_details, ensure_ascii=False, indent=2)}
        
        이 요청을 처리하기 위한 최적의 실행 계획을 수립하세요.
        
        중요:
        - 사용자 의도에 필요한 에이전트만 선택
        - 논리적인 실행 순서 고려
        - 각 단계별 명확한 목적 설정
        
        JSON 형식:
        {{
            "execution_strategy": "전체 전략",
            "steps": [
                {{
                    "agent": "에이전트명",
                    "purpose": "이 단계의 목적",
                    "instruction": "구체적 작업 지시"
                }}
            ]
        }}
        """
        
        try:
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": planning_prompt}],
                response_format={"type": "json_object"},
                temperature=0.3,
                max_tokens=2000
            )
            
            plan = json.loads(response.choices[0].message.content)
            
            # 계획 검증
            valid_steps = []
            for step in plan.get('steps', []):
                if step.get('agent') in healthy_agents:
                    valid_steps.append(step)
            
            plan['steps'] = valid_steps
            
            await task_updater.stream_line("- ✅ 실행 계획 수립 완료")
            return plan
            
        except Exception as e:
            logger.error(f"Planning failed: {e}")
            await task_updater.stream_line("- ⚠️ 기본 계획으로 진행합니다")
            return self._create_basic_plan(healthy_agents)
    
    async def _execute_with_streaming_and_replanning(self,
                                                    plan: Dict,
                                                    user_intent: Dict,
                                                    task_updater: RealTimeStreamingTaskUpdater) -> Dict:
        """스트리밍과 리플래닝을 포함한 실행"""
        
        execution_results = {}
        execution_history = []
        
        for i, step in enumerate(plan['steps']):
            agent_name = step['agent']
            agent_info = self.available_agents.get(agent_name, {})
            agent_url = agent_info.get('url')
            
            if not agent_url:
                await task_updater.stream_line(f"\n⚠️ {agent_name} 에이전트를 찾을 수 없어 건너뜁니다")
                continue
            
            # 단계 시작
            await task_updater.stream_line(f"\n**[{i+1}/{len(plan['steps'])}] {agent_name} 실행**")
            await task_updater.stream_line(f"- 목적: {step['purpose']}")
            
            # 헬스 체크
            health = self.agent_discovery.agent_health_status.get(agent_name, {})
            if health.get('status') != 'healthy':
                await task_updater.stream_line(f"- ⚠️ 에이전트 상태 불량, 건너뜁니다")
                continue
            
            # 스트리밍 실행
            await task_updater.stream_line("- 처리 중...")
            
            async def agent_stream_callback(content: str):
                # 에이전트 출력을 들여쓰기로 표시
                lines = content.split('\n')
                for line in lines:
                    if line.strip():
                        await task_updater.stream_line(f"  > {line}")
            
            result = await self.a2a_communicator.send_message(
                agent_url,
                step.get('instruction', step['purpose']),
                stream_callback=agent_stream_callback
            )
            
            # 결과 저장
            execution_results[agent_name] = result
            execution_history.append({
                'step': i,
                'agent': agent_name,
                'result': result,
                'timestamp': datetime.now().isoformat()
            })
            
            if result['status'] == 'success':
                await task_updater.stream_line(f"- ✅ 완료")
            else:
                await task_updater.stream_line(f"- ❌ 실패: {result.get('error', 'Unknown')}")
                
                # 간단한 리플래닝: 실패시 다음 가능한 에이전트 시도
                if i < len(plan['steps']) - 1:
                    await task_updater.stream_line("- 🔄 대체 경로 탐색 중...")
        
        return {
            'results': execution_results,
            'history': execution_history,
            'total_steps': len(plan['steps']),
            'successful_steps': len([r for r in execution_results.values() 
                                   if r.get('status') == 'success'])
        }
    
    async def _create_comprehensive_response_streaming(self,
                                                     user_input: str,
                                                     user_intent: Dict,
                                                     execution_result: Dict,
                                                     task_updater: RealTimeStreamingTaskUpdater) -> str:
        """종합 응답 생성 (스트리밍)"""
        
        await task_updater.stream_line("- 분석 결과를 종합하고 있습니다...")
        
        if not self.openai_client:
            return self._create_basic_summary(execution_result)
        
        # 성공한 결과만 추출
        successful_results = {
            agent: result
            for agent, result in execution_result['results'].items()
            if result.get('status') == 'success'
        }
        
        if not successful_results:
            # 실패한 에이전트들의 오류 분석
            failed_agents = []
            for agent, result in execution_result['results'].items():
                if result.get('status') == 'failed':
                    failed_agents.append(f"- {agent}: {result.get('error', 'Unknown error')}")
            
            # LLM을 사용하여 대안 응답 생성
            if self.openai_client:
                try:
                    fallback_prompt = f"""
                    사용자 요청: {user_input}
                    
                    AI 에이전트들과의 통신이 실패했지만, 당신의 지식을 바탕으로 사용자 요청에 최대한 도움이 되는 답변을 제공하세요.
                    
                    실패한 에이전트들:
                    {chr(10).join(failed_agents) if failed_agents else '- 모든 에이전트 통신 실패'}
                    
                    지침:
                    1. 사용자 요청의 핵심 내용에 대해 직접 답변
                    2. 일반적인 접근 방법과 고려사항 제시
                    3. 실무에서 활용할 수 있는 구체적인 조언 포함
                    4. 추가 정보가 필요한 부분 명시
                    """
                    
                    response = await self.openai_client.chat.completions.create(
                        model="gpt-4o",
                        messages=[{"role": "user", "content": fallback_prompt}],
                        temperature=0.3,
                        max_tokens=2000
                    )
                    
                    await task_updater.stream_line("- ⚠️ 에이전트 통신 실패, LLM 기반 대안 응답 생성")
                    return response.choices[0].message.content
                    
                except Exception as e:
                    logger.error(f"Fallback response generation failed: {e}")
            
            # 최후 수단: 기본 응답
            return f"""
## 분석 요청 처리 결과

⚠️ **AI 에이전트 시스템과의 통신에 문제가 발생했습니다.**

### 요청 내용
{user_input[:200]}{"..." if len(user_input) > 200 else ""}

### 발생한 문제
{chr(10).join(failed_agents) if failed_agents else "- 모든 AI 에이전트와의 통신이 실패했습니다."}

### 권장 조치
1. 잠시 후 다시 시도해 주세요
2. 요청을 더 구체적으로 작성해 보세요
3. 단계별로 나누어 요청해 보세요

죄송합니다. 현재 시스템 상태로는 완전한 분석을 제공할 수 없습니다.
            """
        
        synthesis_prompt = f"""
        사용자 요청: {user_input}
        사용자 의도: {json.dumps(user_intent, ensure_ascii=False)}
        
        분석 결과:
        {json.dumps(successful_results, ensure_ascii=False, indent=2)[:3000]}
        
        위 결과를 바탕으로 사용자 요청에 대한 종합적인 답변을 작성하세요.
        
        지침:
        1. 사용자의 {user_intent['action_type']} 요청에 직접 답변
        2. 구체적인 데이터와 근거 제시
        3. 핵심 발견사항 강조
        4. 실용적인 인사이트 제공
        """
        
        try:
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": synthesis_prompt}],
                temperature=0.3,
                max_tokens=3000
            )
            
            await task_updater.stream_line("- ✅ 종합 완료")
            
            return response.choices[0].message.content
            
        except Exception as e:
            logger.error(f"Synthesis failed: {e}")
            return self._create_basic_summary(execution_result)
    
    async def _extract_user_intent_precisely(self, user_input: str) -> Dict:
        """사용자 의도 정밀 추출"""
        
        if not self.openai_client:
            return {
                'main_goal': user_input,
                'action_type': 'analyze',
                'specific_requirements': [],
                'expected_outcomes': ['분석 결과']
            }
        
        intent_prompt = f"""
        사용자 입력: "{user_input}"
        
        의도를 추출하세요:
        1. action_type: analyze/verify/recommend/diagnose/predict/compare/explain
        2. main_goal: 한 문장 요약
        3. specific_requirements: 구체적 요구사항
        4. expected_outcomes: 기대 결과
        
        JSON 형식으로 응답하세요.
        """
        
        try:
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": intent_prompt}],
                response_format={"type": "json_object"},
                temperature=0.2,
                max_tokens=500
            )
            
            return json.loads(response.choices[0].message.content)
            
        except Exception as e:
            logger.warning(f"Intent extraction failed: {e}")
            return {
                'main_goal': user_input,
                'action_type': 'analyze',
                'specific_requirements': [],
                'expected_outcomes': ['분석 결과']
            }
    
    async def _analyze_request_depth(self, user_input: str) -> Dict:
        """요청 깊이 분석"""
        
        if not self.openai_client:
            return {
                'detail_level': 5,
                'has_role_description': False,
                'explicit_requirements': ['기본 분석'],
                'implicit_needs': ['데이터 이해']
            }
        
        try:
            analysis_prompt = f"""
            요청 분석: "{user_input}"
            
            분석 항목:
            1. 구체성 수준 (1-10)
            2. 명시적 vs 암시적 요구사항
            3. 예상 응답 깊이
            
            JSON 응답 요청
            """
            
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": analysis_prompt}],
                response_format={"type": "json_object"},
                temperature=0.3,
                max_tokens=500
            )
            
            return json.loads(response.choices[0].message.content)
            
        except Exception as e:
            logger.warning(f"Depth analysis failed: {e}")
            return {
                'detail_level': 5,
                'explicit_requirements': ['기본 분석']
            }
    
    async def _create_precise_instruction_for_agent(self,
                                                  agent_name: str,
                                                  user_intent: Dict,
                                                  agent_info: Dict) -> str:
        """에이전트별 정밀 지시 생성"""
        
        if not self.openai_client:
            return f"{user_intent['main_goal']}을 수행해주세요."
        
        # 에이전트 스킬 정보
        skills = agent_info.get('skills', [])
        skill_names = [s.get('name', '') for s in skills]
        
        instruction_prompt = f"""
        에이전트: {agent_name}
        에이전트 스킬: {skill_names}
        
        사용자 목표: {user_intent['main_goal']}
        액션 타입: {user_intent['action_type']}
        
        이 에이전트가 수행해야 할 구체적인 작업 지시를 작성하세요.
        에이전트의 스킬을 최대한 활용하도록 지시하세요.
        """
        
        try:
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": instruction_prompt}],
                temperature=0.3,
                max_tokens=1000
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            logger.warning(f"Instruction generation failed: {e}")
            return f"{user_intent['main_goal']}을 수행해주세요."
    
    async def _create_final_response_single(self,
                                          user_input: str,
                                          agent_name: str,
                                          result: Dict,
                                          user_intent: Dict) -> str:
        """단일 에이전트 최종 응답"""
        
        if not self.openai_client:
            return f"{agent_name} 에이전트 실행 완료:\n{result.get('summary', '작업 완료')}"
        
        response_prompt = f"""
        사용자 요청: {user_input}
        사용자 의도: {user_intent['main_goal']}
        
        {agent_name} 에이전트 실행 결과:
        {json.dumps(result, ensure_ascii=False)[:2000]}
        
        사용자 요청에 직접 답변하는 응답을 작성하세요.
        """
        
        try:
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": response_prompt}],
                temperature=0.3,
                max_tokens=2000
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            logger.error(f"Response generation failed: {e}")
            return f"{agent_name} 작업 완료"
    
    def _create_basic_plan(self, available_agents: List[str]) -> Dict:
        """기본 실행 계획"""
        steps = []
        
        # 기본 워크플로우
        basic_flow = [
            ('data_loader', '데이터 로드'),
            ('data_cleaning', '데이터 정제'),
            ('eda_tools', '탐색적 분석'),
            ('data_visualization', '시각화')
        ]
        
        for agent, purpose in basic_flow:
            if agent in available_agents:
                steps.append({
                    'agent': agent,
                    'purpose': purpose,
                    'instruction': f'{purpose} 작업을 수행하세요'
                })
        
        return {
            'execution_strategy': '표준 데이터 분석',
            'steps': steps
        }
    
    def _create_basic_summary(self, execution_result: Dict) -> str:
        """기본 요약"""
        total = execution_result['total_steps']
        success = execution_result['successful_steps']
        
        summary = f"## 분석 완료\n\n"
        summary += f"- 총 {total}단계 중 {success}단계 성공\n"
        
        for agent, result in execution_result['results'].items():
            if result.get('status') == 'success':
                summary += f"- ✅ {agent}: 완료\n"
            else:
                summary += f"- ❌ {agent}: 실패\n"
        
        return summary


def create_orchestrator_v8_server():
    """v8.0 서버 생성"""
    
    agent_card = AgentCard(
        name="Universal Intelligent Orchestrator v8.0",
        description="A2A SDK 0.2.9 표준 기능 극대화 + 실시간 스트리밍 혁신",
        url="http://localhost:8100",
        version="8.0.0",
        capabilities=AgentCapabilities(
            streaming=True,
            pushNotifications=True,
            stateTransitionHistory=True
        ),
        defaultInputModes=["text/plain"],
        defaultOutputModes=["text/plain", "application/json"],
        skills=[
            AgentSkill(
                id="real_time_streaming",
                name="Real-Time Character Streaming",
                description="문자 단위 실시간 스트리밍으로 즉각적인 피드백 제공",
                tags=["streaming", "real-time", "responsive"]
            ),
            AgentSkill(
                id="dynamic_discovery",
                name="Dynamic Agent Discovery with A2A",
                description="A2A CardResolver를 활용한 실시간 에이전트 발견 및 헬스 체크",
                tags=["discovery", "a2a", "health-check"]
            ),
            AgentSkill(
                id="standard_a2a_communication",
                name="Standard A2A Protocol Communication",
                description="A2AClient를 통한 표준화된 에이전트 통신",
                tags=["a2a", "protocol", "standard"]
            ),
            AgentSkill(
                id="adaptive_complexity_handling",
                name="Adaptive Complexity Processing",
                description="요청 복잡도에 따른 적응적 처리 (Simple/Single/Complex)",
                tags=["adaptive", "intelligent", "complexity"]
            ),
            AgentSkill(
                id="llm_streaming_integration",
                name="LLM Streaming Integration",
                description="OpenAI 스트리밍과 직접 통합된 실시간 응답",
                tags=["llm", "streaming", "openai"]
            )
        ]
    )
    
    executor = UniversalIntelligentOrchestratorV8()
    
    # 초기화를 위한 비동기 태스크
    async def startup():
        await executor.initialize()
    
    task_store = InMemoryTaskStore()
    request_handler = DefaultRequestHandler(
        agent_executor=executor,
        task_store=task_store
    )
    
    app = A2AStarletteApplication(
        agent_card=agent_card,
        http_handler=request_handler
    )
    
    # Starlette 앱에 startup 이벤트 추가
    starlette_app = app.build()
    starlette_app.add_event_handler("startup", startup)
    
    return starlette_app


def main():
    """메인 실행"""
    logger.info("🚀 Starting Universal Intelligent Orchestrator v8.0")
    logger.info("📡 A2A SDK 0.2.9 Features: Dynamic Discovery + Real-Time Streaming")
    
    app = create_orchestrator_v8_server()
    
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8100,
        log_level="info"
    )


if __name__ == "__main__":
    main()