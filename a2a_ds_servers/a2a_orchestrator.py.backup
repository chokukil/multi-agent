#!/usr/bin/env python3
"""
A2A Orchestrator v8.0 - Universal Intelligent Orchestrator
A2A SDK 0.2.9 í‘œì¤€ ê¸°ëŠ¥ ê·¹ëŒ€í™” + ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° í˜ì‹ 
"""

import asyncio
import json
import logging
import os
import re
import time
from datetime import datetime
from typing import Any, Dict, List, Optional, AsyncGenerator, Set

import httpx
import uvicorn
from openai import AsyncOpenAI

# A2A SDK 0.2.9 í‘œì¤€ ì„í¬íŠ¸
from a2a.server.apps import A2AStarletteApplication
from a2a.server.request_handlers import DefaultRequestHandler
from a2a.server.tasks import InMemoryTaskStore, TaskUpdater
from a2a.server.agent_execution import AgentExecutor, RequestContext
from a2a.server.events import EventQueue
from a2a.types import (
    AgentCard,
    AgentSkill,
    AgentCapabilities,
    TaskState,
    TextPart,
    Message,
    Part,
    SendMessageRequest,
    MessageSendParams
)

# A2A í´ë¼ì´ì–¸íŠ¸ ë° ë””ìŠ¤ì»¤ë²„ë¦¬
from a2a.client import A2ACardResolver, A2AClient

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class RealTimeStreamingTaskUpdater(TaskUpdater):
    """ì‹¤ì‹œê°„ ë¬¸ì ë‹¨ìœ„ ìŠ¤íŠ¸ë¦¬ë°ì„ ì§€ì›í•˜ëŠ” í–¥ìƒëœ TaskUpdater"""
    
    def __init__(self, event_queue: EventQueue, task_id: str, context_id: str):
        super().__init__(event_queue, task_id, context_id)
        self._buffer = ""
        self._last_update_time = 0
        self._min_update_interval = 0.05  # 50ms ìµœì†Œ ê°„ê²©
    
    async def stream_character(self, char: str):
        """ë‹¨ì¼ ë¬¸ì ìŠ¤íŠ¸ë¦¬ë° (ë²„í¼ë§ í¬í•¨)"""
        self._buffer += char
        current_time = time.time()
        
        # ìµœì†Œ ê°„ê²©ì´ ì§€ë‚¬ê±°ë‚˜ íŠ¹ì • ë¬¸ìì¸ ê²½ìš° ì¦‰ì‹œ ì „ì†¡
        if (current_time - self._last_update_time >= self._min_update_interval or
            char in ['\n', '.', '!', '?', ':', ';']):
            await self._flush_buffer()
    
    async def stream_chunk(self, chunk: str):
        """ì²­í¬ ë‹¨ìœ„ ìŠ¤íŠ¸ë¦¬ë°"""
        for char in chunk:
            await self.stream_character(char)
    
    async def stream_line(self, line: str):
        """ë¼ì¸ ë‹¨ìœ„ ìŠ¤íŠ¸ë¦¬ë° (ì¦‰ì‹œ í”ŒëŸ¬ì‹œ)"""
        self._buffer += line + '\n'
        await self._flush_buffer()
    
    async def _flush_buffer(self):
        """ë²„í¼ í”ŒëŸ¬ì‹œ"""
        if self._buffer:
            await self.update_status(
                TaskState.working,
                message=self.new_agent_message(parts=[TextPart(text=self._buffer)])
            )
            self._buffer = ""
            self._last_update_time = time.time()
    
    async def stream_markdown_section(self, section_type: str, content: str):
        """Markdown ì„¹ì…˜ë³„ ìŠ¤íŠ¸ë¦¬ë°"""
        if section_type == "header":
            await self.stream_line(f"\n{content}\n")
        elif section_type == "bullet":
            await self.stream_line(f"- {content}")
        elif section_type == "code":
            await self.stream_line(f"```\n{content}\n```")
        elif section_type == "quote":
            await self.stream_line(f"> {content}")
        else:
            await self.stream_chunk(content)
    
    async def stream_final_response(self, response: str):
        """ìµœì¢… ì‘ë‹µ ì™„ë£Œ (ë²„í¼ í”ŒëŸ¬ì‹œ í›„)"""
        await self._flush_buffer()
        await self.update_status(
            TaskState.completed,
            message=self.new_agent_message(parts=[TextPart(text=response)])
        )
    
    async def stream_from_llm(self, stream: AsyncGenerator):
        """LLM ìŠ¤íŠ¸ë¦¼ ì§ì ‘ ì—°ë™"""
        try:
            async for chunk in stream:
                if chunk.choices[0].delta.content:
                    await self.stream_chunk(chunk.choices[0].delta.content)
            await self._flush_buffer()
        except Exception as e:
            logger.error(f"LLM streaming error: {e}")
            await self._flush_buffer()


class DynamicAgentDiscovery:
    """A2A CardResolverë¥¼ í™œìš©í•œ ë™ì  ì—ì´ì „íŠ¸ ë°œê²¬ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.discovered_agents = {}
        self.agent_health_status = {}
        self.last_discovery_time = {}
        self.discovery_interval = 60  # 60ì´ˆë§ˆë‹¤ ì¬ë°œê²¬
    
    async def discover_all_agents(self, base_ports: List[int] = None) -> Dict[str, Dict]:
        """ëª¨ë“  ì—ì´ì „íŠ¸ ë™ì  ë°œê²¬"""
        if base_ports is None:
            # AI DS Team í‘œì¤€ í¬íŠ¸ + ì¶”ê°€ ìŠ¤ìº” ë²”ìœ„
            base_ports = list(range(8300, 8320))
        
        discovered = {}
        
        async with httpx.AsyncClient(timeout=5.0) as client:
            for port in base_ports:
                agent_url = f"http://localhost:{port}"
                
                try:
                    # A2A í‘œì¤€ ì—ì´ì „íŠ¸ ì¹´ë“œ ì¡°íšŒ
                    card_resolver = A2ACardResolver(
                        httpx_client=client,
                        base_url=agent_url
                    )
                    agent_card = await card_resolver.get_agent_card()
                    
                    if agent_card:
                        agent_name = agent_card.name
                        
                        discovered[agent_name] = {
                            'url': agent_url,
                            'port': port,
                            'card': agent_card,
                            'skills': [skill.model_dump() for skill in agent_card.skills],
                            'capabilities': agent_card.capabilities.model_dump() if agent_card.capabilities else {},
                            'description': agent_card.description,
                            'version': agent_card.version,
                            'discovered_at': datetime.now().isoformat()
                        }
                        
                        # í—¬ìŠ¤ ì²´í¬
                        health = await self._check_agent_health(agent_url)
                        self.agent_health_status[agent_name] = health
                        
                        logger.info(f"âœ… Discovered: {agent_name} on port {port} (Health: {health['status']})")
                        
                except Exception as e:
                    logger.debug(f"Port {port} scan failed: {e}")
        
        self.discovered_agents = discovered
        self.last_discovery_time[datetime.now()] = len(discovered)
        
        logger.info(f"ğŸ” Total discovered agents: {len(discovered)}")
        return discovered
    
    async def _check_agent_health(self, agent_url: str) -> Dict:
        """ì—ì´ì „íŠ¸ í—¬ìŠ¤ ì²´í¬"""
        try:
            async with httpx.AsyncClient(timeout=3.0) as client:
                start_time = time.time()
                
                # ê°„ë‹¨í•œ í—¬ìŠ¤ ì²´í¬ - Agent Card ì¡°íšŒë¡œ ëŒ€ì²´
                card_resolver = A2ACardResolver(
                    httpx_client=client,
                    base_url=agent_url
                )
                agent_card = await card_resolver.get_agent_card()
                
                response_time = (time.time() - start_time) * 1000  # ms
                
                if agent_card:
                    return {
                        'status': 'healthy',
                        'response_time_ms': round(response_time, 2),
                        'last_check': datetime.now().isoformat()
                    }
                else:
                    return {
                        'status': 'unhealthy',
                        'error': 'No agent card',
                        'last_check': datetime.now().isoformat()
                    }
                    
        except Exception as e:
            return {
                'status': 'unreachable',
                'error': str(e),
                'last_check': datetime.now().isoformat()
            }
    
    async def find_best_agent_for_task(self, task_description: str, required_skills: List[str]) -> Optional[str]:
        """ì‘ì—…ì— ê°€ì¥ ì í•©í•œ ì—ì´ì „íŠ¸ ì°¾ê¸°"""
        best_match = None
        best_score = 0
        
        for agent_name, agent_info in self.discovered_agents.items():
            # í—¬ìŠ¤ ì²´í¬
            if self.agent_health_status.get(agent_name, {}).get('status') != 'healthy':
                continue
            
            score = 0
            
            # ìŠ¤í‚¬ ë§¤ì¹­
            agent_skills = {skill.get('id', '') for skill in agent_info.get('skills', [])}
            for required_skill in required_skills:
                if required_skill in agent_skills:
                    score += 10
            
            # ì„¤ëª… ë§¤ì¹­
            description = agent_info.get('description', '').lower()
            task_lower = task_description.lower()
            
            # í‚¤ì›Œë“œ ë§¤ì¹­
            keywords = task_lower.split()
            for keyword in keywords:
                if len(keyword) > 3 and keyword in description:
                    score += 1
            
            if score > best_score:
                best_score = score
                best_match = agent_name
        
        return best_match
    
    async def get_healthy_agents(self) -> List[str]:
        """ê±´ê°•í•œ ì—ì´ì „íŠ¸ ëª©ë¡ ë°˜í™˜"""
        healthy = []
        for agent_name, health in self.agent_health_status.items():
            if health.get('status') == 'healthy':
                healthy.append(agent_name)
        return healthy


class StandardA2ACommunicator:
    """A2A Clientë¥¼ í™œìš©í•œ í‘œì¤€ í†µì‹  ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.clients = {}  # ì—ì´ì „íŠ¸ë³„ í´ë¼ì´ì–¸íŠ¸ ìºì‹œ
    
    async def get_client(self, agent_url: str) -> A2AClient:
        """ì—ì´ì „íŠ¸ë³„ A2A í´ë¼ì´ì–¸íŠ¸ íšë“ (ìºì‹±)"""
        if agent_url not in self.clients:
            async with httpx.AsyncClient() as client:
                self.clients[agent_url] = A2AClient(
                    httpx_client=client,
                    url=agent_url
                )
        return self.clients[agent_url]
    
    async def send_message(self, agent_url: str, message: str, 
                          stream_callback=None) -> Dict:
        """í‘œì¤€ A2A ë©”ì‹œì§€ ì „ì†¡"""
        try:
            async with httpx.AsyncClient() as client:
                a2a_client = A2AClient(
                    httpx_client=client,
                    url=agent_url
                )
                
                # ë©”ì‹œì§€ ìƒì„±
                msg = Message(
                    messageId=f"orchestrator_{int(time.time() * 1000)}",
                    role="user",
                    parts=[TextPart(text=message)]
                )
                
                # SendMessageRequest ìƒì„±
                params = MessageSendParams(message=msg)
                request = SendMessageRequest(
                    id=f"req_{int(time.time() * 1000)}",
                    jsonrpc="2.0",
                    method="message/send",
                    params=params
                )
                
                # ìŠ¤íŠ¸ë¦¬ë° ì½œë°±ì´ ìˆìœ¼ë©´ ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ
                if stream_callback:
                    result = await self._handle_streaming_response(
                        a2a_client, request, stream_callback
                    )
                else:
                    # ì¼ë°˜ ì „ì†¡
                    response = await a2a_client.send_message(request)
                    result = self._parse_a2a_response(response)
                
                return result
            
        except Exception as e:
            logger.error(f"A2A communication error with {agent_url}: {e}")
            return {
                'status': 'failed',
                'error': str(e),
                'summary': f'í†µì‹  ì˜¤ë¥˜: {str(e)}'
            }
    
    async def _handle_streaming_response(self, client: A2AClient, 
                                       request: SendMessageRequest, 
                                       stream_callback) -> Dict:
        """ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²˜ë¦¬"""
        try:
            # A2A ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²˜ë¦¬ - send_message_streaming ì‚¬ìš©
            full_response = ""
            async for chunk in client.send_message_streaming(request):
                if isinstance(chunk, dict):
                    content = chunk.get('content', '')
                    if content:
                        full_response += content
                        await stream_callback(content)
                elif hasattr(chunk, 'content'):
                    content = chunk.content
                    if content:
                        full_response += content
                        await stream_callback(content)
            
            return {
                'status': 'success',
                'result': {'content': full_response},
                'summary': 'ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ'
            }
            
        except Exception as e:
            logger.error(f"Streaming error: {e}")
            return {
                'status': 'failed',
                'error': str(e),
                'summary': 'ìŠ¤íŠ¸ë¦¬ë° ì˜¤ë¥˜'
            }
    
    def _parse_a2a_response(self, response: Any) -> Dict:
        """A2A ì‘ë‹µ íŒŒì‹±"""
        try:
            if hasattr(response, 'status'):
                return {
                    'status': 'success' if response.status.state == 'completed' else 'partial',
                    'result': response,
                    'summary': 'ì‘ì—… ì™„ë£Œ'
                }
            else:
                return {
                    'status': 'success',
                    'result': response,
                    'summary': 'ì‘ì—… ì™„ë£Œ'
                }
        except Exception as e:
            return {
                'status': 'failed',
                'error': str(e),
                'summary': 'ì‘ë‹µ íŒŒì‹± ì˜¤ë¥˜'
            }


class UniversalIntelligentOrchestratorV8(AgentExecutor):
    """v8.0 - A2A SDK ê·¹ëŒ€í™” + ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° í˜ì‹ """
    
    def __init__(self):
        # OpenAI í´ë¼ì´ì–¸íŠ¸
        try:
            api_key = os.getenv("OPENAI_API_KEY")
            if api_key and api_key.strip():
                self.openai_client = AsyncOpenAI(api_key=api_key)
                logger.info("ğŸ¤– Universal Intelligent Orchestrator v8.0 with LLM")
            else:
                self.openai_client = None
                logger.info("ğŸ“Š Universal Orchestrator v8.0 (No LLM)")
        except Exception as e:
            logger.warning(f"OpenAI client initialization failed: {e}")
            self.openai_client = None
        
        # A2A ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        self.agent_discovery = DynamicAgentDiscovery()
        self.a2a_communicator = StandardA2ACommunicator()
        
        # ìƒíƒœ ê´€ë¦¬
        self.available_agents = {}
        self.agent_capabilities = {}
        self.execution_monitor = None
        self.replanning_engine = None
        
        # ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬
        self._discovery_task = None
    
    async def initialize(self):
        """ì‹œìŠ¤í…œ ì´ˆê¸°í™” ë° ì²« ë°œê²¬"""
        logger.info("ğŸš€ Initializing Universal Orchestrator v8.0...")
        
        # ì´ˆê¸° ì—ì´ì „íŠ¸ ë°œê²¬
        self.available_agents = await self.agent_discovery.discover_all_agents()
        
        # ë°±ê·¸ë¼ìš´ë“œ ë°œê²¬ íƒœìŠ¤í¬ ì‹œì‘
        if not self._discovery_task:
            self._discovery_task = asyncio.create_task(
                self._periodic_agent_discovery()
            )
        
        logger.info(f"âœ… Initialization complete with {len(self.available_agents)} agents")
    
    async def _periodic_agent_discovery(self):
        """ì£¼ê¸°ì  ì—ì´ì „íŠ¸ ì¬ë°œê²¬"""
        while True:
            await asyncio.sleep(60)  # 60ì´ˆë§ˆë‹¤
            try:
                new_agents = await self.agent_discovery.discover_all_agents()
                if len(new_agents) != len(self.available_agents):
                    logger.info(f"ğŸ”„ Agent landscape changed: {len(new_agents)} agents")
                    self.available_agents = new_agents
            except Exception as e:
                logger.error(f"Periodic discovery error: {e}")
    
    async def execute(self, context: RequestContext, event_queue: EventQueue) -> None:
        """ë©”ì¸ ì‹¤í–‰ - ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ê°•í™”"""
        # ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì—…ë°ì´í„° ì‚¬ìš©
        task_updater = RealTimeStreamingTaskUpdater(
            event_queue, context.task_id, context.context_id
        )
        
        try:
            await task_updater.submit()
            await task_updater.start_work()
            
            # ì´ˆê¸°í™” í™•ì¸
            if not self.available_agents:
                await self.initialize()
            
            user_input = context.get_user_input()
            logger.info(f"ğŸ¯ Processing: {user_input}")
            
            if not user_input:
                user_input = "Please provide an analysis request."
            
            # ì‹¤ì‹œê°„ í”¼ë“œë°± ì‹œì‘
            await task_updater.stream_markdown_section(
                "header", "## ğŸ§  Universal Intelligent Orchestrator v8.0"
            )
            await task_updater.stream_line("ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
            
            # Step 1: ë³µì¡ë„ í‰ê°€ (ìŠ¤íŠ¸ë¦¬ë°)
            await task_updater.stream_markdown_section(
                "header", "### ğŸ“Š ìš”ì²­ ë¶„ì„ ì¤‘..."
            )
            
            complexity = await self._assess_request_complexity_streaming(
                user_input, task_updater
            )
            
            # Step 2: ë³µì¡ë„ ê¸°ë°˜ ì ì‘ì  ì²˜ë¦¬
            if complexity['level'] == 'simple':
                await self._handle_simple_request_streaming(
                    user_input, task_updater
                )
                
            elif complexity['level'] == 'single_agent':
                await self._handle_single_agent_streaming(
                    user_input,
                    complexity.get('recommended_agent'),
                    task_updater
                )
                
            else:  # complex
                await self._handle_complex_request_streaming(
                    user_input, task_updater
                )
                
        except Exception as e:
            error_msg = f"Orchestrator error: {str(e)}"
            logger.error(error_msg, exc_info=True)
            await task_updater.stream_line(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {error_msg}")
            await task_updater.update_status(
                TaskState.failed,
                message=task_updater.new_agent_message(
                    parts=[TextPart(text=error_msg)]
                )
            )
    
    async def cancel(self, context: RequestContext, event_queue: EventQueue) -> None:
        """ì‘ì—… ì·¨ì†Œ"""
        task_updater = TaskUpdater(event_queue, context.task_id, context.context_id)
        await task_updater.reject()
        logger.info(f"Operation cancelled for context {context.context_id}")
    
    async def _assess_request_complexity_streaming(self, 
                                                 user_input: str,
                                                 task_updater: RealTimeStreamingTaskUpdater) -> Dict:
        """ìš”ì²­ ë³µì¡ë„ í‰ê°€ (ìŠ¤íŠ¸ë¦¬ë°)"""
        
        if not self.openai_client:
            await task_updater.stream_line("- LLM ì—†ì´ ê¸°ë³¸ ë³µì¡ë„ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
            return {'level': 'complex', 'reasoning': 'No LLM available'}
        
        assessment_prompt = f"""
        ë‹¤ìŒ ì‚¬ìš©ì ìš”ì²­ì˜ ë³µì¡ë„ë¥¼ í‰ê°€í•˜ì„¸ìš”:
        "{user_input}"
        
        í‰ê°€ ê¸°ì¤€:
        1. **simple**: ì¦‰ë‹µ ê°€ëŠ¥ (ì •ì˜, ê°œë… ì„¤ëª…, ê°„ë‹¨í•œ ì‚¬ì‹¤ í™•ì¸)
        2. **single_agent**: í•œ ì—ì´ì „íŠ¸ë¡œ ì¶©ë¶„ (ë‹¨ì¼ ì‘ì—…)
        3. **complex**: ì—¬ëŸ¬ ì—ì´ì „íŠ¸ í˜‘ì—… í•„ìš” (ë‹¤ë‹¨ê³„ ë¶„ì„)
        
        JSON ì‘ë‹µ:
        {{
            "level": "simple/single_agent/complex",
            "reasoning": "íŒë‹¨ ê·¼ê±°",
            "recommended_agent": "single_agentì¸ ê²½ìš° ì¶”ì²œ ì—ì´ì „íŠ¸",
            "key_requirements": ["í•µì‹¬ ìš”êµ¬ì‚¬í•­ë“¤"]
        }}
        """
        
        try:
            await task_updater.stream_line("- AIê°€ ìš”ì²­ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
            
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": assessment_prompt}],
                response_format={"type": "json_object"},
                temperature=0.2,
                timeout=30.0
            )
            
            complexity = json.loads(response.choices[0].message.content)
            
            # ê²°ê³¼ ìŠ¤íŠ¸ë¦¬ë°
            level_emoji = {
                'simple': 'ğŸ’¬',
                'single_agent': 'ğŸ¤–', 
                'complex': 'ğŸ¯'
            }
            
            await task_updater.stream_line(
                f"- ë³µì¡ë„: {level_emoji.get(complexity['level'], 'ğŸ“Š')} "
                f"**{complexity['level'].upper()}**"
            )
            await task_updater.stream_line(f"- íŒë‹¨ ê·¼ê±°: {complexity['reasoning']}")
            
            return complexity
            
        except Exception as e:
            logger.warning(f"Complexity assessment failed: {e}")
            await task_updater.stream_line("- ë³µì¡ë„ í‰ê°€ ì‹¤íŒ¨, ê¸°ë³¸ ëª¨ë“œë¡œ ì§„í–‰")
            return {'level': 'complex', 'reasoning': 'Assessment failed'}
    
    async def _handle_simple_request_streaming(self,
                                             user_input: str,
                                             task_updater: RealTimeStreamingTaskUpdater):
        """ê°„ë‹¨í•œ ìš”ì²­ ì¦‰ë‹µ (ìŠ¤íŠ¸ë¦¬ë°)"""
        await task_updater.stream_markdown_section(
            "header", "### ğŸ’¬ ì¦‰ì‹œ ë‹µë³€"
        )
        
        if self.openai_client:
            try:
                # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ
                stream = await self.openai_client.chat.completions.create(
                    model="gpt-4o",
                    messages=[{
                        "role": "system",
                        "content": "ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ê°„ê²°í•˜ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”."
                    }, {
                        "role": "user",
                        "content": user_input
                    }],
                    temperature=0.3,
                    max_tokens=1000,
                    stream=True
                )
                
                await task_updater.stream_line("")
                full_response = ""
                
                async for chunk in stream:
                    if chunk.choices[0].delta.content:
                        content = chunk.choices[0].delta.content
                        full_response += content
                        await task_updater.stream_chunk(content)
                
                await task_updater._flush_buffer()
                
                # ì™„ë£Œ
                await task_updater.update_status(
                    TaskState.completed,
                    message=task_updater.new_agent_message(
                        parts=[TextPart(text=full_response)]
                    )
                )
                
            except Exception as e:
                logger.error(f"Simple request streaming failed: {e}")
                await task_updater.stream_line(f"\nâŒ ì˜¤ë¥˜: {str(e)}")
                await task_updater.update_status(
                    TaskState.failed,
                    message=task_updater.new_agent_message(
                        parts=[TextPart(text=f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}")]
                    )
                )
        else:
            response = "ì£„ì†¡í•©ë‹ˆë‹¤. LLMì´ ì„¤ì •ë˜ì§€ ì•Šì•„ ì¦‰ë‹µì„ ì œê³µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            await task_updater.stream_line(response)
            await task_updater.update_status(
                TaskState.completed,
                message=task_updater.new_agent_message(
                    parts=[TextPart(text=response)]
                )
            )
    
    async def _handle_single_agent_streaming(self,
                                           user_input: str,
                                           agent_name: str,
                                           task_updater: RealTimeStreamingTaskUpdater):
        """ë‹¨ì¼ ì—ì´ì „íŠ¸ ì²˜ë¦¬ (ìŠ¤íŠ¸ë¦¬ë°)"""
        await task_updater.stream_markdown_section(
            "header", f"### ğŸ¤– {agent_name} ì—ì´ì „íŠ¸ ì‹¤í–‰"
        )
        
        # ì—ì´ì „íŠ¸ í™•ì¸
        if agent_name not in self.available_agents:
            # ëŒ€ì²´ ì—ì´ì „íŠ¸ ì°¾ê¸°
            await task_updater.stream_line("- ì§€ì •ëœ ì—ì´ì „íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ëŒ€ì²´ ì—ì´ì „íŠ¸ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤...")
            
            agent_name = await self._find_alternative_agent_streaming(
                user_input, task_updater
            )
            
            if not agent_name:
                await task_updater.stream_line("âŒ ì í•©í•œ ì—ì´ì „íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                await task_updater.update_status(
                    TaskState.failed,
                    message=task_updater.new_agent_message(
                        parts=[TextPart(text="ì—ì´ì „íŠ¸ ì—†ìŒ")]
                    )
                )
                return
        
        # ì—ì´ì „íŠ¸ ì •ë³´
        agent_info = self.available_agents[agent_name]
        agent_url = agent_info['url']
        
        await task_updater.stream_line(f"- ì—ì´ì „íŠ¸: **{agent_name}**")
        await task_updater.stream_line(f"- ìƒíƒœ: âœ… {agent_info.get('version', 'unknown')}")
        
        # ì‚¬ìš©ì ì˜ë„ ì¶”ì¶œ
        await task_updater.stream_line("- ìš”ì²­ ë‚´ìš©ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
        user_intent = await self._extract_user_intent_precisely(user_input)
        
        # ì •ë°€í•œ ì§€ì‹œ ìƒì„±
        await task_updater.stream_line("- ìµœì ì˜ ì‘ì—… ì§€ì‹œë¥¼ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
        instruction = await self._create_precise_instruction_for_agent(
            agent_name, user_intent, agent_info
        )
        
        # A2A í‘œì¤€ í†µì‹ ìœ¼ë¡œ ì‹¤í–‰ (ìŠ¤íŠ¸ë¦¬ë°)
        await task_updater.stream_line(f"\n**ì‹¤í–‰ ì¤‘...**")
        
        # ìŠ¤íŠ¸ë¦¬ë° ì½œë°±
        async def stream_callback(content: str):
            await task_updater.stream_chunk(content)
        
        result = await self.a2a_communicator.send_message(
            agent_url,
            instruction,
            stream_callback=stream_callback
        )
        
        # ê²°ê³¼ ê²€ì¦
        if result['status'] == 'success':
            await task_updater.stream_line(f"\nâœ… {agent_name} ì‘ì—… ì™„ë£Œ")
            
            # ìµœì¢… ì‘ë‹µ ìƒì„±
            final_response = await self._create_final_response_single(
                user_input, agent_name, result, user_intent
            )
            
            await task_updater.update_status(
                TaskState.completed,
                message=task_updater.new_agent_message(
                    parts=[TextPart(text=final_response)]
                )
            )
        else:
            await task_updater.stream_line(f"\nâŒ ì‹¤í–‰ ì‹¤íŒ¨: {result.get('error', 'Unknown')}")
            await task_updater.update_status(
                TaskState.failed,
                message=task_updater.new_agent_message(
                    parts=[TextPart(text=f"ì—ì´ì „íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨: {result.get('error')}")]
                )
            )
    
    async def _handle_complex_request_streaming(self,
                                              user_input: str,
                                              task_updater: RealTimeStreamingTaskUpdater):
        """ë³µì¡í•œ ìš”ì²­ ì²˜ë¦¬ (ìŠ¤íŠ¸ë¦¬ë°)"""
        await task_updater.stream_markdown_section(
            "header", "### ğŸ¯ ë³µì¡í•œ ë¶„ì„ ì‹œì‘"
        )
        
        # Phase 1: ê¹Šì´ ìˆëŠ” ë¶„ì„
        await task_updater.stream_line("\n**1ë‹¨ê³„: ìš”ì²­ ì‹¬ì¸µ ë¶„ì„**")
        
        request_analysis = await self._analyze_request_depth(user_input)
        user_intent = await self._extract_user_intent_precisely(user_input)
        
        await task_updater.stream_line(f"- ì£¼ìš” ëª©í‘œ: {user_intent['main_goal']}")
        await task_updater.stream_line(f"- ì•¡ì…˜ íƒ€ì…: {user_intent['action_type']}")
        
        # Phase 2: ì—ì´ì „íŠ¸ ì¤€ë¹„
        await task_updater.stream_line("\n**2ë‹¨ê³„: AI ì—ì´ì „íŠ¸ ì¤€ë¹„**")
        
        # ê±´ê°•í•œ ì—ì´ì „íŠ¸ë§Œ ì‚¬ìš©
        healthy_agents = await self.agent_discovery.get_healthy_agents()
        await task_updater.stream_line(f"- ì‚¬ìš© ê°€ëŠ¥í•œ ì—ì´ì „íŠ¸: {len(healthy_agents)}ê°œ")
        
        for agent_name in healthy_agents[:5]:  # ìƒìœ„ 5ê°œë§Œ í‘œì‹œ
            health = self.agent_discovery.agent_health_status.get(agent_name, {})
            response_time = health.get('response_time_ms', 'N/A')
            await task_updater.stream_line(f"  - âœ… {agent_name} ({response_time}ms)")
        
        # Phase 3: ì‹¤í–‰ ê³„íš ìˆ˜ë¦½
        await task_updater.stream_line("\n**3ë‹¨ê³„: ìµœì  ì‹¤í–‰ ê³„íš ìˆ˜ë¦½**")
        
        plan = await self._create_streaming_execution_plan(
            user_input, user_intent, healthy_agents, task_updater
        )
        
        if not plan or not plan.get('steps'):
            await task_updater.stream_line("âŒ ì‹¤í–‰ ê³„íš ìˆ˜ë¦½ ì‹¤íŒ¨")
            await task_updater.update_status(
                TaskState.failed,
                message=task_updater.new_agent_message(
                    parts=[TextPart(text="ê³„íš ìˆ˜ë¦½ ì‹¤íŒ¨")]
                )
            )
            return
        
        # ê³„íš í‘œì‹œ
        await task_updater.stream_line(f"\nğŸ“‹ **ì‹¤í–‰ ê³„íš** ({len(plan['steps'])}ë‹¨ê³„)")
        for i, step in enumerate(plan['steps']):
            await task_updater.stream_line(
                f"{i+1}. **{step['agent']}**: {step['purpose']}"
            )
        
        # Phase 4: ì ì‘ì  ì‹¤í–‰
        await task_updater.stream_line("\n**4ë‹¨ê³„: ì‹¤í–‰ ì‹œì‘**")
        
        execution_result = await self._execute_with_streaming_and_replanning(
            plan, user_intent, task_updater
        )
        
        # Phase 5: ê²°ê³¼ ì¢…í•©
        await task_updater.stream_line("\n**5ë‹¨ê³„: ê²°ê³¼ ì¢…í•©**")
        
        final_response = await self._create_comprehensive_response_streaming(
            user_input, user_intent, execution_result, task_updater
        )
        
        # ì™„ë£Œ
        await task_updater.stream_line("\nğŸ‰ **ë¶„ì„ ì™„ë£Œ!**")
        
        await task_updater.update_status(
            TaskState.completed,
            message=task_updater.new_agent_message(
                parts=[TextPart(text=final_response)]
            )
        )
    
    async def _find_alternative_agent_streaming(self,
                                              user_input: str,
                                              task_updater: RealTimeStreamingTaskUpdater) -> Optional[str]:
        """ëŒ€ì²´ ì—ì´ì „íŠ¸ ì°¾ê¸° (ìŠ¤íŠ¸ë¦¬ë°)"""
        
        # íƒœìŠ¤í¬ ì„¤ëª…ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
        keywords = []
        if 'data' in user_input.lower():
            keywords.extend(['data', 'analysis', 'processing'])
        if 'visual' in user_input.lower() or 'chart' in user_input.lower():
            keywords.append('visualization')
        if 'clean' in user_input.lower():
            keywords.append('cleaning')
        
        # A2A Discoveryë¡œ ìµœì  ì—ì´ì „íŠ¸ ì°¾ê¸°
        best_agent = await self.agent_discovery.find_best_agent_for_task(
            user_input, keywords
        )
        
        if best_agent:
            await task_updater.stream_line(f"- ëŒ€ì²´ ì—ì´ì „íŠ¸ ë°œê²¬: **{best_agent}**")
            return best_agent
        
        # í´ë°±: ì²« ë²ˆì§¸ ê±´ê°•í•œ ì—ì´ì „íŠ¸
        healthy = await self.agent_discovery.get_healthy_agents()
        if healthy:
            await task_updater.stream_line(f"- ê¸°ë³¸ ì—ì´ì „íŠ¸ ì‚¬ìš©: **{healthy[0]}**")
            return healthy[0]
        
        return None
    
    async def _create_streaming_execution_plan(self,
                                             user_input: str,
                                             user_intent: Dict,
                                             healthy_agents: List[str],
                                             task_updater: RealTimeStreamingTaskUpdater) -> Dict:
        """ì‹¤í–‰ ê³„íš ìˆ˜ë¦½ (ìŠ¤íŠ¸ë¦¬ë° í”¼ë“œë°±)"""
        
        if not self.openai_client or not healthy_agents:
            return self._create_basic_plan(healthy_agents)
        
        await task_updater.stream_line("- AIê°€ ìµœì ì˜ ì‹¤í–‰ ê²½ë¡œë¥¼ ì„¤ê³„í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
        
        # ì—ì´ì „íŠ¸ ì •ë³´ ìˆ˜ì§‘
        agent_details = {}
        for agent_name in healthy_agents:
            if agent_name in self.available_agents:
                info = self.available_agents[agent_name]
                agent_details[agent_name] = {
                    'description': info.get('description', ''),
                    'skills': [s.get('name', '') for s in info.get('skills', [])]
                }
        
        planning_prompt = f"""
        ì‚¬ìš©ì ìš”ì²­: {user_input}
        ì‚¬ìš©ì ì˜ë„: {json.dumps(user_intent, ensure_ascii=False)}
        
        ì‚¬ìš© ê°€ëŠ¥í•œ ì—ì´ì „íŠ¸:
        {json.dumps(agent_details, ensure_ascii=False, indent=2)}
        
        ì´ ìš”ì²­ì„ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ ìµœì ì˜ ì‹¤í–‰ ê³„íšì„ ìˆ˜ë¦½í•˜ì„¸ìš”.
        
        ì¤‘ìš”:
        - ì‚¬ìš©ì ì˜ë„ì— í•„ìš”í•œ ì—ì´ì „íŠ¸ë§Œ ì„ íƒ
        - ë…¼ë¦¬ì ì¸ ì‹¤í–‰ ìˆœì„œ ê³ ë ¤
        - ê° ë‹¨ê³„ë³„ ëª…í™•í•œ ëª©ì  ì„¤ì •
        
        JSON í˜•ì‹:
        {{
            "execution_strategy": "ì „ì²´ ì „ëµ",
            "steps": [
                {{
                    "agent": "ì—ì´ì „íŠ¸ëª…",
                    "purpose": "ì´ ë‹¨ê³„ì˜ ëª©ì ",
                    "instruction": "êµ¬ì²´ì  ì‘ì—… ì§€ì‹œ"
                }}
            ]
        }}
        """
        
        try:
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": planning_prompt}],
                response_format={"type": "json_object"},
                temperature=0.3,
                max_tokens=2000
            )
            
            plan = json.loads(response.choices[0].message.content)
            
            # ê³„íš ê²€ì¦
            valid_steps = []
            for step in plan.get('steps', []):
                if step.get('agent') in healthy_agents:
                    valid_steps.append(step)
            
            plan['steps'] = valid_steps
            
            await task_updater.stream_line("- âœ… ì‹¤í–‰ ê³„íš ìˆ˜ë¦½ ì™„ë£Œ")
            return plan
            
        except Exception as e:
            logger.error(f"Planning failed: {e}")
            await task_updater.stream_line("- âš ï¸ ê¸°ë³¸ ê³„íšìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤")
            return self._create_basic_plan(healthy_agents)
    
    async def _execute_with_streaming_and_replanning(self,
                                                    plan: Dict,
                                                    user_intent: Dict,
                                                    task_updater: RealTimeStreamingTaskUpdater) -> Dict:
        """ìŠ¤íŠ¸ë¦¬ë°ê³¼ ë¦¬í”Œë˜ë‹ì„ í¬í•¨í•œ ì‹¤í–‰"""
        
        execution_results = {}
        execution_history = []
        
        for i, step in enumerate(plan['steps']):
            agent_name = step['agent']
            agent_info = self.available_agents.get(agent_name, {})
            agent_url = agent_info.get('url')
            
            if not agent_url:
                await task_updater.stream_line(f"\nâš ï¸ {agent_name} ì—ì´ì „íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ê±´ë„ˆëœë‹ˆë‹¤")
                continue
            
            # ë‹¨ê³„ ì‹œì‘
            await task_updater.stream_line(f"\n**[{i+1}/{len(plan['steps'])}] {agent_name} ì‹¤í–‰**")
            await task_updater.stream_line(f"- ëª©ì : {step['purpose']}")
            
            # í—¬ìŠ¤ ì²´í¬
            health = self.agent_discovery.agent_health_status.get(agent_name, {})
            if health.get('status') != 'healthy':
                await task_updater.stream_line(f"- âš ï¸ ì—ì´ì „íŠ¸ ìƒíƒœ ë¶ˆëŸ‰, ê±´ë„ˆëœë‹ˆë‹¤")
                continue
            
            # ìŠ¤íŠ¸ë¦¬ë° ì‹¤í–‰
            await task_updater.stream_line("- ì²˜ë¦¬ ì¤‘...")
            
            async def agent_stream_callback(content: str):
                # ì—ì´ì „íŠ¸ ì¶œë ¥ì„ ë“¤ì—¬ì“°ê¸°ë¡œ í‘œì‹œ
                lines = content.split('\n')
                for line in lines:
                    if line.strip():
                        await task_updater.stream_line(f"  > {line}")
            
            result = await self.a2a_communicator.send_message(
                agent_url,
                step.get('instruction', step['purpose']),
                stream_callback=agent_stream_callback
            )
            
            # ê²°ê³¼ ì €ì¥
            execution_results[agent_name] = result
            execution_history.append({
                'step': i,
                'agent': agent_name,
                'result': result,
                'timestamp': datetime.now().isoformat()
            })
            
            if result['status'] == 'success':
                await task_updater.stream_line(f"- âœ… ì™„ë£Œ")
            else:
                await task_updater.stream_line(f"- âŒ ì‹¤íŒ¨: {result.get('error', 'Unknown')}")
                
                # ê°„ë‹¨í•œ ë¦¬í”Œë˜ë‹: ì‹¤íŒ¨ì‹œ ë‹¤ìŒ ê°€ëŠ¥í•œ ì—ì´ì „íŠ¸ ì‹œë„
                if i < len(plan['steps']) - 1:
                    await task_updater.stream_line("- ğŸ”„ ëŒ€ì²´ ê²½ë¡œ íƒìƒ‰ ì¤‘...")
        
        return {
            'results': execution_results,
            'history': execution_history,
            'total_steps': len(plan['steps']),
            'successful_steps': len([r for r in execution_results.values() 
                                   if r.get('status') == 'success'])
        }
    
    async def _create_comprehensive_response_streaming(self,
                                                     user_input: str,
                                                     user_intent: Dict,
                                                     execution_result: Dict,
                                                     task_updater: RealTimeStreamingTaskUpdater) -> str:
        """ì¢…í•© ì‘ë‹µ ìƒì„± (ìŠ¤íŠ¸ë¦¬ë°)"""
        
        await task_updater.stream_line("- ë¶„ì„ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
        
        if not self.openai_client:
            return self._create_basic_summary(execution_result)
        
        # ì„±ê³µí•œ ê²°ê³¼ë§Œ ì¶”ì¶œ
        successful_results = {
            agent: result
            for agent, result in execution_result['results'].items()
            if result.get('status') == 'success'
        }
        
        if not successful_results:
            # ì‹¤íŒ¨í•œ ì—ì´ì „íŠ¸ë“¤ì˜ ì˜¤ë¥˜ ë¶„ì„
            failed_agents = []
            for agent, result in execution_result['results'].items():
                if result.get('status') == 'failed':
                    failed_agents.append(f"- {agent}: {result.get('error', 'Unknown error')}")
            
            # LLMì„ ì‚¬ìš©í•˜ì—¬ ëŒ€ì•ˆ ì‘ë‹µ ìƒì„±
            if self.openai_client:
                try:
                    fallback_prompt = f"""
                    ì‚¬ìš©ì ìš”ì²­: {user_input}
                    
                    AI ì—ì´ì „íŠ¸ë“¤ê³¼ì˜ í†µì‹ ì´ ì‹¤íŒ¨í–ˆì§€ë§Œ, ë‹¹ì‹ ì˜ ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ì ìš”ì²­ì— ìµœëŒ€í•œ ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.
                    
                    ì‹¤íŒ¨í•œ ì—ì´ì „íŠ¸ë“¤:
                    {chr(10).join(failed_agents) if failed_agents else '- ëª¨ë“  ì—ì´ì „íŠ¸ í†µì‹  ì‹¤íŒ¨'}
                    
                    ì§€ì¹¨:
                    1. ì‚¬ìš©ì ìš”ì²­ì˜ í•µì‹¬ ë‚´ìš©ì— ëŒ€í•´ ì§ì ‘ ë‹µë³€
                    2. ì¼ë°˜ì ì¸ ì ‘ê·¼ ë°©ë²•ê³¼ ê³ ë ¤ì‚¬í•­ ì œì‹œ
                    3. ì‹¤ë¬´ì—ì„œ í™œìš©í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì¸ ì¡°ì–¸ í¬í•¨
                    4. ì¶”ê°€ ì •ë³´ê°€ í•„ìš”í•œ ë¶€ë¶„ ëª…ì‹œ
                    """
                    
                    response = await self.openai_client.chat.completions.create(
                        model="gpt-4o",
                        messages=[{"role": "user", "content": fallback_prompt}],
                        temperature=0.3,
                        max_tokens=2000
                    )
                    
                    await task_updater.stream_line("- âš ï¸ ì—ì´ì „íŠ¸ í†µì‹  ì‹¤íŒ¨, LLM ê¸°ë°˜ ëŒ€ì•ˆ ì‘ë‹µ ìƒì„±")
                    return response.choices[0].message.content
                    
                except Exception as e:
                    logger.error(f"Fallback response generation failed: {e}")
            
            # ìµœí›„ ìˆ˜ë‹¨: ê¸°ë³¸ ì‘ë‹µ
            return f"""
## ë¶„ì„ ìš”ì²­ ì²˜ë¦¬ ê²°ê³¼

âš ï¸ **AI ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œê³¼ì˜ í†µì‹ ì— ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.**

### ìš”ì²­ ë‚´ìš©
{user_input[:200]}{"..." if len(user_input) > 200 else ""}

### ë°œìƒí•œ ë¬¸ì œ
{chr(10).join(failed_agents) if failed_agents else "- ëª¨ë“  AI ì—ì´ì „íŠ¸ì™€ì˜ í†µì‹ ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."}

### ê¶Œì¥ ì¡°ì¹˜
1. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”
2. ìš”ì²­ì„ ë” êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•´ ë³´ì„¸ìš”
3. ë‹¨ê³„ë³„ë¡œ ë‚˜ëˆ„ì–´ ìš”ì²­í•´ ë³´ì„¸ìš”

ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ì‹œìŠ¤í…œ ìƒíƒœë¡œëŠ” ì™„ì „í•œ ë¶„ì„ì„ ì œê³µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
            """
        
        synthesis_prompt = f"""
        ì‚¬ìš©ì ìš”ì²­: {user_input}
        ì‚¬ìš©ì ì˜ë„: {json.dumps(user_intent, ensure_ascii=False)}
        
        ë¶„ì„ ê²°ê³¼:
        {json.dumps(successful_results, ensure_ascii=False, indent=2)[:3000]}
        
        ìœ„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ì ìš”ì²­ì— ëŒ€í•œ ì¢…í•©ì ì¸ ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”.
        
        ì§€ì¹¨:
        1. ì‚¬ìš©ìì˜ {user_intent['action_type']} ìš”ì²­ì— ì§ì ‘ ë‹µë³€
        2. êµ¬ì²´ì ì¸ ë°ì´í„°ì™€ ê·¼ê±° ì œì‹œ
        3. í•µì‹¬ ë°œê²¬ì‚¬í•­ ê°•ì¡°
        4. ì‹¤ìš©ì ì¸ ì¸ì‚¬ì´íŠ¸ ì œê³µ
        """
        
        try:
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": synthesis_prompt}],
                temperature=0.3,
                max_tokens=3000
            )
            
            await task_updater.stream_line("- âœ… ì¢…í•© ì™„ë£Œ")
            
            return response.choices[0].message.content
            
        except Exception as e:
            logger.error(f"Synthesis failed: {e}")
            return self._create_basic_summary(execution_result)
    
    async def _extract_user_intent_precisely(self, user_input: str) -> Dict:
        """ì‚¬ìš©ì ì˜ë„ ì •ë°€ ì¶”ì¶œ"""
        
        if not self.openai_client:
            return {
                'main_goal': user_input,
                'action_type': 'analyze',
                'specific_requirements': [],
                'expected_outcomes': ['ë¶„ì„ ê²°ê³¼']
            }
        
        intent_prompt = f"""
        ì‚¬ìš©ì ì…ë ¥: "{user_input}"
        
        ì˜ë„ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”:
        1. action_type: analyze/verify/recommend/diagnose/predict/compare/explain
        2. main_goal: í•œ ë¬¸ì¥ ìš”ì•½
        3. specific_requirements: êµ¬ì²´ì  ìš”êµ¬ì‚¬í•­
        4. expected_outcomes: ê¸°ëŒ€ ê²°ê³¼
        
        JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”.
        """
        
        try:
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": intent_prompt}],
                response_format={"type": "json_object"},
                temperature=0.2,
                max_tokens=500
            )
            
            return json.loads(response.choices[0].message.content)
            
        except Exception as e:
            logger.warning(f"Intent extraction failed: {e}")
            return {
                'main_goal': user_input,
                'action_type': 'analyze',
                'specific_requirements': [],
                'expected_outcomes': ['ë¶„ì„ ê²°ê³¼']
            }
    
    async def _analyze_request_depth(self, user_input: str) -> Dict:
        """ìš”ì²­ ê¹Šì´ ë¶„ì„"""
        
        if not self.openai_client:
            return {
                'detail_level': 5,
                'has_role_description': False,
                'explicit_requirements': ['ê¸°ë³¸ ë¶„ì„'],
                'implicit_needs': ['ë°ì´í„° ì´í•´']
            }
        
        try:
            analysis_prompt = f"""
            ìš”ì²­ ë¶„ì„: "{user_input}"
            
            ë¶„ì„ í•­ëª©:
            1. êµ¬ì²´ì„± ìˆ˜ì¤€ (1-10)
            2. ëª…ì‹œì  vs ì•”ì‹œì  ìš”êµ¬ì‚¬í•­
            3. ì˜ˆìƒ ì‘ë‹µ ê¹Šì´
            
            JSON ì‘ë‹µ ìš”ì²­
            """
            
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": analysis_prompt}],
                response_format={"type": "json_object"},
                temperature=0.3,
                max_tokens=500
            )
            
            return json.loads(response.choices[0].message.content)
            
        except Exception as e:
            logger.warning(f"Depth analysis failed: {e}")
            return {
                'detail_level': 5,
                'explicit_requirements': ['ê¸°ë³¸ ë¶„ì„']
            }
    
    async def _create_precise_instruction_for_agent(self,
                                                  agent_name: str,
                                                  user_intent: Dict,
                                                  agent_info: Dict) -> str:
        """ì—ì´ì „íŠ¸ë³„ ì •ë°€ ì§€ì‹œ ìƒì„±"""
        
        if not self.openai_client:
            return f"{user_intent['main_goal']}ì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”."
        
        # ì—ì´ì „íŠ¸ ìŠ¤í‚¬ ì •ë³´
        skills = agent_info.get('skills', [])
        skill_names = [s.get('name', '') for s in skills]
        
        instruction_prompt = f"""
        ì—ì´ì „íŠ¸: {agent_name}
        ì—ì´ì „íŠ¸ ìŠ¤í‚¬: {skill_names}
        
        ì‚¬ìš©ì ëª©í‘œ: {user_intent['main_goal']}
        ì•¡ì…˜ íƒ€ì…: {user_intent['action_type']}
        
        ì´ ì—ì´ì „íŠ¸ê°€ ìˆ˜í–‰í•´ì•¼ í•  êµ¬ì²´ì ì¸ ì‘ì—… ì§€ì‹œë¥¼ ì‘ì„±í•˜ì„¸ìš”.
        ì—ì´ì „íŠ¸ì˜ ìŠ¤í‚¬ì„ ìµœëŒ€í•œ í™œìš©í•˜ë„ë¡ ì§€ì‹œí•˜ì„¸ìš”.
        """
        
        try:
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": instruction_prompt}],
                temperature=0.3,
                max_tokens=1000
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            logger.warning(f"Instruction generation failed: {e}")
            return f"{user_intent['main_goal']}ì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”."
    
    async def _create_final_response_single(self,
                                          user_input: str,
                                          agent_name: str,
                                          result: Dict,
                                          user_intent: Dict) -> str:
        """ë‹¨ì¼ ì—ì´ì „íŠ¸ ìµœì¢… ì‘ë‹µ"""
        
        if not self.openai_client:
            return f"{agent_name} ì—ì´ì „íŠ¸ ì‹¤í–‰ ì™„ë£Œ:\n{result.get('summary', 'ì‘ì—… ì™„ë£Œ')}"
        
        response_prompt = f"""
        ì‚¬ìš©ì ìš”ì²­: {user_input}
        ì‚¬ìš©ì ì˜ë„: {user_intent['main_goal']}
        
        {agent_name} ì—ì´ì „íŠ¸ ì‹¤í–‰ ê²°ê³¼:
        {json.dumps(result, ensure_ascii=False)[:2000]}
        
        ì‚¬ìš©ì ìš”ì²­ì— ì§ì ‘ ë‹µë³€í•˜ëŠ” ì‘ë‹µì„ ì‘ì„±í•˜ì„¸ìš”.
        """
        
        try:
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": response_prompt}],
                temperature=0.3,
                max_tokens=2000
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            logger.error(f"Response generation failed: {e}")
            return f"{agent_name} ì‘ì—… ì™„ë£Œ"
    
    def _create_basic_plan(self, available_agents: List[str]) -> Dict:
        """ê¸°ë³¸ ì‹¤í–‰ ê³„íš"""
        steps = []
        
        # ê¸°ë³¸ ì›Œí¬í”Œë¡œìš°
        basic_flow = [
            ('data_loader', 'ë°ì´í„° ë¡œë“œ'),
            ('data_cleaning', 'ë°ì´í„° ì •ì œ'),
            ('eda_tools', 'íƒìƒ‰ì  ë¶„ì„'),
            ('data_visualization', 'ì‹œê°í™”')
        ]
        
        for agent, purpose in basic_flow:
            if agent in available_agents:
                steps.append({
                    'agent': agent,
                    'purpose': purpose,
                    'instruction': f'{purpose} ì‘ì—…ì„ ìˆ˜í–‰í•˜ì„¸ìš”'
                })
        
        return {
            'execution_strategy': 'í‘œì¤€ ë°ì´í„° ë¶„ì„',
            'steps': steps
        }
    
    def _create_basic_summary(self, execution_result: Dict) -> str:
        """ê¸°ë³¸ ìš”ì•½"""
        total = execution_result['total_steps']
        success = execution_result['successful_steps']
        
        summary = f"## ë¶„ì„ ì™„ë£Œ\n\n"
        summary += f"- ì´ {total}ë‹¨ê³„ ì¤‘ {success}ë‹¨ê³„ ì„±ê³µ\n"
        
        for agent, result in execution_result['results'].items():
            if result.get('status') == 'success':
                summary += f"- âœ… {agent}: ì™„ë£Œ\n"
            else:
                summary += f"- âŒ {agent}: ì‹¤íŒ¨\n"
        
        return summary


def create_orchestrator_v8_server():
    """v8.0 ì„œë²„ ìƒì„±"""
    
    agent_card = AgentCard(
        name="Universal Intelligent Orchestrator v8.0",
        description="A2A SDK 0.2.9 í‘œì¤€ ê¸°ëŠ¥ ê·¹ëŒ€í™” + ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° í˜ì‹ ",
        url="http://localhost:8100",
        version="8.0.0",
        capabilities=AgentCapabilities(
            streaming=True,
            pushNotifications=True,
            stateTransitionHistory=True
        ),
        defaultInputModes=["text/plain"],
        defaultOutputModes=["text/plain", "application/json"],
        skills=[
            AgentSkill(
                id="real_time_streaming",
                name="Real-Time Character Streaming",
                description="ë¬¸ì ë‹¨ìœ„ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì¦‰ê°ì ì¸ í”¼ë“œë°± ì œê³µ",
                tags=["streaming", "real-time", "responsive"]
            ),
            AgentSkill(
                id="dynamic_discovery",
                name="Dynamic Agent Discovery with A2A",
                description="A2A CardResolverë¥¼ í™œìš©í•œ ì‹¤ì‹œê°„ ì—ì´ì „íŠ¸ ë°œê²¬ ë° í—¬ìŠ¤ ì²´í¬",
                tags=["discovery", "a2a", "health-check"]
            ),
            AgentSkill(
                id="standard_a2a_communication",
                name="Standard A2A Protocol Communication",
                description="A2AClientë¥¼ í†µí•œ í‘œì¤€í™”ëœ ì—ì´ì „íŠ¸ í†µì‹ ",
                tags=["a2a", "protocol", "standard"]
            ),
            AgentSkill(
                id="adaptive_complexity_handling",
                name="Adaptive Complexity Processing",
                description="ìš”ì²­ ë³µì¡ë„ì— ë”°ë¥¸ ì ì‘ì  ì²˜ë¦¬ (Simple/Single/Complex)",
                tags=["adaptive", "intelligent", "complexity"]
            ),
            AgentSkill(
                id="llm_streaming_integration",
                name="LLM Streaming Integration",
                description="OpenAI ìŠ¤íŠ¸ë¦¬ë°ê³¼ ì§ì ‘ í†µí•©ëœ ì‹¤ì‹œê°„ ì‘ë‹µ",
                tags=["llm", "streaming", "openai"]
            )
        ]
    )
    
    executor = UniversalIntelligentOrchestratorV8()
    
    # ì´ˆê¸°í™”ë¥¼ ìœ„í•œ ë¹„ë™ê¸° íƒœìŠ¤í¬
    async def startup():
        await executor.initialize()
    
    task_store = InMemoryTaskStore()
    request_handler = DefaultRequestHandler(
        agent_executor=executor,
        task_store=task_store
    )
    
    app = A2AStarletteApplication(
        agent_card=agent_card,
        http_handler=request_handler
    )
    
    # Starlette ì•±ì— startup ì´ë²¤íŠ¸ ì¶”ê°€
    starlette_app = app.build()
    starlette_app.add_event_handler("startup", startup)
    
    return starlette_app


def main():
    """ë©”ì¸ ì‹¤í–‰"""
    logger.info("ğŸš€ Starting Universal Intelligent Orchestrator v8.0")
    logger.info("ğŸ“¡ A2A SDK 0.2.9 Features: Dynamic Discovery + Real-Time Streaming")
    
    app = create_orchestrator_v8_server()
    
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8100,
        log_level="info"
    )


if __name__ == "__main__":
    main()