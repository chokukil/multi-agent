#!/usr/bin/env python3
"""
A2A Orchestrator v7.0 - Universal Intelligent Orchestrator
ì™„ì „í•œ í†µí•© ë²„ì „: ì ì‘ì  ì²˜ë¦¬ + ë™ì  ë¦¬í”Œë˜ë‹ + ë²”ìš© LLM ì‹œìŠ¤í…œ
"""

import asyncio
import json
import logging
import os
import re
import time
from datetime import datetime
from typing import Any, Dict, List, Optional, AsyncGenerator

import httpx
import uvicorn
from openai import AsyncOpenAI

# A2A SDK 0.2.9 í‘œì¤€ ì„í¬íŠ¸
from a2a.server.apps import A2AStarletteApplication
from a2a.server.request_handlers import DefaultRequestHandler
from a2a.server.tasks import InMemoryTaskStore, TaskUpdater
from a2a.server.agent_execution import AgentExecutor, RequestContext
from a2a.server.events import EventQueue
from a2a.types import (
    AgentCard,
    AgentSkill,
    AgentCapabilities,
    TaskState,
    TextPart
)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# AI DS Team ì—ì´ì „íŠ¸ í¬íŠ¸ ë§¤í•‘
AGENT_PORTS = {
    "data_cleaning": 8306,
    "data_loader": 8307, 
    "data_visualization": 8308,
    "data_wrangling": 8309,
    "eda_tools": 8310,
    "feature_engineering": 8311,
    "h2o_modeling": 8312,
    "mlflow_tracking": 8313,
    "sql_database": 8314
}


class StreamingTaskUpdater(TaskUpdater):
    """ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì—…ë°ì´íŠ¸ ì§€ì›"""
    
    async def stream_update(self, content: str):
        """ì¤‘ê°„ ê²°ê³¼ ìŠ¤íŠ¸ë¦¬ë°"""
        await self.update_status(
            TaskState.working,
            message=self.new_agent_message(parts=[TextPart(text=content)])
        )
    
    async def stream_final_response(self, response: str):
        """ìµœì¢… ì‘ë‹µì„ ì™„ë£Œ ìƒíƒœë¡œ ì „ë‹¬"""
        await self.update_status(
            TaskState.completed,
            message=self.new_agent_message(parts=[TextPart(text=response)])
        )


class ExecutionMonitor:
    """ì‹¤í–‰ ìƒíƒœë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•˜ê³  ë¦¬í”Œë˜ë‹ í•„ìš”ì„±ì„ íŒë‹¨"""
    
    def __init__(self, openai_client):
        self.openai_client = openai_client
        self.execution_history = []
        self.original_plan = None
        self.current_context = {}
        
    async def should_replan(self, 
                          current_step: int,
                          agent_result: Dict,
                          remaining_steps: List[Dict],
                          user_intent: Dict) -> Dict:
        """ë¦¬í”Œë˜ë‹ì´ í•„ìš”í•œì§€ íŒë‹¨"""
        
        # 1. ì‹¤íŒ¨ ê¸°ë°˜ ë¦¬í”Œë˜ë‹
        if agent_result.get('status') == 'failed':
            return {
                'should_replan': True,
                'reason': 'agent_failure',
                'severity': 'high',
                'details': f"ì—ì´ì „íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨: {agent_result.get('error')}"
            }
        
        # 2. í’ˆì§ˆ ê¸°ë°˜ ë¦¬í”Œë˜ë‹
        validation = agent_result.get('validation', {})
        if not validation.get('is_valid', True):
            return {
                'should_replan': True,
                'reason': 'quality_issue',
                'severity': 'medium',
                'details': f"ê²°ê³¼ í’ˆì§ˆ ë¶€ì¡±: {validation.get('warnings')}"
            }
        
        # 3. ìƒˆë¡œìš´ ë°œê²¬ ê¸°ë°˜ ë¦¬í”Œë˜ë‹
        new_insights = await self._extract_new_insights(agent_result)
        if new_insights.get('changes_direction'):
            return {
                'should_replan': True,
                'reason': 'new_discovery',
                'severity': 'medium',
                'details': new_insights.get('discovery')
            }
        
        # 4. ëª©í‘œ ë‹¬ì„±ë„ ê¸°ë°˜ ë¦¬í”Œë˜ë‹
        achievement = await self._assess_goal_achievement(
            self.execution_history,
            user_intent
        )
        
        if achievement.get('percentage', 0) > 90:
            return {
                'should_replan': True,
                'reason': 'early_completion',
                'severity': 'low',
                'details': "ëª©í‘œê°€ ì¡°ê¸°ì— ë‹¬ì„±ë˜ì–´ ë‚˜ë¨¸ì§€ ë‹¨ê³„ ìƒëµ ê°€ëŠ¥"
            }
        
        # 5. íš¨ìœ¨ì„± ê¸°ë°˜ ë¦¬í”Œë˜ë‹
        if await self._found_better_path(current_step, remaining_steps):
            return {
                'should_replan': True,
                'reason': 'optimization',
                'severity': 'low',
                'details': "ë” íš¨ìœ¨ì ì¸ ê²½ë¡œ ë°œê²¬"
            }
        
        return {'should_replan': False}
    
    async def _extract_new_insights(self, agent_result: Dict) -> Dict:
        """ê²°ê³¼ì—ì„œ ìƒˆë¡œìš´ ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ"""
        if not self.openai_client:
            return {'changes_direction': False}
        
        insight_prompt = f"""
        ë‹¤ìŒ ë¶„ì„ ê²°ê³¼ë¥¼ ê²€í† í•˜ì„¸ìš”:
        {json.dumps(agent_result, ensure_ascii=False)[:1000]}
        
        ì´ ê²°ê³¼ê°€ ë‹¤ìŒì„ í¬í•¨í•˜ëŠ”ì§€ íŒë‹¨í•˜ì„¸ìš”:
        1. ì´ˆê¸° ê°€ì •ê³¼ ë‹¤ë¥¸ ë°œê²¬
        2. ë¶„ì„ ë°©í–¥ì„ ë°”ê¿”ì•¼ í•  ì¤‘ìš”í•œ ì •ë³´
        3. ì¶”ê°€ ì¡°ì‚¬ê°€ í•„ìš”í•œ ì´ìƒ íŒ¨í„´
        4. ë‹¤ë¥¸ ì ‘ê·¼ì´ í•„ìš”í•œ ë³µì¡ì„±
        
        JSON ì‘ë‹µ:
        {{
            "changes_direction": true/false,
            "discovery": "ë°œê²¬ ë‚´ìš©",
            "implications": "ì´ê²ƒì´ ì˜ë¯¸í•˜ëŠ” ë°”",
            "recommended_action": "ê¶Œì¥ ì¡°ì¹˜"
        }}
        """
        
        try:
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": insight_prompt}],
                response_format={"type": "json_object"},
                temperature=0.3,
                timeout=30.0
            )
            
            return json.loads(response.choices[0].message.content)
            
        except Exception as e:
            logger.warning(f"ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return {'changes_direction': False}
    
    async def _assess_goal_achievement(self, execution_history: List[Dict], 
                                     user_intent: Dict) -> Dict:
        """ëª©í‘œ ë‹¬ì„±ë„ í‰ê°€"""
        if not self.openai_client or not execution_history:
            return {'percentage': 0}
        
        assessment_prompt = f"""
        ì‚¬ìš©ì ëª©í‘œ: {user_intent.get('main_goal', '')}
        ê¸°ëŒ€ ê²°ê³¼: {json.dumps(user_intent.get('expected_outcomes', []), ensure_ascii=False)}
        
        í˜„ì¬ê¹Œì§€ ì‹¤í–‰ ê²°ê³¼ ìš”ì•½:
        {json.dumps([{
            'agent': h['agent'],
            'status': h['result'].get('status', 'unknown')
        } for h in execution_history[-5:]], ensure_ascii=False)}
        
        ëª©í‘œ ë‹¬ì„±ë„ë¥¼ 0-100%ë¡œ í‰ê°€í•˜ì„¸ìš”.
        
        JSON ì‘ë‹µ:
        {{
            "percentage": 0-100,
            "achieved_goals": ["ë‹¬ì„±ëœ ëª©í‘œë“¤"],
            "remaining_goals": ["ë‚¨ì€ ëª©í‘œë“¤"]
        }}
        """
        
        try:
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": assessment_prompt}],
                response_format={"type": "json_object"},
                temperature=0.3,
                timeout=30.0
            )
            
            return json.loads(response.choices[0].message.content)
            
        except Exception as e:
            logger.warning(f"ëª©í‘œ ë‹¬ì„±ë„ í‰ê°€ ì‹¤íŒ¨: {e}")
            return {'percentage': 0}
    
    async def _found_better_path(self, current_step: int, 
                               remaining_steps: List[Dict]) -> bool:
        """ë” ë‚˜ì€ ê²½ë¡œê°€ ìˆëŠ”ì§€ í™•ì¸"""
        # ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±: ë‚¨ì€ ë‹¨ê³„ê°€ 3ê°œ ì´ìƒì´ê³  ì¤‘ë³µ ê°€ëŠ¥ì„±ì´ ìˆìœ¼ë©´ True
        if len(remaining_steps) >= 3:
            agents = [step.get('agent') for step in remaining_steps]
            if len(agents) != len(set(agents)):  # ì¤‘ë³µ ì—ì´ì „íŠ¸ê°€ ìˆìœ¼ë©´
                return True
        return False


class ReplanningEngine:
    """ë™ì ìœ¼ë¡œ ê³„íšì„ ìˆ˜ì •í•˜ëŠ” ë¦¬í”Œë˜ë‹ ì—”ì§„"""
    
    def __init__(self, openai_client, available_agents):
        self.openai_client = openai_client
        self.available_agents = available_agents
        self.replanning_history = []
        
    async def create_new_plan(self,
                            replan_reason: Dict,
                            current_state: Dict,
                            remaining_steps: List[Dict],
                            user_intent: Dict,
                            execution_history: List[Dict]) -> Dict:
        """í˜„ì¬ ìƒí™©ì— ë§ëŠ” ìƒˆë¡œìš´ ê³„íš ìƒì„±"""
        
        strategy = self._determine_replanning_strategy(replan_reason)
        
        if strategy == 'recovery':
            return await self._create_recovery_plan(
                replan_reason,
                current_state,
                remaining_steps,
                user_intent
            )
        elif strategy == 'optimization':
            return await self._create_optimized_plan(
                current_state,
                remaining_steps,
                user_intent,
                execution_history
            )
        elif strategy == 'pivot':
            return await self._create_pivot_plan(
                replan_reason,
                current_state,
                user_intent,
                execution_history
            )
        elif strategy == 'completion':
            return await self._create_completion_plan(
                current_state,
                user_intent,
                execution_history
            )
        else:
            return {'steps': remaining_steps}
    
    def _determine_replanning_strategy(self, replan_reason: Dict) -> str:
        """ë¦¬í”Œë˜ë‹ ì „ëµ ê²°ì •"""
        reason = replan_reason.get('reason', '')
        severity = replan_reason.get('severity', 'low')
        
        if reason == 'agent_failure' and severity == 'high':
            return 'recovery'
        elif reason == 'optimization':
            return 'optimization'
        elif reason == 'new_discovery':
            return 'pivot'
        elif reason == 'early_completion':
            return 'completion'
        else:
            return 'continue'
    
    async def _create_recovery_plan(self,
                                  replan_reason: Dict,
                                  current_state: Dict,
                                  remaining_steps: List[Dict],
                                  user_intent: Dict) -> Dict:
        """ì‹¤íŒ¨ ë³µêµ¬ë¥¼ ìœ„í•œ ê³„íš"""
        
        if not self.openai_client:
            return self._create_fallback_recovery_plan(replan_reason, remaining_steps)
        
        recovery_prompt = f"""
        ì‹¤í–‰ ì‹¤íŒ¨ ìƒí™©:
        - ì‹¤íŒ¨ ì´ìœ : {replan_reason['details']}
        - í˜„ì¬ ìƒíƒœ: {json.dumps(current_state, ensure_ascii=False)[:500]}
        - ì‚¬ìš©ì ëª©í‘œ: {user_intent['main_goal']}
        
        ì‚¬ìš© ê°€ëŠ¥í•œ ì—ì´ì „íŠ¸:
        {json.dumps(list(self.available_agents.keys()), ensure_ascii=False)}
        
        ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ì—¬ ë³µêµ¬ ê³„íšì„ ìˆ˜ë¦½í•˜ì„¸ìš”:
        1. ëŒ€ì²´ ì—ì´ì „íŠ¸ë¡œ ê°™ì€ ì‘ì—… ì‹œë„
        2. ë‹¤ë¥¸ ì ‘ê·¼ ë°©ë²•ìœ¼ë¡œ ìš°íšŒ
        3. ë¶€ë¶„ì  ê²°ê³¼ë¡œ ì§„í–‰
        4. ì¶”ê°€ ë°ì´í„° ìˆ˜ì§‘ í›„ ì¬ì‹œë„
        
        JSON í˜•ì‹ìœ¼ë¡œ ìƒˆë¡œìš´ ê³„íšì„ ì‘ì„±í•˜ì„¸ìš”:
        {{
            "recovery_strategy": "ì„ íƒí•œ ì „ëµ",
            "reasoning": "ì´ìœ ",
            "steps": [
                {{
                    "agent": "ì—ì´ì „íŠ¸ëª…",
                    "purpose": "ëª©ì ",
                    "comprehensive_instructions": "êµ¬ì²´ì  ì‘ì—…",
                    "fallback": "ì‹¤íŒ¨ì‹œ ëŒ€ì•ˆ"
                }}
            ]
        }}
        """
        
        try:
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": recovery_prompt}],
                response_format={"type": "json_object"},
                temperature=0.4,
                timeout=60.0
            )
            
            recovery_plan = json.loads(response.choices[0].message.content)
            self._log_replanning('recovery', replan_reason, recovery_plan)
            return recovery_plan
            
        except Exception as e:
            logger.error(f"ë³µêµ¬ ê³„íš ìƒì„± ì‹¤íŒ¨: {e}")
            return self._create_fallback_recovery_plan(replan_reason, remaining_steps)
    
    def _create_fallback_recovery_plan(self, replan_reason: Dict, 
                                     remaining_steps: List[Dict]) -> Dict:
        """í´ë°± ë³µêµ¬ ê³„íš"""
        # ì‹¤íŒ¨í•œ ì—ì´ì „íŠ¸ë¥¼ ê±´ë„ˆë›°ê³  ë‹¤ìŒ ë‹¨ê³„ë¡œ
        return {
            'recovery_strategy': 'skip_failed',
            'reasoning': 'ì‹¤íŒ¨í•œ ë‹¨ê³„ë¥¼ ê±´ë„ˆë›°ê³  ì§„í–‰',
            'steps': remaining_steps
        }
    
    async def _create_optimized_plan(self,
                                   current_state: Dict,
                                   remaining_steps: List[Dict],
                                   user_intent: Dict,
                                   execution_history: List[Dict]) -> Dict:
        """ë” íš¨ìœ¨ì ì¸ ê²½ë¡œë¡œ ìµœì í™”"""
        
        if not self.openai_client:
            return {'steps': remaining_steps}
        
        optimization_prompt = f"""
        í˜„ì¬ê¹Œì§€ì˜ ì‹¤í–‰ ê²°ê³¼ë¥¼ ë³´ê³  ë” íš¨ìœ¨ì ì¸ ê²½ë¡œë¥¼ ì°¾ìœ¼ì„¸ìš”.
        
        ì‹¤í–‰ ì´ë ¥ ìš”ì•½:
        {json.dumps([{
            'agent': h['agent'],
            'status': h['result'].get('status', 'unknown')
        } for h in execution_history[-5:]], ensure_ascii=False)}
        
        ë‚¨ì€ ë‹¨ê³„:
        {json.dumps(remaining_steps, ensure_ascii=False)}
        
        ì‚¬ìš©ì ëª©í‘œ:
        {user_intent.get('main_goal', '')}
        
        ìµœì í™” ê¸°ì¤€:
        1. ë¶ˆí•„ìš”í•œ ë‹¨ê³„ ì œê±°
        2. ë³‘ë ¬ ì‹¤í–‰ ê°€ëŠ¥í•œ ì‘ì—… ì‹ë³„
        3. ë” ì í•©í•œ ì—ì´ì „íŠ¸ë¡œ êµì²´
        4. ì¤‘ë³µ ì‘ì—… í†µí•©
        
        JSON í˜•ì‹ìœ¼ë¡œ ìµœì í™”ëœ ê³„íšì„ ì‘ì„±í•˜ì„¸ìš”.
        """
        
        try:
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": optimization_prompt}],
                response_format={"type": "json_object"},
                temperature=0.3,
                timeout=60.0
            )
            
            optimized_plan = json.loads(response.choices[0].message.content)
            self._log_replanning('optimization', {'reason': 'íš¨ìœ¨ì„± ê°œì„ '}, optimized_plan)
            return optimized_plan
            
        except Exception as e:
            logger.warning(f"ìµœì í™” ì‹¤íŒ¨: {e}")
            return {'steps': remaining_steps}
    
    async def _create_pivot_plan(self,
                               replan_reason: Dict,
                               current_state: Dict,
                               user_intent: Dict,
                               execution_history: List[Dict]) -> Dict:
        """ìƒˆë¡œìš´ ë°œê²¬ì— ë”°ë¥¸ ë°©í–¥ ì „í™˜"""
        
        if not self.openai_client:
            return {'steps': []}  # ì•ˆì „í•˜ê²Œ ì¢…ë£Œ
        
        pivot_prompt = f"""
        ìƒˆë¡œìš´ ë°œê²¬: {replan_reason['details']}
        
        ì´ ë°œê²¬ì„ ë°”íƒ•ìœ¼ë¡œ ë¶„ì„ ë°©í–¥ì„ ì¡°ì •í•˜ì„¸ìš”.
        ì‚¬ìš©ì ëª©í‘œ: {user_intent.get('main_goal', '')}
        
        ìƒˆë¡œìš´ ê³„íšì„ ìˆ˜ë¦½í•˜ì„¸ìš”.
        """
        
        try:
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": pivot_prompt}],
                response_format={"type": "json_object"},
                temperature=0.4,
                timeout=60.0
            )
            
            return json.loads(response.choices[0].message.content)
            
        except Exception as e:
            logger.warning(f"ë°©í–¥ ì „í™˜ ì‹¤íŒ¨: {e}")
            return {'steps': []}
    
    async def _create_completion_plan(self,
                                    current_state: Dict,
                                    user_intent: Dict,
                                    execution_history: List[Dict]) -> Dict:
        """ì¡°ê¸° ì™„ë£Œë¥¼ ìœ„í•œ ë§ˆë¬´ë¦¬ ê³„íš"""
        return {
            'completion_strategy': 'early_finish',
            'reasoning': 'ì¶©ë¶„í•œ ê²°ê³¼ë¥¼ ì–»ì–´ ì¡°ê¸° ì™„ë£Œ',
            'steps': []  # ì¶”ê°€ ë‹¨ê³„ ì—†ìŒ
        }
    
    def _log_replanning(self, strategy: str, reason: Dict, new_plan: Dict):
        """ë¦¬í”Œë˜ë‹ ì´ë ¥ ê¸°ë¡"""
        self.replanning_history.append({
            'timestamp': datetime.now().isoformat(),
            'strategy': strategy,
            'reason': reason,
            'new_steps': len(new_plan.get('steps', []))
        })


class UniversalIntelligentOrchestrator(AgentExecutor):
    """LLM ê¸°ë°˜ ë²”ìš© ì§€ëŠ¥í˜• ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° - ì ì‘ì  ì²˜ë¦¬ + ë™ì  ë¦¬í”Œë˜ë‹"""
    
    def __init__(self):
        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        try:
            api_key = os.getenv("OPENAI_API_KEY")
            if api_key and api_key.strip():
                self.openai_client = AsyncOpenAI(api_key=api_key)
                logger.info("ğŸ¤– Universal Intelligent Orchestrator v7.0 initialized")
            else:
                self.openai_client = None
                logger.info("ğŸ“Š Standard Orchestrator (No LLM)")
        except Exception as e:
            logger.warning(f"OpenAI client initialization failed: {e}")
            self.openai_client = None
        
        self.available_agents = {}
        self.agent_capabilities = {}
        self.execution_monitor = None
        self.replanning_engine = None
    
    async def execute(self, context: RequestContext, event_queue: EventQueue) -> None:
        """ğŸ¯ ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ - ì ì‘ì  ì²˜ë¦¬ + ë¦¬í”Œë˜ë‹"""
        task_updater = StreamingTaskUpdater(event_queue, context.task_id, context.context_id)
        
        try:
            await task_updater.submit()
            await task_updater.start_work()
            
            user_input = context.get_user_input()
            logger.info(f"ğŸ¯ Universal Orchestrator Processing: {user_input}")
            
            if not user_input:
                user_input = "Please provide an analysis request."
            
            # ğŸ¯ Step 1: ìš”ì²­ ë³µì¡ë„ í‰ê°€
            complexity = await self._assess_request_complexity(user_input)
            logger.info(f"ğŸ“Š Request complexity: {complexity['level']}")
            
            # ğŸ¯ Step 2: ë³µì¡ë„ì— ë”°ë¥¸ ì ì‘ì  ì²˜ë¦¬
            if complexity['level'] == 'simple':
                # ì¦‰ë‹µ ê°€ëŠ¥í•œ ê²½ìš° - ë¦¬í”Œë˜ë‹ ë¶ˆí•„ìš”
                await self._handle_simple_request(user_input, task_updater)
                
            elif complexity['level'] == 'single_agent':
                # ë‹¨ì¼ ì—ì´ì „íŠ¸ë¡œ ì²˜ë¦¬ - ê°„ë‹¨í•œ ë¦¬í”Œë˜ë‹ë§Œ
                await self._handle_single_agent_request_with_recovery(
                    user_input, 
                    complexity['recommended_agent'],
                    task_updater
                )
                
            else:  # complex
                # ë³µì¡í•œ ìš”ì²­ - ì „ì²´ ê¸°ëŠ¥ í™œì„±í™”
                await self._handle_complex_request_with_full_features(
                    user_input, 
                    task_updater
                )
                
        except Exception as e:
            error_msg = f"Orchestrator execution error: {str(e)}"
            logger.error(error_msg, exc_info=True)
            await task_updater.update_status(
                TaskState.failed,
                message=task_updater.new_agent_message(parts=[TextPart(text=error_msg)])
            )
    
    async def cancel(self, context: RequestContext, event_queue: EventQueue) -> None:
        """Cancel the operation"""
        task_updater = TaskUpdater(event_queue, context.task_id, context.context_id)
        await task_updater.reject()
        logger.info(f"Operation cancelled for context {context.context_id}")
    
    async def _assess_request_complexity(self, user_input: str) -> Dict:
        """ìš”ì²­ ë³µì¡ë„ë¥¼ íŒë‹¨í•˜ëŠ” ì§€ëŠ¥í˜• ë¶„ë¥˜ê¸°"""
        
        if not self.openai_client:
            return {'level': 'complex', 'reasoning': 'ê¸°ë³¸ê°’'}
        
        assessment_prompt = f"""
        ë‹¤ìŒ ì‚¬ìš©ì ìš”ì²­ì˜ ë³µì¡ë„ë¥¼ í‰ê°€í•˜ì„¸ìš”:
        "{user_input}"
        
        í‰ê°€ ê¸°ì¤€:
        1. **simple**: ì¦‰ë‹µ ê°€ëŠ¥ (ì •ì˜, ê°œë… ì„¤ëª…, ê°„ë‹¨í•œ ì‚¬ì‹¤ í™•ì¸)
        2. **single_agent**: í•œ ì—ì´ì „íŠ¸ë¡œ ì¶©ë¶„ (ë‹¨ì¼ ì‘ì—…)
        3. **complex**: ì—¬ëŸ¬ ì—ì´ì „íŠ¸ í˜‘ì—… í•„ìš” (ë‹¤ë‹¨ê³„ ë¶„ì„)
        
        íŒë‹¨ ìš”ì†Œ:
        - ìš”ì²­ëœ ì‘ì—…ì˜ ìˆ˜
        - ë°ì´í„° ì²˜ë¦¬ í•„ìš” ì—¬ë¶€
        - ë¶„ì„ ê¹Šì´
        - ë„ë©”ì¸ ì „ë¬¸ì„± í•„ìš”ë„
        
        JSON ì‘ë‹µ:
        {{
            "level": "simple/single_agent/complex",
            "reasoning": "íŒë‹¨ ê·¼ê±°",
            "recommended_agent": "single_agentì¸ ê²½ìš° ì¶”ì²œ ì—ì´ì „íŠ¸",
            "key_requirements": ["í•µì‹¬ ìš”êµ¬ì‚¬í•­ë“¤"]
        }}
        """
        
        try:
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": assessment_prompt}],
                response_format={"type": "json_object"},
                temperature=0.2,
                timeout=30.0
            )
            
            return json.loads(response.choices[0].message.content)
            
        except Exception as e:
            logger.warning(f"ë³µì¡ë„ í‰ê°€ ì‹¤íŒ¨: {e}")
            return {'level': 'complex', 'reasoning': 'í‰ê°€ ì‹¤íŒ¨ë¡œ ì•ˆì „í•œ ê²½ë¡œ ì„ íƒ'}
    
    async def _handle_simple_request(self, user_input: str, task_updater: StreamingTaskUpdater):
        """ê°„ë‹¨í•œ ìš”ì²­ ì¦‰ë‹µ ì²˜ë¦¬"""
        await task_updater.stream_update("ğŸ’¬ ê°„ë‹¨í•œ ì§ˆë¬¸ìœ¼ë¡œ íŒë‹¨ë˜ì–´ ì¦‰ì‹œ ë‹µë³€ë“œë¦½ë‹ˆë‹¤...")
        
        if self.openai_client:
            try:
                response = await self.openai_client.chat.completions.create(
                    model="gpt-4o",
                    messages=[{
                        "role": "system",
                        "content": "ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ê°„ê²°í•˜ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”."
                    }, {
                        "role": "user",
                        "content": user_input
                    }],
                    temperature=0.3,
                    max_tokens=1000,
                    timeout=30.0
                )
                
                answer = response.choices[0].message.content
                await task_updater.update_status(
                    TaskState.completed,
                    message=task_updater.new_agent_message(parts=[TextPart(text=answer)])
                )
                
            except Exception as e:
                logger.error(f"Simple request handling failed: {e}")
                await task_updater.update_status(
                    TaskState.failed,
                    message=task_updater.new_agent_message(
                        parts=[TextPart(text=f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")]
                    )
                )
        else:
            answer = "ì£„ì†¡í•©ë‹ˆë‹¤. LLMì´ ì„¤ì •ë˜ì§€ ì•Šì•„ ê°„ë‹¨í•œ ë‹µë³€ì„ ì œê³µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            await task_updater.update_status(
                TaskState.completed,
                message=task_updater.new_agent_message(parts=[TextPart(text=answer)])
            )
    
    async def _handle_single_agent_request_with_recovery(self, 
                                                        user_input: str,
                                                        agent_name: str,
                                                        task_updater: StreamingTaskUpdater):
        """ë‹¨ì¼ ì—ì´ì „íŠ¸ ì²˜ë¦¬ with ì‹¤íŒ¨ ë³µêµ¬"""
        await task_updater.stream_update(f"ğŸ¤– {agent_name} ì—ì´ì „íŠ¸ë¡œ ì²˜ë¦¬ ì¤‘...")
        
        # ì—ì´ì „íŠ¸ ë°œê²¬
        self.available_agents = await self._discover_agents()
        
        if agent_name not in self.available_agents:
            # ëŒ€ì²´ ì—ì´ì „íŠ¸ ì°¾ê¸°
            alternative = await self._find_alternative_agent(user_input, self.available_agents)
            if alternative:
                agent_name = alternative
                await task_updater.stream_update(f"ğŸ”„ ëŒ€ì²´ ì—ì´ì „íŠ¸ {agent_name} ì‚¬ìš©")
            else:
                await task_updater.update_status(
                    TaskState.failed,
                    message=task_updater.new_agent_message(
                        parts=[TextPart(text="ì í•©í•œ ì—ì´ì „íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")]
                    )
                )
                return
        
        # ì‚¬ìš©ì ì˜ë„ ì¶”ì¶œ
        user_intent = await self._extract_user_intent_precisely(user_input)
        
        # ì—ì´ì „íŠ¸ ëŠ¥ë ¥ íŒŒì•…
        agent_capability = await self._discover_agent_capabilities(agent_name)
        
        # ì •ë°€í•œ ì§€ì‹œ ìƒì„±
        instruction = await self._create_precise_agent_instruction(
            agent_name,
            user_intent,
            agent_capability,
            {}
        )
        
        # ì‹¤í–‰ with ì¬ì‹œë„
        max_retries = 2
        for attempt in range(max_retries):
            result = await self._execute_agent_with_comprehensive_instructions(
                agent_name,
                {'comprehensive_instructions': instruction},
                {},
                {}
            )
            
            # ê²€ì¦
            validation = await self._validate_agent_response(agent_name, result)
            result['validation'] = validation
            
            if validation['is_valid']:
                # ì„±ê³µ - ê²°ê³¼ ìƒì„±
                final_response = await self._create_evidence_based_response(
                    user_input,
                    {agent_name: result},
                    user_intent
                )
                
                await task_updater.update_status(
                    TaskState.completed,
                    message=task_updater.new_agent_message(parts=[TextPart(text=final_response)])
                )
                return
            else:
                # ì‹¤íŒ¨ - ì¬ì‹œë„ ë˜ëŠ” ë³µêµ¬
                if attempt < max_retries - 1:
                    await task_updater.stream_update(
                        f"âš ï¸ ê²°ê³¼ ê²€ì¦ ì‹¤íŒ¨. ì¬ì‹œë„ ì¤‘... ({attempt + 2}/{max_retries})"
                    )
                    # ì§€ì‹œ ê°œì„ 
                    instruction = await self._improve_instruction_based_on_failure(
                        instruction,
                        validation['warnings'],
                        user_intent
                    )
                else:
                    # ìµœì¢… ì‹¤íŒ¨ - ëŒ€ì²´ ë°©ì•ˆ
                    await task_updater.stream_update("ğŸ”„ ëŒ€ì²´ ë°©ì•ˆìœ¼ë¡œ ì „í™˜...")
                    await self._handle_with_alternative_approach(
                        user_input,
                        user_intent,
                        task_updater
                    )
    
    async def _handle_complex_request_with_full_features(self, 
                                                        user_input: str,
                                                        task_updater: StreamingTaskUpdater):
        """ë³µì¡í•œ ìš”ì²­ ì²˜ë¦¬ - ëª¨ë“  ê¸°ëŠ¥ í™œì„±í™”"""
        
        # ì´ˆê¸°í™”
        self.execution_monitor = ExecutionMonitor(self.openai_client)
        self.replanning_engine = ReplanningEngine(self.openai_client, self.available_agents)
        
        # ğŸ¯ Phase 1: ê¹Šì´ ìˆëŠ” ìš”ì²­ ë¶„ì„
        await task_updater.stream_update("ğŸ§  ìš”ì²­ì„ ê¹Šì´ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
        
        # 1.1 ìš”ì²­ ê¹Šì´ ë¶„ì„
        request_analysis = await self._analyze_request_depth(user_input)
        
        # 1.2 ì‚¬ìš©ì ì˜ë„ ì •ë°€ ì¶”ì¶œ
        user_intent = await self._extract_user_intent_precisely(user_input)
        
        # 1.3 ì ì‘ì  ì»¨í…ìŠ¤íŠ¸ êµ¬ì¶•
        adaptive_context = await self._build_adaptive_context(user_input, request_analysis)
        
        # 1.4 ìš”ì²­ í™•ì¥ (í•„ìš”ì‹œ)
        expanded_request = await self._expand_simple_requests(user_input, request_analysis)
        
        # ğŸ¯ Phase 2: ì—ì´ì „íŠ¸ ì¤€ë¹„ ë° ëŠ¥ë ¥ íŒŒì•…
        await task_updater.stream_update("ğŸ” AI DS Team ì—ì´ì „íŠ¸ ëŠ¥ë ¥ì„ íŒŒì•…í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
        
        # 2.1 ì—ì´ì „íŠ¸ ë°œê²¬
        self.available_agents = await self._discover_agents()
        
        if not self.available_agents:
            await task_updater.update_status(
                TaskState.failed,
                message=task_updater.new_agent_message(
                    parts=[TextPart(text="âŒ ì‚¬ìš© ê°€ëŠ¥í•œ ì—ì´ì „íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")]
                )
            )
            return
        
        # 2.2 ê° ì—ì´ì „íŠ¸ ëŠ¥ë ¥ ìƒì„¸ íŒŒì•…
        for agent_name in self.available_agents:
            self.agent_capabilities[agent_name] = await self._discover_agent_capabilities(agent_name)
        
        await task_updater.stream_update(
            f"âœ… {len(self.available_agents)}ê°œ ì—ì´ì „íŠ¸ ì¤€ë¹„ ì™„ë£Œ"
        )
        
        # ğŸ¯ Phase 3: ì´ˆê¸° ê³„íš ìˆ˜ë¦½
        await task_updater.stream_update("ğŸ“‹ ìµœì ì˜ ì‹¤í–‰ ê³„íšì„ ìˆ˜ë¦½í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
        
        initial_plan = await self._create_comprehensive_execution_plan(
            expanded_request,
            user_intent,
            self.available_agents,
            self.agent_capabilities,
            adaptive_context
        )
        
        if not initial_plan or not initial_plan.get('steps'):
            initial_plan = self._create_fallback_plan(self.available_agents)
        
        # ê³„íš í‘œì‹œ
        plan_display = self._create_beautiful_plan_display(initial_plan, user_intent)
        await task_updater.stream_update(plan_display)
        
        # ê³„íš ì•„í‹°íŒ©íŠ¸ ì €ì¥
        await self._save_plan_artifact(initial_plan, task_updater)
        
        # ğŸ¯ Phase 4: ì ì‘ì  ì‹¤í–‰ with ë¦¬í”Œë˜ë‹
        await task_updater.stream_update("ğŸš€ ì‹¤í–‰ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        
        execution_result = await self._execute_with_adaptive_replanning(
            initial_plan,
            user_intent,
            adaptive_context,
            task_updater
        )
        
        # ğŸ¯ Phase 5: ê²°ê³¼ ì¢…í•© ë° ê²€ì¦
        await task_updater.stream_update("ğŸ¨ ë¶„ì„ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
        
        # 5.1 ì½˜í…ì¸  í’ë¶€ë„ í‰ê°€
        content_assessment = await self._assess_content_richness(execution_result['results'])
        
        # 5.2 ì¦ê±° ê¸°ë°˜ ì‘ë‹µ ìƒì„±
        final_response = await self._create_intelligent_final_response(
            user_input,
            user_intent,
            execution_result,
            content_assessment,
            adaptive_context
        )
        
        # 5.3 ì˜ë„ ë§¤ì¹­ ê²€ì¦
        if not await self._verify_response_matches_intent(final_response, user_intent):
            final_response = await self._regenerate_response_for_intent(
                user_input,
                execution_result['results'],
                user_intent
            )
        
        # ğŸ¯ Phase 6: ìµœì¢… ì „ë‹¬
        await task_updater.stream_update("ğŸ‰ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        
        # ì‹¤í–‰ ìš”ì•½ ì•„í‹°íŒ©íŠ¸
        await self._save_execution_summary(
            execution_result,
            content_assessment,
            task_updater
        )
        
        # ìµœì¢… ì‘ë‹µ ì „ë‹¬
        await task_updater.update_status(
            TaskState.completed,
            message=task_updater.new_agent_message(parts=[TextPart(text=final_response)])
        )
    
    async def _execute_with_adaptive_replanning(self,
                                              initial_plan: Dict,
                                              user_intent: Dict,
                                              context: Dict,
                                              task_updater: StreamingTaskUpdater) -> Dict:
        """ì ì‘ì  ë¦¬í”Œë˜ë‹ì„ í¬í•¨í•œ ì‹¤í–‰"""
        
        current_plan = initial_plan.copy()
        execution_history = []
        validated_results = {}
        replanning_count = 0
        max_replanning = 5
        
        step_index = 0
        
        while step_index < len(current_plan['steps']) and replanning_count < max_replanning:
            current_step = current_plan['steps'][step_index]
            agent_name = current_step.get('agent', 'unknown')
            
            # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
            await task_updater.stream_update(
                f"ğŸ”„ ë‹¨ê³„ {step_index + 1}/{len(current_plan['steps'])}: "
                f"{agent_name} ì‹¤í–‰ ì¤‘..."
            )
            
            # ì •ë°€í•œ ì§€ì‹œ ìƒì„± (ì´ì „ ê²°ê³¼ ë°˜ì˜)
            instruction = await self._create_contextual_instruction(
                agent_name,
                current_step,
                user_intent,
                self.agent_capabilities.get(agent_name, {}),
                validated_results,
                context
            )
            
            # ì—ì´ì „íŠ¸ ì‹¤í–‰
            result = await self._execute_agent_with_comprehensive_instructions(
                agent_name,
                {'comprehensive_instructions': instruction},
                context,
                validated_results
            )
            
            # ì‘ë‹µ ê²€ì¦
            validation = await self._validate_agent_response(agent_name, result)
            result['validation'] = validation
            
            # ì‹¤í–‰ ì´ë ¥ ê¸°ë¡
            execution_history.append({
                'step': step_index,
                'agent': agent_name,
                'result': result,
                'timestamp': datetime.now().isoformat()
            })
            
            # ë¦¬í”Œë˜ë‹ í•„ìš”ì„± í‰ê°€
            remaining_steps = current_plan['steps'][step_index + 1:]
            replan_decision = await self.execution_monitor.should_replan(
                step_index,
                result,
                remaining_steps,
                user_intent
            )
            
            if replan_decision['should_replan']:
                replanning_count += 1
                await task_updater.stream_update(
                    f"ğŸ”„ ë¦¬í”Œë˜ë‹ {replanning_count}/{max_replanning}: "
                    f"{replan_decision['reason']} - {replan_decision['details']}"
                )
                
                # ìƒˆë¡œìš´ ê³„íš ìƒì„±
                new_plan = await self.replanning_engine.create_new_plan(
                    replan_decision,
                    {
                        'step_index': step_index,
                        'history': execution_history,
                        'current_results': validated_results
                    },
                    remaining_steps,
                    user_intent,
                    execution_history
                )
                
                if new_plan and new_plan.get('steps'):
                    # ê³„íš ì—…ë°ì´íŠ¸
                    current_plan['steps'] = (
                        current_plan['steps'][:step_index + 1] + 
                        new_plan['steps']
                    )
                    
                    await task_updater.stream_update(
                        f"âœ… ë¦¬í”Œë˜ë‹ ì™„ë£Œ: {len(new_plan['steps'])}ê°œì˜ ìƒˆë¡œìš´ ë‹¨ê³„"
                    )
                    
                    # ì¡°ê¸° ì™„ë£Œ ì²´í¬
                    if replan_decision['reason'] == 'early_completion':
                        break
            
            # ê²°ê³¼ ì €ì¥ (ê²€ì¦ í†µê³¼í•œ ê²ƒë§Œ)
            if validation['is_valid']:
                validated_results[agent_name] = result
            else:
                await task_updater.stream_update(
                    f"âš ï¸ {agent_name} ê²°ê³¼ê°€ ê²€ì¦ì„ í†µê³¼í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
                )
            
            step_index += 1
            
            # ì£¼ê¸°ì  ì§„í–‰ë¥  ì²´í¬ (3ë‹¨ê³„ë§ˆë‹¤)
            if step_index % 3 == 0:
                progress = await self._check_overall_progress(
                    execution_history,
                    user_intent,
                    current_plan
                )
                
                if progress.get('should_conclude'):
                    await task_updater.stream_update(
                        f"âœ… ëª©í‘œ ë‹¬ì„±ë„ {progress['achievement_percentage']}%ë¡œ ì¡°ê¸° ì™„ë£Œí•©ë‹ˆë‹¤."
                    )
                    break
        
        return {
            'results': validated_results,
            'history': execution_history,
            'final_plan': current_plan,
            'replanning_count': replanning_count,
            'completion_reason': 'normal' if step_index >= len(current_plan['steps']) else 'early'
        }
    
    async def _discover_agents(self) -> Dict[str, Dict[str, Any]]:
        """A2A í‘œì¤€ ì—ì´ì „íŠ¸ ë°œê²¬"""
        available_agents = {}
        
        async with httpx.AsyncClient(timeout=10.0) as client:
            for agent_name, port in AGENT_PORTS.items():
                try:
                    response = await client.get(f"http://localhost:{port}/.well-known/agent.json")
                    if response.status_code == 200:
                        agent_card = response.json()
                        available_agents[agent_name] = {
                            "name": agent_card.get("name", agent_name),
                            "url": f"http://localhost:{port}",
                            "port": port,
                            "description": agent_card.get("description", ""),
                            "status": "available"
                        }
                        logger.info(f"âœ… {agent_name} agent discovered on port {port}")
                except Exception as e:
                    logger.warning(f"âš ï¸ {agent_name} agent on port {port} not available: {e}")
        
        logger.info(f"ğŸ” Total discovered agents: {len(available_agents)}")
        return available_agents
    
    async def _discover_agent_capabilities(self, agent_name: str) -> Dict:
        """ì—ì´ì „íŠ¸ì˜ ì‹¤ì œ ëŠ¥ë ¥ì„ A2A í”„ë¡œí† ì½œë¡œ ì¡°íšŒ"""
        
        agent_info = self.available_agents.get(agent_name, {})
        agent_url = agent_info.get('url')
        
        if not agent_url:
            return {}
        
        try:
            async with httpx.AsyncClient(timeout=10.0) as client:
                response = await client.get(f"{agent_url}/.well-known/agent.json")
                
                if response.status_code == 200:
                    agent_card = response.json()
                    
                    skills = agent_card.get('skills', [])
                    capabilities = {
                        'skills': [
                            {
                                'id': skill.get('id'),
                                'name': skill.get('name'),
                                'description': skill.get('description'),
                                'tags': skill.get('tags', [])
                            }
                            for skill in skills
                        ],
                        'input_modes': agent_card.get('defaultInputModes', []),
                        'output_modes': agent_card.get('defaultOutputModes', []),
                        'capabilities': agent_card.get('capabilities', {})
                    }
                    
                    return capabilities
                    
        except Exception as e:
            logger.warning(f"ì—ì´ì „íŠ¸ ëŠ¥ë ¥ ì¡°íšŒ ì‹¤íŒ¨ {agent_name}: {e}")
        
        return {}
    
    async def _analyze_request_depth(self, user_input: str) -> Dict:
        """ìš”ì²­ì˜ ê¹Šì´ì™€ íŠ¹ì„±ì„ LLMì´ ìë™ ë¶„ì„"""
        
        if not self.openai_client:
            return {
                "detail_level": 5,
                "has_role_description": False,
                "role_description": "",
                "explicit_requirements": ["ê¸°ë³¸ ë¶„ì„"],
                "implicit_needs": ["ë°ì´í„° ì´í•´"],
                "suggested_response_depth": "moderate",
                "needs_clarification": []
            }
        
        analysis_prompt = f"""
        ë‹¤ìŒ ì‚¬ìš©ì ìš”ì²­ì„ ë¶„ì„í•˜ì„¸ìš”:
        "{user_input}"
        
        ë¶„ì„í•  ë‚´ìš©:
        1. ìš”ì²­ì˜ êµ¬ì²´ì„± ìˆ˜ì¤€ (1-10)
        2. ì—­í• ì´ë‚˜ ì „ë¬¸ì„± ì–¸ê¸‰ ì—¬ë¶€
        3. ëª…ì‹œì  ìš”êµ¬ì‚¬í•­ vs ì•”ì‹œì  ë‹ˆì¦ˆ
        4. ì˜ˆìƒë˜ëŠ” ë‹µë³€ì˜ ê¹Šì´
        5. ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ê°€ í•„ìš”í•œì§€ ì—¬ë¶€
        
        JSON ì‘ë‹µ:
        {{
            "detail_level": 1-10,
            "has_role_description": true/false,
            "role_description": "ìˆë‹¤ë©´ ì–´ë–¤ ì—­í• ì¸ì§€",
            "explicit_requirements": ["ëª…ì‹œì ìœ¼ë¡œ ìš”ì²­í•œ ê²ƒë“¤"],
            "implicit_needs": ["ë§¥ë½ìƒ í•„ìš”í•  ê²ƒìœ¼ë¡œ ë³´ì´ëŠ” ê²ƒë“¤"],
            "suggested_response_depth": "brief/moderate/comprehensive",
            "needs_clarification": ["ëª…í™•íˆ í•  í•„ìš”ê°€ ìˆëŠ” ë¶€ë¶„ë“¤"],
            "explicitly_wants_brief": true/false
        }}
        """
        
        try:
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": analysis_prompt}],
                response_format={"type": "json_object"},
                temperature=0.3,
                timeout=60.0
            )
            
            analysis = json.loads(response.choices[0].message.content)
            logger.info(f"ğŸ“Š Request depth analysis: level {analysis.get('detail_level', 5)}/10")
            return analysis
            
        except Exception as e:
            logger.warning(f"Request depth analysis failed: {e}")
            return {
                "detail_level": 5,
                "has_role_description": False,
                "role_description": "",
                "explicit_requirements": ["ê¸°ë³¸ ë¶„ì„"],
                "implicit_needs": ["ë°ì´í„° ì´í•´"],
                "suggested_response_depth": "moderate",
                "needs_clarification": []
            }
    
    async def _extract_user_intent_precisely(self, user_input: str) -> Dict:
        """ì‚¬ìš©ì ì˜ë„ë¥¼ ì •ë°€í•˜ê²Œ ì¶”ì¶œ"""
        
        if not self.openai_client:
            return {
                'main_goal': 'ë°ì´í„° ë¶„ì„',
                'action_type': 'analyze',
                'specific_requirements': [],
                'expected_outcomes': ['ë¶„ì„ ê²°ê³¼']
            }
        
        intent_prompt = f"""
        ì‚¬ìš©ì ì…ë ¥ì„ ì •ë°€ ë¶„ì„í•˜ì„¸ìš”:
        "{user_input}"
        
        ì¶”ì¶œí•´ì•¼ í•  ì •ë³´:
        
        1. **action_type**: ì‚¬ìš©ìê°€ ì›í•˜ëŠ” í–‰ë™ ìœ í˜•
           - analyze: ë¶„ì„í•˜ê¸°
           - verify: ê²€ì¦/í™•ì¸í•˜ê¸°
           - recommend: ì¶”ì²œí•˜ê¸°
           - diagnose: ì§„ë‹¨í•˜ê¸°
           - predict: ì˜ˆì¸¡í•˜ê¸°
           - compare: ë¹„êµí•˜ê¸°
           - explain: ì„¤ëª…í•˜ê¸°
        
        2. **main_goal**: í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•œ ì£¼ìš” ëª©í‘œ
        
        3. **specific_requirements**: êµ¬ì²´ì  ìš”êµ¬ì‚¬í•­ ëª©ë¡
           - ë¶„ì„í•´ì•¼ í•  ë³€ìˆ˜
           - í™•ì¸í•´ì•¼ í•  ì¡°ê±´
           - í¬í•¨ë˜ì–´ì•¼ í•  ë‚´ìš©
        
        4. **expected_outcomes**: ê¸°ëŒ€í•˜ëŠ” ê²°ê³¼ë¬¼
           - ìˆ˜ì¹˜ì  ê²°ê³¼
           - ì‹œê°í™”
           - ê¶Œì¥ì‚¬í•­
           - ì§„ë‹¨ ê²°ê³¼
        
        5. **domain_context**: ë„ë©”ì¸ íŠ¹í™” ì»¨í…ìŠ¤íŠ¸
           - ì „ë¬¸ ìš©ì–´
           - ì—…ê³„ ê¸°ì¤€
           - íŠ¹ë³„í•œ ì œì•½ì‚¬í•­
        
        6. **priority_aspects**: ìš°ì„ ìˆœìœ„ê°€ ë†’ì€ ì¸¡ë©´ë“¤
        
        JSON í˜•ì‹ìœ¼ë¡œ ì •í™•íˆ ì‘ë‹µí•˜ì„¸ìš”.
        """
        
        try:
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": intent_prompt}],
                response_format={"type": "json_object"},
                temperature=0.2,
                timeout=60.0
            )
            
            intent = json.loads(response.choices[0].message.content)
            logger.info(f"ğŸ¯ ì‚¬ìš©ì ì˜ë„ ì¶”ì¶œ: {intent['action_type']} - {intent['main_goal']}")
            return intent
            
        except Exception as e:
            logger.warning(f"ì˜ë„ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return {
                'main_goal': user_input,
                'action_type': 'analyze',
                'specific_requirements': [],
                'expected_outcomes': ['ë¶„ì„ ê²°ê³¼']
            }
    
    async def _build_adaptive_context(self, user_input: str, request_analysis: Dict) -> Dict:
        """ìš”ì²­ ë¶„ì„ì— ë”°ë¼ ì ì‘ì  ì»¨í…ìŠ¤íŠ¸ êµ¬ì¶•"""
        
        if not self.openai_client:
            return {
                "adopted_perspective": "ì¼ë°˜ ë°ì´í„° ë¶„ì„ê°€",
                "analysis_approach": "í‘œì¤€ ë¶„ì„",
                "response_style": "professional",
                "focus_areas": ["ê¸°ë³¸ í†µê³„"],
                "depth_strategy": "moderate"
            }
        
        context_prompt = f"""
        ì‚¬ìš©ì ìš”ì²­: "{user_input}"
        ìš”ì²­ ë¶„ì„: {json.dumps(request_analysis, ensure_ascii=False)}
        
        ì´ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì ì ˆí•œ ë¶„ì„ ì»¨í…ìŠ¤íŠ¸ë¥¼ êµ¬ì¶•í•˜ì„¸ìš”:
        
        1. ì—­í• ì´ ëª…ì‹œë˜ì—ˆë‹¤ë©´: ê·¸ ì—­í• ì˜ ê´€ì  ì±„íƒ
        2. ì—­í• ì´ ì—†ë‹¤ë©´: ìš”ì²­ ë‚´ìš©ì—ì„œ ì ì ˆí•œ ì „ë¬¸ì„± ìˆ˜ì¤€ ì¶”ë¡ 
        3. ìƒì„¸í•œ ìš”ì²­ì´ë©´: ê¹Šì´ ìˆëŠ” ë¶„ì„ ì¤€ë¹„
        4. ê°„ë‹¨í•œ ìš”ì²­ì´ë©´: í•µì‹¬ë§Œ ê°„ê²°í•˜ê²Œ
        
        ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë§Œë“œì„¸ìš”:
        {{
            "adopted_perspective": "ì±„íƒí•  ê´€ì ",
            "analysis_approach": "ë¶„ì„ ì ‘ê·¼ ë°©ì‹",
            "response_style": "ë‹µë³€ ìŠ¤íƒ€ì¼",
            "focus_areas": ["ì§‘ì¤‘í•  ì˜ì—­ë“¤"],
            "depth_strategy": "ì–¼ë§ˆë‚˜ ê¹Šì´ ë“¤ì–´ê°ˆì§€",
            "domain": "ì¶”ë¡ ëœ ë„ë©”ì¸",
            "expertise_level": "í•„ìš”í•œ ì „ë¬¸ì„± ìˆ˜ì¤€"
        }}
        """
        
        try:
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": context_prompt}],
                response_format={"type": "json_object"},
                temperature=0.3,
                timeout=60.0
            )
            
            context = json.loads(response.choices[0].message.content)
            logger.info(f"ğŸ­ Adaptive context: {context.get('adopted_perspective', 'unknown')}")
            return context
            
        except Exception as e:
            logger.warning(f"Adaptive context building failed: {e}")
            return {
                "adopted_perspective": "ì¼ë°˜ ë°ì´í„° ë¶„ì„ê°€",
                "analysis_approach": "í‘œì¤€ ë¶„ì„",
                "response_style": "professional",
                "focus_areas": ["ê¸°ë³¸ í†µê³„"],
                "depth_strategy": "moderate"
            }
    
    async def _expand_simple_requests(self, user_input: str, request_analysis: Dict) -> str:
        """ê°„ë‹¨í•œ ìš”ì²­ì„ ì§€ëŠ¥ì ìœ¼ë¡œ í™•ì¥ (í•„ìš”í•œ ê²½ìš°ë§Œ)"""
        
        if request_analysis['detail_level'] >= 7:
            return user_input
        
        if request_analysis['needs_clarification'] and not self.openai_client:
            return user_input
        
        if request_analysis['needs_clarification']:
            expansion_prompt = f"""
            ì‚¬ìš©ìì˜ ê°„ë‹¨í•œ ìš”ì²­: "{user_input}"
            
            ì´ ìš”ì²­ì—ì„œ ì‚¬ìš©ìê°€ ì•”ë¬µì ìœ¼ë¡œ ì•Œê³  ì‹¶ì–´í•  ìˆ˜ ìˆëŠ” ê²ƒë“¤ì„ ì¶”ë¡ í•˜ì„¸ìš”.
            í•˜ì§€ë§Œ ê³¼ë„í•˜ê²Œ í™•ì¥í•˜ì§€ ë§ê³ , ë§¥ë½ìƒ í•©ë¦¬ì ì¸ ìˆ˜ì¤€ì—ì„œë§Œ ë³´ì™„í•˜ì„¸ìš”.
            
            ì˜ˆì‹œ:
            - "ë°ì´í„° ë¶„ì„í•´ì¤˜" â†’ ê¸°ë³¸ í†µê³„, íŒ¨í„´, ì´ìƒì¹˜ ì •ë„
            - "ë¶ˆëŸ‰ ì›ì¸ ì°¾ì•„ì¤˜" â†’ ë°ì´í„° ê¸°ë°˜ ì›ì¸ ì¶”ì •, ê°€ëŠ¥ì„± ìˆœìœ„
            
            ì¶”ë¡ ëœ ìƒì„¸ ìš”êµ¬ì‚¬í•­:
            """
            
            try:
                response = await self.openai_client.chat.completions.create(
                    model="gpt-4o",
                    messages=[{"role": "user", "content": expansion_prompt}],
                    temperature=0.3,
                    timeout=60.0
                )
                
                expanded = response.choices[0].message.content
                logger.info(f"ğŸ“ˆ Request expanded: {len(expanded)} chars")
                return expanded
                
            except Exception as e:
                logger.warning(f"Request expansion failed: {e}")
                return user_input
        
        return user_input
    
    async def _create_comprehensive_execution_plan(self, 
                                                 expanded_request: str,
                                                 user_intent: Dict,
                                                 available_agents: Dict,
                                                 agent_capabilities: Dict,
                                                 adaptive_context: Dict) -> Dict:
        """ì™„ì „ LLM ê¸°ë°˜ ë™ì  ê³„íš ìƒì„±"""
        
        if not self.openai_client:
            return self._create_fallback_plan(available_agents)
        
        # ì—ì´ì „íŠ¸ë“¤ì˜ ìƒì„¸ ì •ë³´ êµ¬ì¡°í™”
        agents_details = {}
        for name, info in available_agents.items():
            agents_details[name] = {
                "description": info.get('description', ''),
                "capabilities": agent_capabilities.get(name, {}).get('skills', []),
                "typical_use_cases": self._infer_use_cases(name)
            }
        
        planning_prompt = f"""ë‹¹ì‹ ì€ ë°ì´í„° ë¶„ì„ ì›Œí¬í”Œë¡œìš° ì„¤ê³„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ìš”ì²­ì„ ë¶„ì„í•˜ê³ , ê°€ì¥ íš¨ê³¼ì ì¸ ì—ì´ì „íŠ¸ ì‹¤í–‰ ê³„íšì„ ìˆ˜ë¦½í•´ì•¼ í•©ë‹ˆë‹¤.

## ğŸ“‹ ì‚¬ìš©ì ìš”ì²­ ë¶„ì„
ì›ë³¸ ìš”ì²­: {expanded_request}
ì˜ë„ ë¶„ì„: {json.dumps(user_intent, ensure_ascii=False, indent=2)}
ì»¨í…ìŠ¤íŠ¸: {json.dumps(adaptive_context, ensure_ascii=False, indent=2)}

## ğŸ¤– ì‚¬ìš© ê°€ëŠ¥í•œ ì—ì´ì „íŠ¸ë“¤
{json.dumps(agents_details, ensure_ascii=False, indent=2)}

## ğŸ¯ ê³„íš ìˆ˜ë¦½ ì§€ì¹¨
1. **ìš”ì²­ ì¤‘ì‹¬ ì ‘ê·¼**: ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ê²°ê³¼ì— ì§‘ì¤‘í•˜ì—¬ í•„ìš”í•œ ì—ì´ì „íŠ¸ë§Œ ì„ íƒ
2. **ë…¼ë¦¬ì  ìˆœì„œ**: ë°ì´í„° íë¦„ê³¼ ì˜ì¡´ì„±ì„ ê³ ë ¤í•œ ìˆœì„œ ê²°ì •
3. **íš¨ìœ¨ì„± ìµœì í™”**: ë¶ˆí•„ìš”í•œ ë‹¨ê³„ ì œê±°, í•µì‹¬ ë¶„ì„ì— ì§‘ì¤‘
4. **ë„ë©”ì¸ ì ì‘**: {adaptive_context.get('domain', 'ì¼ë°˜')} ë„ë©”ì¸ íŠ¹ì„± ë°˜ì˜
5. **ì‚¬ìš©ì ìˆ˜ì¤€ ê³ ë ¤**: {adaptive_context.get('expertise_level', 'ì¼ë°˜')} ìˆ˜ì¤€ì— ë§ëŠ” ë¶„ì„ ê¹Šì´

## ğŸš€ ë™ì  ì—ì´ì „íŠ¸ ì„ íƒ ê¸°ì¤€
- ì‚¬ìš©ì ì§ˆë¬¸ì˜ í•µì‹¬ ì˜ë„ê°€ ë¬´ì—‡ì¸ê°€?
- ì–´ë–¤ ì¢…ë¥˜ì˜ ë¶„ì„ì´ ì‹¤ì œë¡œ í•„ìš”í•œê°€?
- ê° ì—ì´ì „íŠ¸ê°€ ì œê³µí•  ìˆ˜ ìˆëŠ” ê°€ì¹˜ëŠ” ë¬´ì—‡ì¸ê°€?
- ìµœì†Œí•œì˜ ë‹¨ê³„ë¡œ ìµœëŒ€í•œì˜ ì¸ì‚¬ì´íŠ¸ë¥¼ ì–»ìœ¼ë ¤ë©´?

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
{{
    "execution_strategy": "ì´ ìš”ì²­ì— ëŒ€í•œ ì „ì²´ì  ë¶„ì„ ì „ëµ",
    "agent_selection_reasoning": "ì„ íƒëœ ì—ì´ì „íŠ¸ë“¤ê³¼ ê·¸ ì´ìœ ",
    "steps": [
        {{
            "step_number": 1,
            "agent": "ì„ íƒëœ_ì—ì´ì „íŠ¸ëª…",
            "purpose": "ì´ ë‹¨ê³„ì˜ êµ¬ì²´ì  ëª©ì ",
            "comprehensive_instructions": "ì—ì´ì „íŠ¸ì—ê²Œ ì „ë‹¬í•  ìƒì„¸í•œ ì‘ì—… ì§€ì‹œ (ë„ë©”ì¸ ì»¨í…ìŠ¤íŠ¸ í¬í•¨)",
            "expected_deliverables": {{
                "minimum": "ìµœì†Œí•œ í•„ìš”í•œ ê²°ê³¼",
                "standard": "í‘œì¤€ì ì¸ ê²°ê³¼",
                "exceptional": "íƒì›”í•œ ê²°ê³¼"
            }},
            "success_criteria": "ì„±ê³µ íŒë‹¨ ê¸°ì¤€",
            "context_for_next": "ë‹¤ìŒ ë‹¨ê³„ë¡œ ì „ë‹¬í•  í•µì‹¬ ì •ë³´"
        }}
    ],
    "final_synthesis_strategy": "ëª¨ë“  ê²°ê³¼ë¥¼ ì–´ë–»ê²Œ ì¢…í•©í•  ê²ƒì¸ê°€",
    "potential_insights": "ì´ ê³„íšìœ¼ë¡œ ì–»ì„ ìˆ˜ ìˆëŠ” ì˜ˆìƒ ì¸ì‚¬ì´íŠ¸ë“¤"
}}

ì¤‘ìš”: í…œí”Œë¦¿ì´ë‚˜ ê³ ì •ëœ íŒ¨í„´ì„ ì‚¬ìš©í•˜ì§€ ë§ê³ , ì´ íŠ¹ì • ìš”ì²­ì— ìµœì í™”ëœ ê³„íšì„ ìˆ˜ë¦½í•˜ì„¸ìš”."""

        try:
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {
                        "role": "system", 
                        "content": "ë‹¹ì‹ ì€ ë°ì´í„° ë¶„ì„ ì›Œí¬í”Œë¡œìš° ìµœì í™” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ê° ìš”ì²­ì˜ ê³ ìœ í•œ íŠ¹ì„±ì„ íŒŒì•…í•˜ê³ , ê°€ì¥ íš¨ìœ¨ì ì´ê³  íš¨ê³¼ì ì¸ ë¶„ì„ ê²½ë¡œë¥¼ ì„¤ê³„í•©ë‹ˆë‹¤."
                    },
                    {"role": "user", "content": planning_prompt}
                ],
                response_format={"type": "json_object"},
                temperature=0.4,
                max_tokens=3000,
                timeout=90.0
            )
            
            plan = json.loads(response.choices[0].message.content)
            
            # ê³„íš ê²€ì¦ ë° ë³´ì •
            validated_plan = self._validate_and_enhance_plan(plan, available_agents)
            
            return validated_plan
            
        except Exception as e:
            logger.warning(f"Dynamic planning failed: {e}")
            return self._create_fallback_plan(available_agents)
    
    def _validate_and_enhance_plan(self, plan: Dict, available_agents: Dict) -> Dict:
        """ìƒì„±ëœ ê³„íšì„ ê²€ì¦í•˜ê³  ë³´ê°•"""
        try:
            if not plan.get('steps'):
                logger.warning("Plan has no steps, using fallback")
                return self._create_fallback_plan(available_agents)
            
            # ì—ì´ì „íŠ¸ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ ë° ë³´ì •
            valid_steps = []
            for i, step in enumerate(plan.get('steps', [])):
                agent_name = step.get('agent', '')
                if agent_name in available_agents:
                    # í•„ìˆ˜ í•„ë“œ ë³´ì™„
                    enhanced_step = {
                        "step_number": step.get('step_number', i + 1),
                        "agent": agent_name,
                        "purpose": step.get('purpose', f'{agent_name} ë¶„ì„ ìˆ˜í–‰'),
                        "comprehensive_instructions": step.get(
                            'comprehensive_instructions', 
                            step.get('enriched_task', f'{agent_name} ì‘ì—… ìˆ˜í–‰')
                        ),
                        "expected_deliverables": step.get('expected_deliverables', {
                            "minimum": "ê¸°ë³¸ ë¶„ì„ ê²°ê³¼",
                            "standard": "ìƒì„¸ ë¶„ì„ ê²°ê³¼",
                            "exceptional": "ì‹¬ì¸µ ì¸ì‚¬ì´íŠ¸"
                        }),
                        "success_criteria": step.get('success_criteria', 'ë¶„ì„ ì™„ë£Œ'),
                        "context_for_next": step.get('context_for_next', ['ë¶„ì„ ê²°ê³¼'])
                    }
                    valid_steps.append(enhanced_step)
                else:
                    logger.warning(f"Agent {agent_name} not available, skipping step")
            
            if not valid_steps:
                logger.warning("No valid steps after validation, using fallback")
                return self._create_fallback_plan(available_agents)
            
            # í–¥ìƒëœ ê³„íš ë°˜í™˜
            enhanced_plan = {
                "execution_strategy": plan.get('execution_strategy', 'ì‚¬ìš©ì ìš”ì²­ì— ìµœì í™”ëœ ë¶„ì„'),
                "agent_selection_reasoning": plan.get('agent_selection_reasoning', 'ìš”ì²­ ê¸°ë°˜ ì„ íƒ'),
                "steps": valid_steps,
                "final_synthesis_strategy": plan.get('final_synthesis_strategy', 'ê²°ê³¼ ì¢…í•©'),
                "potential_insights": plan.get('potential_insights', ['ë°ì´í„° ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸'])
            }
            
            return enhanced_plan
            
        except Exception as e:
            logger.error(f"Plan validation failed: {e}")
            return self._create_fallback_plan(available_agents)
    
    async def _create_precise_agent_instruction(self, 
                                              agent_name: str,
                                              user_intent: Dict,
                                              agent_capabilities: Dict,
                                              context: Dict) -> str:
        """ì—ì´ì „íŠ¸ ëŠ¥ë ¥ì— ë§ì¶˜ ì •ë°€í•œ ì§€ì‹œ ìƒì„±"""
        
        if not self.openai_client:
            return f"{agent_name}ì„ ì‚¬ìš©í•˜ì—¬ {user_intent.get('main_goal', 'ë¶„ì„')}ì„ ìˆ˜í–‰í•˜ì„¸ìš”."
        
        instruction_prompt = f"""
        ì—ì´ì „íŠ¸: {agent_name}
        ì—ì´ì „íŠ¸ ëŠ¥ë ¥: {json.dumps(agent_capabilities, ensure_ascii=False)}
        
        ì‚¬ìš©ì ì˜ë„:
        - ì£¼ìš” ëª©í‘œ: {user_intent.get('main_goal')}
        - êµ¬ì²´ì  ìš”êµ¬ì‚¬í•­: {user_intent.get('specific_requirements')}
        - ê¸°ëŒ€ ê²°ê³¼: {user_intent.get('expected_outcomes')}
        
        ì»¨í…ìŠ¤íŠ¸:
        - ë„ë©”ì¸: {context.get('domain')}
        - ì´ì „ ê²°ê³¼: {context.get('previous_insights')}
        
        ì´ ì—ì´ì „íŠ¸ì˜ ëŠ¥ë ¥ì„ ìµœëŒ€í•œ í™œìš©í•˜ì—¬ ì‚¬ìš©ì ì˜ë„ë¥¼ ë‹¬ì„±í•  ìˆ˜ ìˆëŠ”
        ë§¤ìš° êµ¬ì²´ì ì´ê³  ìƒì„¸í•œ ì‘ì—… ì§€ì‹œë¥¼ ì‘ì„±í•˜ì„¸ìš”.
        
        í¬í•¨í•´ì•¼ í•  ë‚´ìš©:
        1. ì •í™•íˆ ë¬´ì—‡ì„ ë¶„ì„/ì²˜ë¦¬í•´ì•¼ í•˜ëŠ”ì§€
        2. ì–´ë–¤ ë°©ë²•ë¡ ì´ë‚˜ ê¸°ë²•ì„ ì‚¬ìš©í•´ì•¼ í•˜ëŠ”ì§€
        3. ê²°ê³¼ë¬¼ì˜ í˜•íƒœì™€ í¬í•¨ë˜ì–´ì•¼ í•  ì •ë³´
        4. ì£¼ì˜ì‚¬í•­ì´ë‚˜ ì œì•½ì‚¬í•­
        5. ë‹¤ìŒ ë‹¨ê³„ë¥¼ ìœ„í•´ ë³´ì¡´í•´ì•¼ í•  ì •ë³´
        """
        
        try:
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": instruction_prompt}],
                temperature=0.3,
                max_tokens=1500,
                timeout=60.0
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            logger.warning(f"ì •ë°€ ì§€ì‹œ ìƒì„± ì‹¤íŒ¨: {e}")
            return f"{agent_name}ì„ ì‚¬ìš©í•˜ì—¬ {user_intent.get('main_goal', 'ë¶„ì„')}ì„ ìˆ˜í–‰í•˜ì„¸ìš”."
    
    async def _execute_agent_with_comprehensive_instructions(self, 
                                                           agent_name: str, 
                                                           step: Dict,
                                                           adaptive_context: Dict,
                                                           previous_results: Dict) -> Dict:
        """ì¢…í•©ì  ì§€ì‹œì‚¬í•­ìœ¼ë¡œ ì—ì´ì „íŠ¸ ì‹¤í–‰"""
        
        if agent_name not in self.available_agents:
            return {
                'status': 'failed',
                'error': f'Agent {agent_name} not available',
                'summary': f'ì—ì´ì „íŠ¸ {agent_name}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤'
            }
        
        comprehensive_instructions = step.get(
            'comprehensive_instructions', 
            f'{agent_name}ì— ëŒ€í•œ ë¶„ì„ì„ ìˆ˜í–‰í•˜ì„¸ìš”.'
        )
        
        logger.info(f"ğŸ” Sending to {agent_name}: {comprehensive_instructions[:200]}...")
        
        agent_url = self.available_agents[agent_name]['url']
        
        payload = {
            "jsonrpc": "2.0",
            "method": "message/send",
            "params": {
                "message": {
                    "messageId": f"universal_req_{agent_name}_{int(time.time())}",
                    "role": "user",
                    "parts": [{
                        "kind": "text",
                        "text": comprehensive_instructions
                    }]
                }
            },
            "id": f"universal_req_{agent_name}_{int(time.time())}"
        }
        
        try:
            async with httpx.AsyncClient(timeout=180.0) as client:
                response = await client.post(
                    agent_url,
                    json=payload,
                    headers={"Content-Type": "application/json"}
                )
                
                if response.status_code == 200:
                    result = response.json()
                    logger.info(f"âœ… {agent_name} response received")
                    return self._parse_agent_response(result, agent_name)
                else:
                    logger.warning(f"âŒ {agent_name} HTTP error: {response.status_code}")
                    return {
                        'status': 'failed',
                        'error': f'HTTP {response.status_code}',
                        'summary': f'ì—ì´ì „íŠ¸ í˜¸ì¶œ ì‹¤íŒ¨ (HTTP {response.status_code})'
                    }
                    
        except Exception as e:
            logger.error(f"Agent {agent_name} execution error: {e}")
            return {
                'status': 'failed',
                'error': str(e),
                'summary': f'ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}'
            }
    
    def _parse_agent_response(self, response: Dict, agent_name: str) -> Dict:
        """ì—ì´ì „íŠ¸ ì‘ë‹µ íŒŒì‹±"""
        try:
            if 'result' in response:
                result = response['result']
                if isinstance(result, dict):
                    # A2A í‘œì¤€ ì‘ë‹µ ì²˜ë¦¬
                    status = result.get('status', {})
                    if isinstance(status, dict) and status.get('state') == 'completed':
                        return {
                            'status': 'success',
                            'result': result,
                            'summary': f'{agent_name} ì—ì´ì „íŠ¸ ì‘ì—… ì™„ë£Œ'
                        }
                    else:
                        return {
                            'status': 'partial',
                            'result': result,
                            'summary': f'{agent_name} ì—ì´ì „íŠ¸ ë¶€ë¶„ ì™„ë£Œ'
                        }
                else:
                    return {
                        'status': 'success',
                        'result': result,
                        'summary': f'{agent_name} ì—ì´ì „íŠ¸ ì‘ì—… ì™„ë£Œ'
                    }
            else:
                return {
                    'status': 'failed',
                    'error': 'No result in response',
                    'summary': f'{agent_name} ì—ì´ì „íŠ¸ ì‘ë‹µ ì˜¤ë¥˜'
                }
        except Exception as e:
            return {
                'status': 'failed',
                'error': str(e),
                'summary': f'{agent_name} ì—ì´ì „íŠ¸ ì‘ë‹µ íŒŒì‹± ì˜¤ë¥˜'
            }
    
    async def _validate_agent_response(self, agent_name: str, response: Dict) -> Dict:
        """ì—ì´ì „íŠ¸ ì‘ë‹µì˜ ì‹ ë¢°ì„± ê²€ì¦"""
        
        validation_result = {
            'is_valid': True,
            'has_data': False,
            'data_sources': [],
            'confidence_score': 0,
            'warnings': []
        }
        
        try:
            # ì‘ë‹µì—ì„œ ì‹¤ì œ ë°ì´í„° ì¶”ì¶œ
            if 'result' in response and isinstance(response['result'], dict):
                result = response['result']
                
                # ì•„í‹°íŒ©íŠ¸ í™•ì¸
                if 'artifacts' in result:
                    for artifact in result['artifacts']:
                        if isinstance(artifact, dict):
                            content_type = artifact.get('metadata', {}).get('content_type', '')
                            if content_type in ['application/json', 'text/csv', 'application/vnd.plotly.v1+json']:
                                validation_result['has_data'] = True
                                validation_result['data_sources'].append({
                                    'name': artifact.get('name'),
                                    'type': content_type
                                })
                
                # ë©”ì‹œì§€ ë‚´ìš© í™•ì¸
                if 'history' in result:
                    for msg in result['history']:
                        if msg.get('role') == 'agent' and 'parts' in msg:
                            for part in msg['parts']:
                                if part.get('kind') == 'text':
                                    text = part.get('text', '')
                                    # ìˆ˜ì¹˜ ë°ì´í„° ì¡´ì¬ ì—¬ë¶€
                                    numbers = re.findall(r'\d+\.?\d*', text)
                                    if numbers:
                                        validation_result['confidence_score'] += 30
                                    
                                    # ë¶„ì„ í‚¤ì›Œë“œ ì¡´ì¬ ì—¬ë¶€
                                    keywords = ['í‰ê· ', 'í‘œì¤€í¸ì°¨', 'ìƒê´€ê´€ê³„', 'ë¶„í¬', 'íŒ¨í„´', 'ì¶”ì„¸']
                                    for keyword in keywords:
                                        if keyword in text:
                                            validation_result['confidence_score'] += 10
            
            # ê²€ì¦ ê²°ê³¼ íŒë‹¨
            validation_result['confidence_score'] = min(validation_result['confidence_score'], 100)
            
            if not validation_result['has_data'] and validation_result['confidence_score'] < 50:
                validation_result['warnings'].append('êµ¬ì²´ì ì¸ ë°ì´í„°ë‚˜ ë¶„ì„ ê²°ê³¼ê°€ ë¶€ì¡±í•¨')
                validation_result['is_valid'] = False
                
        except Exception as e:
            logger.warning(f"ì‘ë‹µ ê²€ì¦ ì‹¤íŒ¨: {e}")
            validation_result['warnings'].append(f'ê²€ì¦ ì˜¤ë¥˜: {str(e)}')
        
        return validation_result
    
    async def _check_overall_progress(self,
                                    execution_history: List[Dict],
                                    user_intent: Dict,
                                    current_plan: Dict) -> Dict:
        """ì „ì²´ ì§„í–‰ ìƒí™©ì„ í‰ê°€í•˜ê³  ì¡°ê¸° ì™„ë£Œ ê°€ëŠ¥ì„± íŒë‹¨"""
        
        if not self.openai_client:
            return {'should_conclude': False}
        
        # ì‹¤í–‰ ì´ë ¥ ìš”ì•½
        history_summary = []
        for h in execution_history[-5:]:  # ìµœê·¼ 5ê°œë§Œ
            history_summary.append({
                'agent': h['agent'],
                'status': h['result'].get('status', 'unknown'),
                'has_valid_data': h['result'].get('validation', {}).get('is_valid', False)
            })
        
        progress_prompt = f"""
        ì‚¬ìš©ì ëª©í‘œ: {user_intent['main_goal']}
        í•„ìš”í•œ ê²°ê³¼: {json.dumps(user_intent['expected_outcomes'], ensure_ascii=False)}
        
        í˜„ì¬ê¹Œì§€ ì‹¤í–‰ ê²°ê³¼:
        {json.dumps(history_summary, ensure_ascii=False)}
        
        ë‹¤ìŒì„ í‰ê°€í•˜ì„¸ìš”:
        1. ì‚¬ìš©ì ëª©í‘œ ë‹¬ì„±ë„ (0-100%)
        2. ì¶”ê°€ ì‹¤í–‰ì´ ì˜ë¯¸ìˆëŠ” ê°œì„ ì„ ê°€ì ¸ì˜¬ì§€
        3. í˜„ì¬ ê²°ê³¼ë¡œ ì¶©ë¶„í•œ ë‹µë³€ì´ ê°€ëŠ¥í•œì§€
        
        JSON ì‘ë‹µ:
        {{
            "achievement_percentage": 0-100,
            "key_goals_met": ["ë‹¬ì„±ëœ ëª©í‘œë“¤"],
            "missing_elements": ["ë¶€ì¡±í•œ ë¶€ë¶„ë“¤"],
            "should_conclude": true/false,
            "reasoning": "íŒë‹¨ ê·¼ê±°"
        }}
        """
        
        try:
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": progress_prompt}],
                response_format={"type": "json_object"},
                temperature=0.3,
                timeout=30.0
            )
            
            return json.loads(response.choices[0].message.content)
            
        except Exception as e:
            logger.warning(f"ì§„í–‰ë¥  í‰ê°€ ì‹¤íŒ¨: {e}")
            return {'should_conclude': False}
    
    async def _create_contextual_instruction(self,
                                           agent_name: str,
                                           step: Dict,
                                           user_intent: Dict,
                                           agent_capability: Dict,
                                           previous_results: Dict,
                                           context: Dict) -> str:
        """ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°˜ì˜í•œ ì •ë°€í•œ ì§€ì‹œ ìƒì„±"""
        
        # ì´ì „ ê²°ê³¼ì—ì„œ í•µì‹¬ ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ
        previous_insights = self._extract_key_insights(previous_results)
        
        if not self.openai_client:
            return step.get('comprehensive_instructions', f"{agent_name} ì‘ì—… ìˆ˜í–‰")
        
        instruction_prompt = f"""
        ì—ì´ì „íŠ¸: {agent_name}
        ì—ì´ì „íŠ¸ ëŠ¥ë ¥: {json.dumps(agent_capability, ensure_ascii=False)}
        
        í˜„ì¬ ë‹¨ê³„ ëª©ì : {step.get('purpose', '')}
        ê¸°ë³¸ ì‘ì—…: {step.get('comprehensive_instructions', '')}
        
        ì‚¬ìš©ì ì˜ë„:
        - ì•¡ì…˜ íƒ€ì…: {user_intent.get('action_type')}
        - ì£¼ìš” ëª©í‘œ: {user_intent.get('main_goal')}
        - êµ¬ì²´ì  ìš”êµ¬ì‚¬í•­: {user_intent.get('specific_requirements')}
        - ê¸°ëŒ€ ê²°ê³¼: {user_intent.get('expected_outcomes')}
        
        ë„ë©”ì¸ ì»¨í…ìŠ¤íŠ¸:
        - ë¶„ì•¼: {context.get('domain')}
        - ì „ë¬¸ì„± ìˆ˜ì¤€: {context.get('expertise_level')}
        - íŠ¹ë³„ ê³ ë ¤ì‚¬í•­: {context.get('special_considerations')}
        
        ì´ì „ ë‹¨ê³„ì—ì„œ ë°œê²¬ëœ ì¸ì‚¬ì´íŠ¸:
        {json.dumps(previous_insights, ensure_ascii=False)}
        
        ìœ„ ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ {agent_name}ì´ ìˆ˜í–‰í•´ì•¼ í•  ë§¤ìš° êµ¬ì²´ì ì´ê³  
        ì»¨í…ìŠ¤íŠ¸ì— ë§ëŠ” ì‘ì—… ì§€ì‹œë¥¼ ì‘ì„±í•˜ì„¸ìš”.
        
        í¬í•¨ì‚¬í•­:
        1. ì •í™•íˆ ë¬´ì—‡ì„ ë¶„ì„/ì²˜ë¦¬í•´ì•¼ í•˜ëŠ”ì§€
        2. ì´ì „ ê²°ê³¼ë¥¼ ì–´ë–»ê²Œ í™œìš©í•´ì•¼ í•˜ëŠ”ì§€
        3. ì–´ë–¤ í˜•íƒœì˜ ê²°ê³¼ë¬¼ì„ ìƒì„±í•´ì•¼ í•˜ëŠ”ì§€
        4. ì£¼ì˜ì‚¬í•­ê³¼ í’ˆì§ˆ ê¸°ì¤€
        """
        
        try:
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": instruction_prompt}],
                temperature=0.3,
                max_tokens=1500,
                timeout=60.0
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            logger.warning(f"Contextual instruction generation failed: {e}")
            return step.get('comprehensive_instructions', f"{agent_name} ì‘ì—… ìˆ˜í–‰")
    
    def _extract_key_insights(self, previous_results: Dict) -> Dict:
        """ì´ì „ ê²°ê³¼ì—ì„œ í•µì‹¬ ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ"""
        insights = {}
        for agent_name, result in previous_results.items():
            if result.get('status') == 'success':
                insights[agent_name] = result.get('summary', 'ì‘ì—… ì™„ë£Œ')
            else:
                insights[agent_name] = f"ì˜¤ë¥˜: {result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}"
        return insights
    
    async def _assess_content_richness(self, agent_results: Dict) -> Dict:
        """ìƒì„±ëœ ì½˜í…ì¸ ì˜ í’ë¶€í•¨ì„ í‰ê°€í•˜ê³  í™œìš© ë°©ì•ˆ ê²°ì •"""
        
        if not self.openai_client:
            return {
                "has_visualizations": False,
                "visualization_details": [],
                "key_metrics": {},
                "critical_findings": ["ê¸°ë³¸ ë¶„ì„ ê²°ê³¼"],
                "data_quality_score": 5,
                "recommended_inclusion": ["ë¶„ì„ ìš”ì•½"]
            }
        
        # ê²°ê³¼ ìš”ì•½ ìƒì„±
        results_summary = {}
        for agent, result in agent_results.items():
            if result.get('validation', {}).get('is_valid', False):
                results_summary[agent] = {
                    'status': result.get('status'),
                    'has_artifacts': bool(result.get('result', {}).get('artifacts')),
                    'data_sources': result.get('validation', {}).get('data_sources', [])
                }
        
        assessment_prompt = f"""
        ë‹¤ìŒ ë¶„ì„ ê²°ê³¼ë“¤ì„ í‰ê°€í•˜ì„¸ìš”:
        {json.dumps(results_summary, ensure_ascii=False)}
        
        í‰ê°€í•  í•­ëª©:
        1. ì‹œê°í™” ìë£Œ (ì°¨íŠ¸, ê·¸ë˜í”„)ì˜ ì¡´ì¬ì™€ ì¤‘ìš”ë„
        2. êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ë‚˜ í†µê³„ ë°ì´í„°
        3. ë°œê²¬ëœ íŒ¨í„´ì´ë‚˜ ì´ìƒì¹˜
        4. ì‹¤ë¬´ì  ì¸ì‚¬ì´íŠ¸ì˜ ê°€ì¹˜
        5. ì‚¬ìš©ìê°€ ë†“ì¹˜ë©´ ì•„ê¹Œìš¸ ì¤‘ìš” ì •ë³´
        
        {{
            "has_visualizations": true/false,
            "visualization_details": ["ì–´ë–¤ ì‹œê°í™”ê°€ ìˆëŠ”ì§€"],
            "key_metrics": {{"ë©”íŠ¸ë¦­ëª…": "ê°’"}},
            "critical_findings": ["ë†“ì¹˜ë©´ ì•ˆ ë˜ëŠ” ë°œê²¬ì‚¬í•­"],
            "data_quality_score": 1-10,
            "recommended_inclusion": ["ë°˜ë“œì‹œ í¬í•¨í•´ì•¼ í•  ìš”ì†Œë“¤"]
        }}
        """
        
        try:
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": assessment_prompt}],
                response_format={"type": "json_object"},
                temperature=0.3,
                timeout=60.0
            )
            
            assessment = json.loads(response.choices[0].message.content)
            logger.info(f"ğŸ¨ Content richness assessed: score {assessment.get('data_quality_score', 5)}/10")
            return assessment
            
        except Exception as e:
            logger.warning(f"Content richness assessment failed: {e}")
            return {
                "has_visualizations": False,
                "visualization_details": [],
                "key_metrics": {},
                "critical_findings": ["ê¸°ë³¸ ë¶„ì„ ê²°ê³¼"],
                "data_quality_score": 5,
                "recommended_inclusion": ["ë¶„ì„ ìš”ì•½"]
            }
    
    async def _create_evidence_based_response(self, 
                                            user_input: str,
                                            validated_results: Dict[str, Dict],
                                            user_intent: Dict) -> str:
        """ê²€ì¦ëœ ë°ì´í„°ë§Œì„ ê¸°ë°˜ìœ¼ë¡œ í•œ ì¦ê±° ê¸°ë°˜ ì‘ë‹µ ìƒì„±"""
        
        # ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ê²°ê³¼ë§Œ í•„í„°ë§
        reliable_results = {
            agent: result
            for agent, result in validated_results.items()
            if result.get('validation', {}).get('is_valid', False)
        }
        
        if not reliable_results:
            return "ì¶©ë¶„í•œ ë¶„ì„ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."
        
        if not self.openai_client:
            return self._create_fallback_synthesis(user_input, reliable_results)
        
        evidence_prompt = f"""
        ì‚¬ìš©ì ìš”ì²­: "{user_input}"
        ì‚¬ìš©ì ì˜ë„: {json.dumps(user_intent, ensure_ascii=False)}
        
        ê²€ì¦ëœ ë¶„ì„ ê²°ê³¼:
        {self._structure_reliable_results(reliable_results)}
        
        ìœ„ì˜ ê²€ì¦ëœ ë°ì´í„°ë§Œì„ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µì„ ì‘ì„±í•˜ì„¸ìš”.
        
        ì—„ê²©í•œ ê·œì¹™:
        1. ìœ„ì— ì—†ëŠ” ë°ì´í„°ëŠ” ì ˆëŒ€ ë§Œë“¤ì§€ ë§ˆì„¸ìš”
        2. ì¶”ì¸¡ì´ë‚˜ ì¼ë°˜ë¡ ì€ ê¸ˆì§€
        3. ëª¨ë“  ì£¼ì¥ì€ ìœ„ ë°ì´í„°ì—ì„œ ì§ì ‘ ì¸ìš©
        4. ë°ì´í„°ê°€ ì—†ëŠ” ë¶€ë¶„ì€ "ë°ì´í„° ì—†ìŒ"ìœ¼ë¡œ ëª…ì‹œ
        5. êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ì™€ ì¶œì²˜ë¥¼ í•­ìƒ ëª…ì‹œ
        
        ì‘ë‹µ êµ¬ì¡°:
        1. í•µì‹¬ ë°œê²¬ì‚¬í•­ (ë°ì´í„° ê¸°ë°˜)
        2. ìƒì„¸ ë¶„ì„ (ê° ì£¼ì¥ë§ˆë‹¤ ê·¼ê±° ëª…ì‹œ)
        3. í•œê³„ì  (ë¶„ì„ë˜ì§€ ì•Šì€ ë¶€ë¶„ ëª…ì‹œ)
        4. ê²°ë¡  (ì‚¬ìš©ì ì§ˆë¬¸ì— ì§ì ‘ ë‹µë³€)
        """
        
        try:
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": evidence_prompt}],
                temperature=0.1,
                max_tokens=3000,
                timeout=90.0
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            logger.error(f"ì¦ê±° ê¸°ë°˜ ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
            return self._create_fallback_synthesis(user_input, reliable_results)
    
    async def _create_intelligent_final_response(self,
                                               user_input: str,
                                               user_intent: Dict,
                                               execution_result: Dict,
                                               content_assessment: Dict,
                                               context: Dict) -> str:
        """ì§€ëŠ¥ì ì¸ ìµœì¢… ì‘ë‹µ ìƒì„±"""
        
        if not self.openai_client:
            return self._create_fallback_synthesis(user_input, execution_result['results'])
        
        # ê²€ì¦ëœ ê²°ê³¼ë§Œ ì‚¬ìš©
        reliable_results = {
            agent: result
            for agent, result in execution_result['results'].items()
            if result.get('validation', {}).get('is_valid', False)
        }
        
        response_prompt = f"""
        ë‹¹ì‹ ì€ {context.get('adopted_perspective', 'ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€')}ì…ë‹ˆë‹¤.
        
        ì‚¬ìš©ì ìš”ì²­: "{user_input}"
        
        ì‚¬ìš©ì ì˜ë„ ë¶„ì„:
        - ì•¡ì…˜ íƒ€ì…: {user_intent['action_type']}
        - ì£¼ìš” ëª©í‘œ: {user_intent['main_goal']}
        - ê¸°ëŒ€ ê²°ê³¼: {json.dumps(user_intent['expected_outcomes'], ensure_ascii=False)}
        
        ê²€ì¦ëœ ë¶„ì„ ê²°ê³¼:
        {self._structure_reliable_results(reliable_results)}
        
        ì‹¤í–‰ ìš”ì•½:
        - ì´ ë‹¨ê³„: {len(execution_result['history'])}
        - ì„±ê³µë¥ : {len(reliable_results)}/{len(execution_result['results'])}
        - ë¦¬í”Œë˜ë‹: {execution_result['replanning_count']}íšŒ
        - ì™„ë£Œ ë°©ì‹: {execution_result['completion_reason']}
        
        ì½˜í…ì¸  í‰ê°€:
        - ë°ì´í„° í’ˆì§ˆ: {content_assessment.get('data_quality_score')}/10
        - í•µì‹¬ ë°œê²¬: {len(content_assessment.get('critical_findings', []))}ê°œ
        - ì‹œê°í™”: {content_assessment.get('has_visualizations')}
        
        ì‘ë‹µ ì‘ì„± ì§€ì¹¨:
        1. ì‚¬ìš©ìì˜ {user_intent['action_type']} ìš”ì²­ì— ì •í™•íˆ ë‹µë³€
        2. ê²€ì¦ëœ ë°ì´í„°ë§Œ ì‚¬ìš© (ìœ„ì— ì—†ëŠ” ë‚´ìš© ì°½ì‘ ê¸ˆì§€)
        3. {context.get('response_style', 'professional')} í†¤ ìœ ì§€
        4. ëª¨ë“  ì£¼ì¥ì— êµ¬ì²´ì  ê·¼ê±° ì œì‹œ
        5. í•œê³„ì ì´ ìˆë‹¤ë©´ ëª…í™•íˆ ëª…ì‹œ
        
        {self._get_action_specific_instructions(user_intent['action_type'])}
        """
        
        try:
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": response_prompt}],
                temperature=0.3,
                max_tokens=4000,
                timeout=90.0
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            logger.error(f"Intelligent response generation failed: {e}")
            return self._create_fallback_synthesis(user_input, reliable_results)
    
    def _structure_reliable_results(self, reliable_results: Dict) -> str:
        """ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ê²°ê³¼ë¥¼ êµ¬ì¡°í™”"""
        structured = "### ê²€ì¦ëœ ë¶„ì„ ê²°ê³¼\n\n"
        
        for agent_name, result in reliable_results.items():
            validation = result.get('validation', {})
            confidence = validation.get('confidence_score', 0)
            
            structured += f"#### {agent_name} (ì‹ ë¢°ë„: {confidence}%)\n"
            
            # ì£¼ìš” ê²°ê³¼ ì¶”ì¶œ
            if 'summary' in result:
                structured += f"- **ìš”ì•½**: {result['summary']}\n"
            
            # êµ¬ì²´ì  ë°ì´í„° ì¶”ì¶œ
            if 'result' in result and isinstance(result['result'], dict):
                result_data = result['result']
                
                # ì•„í‹°íŒ©íŠ¸ ì •ë³´
                if 'artifacts' in result_data:
                    artifacts = result_data['artifacts']
                    structured += f"- **ìƒì„±ëœ ë°ì´í„°**: {len(artifacts)}ê°œ\n"
                    
                    for artifact in artifacts[:2]:  # ì£¼ìš” 2ê°œë§Œ
                        if isinstance(artifact, dict):
                            name = artifact.get('name', 'unnamed')
                            content_type = artifact.get('metadata', {}).get('content_type', 'unknown')
                            structured += f"  - {name} ({content_type})\n"
            
            # í•µì‹¬ ìˆ˜ì¹˜ ì¶”ì¶œ
            if validation.get('data_sources'):
                structured += f"- **ë°ì´í„° ì†ŒìŠ¤**: {len(validation['data_sources'])}ê°œ\n"
            
            structured += "\n"
        
        return structured
    
    async def _verify_response_matches_intent(self, response: str, user_intent: Dict) -> bool:
        """ì‘ë‹µì´ ì‚¬ìš©ì ì˜ë„ì™€ ì¼ì¹˜í•˜ëŠ”ì§€ ê²€ì¦"""
        
        if not self.openai_client:
            return True  # ê²€ì¦ ë¶ˆê°€ì‹œ í†µê³¼
        
        verification_prompt = f"""
        ì‚¬ìš©ì ì˜ë„:
        - ì•¡ì…˜ íƒ€ì…: {user_intent['action_type']}
        - ì£¼ìš” ëª©í‘œ: {user_intent['main_goal']}
        - ê¸°ëŒ€ ê²°ê³¼: {json.dumps(user_intent['expected_outcomes'], ensure_ascii=False)}
        
        ìƒì„±ëœ ì‘ë‹µ:
        {response[:1000]}...
        
        ì´ ì‘ë‹µì´ ì‚¬ìš©ì ì˜ë„ì™€ ì¼ì¹˜í•˜ëŠ”ì§€ í‰ê°€í•˜ì„¸ìš”:
        
        {{
            "matches_intent": true/false,
            "missing_elements": ["ë¶€ì¡±í•œ ìš”ì†Œë“¤"],
            "alignment_score": 0-100
        }}
        """
        
        try:
            response_obj = await self.openai_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": verification_prompt}],
                response_format={"type": "json_object"},
                temperature=0.2,
                timeout=30.0
            )
            
            verification = json.loads(response_obj.choices[0].message.content)
            return verification.get('matches_intent', True)
            
        except Exception as e:
            logger.warning(f"Intent verification failed: {e}")
            return True
    
    async def _regenerate_response_for_intent(self,
                                            user_input: str,
                                            validated_results: Dict,
                                            user_intent: Dict) -> str:
        """ì˜ë„ì— ë§ê²Œ ì‘ë‹µ ì¬ìƒì„±"""
        
        if not self.openai_client:
            return self._create_fallback_synthesis(user_input, validated_results)
        
        regeneration_prompt = f"""
        ì‚¬ìš©ìê°€ ì •í™•íˆ ì›í•˜ëŠ” ê²ƒ:
        - ì•¡ì…˜: {user_intent['action_type']}
        - ëª©í‘œ: {user_intent['main_goal']}
        - ê¸°ëŒ€ ê²°ê³¼: {json.dumps(user_intent['expected_outcomes'], ensure_ascii=False)}
        
        ì›ë³¸ ìš”ì²­: "{user_input}"
        
        ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°:
        {self._structure_reliable_results(validated_results)}
        
        ìœ„ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ì ì˜ë„ì— ì •í™•íˆ ë§ëŠ” ì‘ë‹µì„ ì‘ì„±í•˜ì„¸ìš”.
        {self._get_action_specific_instructions(user_intent['action_type'])}
        """
        
        try:
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": regeneration_prompt}],
                temperature=0.2,
                max_tokens=4000,
                timeout=90.0
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            logger.error(f"Response regeneration failed: {e}")
            return self._create_fallback_synthesis(user_input, validated_results)
    
    def _get_action_specific_instructions(self, action_type: str) -> str:
        """ì•¡ì…˜ íƒ€ì…ë³„ êµ¬ì²´ì  ì§€ì‹œì‚¬í•­"""
        instructions = {
            'analyze': """
            ë¶„ì„ ê²°ê³¼ êµ¬ì¡°:
            1. í•µì‹¬ ë°œê²¬ì‚¬í•­ ìš”ì•½
            2. ìƒì„¸ ë¶„ì„ (ë°ì´í„° ê¸°ë°˜)
            3. íŒ¨í„´ê³¼ íŠ¸ë Œë“œ
            4. ê²°ë¡  ë° ì‹œì‚¬ì 
            """,
            
            'verify': """
            ê²€ì¦ ê²°ê³¼ êµ¬ì¡°:
            1. ê²€ì¦ ëŒ€ìƒ ëª…í™•í™”
            2. ì‚¬ì‹¤ ì—¬ë¶€ íŒë‹¨ (O/X)
            3. íŒë‹¨ ê·¼ê±° (ë°ì´í„° ì¸ìš©)
            4. ì‹ ë¢°ë„ í‰ê°€
            """,
            
            'recommend': """
            ì¶”ì²œ ê²°ê³¼ êµ¬ì¡°:
            1. ì¶”ì²œ ì‚¬í•­ (ìš°ì„ ìˆœìœ„ í¬í•¨)
            2. ê° ì¶”ì²œì˜ ê·¼ê±°
            3. ì˜ˆìƒ íš¨ê³¼
            4. ì‹¤í–‰ ì‹œ ê³ ë ¤ì‚¬í•­
            """,
            
            'diagnose': """
            ì§„ë‹¨ ê²°ê³¼ êµ¬ì¡°:
            1. í˜„ì¬ ìƒíƒœ í‰ê°€
            2. ë¬¸ì œì  ì‹ë³„
            3. ì›ì¸ ë¶„ì„
            4. ê°œì„  ë°©í–¥
            """,
            
            'predict': """
            ì˜ˆì¸¡ ê²°ê³¼ êµ¬ì¡°:
            1. ì˜ˆì¸¡ ê²°ê³¼
            2. ì˜ˆì¸¡ ê·¼ê±°
            3. ì‹ ë¢°ë„ ë° ë¶ˆí™•ì‹¤ì„±
            4. ì‹œë‚˜ë¦¬ì˜¤ë³„ ì „ë§
            """,
            
            'compare': """
            ë¹„êµ ê²°ê³¼ êµ¬ì¡°:
            1. ë¹„êµ ëŒ€ìƒ ëª…í™•í™”
            2. ì£¼ìš” ì°¨ì´ì 
            3. ì¥ë‹¨ì  ë¶„ì„
            4. ìƒí™©ë³„ ì¶”ì²œ
            """,
            
            'explain': """
            ì„¤ëª… ê²°ê³¼ êµ¬ì¡°:
            1. ê°œë…/í˜„ìƒ ì •ì˜
            2. ì‘ë™ ì›ë¦¬/ë©”ì»¤ë‹ˆì¦˜
            3. ì‹¤ì œ ì‚¬ë¡€
            4. ì¶”ê°€ ì°¸ê³ ì‚¬í•­
            """
        }
        
        return instructions.get(action_type, "ì‚¬ìš©ì ìš”ì²­ì— ë§ëŠ” êµ¬ì¡°ë¡œ ë‹µë³€í•˜ì„¸ìš”.")
    
    async def _find_alternative_agent(self, user_input: str, available_agents: Dict) -> Optional[str]:
        """ëŒ€ì²´ ì—ì´ì „íŠ¸ ì°¾ê¸°"""
        if not self.openai_client or not available_agents:
            return None
        
        try:
            agent_list = list(available_agents.keys())
            prompt = f"""
            ì‚¬ìš©ì ìš”ì²­: "{user_input}"
            
            ì‚¬ìš© ê°€ëŠ¥í•œ ì—ì´ì „íŠ¸: {agent_list}
            
            ì´ ìš”ì²­ì„ ì²˜ë¦¬í•˜ê¸°ì— ê°€ì¥ ì í•©í•œ ì—ì´ì „íŠ¸ë¥¼ ì„ íƒí•˜ì„¸ìš”.
            """
            
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.2,
                max_tokens=100,
                timeout=30.0
            )
            
            selected = response.choices[0].message.content.strip()
            
            # ì„ íƒëœ ì—ì´ì „íŠ¸ê°€ ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
            for agent in agent_list:
                if agent in selected:
                    return agent
            
            return agent_list[0] if agent_list else None
            
        except Exception as e:
            logger.warning(f"Alternative agent selection failed: {e}")
            return list(available_agents.keys())[0] if available_agents else None
    
    async def _improve_instruction_based_on_failure(self, 
                                                  original_instruction: str,
                                                  warnings: List[str],
                                                  user_intent: Dict) -> str:
        """ì‹¤íŒ¨ ì›ì¸ì„ ë°”íƒ•ìœ¼ë¡œ ì§€ì‹œ ê°œì„ """
        
        if not self.openai_client:
            return original_instruction + "\n\në” êµ¬ì²´ì ì´ê³  ìƒì„¸í•œ ë¶„ì„ì„ ìˆ˜í–‰í•˜ì„¸ìš”."
        
        improvement_prompt = f"""
        ì›ë˜ ì§€ì‹œ: {original_instruction}
        
        ì‹¤íŒ¨ ì›ì¸: {warnings}
        ì‚¬ìš©ì ì˜ë„: {user_intent['main_goal']}
        
        ìœ„ ì‹¤íŒ¨ ì›ì¸ì„ í•´ê²°í•  ìˆ˜ ìˆë„ë¡ ì§€ì‹œë¥¼ ê°œì„ í•˜ì„¸ìš”.
        ë” êµ¬ì²´ì ì´ê³  ëª…í™•í•œ ì§€ì‹œë¥¼ ì‘ì„±í•˜ì„¸ìš”.
        """
        
        try:
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": improvement_prompt}],
                temperature=0.3,
                max_tokens=1500,
                timeout=60.0
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            logger.warning(f"Instruction improvement failed: {e}")
            return original_instruction + "\n\në” êµ¬ì²´ì ì´ê³  ìƒì„¸í•œ ë¶„ì„ì„ ìˆ˜í–‰í•˜ì„¸ìš”."
    
    async def _handle_with_alternative_approach(self,
                                              user_input: str,
                                              user_intent: Dict,
                                              task_updater: StreamingTaskUpdater):
        """ëŒ€ì²´ ì ‘ê·¼ ë°©ì‹ìœ¼ë¡œ ì²˜ë¦¬"""
        
        if self.openai_client:
            try:
                # LLMìœ¼ë¡œ ì§ì ‘ ì‘ë‹µ ìƒì„±
                alternative_prompt = f"""
                ì‚¬ìš©ì ìš”ì²­: "{user_input}"
                
                ì—ì´ì „íŠ¸ ì‹¤í–‰ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.
                ì‚¬ìš© ê°€ëŠ¥í•œ ì •ë³´ì™€ ì¼ë°˜ì ì¸ ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ
                ìµœì„ ì˜ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.
                
                ì£¼ì˜: ì¶”ì¸¡ì´ë‚˜ ê°€ì •ì€ ìµœì†Œí™”í•˜ê³ ,
                í™•ì‹¤í•œ ì •ë³´ë§Œ ì œê³µí•˜ì„¸ìš”.
                """
                
                response = await self.openai_client.chat.completions.create(
                    model="gpt-4o",
                    messages=[{"role": "user", "content": alternative_prompt}],
                    temperature=0.3,
                    max_tokens=2000,
                    timeout=60.0
                )
                
                answer = response.choices[0].message.content
                answer = f"âš ï¸ ì—ì´ì „íŠ¸ ì‹¤í–‰ì— ì‹¤íŒ¨í•˜ì—¬ ì œí•œëœ ì •ë³´ë¡œ ë‹µë³€ë“œë¦½ë‹ˆë‹¤.\n\n{answer}"
                
                await task_updater.update_status(
                    TaskState.completed,
                    message=task_updater.new_agent_message(parts=[TextPart(text=answer)])
                )
                
            except Exception as e:
                logger.error(f"Alternative approach failed: {e}")
                await task_updater.update_status(
                    TaskState.failed,
                    message=task_updater.new_agent_message(
                        parts=[TextPart(text="ì£„ì†¡í•©ë‹ˆë‹¤. ìš”ì²­ì„ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")]
                    )
                )
        else:
            await task_updater.update_status(
                TaskState.failed,
                message=task_updater.new_agent_message(
                    parts=[TextPart(text="ì—ì´ì „íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨ ë° ëŒ€ì²´ ë°©ì•ˆë„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")]
                )
            )
    
    async def _save_plan_artifact(self, plan: Dict, task_updater: StreamingTaskUpdater):
        """ê³„íšì„ ì•„í‹°íŒ©íŠ¸ë¡œ ì €ì¥"""
        
        plan_artifact = {
            "execution_strategy": plan.get('execution_strategy', ''),
            "agent_selection_reasoning": plan.get('agent_selection_reasoning', ''),
            "plan_executed": [
                {
                    "step": i + 1,
                    "agent": step.get('agent', 'unknown'),
                    "purpose": step.get('purpose', ''),
                    "comprehensive_instructions": step.get('comprehensive_instructions', ''),
                    "expected_deliverables": step.get('expected_deliverables', {})
                }
                for i, step in enumerate(plan.get('steps', []))
            ]
        }
        
        await task_updater.add_artifact(
            parts=[TextPart(text=json.dumps(plan_artifact, ensure_ascii=False, indent=2))],
            name="comprehensive_execution_plan.json",
            metadata={
                "content_type": "application/json",
                "plan_type": "universal_intelligent_orchestration",
                "description": "Universal Intelligent Orchestrator ì‹¤í–‰ ê³„íš"
            }
        )
    
    async def _save_execution_summary(self,
                                    execution_result: Dict,
                                    content_assessment: Dict,
                                    task_updater: StreamingTaskUpdater):
        """ì‹¤í–‰ ìš”ì•½ì„ ì•„í‹°íŒ©íŠ¸ë¡œ ì €ì¥"""
        
        execution_summary = {
            "total_steps_executed": len(execution_result['history']),
            "successful_agents": len([r for r in execution_result['results'].values() 
                                    if r.get('validation', {}).get('is_valid', False)]),
            "replanning_count": execution_result['replanning_count'],
            "completion_reason": execution_result['completion_reason'],
            "content_assessment": content_assessment,
            "execution_strategy": "universal_intelligent_orchestration_v7"
        }
        
        await task_updater.add_artifact(
            parts=[TextPart(text=json.dumps(execution_summary, ensure_ascii=False, indent=2))],
            name="execution_summary.json",
            metadata={
                "content_type": "application/json",
                "summary_type": "universal_system_execution",
                "description": "Universal System ì‹¤í–‰ ìš”ì•½"
            }
        )
    
    def _create_beautiful_plan_display(self, execution_plan: Dict, user_intent: Dict) -> str:
        """ì˜ˆìœ ì‹¤í–‰ ê³„íš í‘œì‹œ ìƒì„±"""
        
        plan_display = f"""
## ğŸ“‹ Intelligent Execution Plan

### ğŸ¯ ë¶„ì„ ê°œìš”
- **ëª©í‘œ**: {user_intent.get('main_goal', 'ë°ì´í„° ë¶„ì„')}
- **ì•¡ì…˜ íƒ€ì…**: {user_intent.get('action_type', 'analyze')}
- **ì´ ë‹¨ê³„**: {len(execution_plan.get('steps', []))}ê°œ

### ğŸš€ ì‹¤í–‰ ì „ëµ
{execution_plan.get('execution_strategy', 'ì‚¬ìš©ì ìš”ì²­ì— ìµœì í™”ëœ ë¶„ì„')}

### ğŸ“Š ë‹¨ê³„ë³„ ê³„íš

"""
        
        for i, step in enumerate(execution_plan.get('steps', [])):
            step_num = i + 1
            agent_name = step.get('agent', 'unknown')
            purpose = step.get('purpose', '')
            
            plan_display += f"""**{step_num}. {agent_name}**
   - ğŸ¯ **ëª©ì **: {purpose}
   - ğŸ“ **ê¸°ëŒ€ ê²°ê³¼**: 
     - ìµœì†Œ: {step.get('expected_deliverables', {}).get('minimum', 'ê¸°ë³¸ ê²°ê³¼')}
     - í‘œì¤€: {step.get('expected_deliverables', {}).get('standard', 'ìƒì„¸ ê²°ê³¼')}
     - íƒì›”: {step.get('expected_deliverables', {}).get('exceptional', 'ì‹¬ì¸µ ì¸ì‚¬ì´íŠ¸')}

"""
        
        plan_display += f"""
### ğŸ§  ì„ íƒ ê·¼ê±°
{execution_plan.get('agent_selection_reasoning', 'ìš”ì²­ì— ìµœì í™”ëœ ì—ì´ì „íŠ¸ ì„ íƒ')}

---
"""
        
        return plan_display
    
    def _create_fallback_plan(self, available_agents: Dict[str, Dict[str, Any]]) -> Dict[str, Any]:
        """LLMì´ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•  ë•Œì˜ í´ë°± ê³„íš"""
        steps = []
        
        # ê¸°ë³¸ì ì¸ ë°ì´í„° ë¶„ì„ ì›Œí¬í”Œë¡œìš°
        basic_workflow = [
            ("data_loader", "ë°ì´í„° ë¡œë“œ ë° ê¸°ë³¸ ê²€ì¦", "ë°ì´í„° íŒŒì¼ì„ ë¡œë“œí•˜ê³  ê¸°ë³¸ì ì¸ êµ¬ì¡°ë¥¼ íŒŒì•…í•©ë‹ˆë‹¤"),
            ("data_cleaning", "ë°ì´í„° í’ˆì§ˆ í™•ì¸ ë° ì •ë¦¬", "ë°ì´í„°ì˜ í’ˆì§ˆì„ í™•ì¸í•˜ê³  í•„ìš”í•œ ì •ë¦¬ ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤"),
            ("eda_tools", "íƒìƒ‰ì  ë°ì´í„° ë¶„ì„ ìˆ˜í–‰", "ë°ì´í„°ì˜ ë¶„í¬ì™€ íŒ¨í„´ì„ íƒìƒ‰í•˜ê³  ê¸°ì´ˆ í†µê³„ë¥¼ ìƒì„±í•©ë‹ˆë‹¤"),
            ("data_visualization", "ë°ì´í„° ì‹œê°í™” ë° ì¸ì‚¬ì´íŠ¸ ë„ì¶œ", "ë°ì´í„°ë¥¼ ì‹œê°í™”í•˜ì—¬ ì¸ì‚¬ì´íŠ¸ë¥¼ ë„ì¶œí•©ë‹ˆë‹¤")
        ]
        
        for agent_name, purpose, task_desc in basic_workflow:
            if agent_name in available_agents:
                steps.append({
                    "step_number": len(steps) + 1,
                    "agent": agent_name,
                    "purpose": purpose,
                    "comprehensive_instructions": task_desc,
                    "expected_deliverables": {
                        "minimum": f"{purpose} ê¸°ë³¸ ê²°ê³¼",
                        "standard": f"{purpose} ìƒì„¸ ê²°ê³¼",
                        "exceptional": f"{purpose} ì‹¬ì¸µ ë¶„ì„"
                    },
                    "success_criteria": "ë¶„ì„ ì™„ë£Œ",
                    "context_for_next": ["ë¶„ì„ ê²°ê³¼", "ë°ì´í„° ì •ë³´"]
                })
        
        return {
            "execution_strategy": "í‘œì¤€ ë°ì´í„° ë¶„ì„ ì›Œí¬í”Œë¡œìš°",
            "agent_selection_reasoning": "ê¸°ë³¸ì ì¸ ë°ì´í„° ë¶„ì„ì„ ìœ„í•œ í‘œì¤€ ì—ì´ì „íŠ¸ ì„ íƒ",
            "steps": steps,
            "final_synthesis_strategy": "ëª¨ë“  ë¶„ì„ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ì¸ì‚¬ì´íŠ¸ ë„ì¶œ",
            "potential_insights": ["ë°ì´í„° íŒ¨í„´", "í†µê³„ì  íŠ¹ì„±", "ì‹œê°ì  ë°œê²¬"]
        }
    
    def _create_fallback_synthesis(self, original_request: str, all_results: Dict) -> str:
        """í´ë°± ìµœì¢… ë‹µë³€ ìƒì„±"""
        
        successful_agents = [name for name, result in all_results.items() 
                           if result.get('status') == 'success']
        failed_agents = [name for name, result in all_results.items() 
                        if result.get('status') == 'failed']
        
        synthesis = f"""## ğŸ“Š ë°ì´í„° ë¶„ì„ ê²°ê³¼ ì¢…í•©

### ğŸ¯ ìš”ì²­ ì‚¬í•­
{original_request}

### âœ… ì™„ë£Œëœ ë¶„ì„ ë‹¨ê³„
"""
        
        for agent_name in successful_agents:
            result = all_results[agent_name]
            synthesis += f"- **{agent_name}**: {result.get('summary', 'ì‘ì—… ì™„ë£Œ')}\n"
        
        if failed_agents:
            synthesis += f"\n### âš ï¸ ì¼ë¶€ ì œí•œì‚¬í•­\n"
            for agent_name in failed_agents:
                result = all_results[agent_name]
                synthesis += f"- **{agent_name}**: {result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}\n"
        
        synthesis += f"""

### ğŸ‰ ê²°ë¡ 
ì´ {len(successful_agents)}ê°œì˜ ë¶„ì„ ë‹¨ê³„ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. 
ê° ì—ì´ì „íŠ¸ê°€ ìƒì„±í•œ ê²°ê³¼ë¬¼ê³¼ ì•„í‹°íŒ©íŠ¸ë¥¼ í™•ì¸í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.

ë¶„ì„ ê²°ê³¼ì— ëŒ€í•œ ì¶”ê°€ ì§ˆë¬¸ì´ë‚˜ ë” ìì„¸í•œ ë¶„ì„ì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“  ìš”ì²­í•´ ì£¼ì„¸ìš”.
"""
        
        return synthesis
    
    def _infer_use_cases(self, agent_name: str) -> List[str]:
        """ì—ì´ì „íŠ¸ ì´ë¦„ì—ì„œ ì‚¬ìš© ì‚¬ë¡€ ì¶”ë¡ """
        use_cases = {
            "data_loader": ["ë°ì´í„° íŒŒì¼ ë¡œë“œ", "ë°ì´í„° êµ¬ì¡° íŒŒì•…", "ê¸°ë³¸ ê²€ì¦"],
            "data_cleaning": ["ê²°ì¸¡ê°’ ì²˜ë¦¬", "ì¤‘ë³µ ì œê±°", "ë°ì´í„° ì •ì œ"],
            "eda_tools": ["í†µê³„ ë¶„ì„", "ë¶„í¬ í™•ì¸", "ìƒê´€ê´€ê³„ ë¶„ì„"],
            "data_visualization": ["ì°¨íŠ¸ ìƒì„±", "ì‹œê°í™”", "íŒ¨í„´ ë°œê²¬"],
            "data_wrangling": ["ë°ì´í„° ë³€í™˜", "í˜•íƒœ ë³€ê²½", "ì§‘ê³„"],
            "feature_engineering": ["íŠ¹ì„± ìƒì„±", "ì°¨ì› ì¶•ì†Œ", "íŠ¹ì„± ì„ íƒ"],
            "sql_database": ["SQL ì¿¼ë¦¬", "ë°ì´í„°ë² ì´ìŠ¤ ì¡°íšŒ", "ì¡°ì¸"],
            "h2o_modeling": ["ë¨¸ì‹ ëŸ¬ë‹", "ì˜ˆì¸¡ ëª¨ë¸", "AutoML"],
            "mlflow_tracking": ["ì‹¤í—˜ ì¶”ì ", "ëª¨ë¸ ë²„ì „ ê´€ë¦¬", "ì„±ëŠ¥ ë¹„êµ"]
        }
        
        return use_cases.get(agent_name, ["ë°ì´í„° ì²˜ë¦¬"])


def create_universal_intelligent_orchestrator_server():
    """Universal Intelligent Orchestrator ì„œë²„ ìƒì„±"""
    
    agent_card = AgentCard(
        name="Universal Intelligent Orchestrator v7.0",
        description="LLM ê¸°ë°˜ ë²”ìš© ì§€ëŠ¥í˜• ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° - ì ì‘ì  ì²˜ë¦¬, ë™ì  ë¦¬í”Œë˜ë‹, ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì§€ì›",
        url="http://localhost:8100",
        version="7.0.0",
        capabilities=AgentCapabilities(
            streaming=True,
            pushNotifications=True,
            stateTransitionHistory=True
        ),
        defaultInputModes=["text/plain"],
        defaultOutputModes=["text/plain", "application/json"],
        skills=[
            AgentSkill(
                id="adaptive_processing",
                name="Adaptive Request Processing",
                description="ìš”ì²­ ë³µì¡ë„ì— ë”°ë¼ ì¦‰ë‹µ, ë‹¨ì¼ ì—ì´ì „íŠ¸, ë³µì¡í•œ ì›Œí¬í”Œë¡œìš°ë¥¼ ìë™ ì„ íƒ",
                tags=["adaptive", "intelligent", "complexity-aware"]
            ),
            AgentSkill(
                id="dynamic_replanning",
                name="Dynamic Replanning System",
                description="ì‹¤í–‰ ì¤‘ ìƒí™© ë³€í™”ì— ë”°ë¼ ê³„íšì„ ë™ì ìœ¼ë¡œ ìˆ˜ì •í•˜ê³  ìµœì í™”",
                tags=["replanning", "optimization", "recovery"]
            ),
            AgentSkill(
                id="llm_powered_orchestration",
                name="LLM Powered Orchestration",
                description="LLMì´ ì‚¬ìš©ì ì˜ë„ë¥¼ ì •í™•íˆ íŒŒì•…í•˜ê³  ìµœì ì˜ ì‹¤í–‰ ê³„íšì„ ìƒì„±",
                tags=["llm", "ai", "intent-understanding"]
            ),
            AgentSkill(
                id="evidence_based_synthesis",
                name="Evidence Based Response Generation",
                description="ê²€ì¦ëœ ë°ì´í„°ë§Œì„ ê¸°ë°˜ìœ¼ë¡œ í• ë£¨ì‹œë„¤ì´ì…˜ ì—†ëŠ” ì •í™•í•œ ì‘ë‹µ ìƒì„±",
                tags=["evidence-based", "validation", "accuracy"]
            )
        ]
    )
    
    executor = UniversalIntelligentOrchestrator()
    task_store = InMemoryTaskStore()
    request_handler = DefaultRequestHandler(
        agent_executor=executor,
        task_store=task_store
    )
    
    return A2AStarletteApplication(
        agent_card=agent_card,
        http_handler=request_handler
    )


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    logger.info("ğŸš€ Starting Universal Intelligent Orchestrator v7.0")
    
    app = create_universal_intelligent_orchestrator_server()
    
    uvicorn.run(
        app.build(),
        host="0.0.0.0",
        port=8100,
        log_level="info"
    )


if __name__ == "__main__":
    main()