#!/usr/bin/env python3
"""
CherryAI v8 - Universal Intelligent Orchestrator
v7 ì¥ì  + A2A í”„ë¡œí† ì½œ ê·¹ëŒ€í™” + v8 ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° í†µí•©
"""

import asyncio
import json
import logging
import os
import re
import time
from datetime import datetime
from typing import Any, Dict, List, Optional, AsyncGenerator
from dataclasses import dataclass

import httpx
import uvicorn
from openai import AsyncOpenAI

# A2A SDK 0.2.9 í‘œì¤€ ì„í¬íŠ¸
from a2a.server.apps import A2AStarletteApplication
from a2a.server.request_handlers import DefaultRequestHandler
from a2a.server.tasks import InMemoryTaskStore, TaskUpdater
from a2a.server.agent_execution import AgentExecutor, RequestContext
from a2a.server.events import EventQueue
from a2a.types import (
    AgentCard,
    AgentSkill,
    AgentCapabilities,
    TaskState,
    TextPart
)
from a2a.client import A2ACardResolver, A2AClient

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# AI DS Team ì—ì´ì „íŠ¸ í¬íŠ¸ ë§¤í•‘
AGENT_PORTS = {
    "data_cleaning": 8306,
    "data_loader": 8307, 
    "data_visualization": 8308,
    "data_wrangling": 8309,
    "eda_tools": 8310,
    "feature_engineering": 8311,
    "h2o_modeling": 8312,
    "mlflow_tracking": 8313,
    "sql_database": 8314
}

@dataclass
class DiscoveredAgent:
    """A2A í”„ë¡œí† ì½œë¡œ ë°œê²¬ëœ ì—ì´ì „íŠ¸ ì •ë³´"""
    name: str
    url: str
    description: str
    skills: Dict[str, Any]
    capabilities: Dict[str, Any]
    agent_card: AgentCard
    last_seen: datetime
    health_status: str = "healthy"


class RealTimeStreamingTaskUpdater(TaskUpdater):
    """v8: ì§„ì •í•œ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° êµ¬í˜„"""
    
    async def stream_update(self, content: str):
        """ì¤‘ê°„ ê²°ê³¼ ìŠ¤íŠ¸ë¦¬ë°"""
        await self.update_status(
            TaskState.working,
            message=self.new_agent_message(parts=[TextPart(text=content)])
        )
    
    async def stream_response_progressively(self, response: str, 
                                          chunk_size: int = 50,
                                          delay: float = 0.03) -> None:
        """ë¬¸ì ë‹¨ìœ„ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°"""
        
        await self.stream_update("ğŸ“ ë‹µë³€ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
        await asyncio.sleep(0.1)
        
        for i in range(0, len(response), chunk_size):
            chunk = response[i:i+chunk_size]
            await self.update_status(
                TaskState.working,
                message=self.new_agent_message(parts=[TextPart(text=chunk)])
            )
            await asyncio.sleep(delay)
        
        await self.stream_update("âœ… ë‹µë³€ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        await asyncio.sleep(0.2)
        
        await self.update_status(
            TaskState.completed,
            message=self.new_agent_message(parts=[TextPart(text=response)])
        )


class CherryAI_v8_UniversalIntelligentOrchestrator(AgentExecutor):
    """CherryAI v8 - Universal Intelligent Orchestrator"""
    
    def __init__(self):
        super().__init__()
        self.openai_client = self._initialize_openai_client()
        self.discovered_agents = {}
        self.streaming_updater = None
        logger.info("ğŸš€ CherryAI v8 Universal Intelligent Orchestrator ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _initialize_openai_client(self) -> Optional[AsyncOpenAI]:
        """OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        try:
            api_key = os.getenv("OPENAI_API_KEY")
            if not api_key:
                logger.warning("âš ï¸ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
                return None
            return AsyncOpenAI(api_key=api_key)
        except Exception as e:
            logger.error(f"âŒ OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return None
    
    async def execute(self, context: RequestContext) -> None:
        """v8 ë©”ì¸ ì‹¤í–‰ ë¡œì§"""
        
        self.streaming_updater = RealTimeStreamingTaskUpdater(
            context.task_updater.task_store,
            context.task_updater.task_id,
            context.task_updater.event_queue
        )
        
        try:
            user_input = self._extract_user_input(context)
            if not user_input:
                await self.streaming_updater.stream_update("âŒ ì‚¬ìš©ì ì…ë ¥ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            logger.info(f"ğŸ“ ì‚¬ìš©ì ìš”ì²­: {user_input[:100]}...")
            
            # A2A ë™ì  ì—ì´ì „íŠ¸ ë°œê²¬
            await self.streaming_updater.stream_update("ğŸ” A2A í”„ë¡œí† ì½œë¡œ ì—ì´ì „íŠ¸ë¥¼ ë°œê²¬í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
            await self._discover_agents()
            
            # ë³µì¡ë„ ë¶„ì„
            await self.streaming_updater.stream_update("ğŸ§  ìš”ì²­ ë³µì¡ë„ë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
            complexity_assessment = await self._assess_request_complexity(user_input)
            
            complexity_level = complexity_assessment.get('complexity_level', 'complex')
            await self.streaming_updater.stream_update(
                f"ğŸ“Š ìš”ì²­ ë³µì¡ë„: {complexity_level}"
            )
            
            # ë³µì¡ë„ë³„ ì²˜ë¦¬
            if complexity_level == 'simple':
                await self._handle_simple_request(user_input)
            else:
                await self._handle_complex_request(user_input)
                
        except Exception as e:
            logger.error(f"âŒ v8 ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
            await self.streaming_updater.stream_update(f"âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    
    def _extract_user_input(self, context: RequestContext) -> str:
        """ì‚¬ìš©ì ì…ë ¥ ì¶”ì¶œ"""
        try:
            if context.message and context.message.parts:
                for part in context.message.parts:
                    if hasattr(part.root, 'kind') and part.root.kind == 'text':
                        return part.root.text
                    elif hasattr(part.root, 'type') and part.root.type == 'text':
                        return part.root.text
            return ""
        except Exception as e:
            logger.error(f"ì‚¬ìš©ì ì…ë ¥ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return ""
    
    async def _discover_agents(self):
        """A2A ì—ì´ì „íŠ¸ ë°œê²¬"""
        self.discovered_agents = {}
        
        async with httpx.AsyncClient(timeout=10.0) as client:
            for port in AGENT_PORTS.values():
                try:
                    endpoint = f"http://localhost:{port}"
                    resolver = A2ACardResolver(httpx_client=client, base_url=endpoint)
                    agent_card = await resolver.get_agent_card()
                    
                    if agent_card:
                        self.discovered_agents[agent_card.name] = {
                            'url': endpoint,
                            'card': agent_card
                        }
                        logger.info(f"âœ… A2A Agent discovered: {agent_card.name}")
                        
                except Exception as e:
                    logger.warning(f"Agent discovery failed for port {port}: {e}")
        
        await self.streaming_updater.stream_update(
            f"âœ… {len(self.discovered_agents)}ê°œì˜ A2A ì—ì´ì „íŠ¸ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤!"
        )
    
    async def _assess_request_complexity(self, user_input: str) -> Dict:
        """ë³µì¡ë„ ë¶„ì„"""
        word_count = len(user_input.split())
        question_marks = user_input.count('?')
        
        if word_count < 10 and question_marks > 0:
            return {'complexity_level': 'simple'}
        else:
            return {'complexity_level': 'complex'}
    
    async def _handle_simple_request(self, user_input: str):
        """Simple ìš”ì²­ ì²˜ë¦¬"""
        await self.streaming_updater.stream_update("ğŸ’¡ ê°„ë‹¨í•œ ìš”ì²­ìœ¼ë¡œ íŒë‹¨ë˜ì–´ ì¦‰ì‹œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤...")
        
        if not self.openai_client:
            await self.streaming_updater.stream_response_progressively(
                "ì£„ì†¡í•©ë‹ˆë‹¤. OpenAI APIê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            )
            return
        
        try:
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": f"ë‹¤ìŒ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”: {user_input}"}],
                temperature=0.5,
                timeout=60.0
            )
            
            answer = response.choices[0].message.content
            await self.streaming_updater.stream_response_progressively(answer)
            
        except Exception as e:
            await self.streaming_updater.stream_response_progressively(
                f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            )
    
    async def _handle_complex_request(self, user_input: str):
        """Complex ìš”ì²­ ì²˜ë¦¬"""
        await self.streaming_updater.stream_update("ğŸ”„ ë³µí•©ì ì¸ ìš”ì²­ìœ¼ë¡œ ì—ì´ì „íŠ¸ë“¤ê³¼ í˜‘ë ¥í•˜ì—¬ ì²˜ë¦¬í•©ë‹ˆë‹¤...")
        
        # ê¸°ë³¸ ì—ì´ì „íŠ¸ ìˆœì„œë¡œ ì‹¤í–‰
        agent_sequence = ["Data Loader Agent", "EDA Tools Agent", "Data Visualization Agent"]
        results = []
        
        for agent_name in agent_sequence:
            if agent_name in self.discovered_agents:
                await self.streaming_updater.stream_update(f"ğŸ¤– {agent_name} ì‹¤í–‰ ì¤‘...")
                
                result = await self._execute_agent(agent_name, user_input)
                results.append(result)
                
                if result.get('status') == 'success':
                    await self.streaming_updater.stream_update(f"âœ… {agent_name} ì™„ë£Œ")
                else:
                    await self.streaming_updater.stream_update(f"âš ï¸ {agent_name} ì‹¤íŒ¨: {result.get('error', '')}")
        
        # ìµœì¢… ì‘ë‹µ ìƒì„±
        await self._generate_final_response(results, user_input)
    
    async def _execute_agent(self, agent_name: str, instruction: str) -> Dict:
        """ë‹¨ì¼ ì—ì´ì „íŠ¸ ì‹¤í–‰"""
        agent_info = self.discovered_agents.get(agent_name)
        if not agent_info:
            return {'status': 'failed', 'error': f'ì—ì´ì „íŠ¸ {agent_name}ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤'}
        
        try:
            async with httpx.AsyncClient(timeout=120.0) as client:
                a2a_client = A2AClient(httpx_client=client, base_url=agent_info['url'])
                
                message = {
                    "parts": [{"kind": "text", "text": instruction}],
                    "messageId": f"msg_{int(time.time())}",
                    "role": "user"
                }
                
                response = await a2a_client.send_message(message)
                
                if response and hasattr(response, 'parts') and response.parts:
                    result_text = ""
                    for part in response.parts:
                        if hasattr(part.root, 'text'):
                            result_text += part.root.text
                    
                    return {'status': 'success', 'result': result_text}
                else:
                    return {'status': 'failed', 'error': 'ì—ì´ì „íŠ¸ì—ì„œ ì‘ë‹µì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤'}
                    
        except Exception as e:
            return {'status': 'failed', 'error': str(e)}
    
    async def _generate_final_response(self, results: List[Dict], user_input: str):
        """ìµœì¢… ì‘ë‹µ ìƒì„±"""
        await self.streaming_updater.stream_update("ğŸ“ ìµœì¢… ì¢…í•© ë¶„ì„ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
        
        if not self.openai_client:
            # í´ë°± ì‘ë‹µ
            response = f"# {user_input}ì— ëŒ€í•œ ë¶„ì„ ê²°ê³¼\n\n"
            for i, result in enumerate(results):
                response += f"## ë‹¨ê³„ {i+1} ê²°ê³¼\n\n"
                if result.get('status') == 'success':
                    response += f"{result.get('result', 'ê²°ê³¼ ì—†ìŒ')}\n\n"
                else:
                    response += f"âš ï¸ ì‹¤í–‰ ì‹¤íŒ¨: {result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}\n\n"
            
            await self.streaming_updater.stream_response_progressively(response)
            return
        
        # ì„±ê³µí•œ ê²°ê³¼ë“¤ë§Œ ìˆ˜ì§‘
        successful_results = [r for r in results if r.get('status') == 'success']
        
        if not successful_results:
            await self.streaming_updater.stream_response_progressively(
                "ì£„ì†¡í•©ë‹ˆë‹¤. ëª¨ë“  ì—ì´ì „íŠ¸ ì‹¤í–‰ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
            )
            return
        
        # LLMìœ¼ë¡œ ìµœì¢… ì¢…í•©
        results_text = "\n\n".join([r.get('result', '') for r in successful_results])
        
        try:
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[{
                    "role": "user", 
                    "content": f"""
                    ì‚¬ìš©ì ìš”ì²­: {user_input}
                    
                    ì—ì´ì „íŠ¸ ì‹¤í–‰ ê²°ê³¼ë“¤:
                    {results_text}
                    
                    ìœ„ ê²°ê³¼ë“¤ì„ ì¢…í•©í•˜ì—¬ ì‚¬ìš©ì ìš”ì²­ì— ëŒ€í•œ ì™„ì „í•œ ë‹µë³€ì„ ìƒì„±í•˜ì„¸ìš”.
                    êµ¬ì¡°í™”ëœ Markdown í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
                    """
                }],
                temperature=0.5,
                timeout=90.0
            )
            
            final_answer = response.choices[0].message.content
            await self.streaming_updater.stream_response_progressively(final_answer)
            
        except Exception as e:
            logger.error(f"ìµœì¢… ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
            await self.streaming_updater.stream_response_progressively(
                f"ìµœì¢… ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            )
    
    async def cancel(self, context: RequestContext) -> None:
        """ì‘ì—… ì·¨ì†Œ"""
        logger.info("ğŸ›‘ CherryAI v8 ì‘ì—…ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤")
        if self.streaming_updater:
            await self.streaming_updater.stream_update("ğŸ›‘ ì‘ì—…ì´ ì‚¬ìš©ìì— ì˜í•´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")


def create_agent_card() -> AgentCard:
    """CherryAI v8 Agent Card ìƒì„±"""
    return AgentCard(
        name="CherryAI v8 Universal Intelligent Orchestrator",
        description="v7 ì¥ì  + A2A í”„ë¡œí† ì½œ ê·¹ëŒ€í™” + v8 ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°ì„ í†µí•©í•œ ë²”ìš© ì§€ëŠ¥í˜• ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°",
        skills=[
            AgentSkill(
                id="universal_analysis",
                name="ë²”ìš© ë°ì´í„° ë¶„ì„",
                description="ëª¨ë“  ì¢…ë¥˜ì˜ ë°ì´í„° ë¶„ì„ ìš”ì²­ì„ A2A ì—ì´ì „íŠ¸ë“¤ê³¼ í˜‘ë ¥í•˜ì—¬ ì²˜ë¦¬",
                tags=["data-analysis", "orchestration", "a2a", "streaming"],
                examples=[
                    "ë°ì´í„°ì…‹ì˜ íŒ¨í„´ê³¼ ì´ìƒì¹˜ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”",
                    "ë§¤ì¶œ ë°ì´í„°ì˜ íŠ¸ë Œë“œë¥¼ ì˜ˆì¸¡í•´ì£¼ì„¸ìš”", 
                    "ê³ ê° ì„¸ë¶„í™” ë¶„ì„ì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”"
                ]
            ),
            AgentSkill(
                id="realtime_streaming",
                name="ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°",
                description="ë¶„ì„ ê³¼ì •ê³¼ ê²°ê³¼ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ìŠ¤íŠ¸ë¦¬ë°í•˜ì—¬ ì‚¬ìš©ì ê²½í—˜ í–¥ìƒ",
                tags=["streaming", "realtime", "progressive"],
                examples=[
                    "ë¶„ì„ ì§„í–‰ ìƒí™©ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ í™•ì¸",
                    "ê²°ê³¼ë¥¼ ì ì§„ì ìœ¼ë¡œ ë°›ì•„ë³´ê¸°"
                ]
            )
        ],
        capabilities=AgentCapabilities(
            streaming=True,
            pushNotifications=False,
            supportsAuthenticatedExtendedCard=False
        )
    )


if __name__ == "__main__":
    task_store = InMemoryTaskStore()
    event_queue = EventQueue()
    
    orchestrator = CherryAI_v8_UniversalIntelligentOrchestrator()
    
    request_handler = DefaultRequestHandler(
        agent_executor=orchestrator,
        task_store=task_store,
        event_queue=event_queue
    )
    
    app = A2AStarletteApplication(
        agent_card=create_agent_card(),
        request_handler=request_handler
    )
    
    uvicorn.run(app, host="0.0.0.0", port=8100, log_level="info") 