import sys
import os
from pathlib import Path

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# Import common utilities
from a2a_ds_servers.common.import_utils import setup_project_paths, log_import_status

# Setup paths and log status
setup_project_paths()
log_import_status()

from a2a.utils import new_agent_text_message#!/usr/bin/env python3
"""

AI_DS_Team DataWranglingAgent A2A Server
Port: 8309

AI_DS_Teamì˜ DataWranglingAgentë¥¼ A2A í”„ë¡œí† ì½œë¡œ ë˜í•‘í•˜ì—¬ ì œê³µí•©ë‹ˆë‹¤.
ë°ì´í„° ì‹œê°í™” ë° ì°¨íŠ¸ ìƒì„± ì „ë¬¸
"""

import asyncio
import sys
import os
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / "ai_ds_team"))

from a2a.server.apps import A2AStarletteApplication
from a2a.server.request_handlers.default_request_handler import DefaultRequestHandler
from a2a.server.tasks.inmemory_task_store import InMemoryTaskStore
from a2a.server.tasks.task_updater import TaskUpdater
from a2a.server.agent_execution import AgentExecutor, RequestContext
from a2a.types import TextPart, TaskState, AgentCard, AgentSkill, AgentCapabilities
import uvicorn
import logging

# AI_DS_Team imports
from ai_data_science_team.tools.dataframe import get_dataframe_summary
from ai_data_science_team.agents import DataWranglingAgent
from ai_data_science_team.utils.plotly import plotly_from_dict
import pandas as pd
import json

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# .env íŒŒì¼ì—ì„œ ë¡œê¹… ì„¤ì • ë¡œë“œ
from dotenv import load_dotenv
load_dotenv()

# Langfuse ë¡œê¹… ì„¤ì • (ì„ íƒì )
langfuse_handler = None
if os.getenv("LOGGING_PROVIDER") in ["langfuse", "both"]:
    try:
        from langfuse.callback import CallbackHandler
        langfuse_handler = CallbackHandler(
            public_key=os.getenv("LANGFUSE_PUBLIC_KEY"),
            secret_key=os.getenv("LANGFUSE_SECRET_KEY"),
            host=os.getenv("LANGFUSE_HOST"),
        )
        logger.info("âœ… Langfuse logging enabled")
    except Exception as e:
        logger.warning(f"âš ï¸ Langfuse logging setup failed: {e}")

# LangSmith ë¡œê¹… ì„¤ì • (ì„ íƒì )
if os.getenv("LOGGING_PROVIDER") in ["langsmith", "both"]:
    os.environ["LANGCHAIN_TRACING_V2"] = os.getenv("LANGCHAIN_TRACING_V2", "false")
    os.environ["LANGCHAIN_PROJECT"] = os.getenv("LANGCHAIN_PROJECT", "ai-ds-team")
    if os.getenv("LANGCHAIN_API_KEY"):
        os.environ["LANGCHAIN_API_KEY"] = os.getenv("LANGCHAIN_API_KEY")
        logger.info("âœ… LangSmith logging enabled")


class DataWranglingAgentExecutor(AgentExecutor):
    """AI_DS_Team DataWranglingAgentë¥¼ A2A í”„ë¡œí† ì½œë¡œ ë˜í•‘"""
    
    def __init__(self):
        # LLM ì„¤ì • (langfuse ì½œë°±ì€ LLM íŒ©í† ë¦¬ì—ì„œ ìë™ ì²˜ë¦¬)
        from core.llm_factory import create_llm_instance
        self.llm = create_llm_instance()
        self.agent = DataWranglingAgent(model=self.llm)
        logger.info("DataWranglingAgent initialized with LLM factory (langfuse auto-enabled)")
    
    async def execute(self, context: RequestContext, event_queue) -> None:
        """A2A í”„ë¡œí† ì½œì— ë”°ë¥¸ ì‹¤í–‰"""
        # event_queue passed as parameter
        task_updater = TaskUpdater(event_queue, context.task_id, context.context_id)
        
        try:
            # ì‘ì—… ì‹œì‘
            await task_updater.submit()
            await task_updater.start_work()
            
            # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ì¶œ
            user_instructions = ""
            if context.message and context.message.parts:
                for part in context.message.parts:
                    if part.root.kind == "text":
                        user_instructions += part.root.text + " "
                
                user_instructions = user_instructions.strip()
                logger.info(f"Processing data visualization request: {user_instructions}")
                
                # ë°ì´í„° ë¡œë“œ ì‹œë„
                data_path = "a2a_ds_servers/artifacts/data/shared_dataframes/"
                available_data = []
                
                try:
                    for file in os.listdir(data_path):
                        if file.endswith(('.csv', '.pkl')):
                            available_data.append(file)
                except:
                    pass
                
                if available_data:
                    # ë°ì´í„° íŒŒì¼ ì„ íƒ ë¡œì§ ê°œì„ 
                    data_file = None
                    
                    # 1. ì‚¬ìš©ì ìš”ì²­ì—ì„œ íŠ¹ì • ë°ì´í„° íŒŒì¼ ì–¸ê¸‰ í™•ì¸
                    user_lower = user_instructions.lower()
                    for file in available_data:
                        file_name_lower = file.lower()
                        file_base = file_name_lower.replace('.csv', '').replace('.pkl', '')
                        
                        # íŒŒì¼ëª…ì´ ì‚¬ìš©ì ìš”ì²­ì— í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
                        if (file_base in user_lower or 
                            any(keyword in file_name_lower for keyword in user_lower.split() if len(keyword) > 3)):
                            data_file = file
                            logger.info(f"ğŸ¯ ì‚¬ìš©ì ìš”ì²­ì—ì„œ ì–¸ê¸‰ëœ ë°ì´í„° íŒŒì¼ ì„ íƒ: {data_file}")
                            break
                    
                    # 2. ion_implant ë°ì´í„° ìš°ì„  ì„ íƒ (ë°˜ë„ì²´ ë¶„ì„ íŠ¹í™”)
                    if not data_file:
                        for file in available_data:
                            if "ion_implant" in file.lower():
                                data_file = file
                                logger.info(f"ğŸ”¬ ë°˜ë„ì²´ ë¶„ì„ìš© ion_implant ë°ì´í„° ì„ íƒ: {data_file}")
                                break
                    
                    # 3. ê°€ì¥ ìµœê·¼ ìˆ˜ì •ëœ íŒŒì¼ ì„ íƒ (fallback)
                    if not data_file:
                        try:
                            file_times = []
                            for file in available_data:
                                file_path = os.path.join(data_path, file)
                                if os.path.exists(file_path):
                                    mtime = os.path.getmtime(file_path)
                                    file_times.append((file, mtime))
                            
                            if file_times:
                                file_times.sort(key=lambda x: x[1], reverse=True)
                                data_file = file_times[0][0]
                                logger.info(f"ğŸ“… ê°€ì¥ ìµœê·¼ íŒŒì¼ ì„ íƒ: {data_file}")
                            else:
                                data_file = available_data[0]
                                logger.info(f"ğŸ“ ì²« ë²ˆì§¸ ì‚¬ìš© ê°€ëŠ¥í•œ íŒŒì¼ ì„ íƒ: {data_file}")
                        except Exception as e:
                            logger.warning(f"íŒŒì¼ ì‹œê°„ ì •ë ¬ ì‹¤íŒ¨: {e}")
                            data_file = available_data[0]
                            logger.info(f"ğŸ“ ê¸°ë³¸ íŒŒì¼ ì„ íƒ: {data_file}")
                    
                    if data_file.endswith('.csv'):
                        df = pd.read_csv(os.path.join(data_path, data_file))
                    else:
                        df = pd.read_pickle(os.path.join(data_path, data_file))
                    
                    logger.info(f"Loaded data: {data_file}, shape: {df.shape}")
                    
                    # DataWranglingAgent ì‹¤í–‰
                    try:
                        result = self.agent.invoke_agent(
                            user_instructions=user_instructions,
                            data_raw=df
                        )
                        
                        # ê²°ê³¼ ì²˜ë¦¬
                        # ê²°ê³¼ ì²˜ë¦¬ (ì•ˆì „í•œ ë°©ì‹ìœ¼ë¡œ workflow summary ê°€ì ¸ì˜¤ê¸°)

                        try:

                            workflow_summary = self.agent.get_workflow_summary(markdown=True)

                        except AttributeError:

                            # get_workflow_summary ë©”ì„œë“œê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ìš”ì•½ ìƒì„±

                            workflow_summary = f"âœ… ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\n\n**ìš”ì²­**: {user_instructions}"

                        except Exception as e:

                            logger.warning(f"Error getting workflow summary: {e}")

                            workflow_summary = f"âœ… ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\n\n**ìš”ì²­**: {user_instructions}"
                        
                        # ìƒì„±ëœ ì°¨íŠ¸ ì •ë³´ ìˆ˜ì§‘
                        charts_info = ""
                        artifacts_path = "a2a_ds_servers/artifacts/plots/"
                        os.makedirs(artifacts_path, exist_ok=True)
                        
                        # ì°¨íŠ¸ íŒŒì¼ ì €ì¥ í™•ì¸
                        saved_files = []
                        try:
                            if os.path.exists(artifacts_path):
                                for file in os.listdir(artifacts_path):
                                    if file.endswith(('.png', '.jpg', '.html', '.json')):
                                        saved_files.append(file)
                        except:
                            pass
                        
                        if saved_files:
                            charts_info += f"""
### ğŸ’¾ ì €ì¥ëœ ì°¨íŠ¸ íŒŒì¼ë“¤
{chr(10).join([f"- {file}" for file in saved_files[-5:]])}
"""
                        
                        # ë°ì´í„° ìš”ì•½ ìƒì„±
                        data_summary = get_dataframe_summary(df, n_sample=10)
                        
                        response_text = f"""## ğŸ“Š ë°ì´í„° ì‹œê°í™” ì™„ë£Œ

{workflow_summary}

{charts_info}

### ğŸ“‹ ì‚¬ìš©ëœ ë°ì´í„° ìš”ì•½
{data_summary[0] if data_summary else 'ë°ì´í„° ìš”ì•½ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}

### ğŸ¨ Data Visualization Agent ê¸°ëŠ¥
- **Plotly ì°¨íŠ¸**: ì¸í„°ë™í‹°ë¸Œ ì°¨íŠ¸ ìƒì„±
- **Matplotlib ì°¨íŠ¸**: ê³ í’ˆì§ˆ ì •ì  ì°¨íŠ¸
- **í†µê³„ ì‹œê°í™”**: ë¶„í¬, ìƒê´€ê´€ê³„, íŠ¸ë Œë“œ ë¶„ì„
- **ëŒ€ì‹œë³´ë“œ**: ë³µí•© ì‹œê°í™” ëŒ€ì‹œë³´ë“œ
- **ì»¤ìŠ¤í…€ ì°¨íŠ¸**: ìš”êµ¬ì‚¬í•­ì— ë§ëŠ” ë§ì¶¤í˜• ì‹œê°í™”
"""
                        
                    except Exception as agent_error:
                        logger.warning(f"Agent execution failed, providing guidance: {agent_error}")
                        response_text = f"""## ğŸ“Š ë°ì´í„° ì‹œê°í™” ê°€ì´ë“œ

ìš”ì²­ì„ ì²˜ë¦¬í•˜ëŠ” ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(agent_error)}

### ğŸ’¡ ë°ì´í„° ì‹œê°í™” ì‚¬ìš©ë²•
ë‹¤ìŒê³¼ ê°™ì€ ìš”ì²­ì„ ì‹œë„í•´ë³´ì„¸ìš”:

1. **ê¸°ë³¸ ì°¨íŠ¸**:
   - "ë§¤ì¶œ ë°ì´í„°ì˜ ì›”ë³„ íŠ¸ë Œë“œë¥¼ ì„  ê·¸ë˜í”„ë¡œ ê·¸ë ¤ì£¼ì„¸ìš”"
   - "ê³ ê° ë‚˜ì´ëŒ€ë³„ ë¶„í¬ë¥¼ íˆìŠ¤í† ê·¸ë¨ìœ¼ë¡œ ë³´ì—¬ì£¼ì„¸ìš”"

2. **ê³ ê¸‰ ì‹œê°í™”**:
   - "ë³€ìˆ˜ë“¤ ê°„ì˜ ìƒê´€ê´€ê³„ë¥¼ íˆíŠ¸ë§µìœ¼ë¡œ í‘œì‹œí•´ì£¼ì„¸ìš”"
   - "ì¹´í…Œê³ ë¦¬ë³„ ë°•ìŠ¤í”Œë¡¯ì„ ìƒì„±í•´ì£¼ì„¸ìš”"

3. **ì¸í„°ë™í‹°ë¸Œ ì°¨íŠ¸**:
   - "Plotlyë¥¼ ì‚¬ìš©í•´ì„œ ì¸í„°ë™í‹°ë¸Œ ì°¨íŠ¸ë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”"
   - "ëŒ€ì‹œë³´ë“œ í˜•íƒœë¡œ ì—¬ëŸ¬ ì°¨íŠ¸ë¥¼ ì¡°í•©í•´ì£¼ì„¸ìš”"

ìš”ì²­: {user_instructions}
"""
                
                else:
                    response_text = f"""## âŒ ë°ì´í„° ì—†ìŒ

ë°ì´í„° ì‹œê°í™”ë¥¼ ìˆ˜í–‰í•˜ë ¤ë©´ ë¨¼ì € ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•´ì•¼ í•©ë‹ˆë‹¤.
ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤: {data_path}

ìš”ì²­: {user_instructions}

### ğŸ“Š Data Visualization Agent ê¸°ëŠ¥
- **ì°¨íŠ¸ ìœ í˜•**: ì„ ê·¸ë˜í”„, ë§‰ëŒ€ê·¸ë˜í”„, íˆìŠ¤í† ê·¸ë¨, ì‚°ì ë„, ë°•ìŠ¤í”Œë¡¯ ë“±
- **ì¸í„°ë™í‹°ë¸Œ**: Plotly ê¸°ë°˜ ë™ì  ì°¨íŠ¸
- **ì •ì  ì°¨íŠ¸**: Matplotlib ê¸°ë°˜ ê³ í’ˆì§ˆ ì´ë¯¸ì§€
- **í†µê³„ ì‹œê°í™”**: ë¶„í¬ ë¶„ì„, ìƒê´€ê´€ê³„ ë¶„ì„
- **ëŒ€ì‹œë³´ë“œ**: ë³µí•© ì‹œê°í™” ë ˆì´ì•„ì›ƒ
"""
                
                # ì‘ì—… ì™„ë£Œ
                await task_updater.update_status(
                    TaskState.completed,
                    message=new_agent_text_message(response_text)
                )
                
            else:
                # ë©”ì‹œì§€ê°€ ì—†ëŠ” ê²½ìš°
                await task_updater.update_status(
                    TaskState.completed,
                    message=new_agent_text_message("ì‹œê°í™” ìš”ì²­ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. êµ¬ì²´ì ì¸ ì°¨íŠ¸ë‚˜ ê·¸ë˜í”„ ìš”ì²­ì„ í•´ì£¼ì„¸ìš”.")
                )
                
        except Exception as e:
            logger.error(f"Error in DataWranglingAgent execution: {e}")
            await task_updater.update_status(
                TaskState.failed,
                message=new_agent_text_message(f"ë°ì´í„° ì‹œê°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            )
    
    async def cancel(self, context: RequestContext) -> None:
        """ì‘ì—… ì·¨ì†Œ"""
        logger.info(f"DataWranglingAgent task cancelled: {context.task_id}")


def main():
    """A2A ì„œë²„ ìƒì„± ë° ì‹¤í–‰"""
    
    # AgentSkill ì •ì˜
    skill = AgentSkill(
        id="data-wrangling",
        name="Data Visualization & Chart Creation",
        description="ì „ë¬¸ì ì¸ ë°ì´í„° ì‹œê°í™” ë° ì°¨íŠ¸ ìƒì„± ì„œë¹„ìŠ¤. Plotly, Matplotlibì„ í™œìš©í•˜ì—¬ ì¸í„°ë™í‹°ë¸Œ ë° ì •ì  ì°¨íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.",
        tags=["data-visualization", "plotly", "matplotlib", "charts", "dashboard"],
        examples=[
            "ë§¤ì¶œ ë°ì´í„°ì˜ ì›”ë³„ íŠ¸ë Œë“œë¥¼ ì„  ê·¸ë˜í”„ë¡œ ê·¸ë ¤ì£¼ì„¸ìš”",
            "ê³ ê° ë‚˜ì´ëŒ€ë³„ ë¶„í¬ë¥¼ íˆìŠ¤í† ê·¸ë¨ìœ¼ë¡œ ë³´ì—¬ì£¼ì„¸ìš”",
            "ë³€ìˆ˜ë“¤ ê°„ì˜ ìƒê´€ê´€ê³„ë¥¼ íˆíŠ¸ë§µìœ¼ë¡œ í‘œì‹œí•´ì£¼ì„¸ìš”",
            "ì¹´í…Œê³ ë¦¬ë³„ ë°•ìŠ¤í”Œë¡¯ì„ ìƒì„±í•´ì£¼ì„¸ìš”",
            "ì¸í„°ë™í‹°ë¸Œ ëŒ€ì‹œë³´ë“œë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”"
        ]
    )
    
    # Agent Card ì •ì˜
    agent_card = AgentCard(
        name="AI_DS_Team DataWranglingAgent",
        description="ì „ë¬¸ì ì¸ ë°ì´í„° ì‹œê°í™” ë° ì°¨íŠ¸ ìƒì„± ì„œë¹„ìŠ¤. Plotly, Matplotlibì„ í™œìš©í•˜ì—¬ ì¸í„°ë™í‹°ë¸Œ ë° ì •ì  ì°¨íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.",
        url="http://localhost:8309/",
        version="1.0.0",
        defaultInputModes=["text"],
        defaultOutputModes=["text"],
        capabilities=AgentCapabilities(streaming=False),
        skills=[skill],
        supportsAuthenticatedExtendedCard=False
    )
    
    # Request Handler ìƒì„±
    request_handler = DefaultRequestHandler(
        agent_executor=DataWranglingAgentExecutor(),
        task_store=InMemoryTaskStore(),
    )
    
    # A2A Server ìƒì„±
    server = A2AStarletteApplication(
        agent_card=agent_card,
        http_handler=request_handler,
    )
    
    print("ğŸ“Š Starting AI_DS_Team DataWranglingAgent Server")
    print("ğŸŒ Server starting on http://localhost:8309")
    print("ğŸ“‹ Agent card: http://localhost:8309/.well-known/agent.json")
    print("ğŸ¨ Features: Interactive charts, static plots, dashboards")
    
    uvicorn.run(server.build(), host="0.0.0.0", port=8309, log_level="info")


if __name__ == "__main__":
    main() 