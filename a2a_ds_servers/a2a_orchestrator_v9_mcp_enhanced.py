#!/usr/bin/env python3
"""
A2A Orchestrator v9.0 - MCP Enhanced Universal Intelligent Orchestrator
A2A SDK 0.2.9 í‘œì¤€ + MCP (Model Context Protocol) í†µí•© + ì§€ëŠ¥í˜• ë¼ìš°íŒ…

ğŸ”— ìƒˆë¡œìš´ ê¸°ëŠ¥:
1. MCP ë„êµ¬ í†µí•© - 7ê°œ MCP ë„êµ¬ì™€ A2A ì—ì´ì „íŠ¸ ì—°ë™
2. ì§€ëŠ¥í˜• ë¼ìš°íŒ… - ì‚¬ìš©ì ì˜ë„ ë¶„ì„ ê¸°ë°˜ ìµœì  ë¼ìš°íŒ…
3. ë™ì  ì›Œí¬í”Œë¡œìš° - A2A + MCP í†µí•© ì‹¤í–‰ ê³„íš
4. Context Engineering - 6 Data Layers ì™„ì „ ì§€ì›
5. ì‹¤ì‹œê°„ í˜‘ì—… ëª¨ë‹ˆí„°ë§ - ì—ì´ì „íŠ¸ + MCP ë„êµ¬ ìƒíƒœ ì¶”ì 

Architecture:
- Universal Intelligent Orchestrator (ê¸°ì¡´ v8.0 ê¸°ë°˜)
- MCP Integration Layer (ìƒˆë¡œ ì¶”ê°€)
- Intelligent Intent Analyzer (í–¥ìƒëœ ì˜ë„ ë¶„ì„)
- Enhanced Collaboration Engine (A2A + MCP í†µí•©)
"""

import asyncio
import json
import logging
import os
import re
import time
import uuid
from datetime import datetime
from typing import Any, Dict, List, Optional, AsyncGenerator, Set
from dataclasses import dataclass, asdict

import httpx
import uvicorn
from openai import AsyncOpenAI

# A2A SDK 0.2.9 í‘œì¤€ ì„í¬íŠ¸
from a2a.server.apps import A2AStarletteApplication
from a2a.server.request_handlers import DefaultRequestHandler
from a2a.server.tasks import InMemoryTaskStore, TaskUpdater
from a2a.server.agent_execution import AgentExecutor, RequestContext
from a2a.server.events import EventQueue
from a2a.types import (
    AgentCard,
    AgentSkill,
    AgentCapabilities,
    TaskState,
    TextPart,
    Message,
    Part,
    SendMessageRequest,
    MessageSendParams
)

# A2A í´ë¼ì´ì–¸íŠ¸ ë° ë””ìŠ¤ì»¤ë²„ë¦¬
from a2a.client import A2ACardResolver, A2AClient

# MCP í†µí•© ì„í¬íŠ¸
import sys
sys.path.append(os.path.join(os.path.dirname(__file__), 'tools'))
sys.path.append(os.path.join(os.path.dirname(__file__), 'pandas_agent'))

from mcp_integration import get_mcp_integration, MCPToolType
from pandas_collaboration_hub_enhanced import get_enhanced_collaboration_hub

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# AI DS Team ì—ì´ì „íŠ¸ í¬íŠ¸ ë§¤í•‘ (v9.0 ì—…ë°ì´íŠ¸)
AGENT_PORTS = {
    "data_cleaning": 8306,
    "data_loader": 8307,
    "data_visualization": 8308,
    "data_wrangling": 8309,
    "feature_engineering": 8310,
    "sql_database": 8311,
    "eda_tools": 8312,
    "h2o_ml": 8313,
    "mlflow_tools": 8314,
    "pandas_collaboration_hub": 8315,  # Enhanced í˜‘ì—… í—ˆë¸Œ
}

# MCP ë„êµ¬ í¬íŠ¸ ë§¤í•‘
MCP_TOOL_PORTS = {
    "playwright": 3000,
    "file_manager": 3001,
    "database_connector": 3002,
    "api_gateway": 3003,
    "data_analyzer": 3004,
    "chart_generator": 3005,
    "llm_gateway": 3006,
}

@dataclass
class IntentAnalysisResult:
    """ì˜ë„ ë¶„ì„ ê²°ê³¼"""
    primary_intent: str
    confidence: float
    required_agents: List[str]
    required_mcp_tools: List[str]
    workflow_type: str  # 'simple', 'complex', 'collaborative'
    priority: int
    estimated_complexity: str  # 'low', 'medium', 'high'
    context_requirements: Dict[str, Any]

@dataclass
class EnhancedWorkflowStep:
    """í–¥ìƒëœ ì›Œí¬í”Œë¡œìš° ë‹¨ê³„"""
    step_id: str
    step_type: str  # 'agent', 'mcp_tool', 'collaboration'
    executor: str  # ì—ì´ì „íŠ¸ ID ë˜ëŠ” MCP ë„êµ¬ ID
    action: str
    parameters: Dict[str, Any]
    dependencies: List[str]
    estimated_duration: float
    parallel_execution: bool = False

@dataclass
class CollaborationSession:
    """í˜‘ì—… ì„¸ì…˜ ì •ë³´"""
    session_id: str
    user_request: str
    intent_analysis: IntentAnalysisResult
    workflow_steps: List[EnhancedWorkflowStep]
    active_agents: Set[str]
    active_mcp_tools: Set[str]
    status: str  # 'pending', 'in_progress', 'completed', 'failed'
    created_at: datetime
    updated_at: datetime
    results: Dict[str, Any]

def new_agent_text_message(text: str):
    """ì—ì´ì „íŠ¸ í…ìŠ¤íŠ¸ ë©”ì‹œì§€ ìƒì„±"""
    return Message(
        messageId=str(uuid.uuid4()),
        role="agent",
        parts=[TextPart(text=text)]
    )

class IntelligentIntentAnalyzer:
    """ì§€ëŠ¥í˜• ì˜ë„ ë¶„ì„ê¸° (v9.0 enhanced)"""
    
    def __init__(self, openai_client: Optional[AsyncOpenAI] = None):
        self.openai_client = openai_client
        
        # ì˜ë„ ë¶„ì„ íŒ¨í„´ ë§¤í•‘
        self.intent_patterns = {
            "data_analysis": {
                "keywords": ["ë¶„ì„", "analyze", "íƒìƒ‰", "explore", "í†µê³„", "statistics"],
                "agents": ["pandas_collaboration_hub", "eda_tools", "data_analyzer"],
                "mcp_tools": ["data_analyzer", "chart_generator"]
            },
            "data_loading": {
                "keywords": ["ë¡œë“œ", "load", "ì½ê¸°", "read", "ê°€ì ¸ì˜¤ê¸°", "import"],
                "agents": ["data_loader", "pandas_collaboration_hub"],
                "mcp_tools": ["file_manager", "database_connector", "api_gateway"]
            },
            "data_visualization": {
                "keywords": ["ì‹œê°í™”", "visualization", "ì°¨íŠ¸", "chart", "ê·¸ë˜í”„", "plot"],
                "agents": ["data_visualization", "pandas_collaboration_hub"],
                "mcp_tools": ["chart_generator", "data_analyzer"]
            },
            "web_scraping": {
                "keywords": ["ì›¹", "web", "ìŠ¤í¬ë˜í•‘", "scraping", "í¬ë¡¤ë§", "crawling"],
                "agents": ["data_loader"],
                "mcp_tools": ["playwright", "api_gateway"]
            },
            "machine_learning": {
                "keywords": ["ë¨¸ì‹ ëŸ¬ë‹", "machine learning", "ml", "ëª¨ë¸", "model", "ì˜ˆì¸¡"],
                "agents": ["h2o_ml", "feature_engineering", "mlflow_tools"],
                "mcp_tools": ["data_analyzer", "llm_gateway"]
            },
            "data_cleaning": {
                "keywords": ["ì •ë¦¬", "clean", "ì „ì²˜ë¦¬", "preprocessing", "ì •ì œ"],
                "agents": ["data_cleaning", "data_wrangling"],
                "mcp_tools": ["data_analyzer", "file_manager"]
            },
            "comprehensive_analysis": {
                "keywords": ["ì¢…í•©", "comprehensive", "ì „ì²´", "complete", "ëª¨ë“ "],
                "agents": ["pandas_collaboration_hub", "eda_tools", "data_visualization"],
                "mcp_tools": ["data_analyzer", "chart_generator", "llm_gateway"]
            }
        }
    
    async def analyze_intent(self, user_request: str, context: Dict[str, Any] = None) -> IntentAnalysisResult:
        """ì‚¬ìš©ì ìš”ì²­ì˜ ì˜ë„ ë¶„ì„"""
        logger.info(f"ğŸ§  ì˜ë„ ë¶„ì„ ì‹œì‘: {user_request}")
        
        # í‚¤ì›Œë“œ ê¸°ë°˜ ê¸°ë³¸ ë¶„ì„
        intent_scores = {}
        for intent, config in self.intent_patterns.items():
            score = self._calculate_keyword_score(user_request, config["keywords"])
            if score > 0:
                intent_scores[intent] = score
        
        # ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ ì˜ë„ ì„ íƒ
        if intent_scores:
            primary_intent = max(intent_scores, key=intent_scores.get)
            confidence = intent_scores[primary_intent]
        else:
            primary_intent = "comprehensive_analysis"
            confidence = 0.5
        
        # LLM ê¸°ë°˜ ê³ ê¸‰ ë¶„ì„ (OpenAI ì‚¬ìš© ê°€ëŠ¥ì‹œ)
        if self.openai_client:
            try:
                enhanced_analysis = await self._llm_enhanced_analysis(user_request, primary_intent, context)
                if enhanced_analysis:
                    primary_intent = enhanced_analysis.get("intent", primary_intent)
                    confidence = enhanced_analysis.get("confidence", confidence)
            except Exception as e:
                logger.warning(f"LLM ë¶„ì„ ì‹¤íŒ¨: {e}")
        
        # í•„ìš”í•œ ì—ì´ì „íŠ¸ ë° MCP ë„êµ¬ ê²°ì •
        intent_config = self.intent_patterns.get(primary_intent, self.intent_patterns["comprehensive_analysis"])
        required_agents = intent_config["agents"]
        required_mcp_tools = intent_config["mcp_tools"]
        
        # ì›Œí¬í”Œë¡œìš° íƒ€ì… ê²°ì •
        workflow_type = self._determine_workflow_type(required_agents, required_mcp_tools)
        
        # ë³µì¡ì„± ì¶”ì •
        complexity = self._estimate_complexity(user_request, required_agents, required_mcp_tools)
        
        result = IntentAnalysisResult(
            primary_intent=primary_intent,
            confidence=confidence,
            required_agents=required_agents,
            required_mcp_tools=required_mcp_tools,
            workflow_type=workflow_type,
            priority=self._calculate_priority(confidence, complexity),
            estimated_complexity=complexity,
            context_requirements=context or {}
        )
        
        logger.info(f"âœ… ì˜ë„ ë¶„ì„ ì™„ë£Œ: {primary_intent} (ì‹ ë¢°ë„: {confidence:.2f})")
        return result
    
    def _calculate_keyword_score(self, text: str, keywords: List[str]) -> float:
        """í‚¤ì›Œë“œ ê¸°ë°˜ ì ìˆ˜ ê³„ì‚°"""
        text_lower = text.lower()
        matches = sum(1 for keyword in keywords if keyword in text_lower)
        return matches / len(keywords) if keywords else 0
    
    async def _llm_enhanced_analysis(self, user_request: str, basic_intent: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """LLM ê¸°ë°˜ í–¥ìƒëœ ì˜ë„ ë¶„ì„"""
        if not self.openai_client:
            return {}
        
        prompt = f"""
        ì‚¬ìš©ì ìš”ì²­ì„ ë¶„ì„í•˜ì—¬ ìµœì ì˜ ì˜ë„ì™€ ì‹¤í–‰ ì „ëµì„ ì œì•ˆí•´ì£¼ì„¸ìš”.
        
        ìš”ì²­: {user_request}
        ê¸°ë³¸ ì˜ë„: {basic_intent}
        ì»¨í…ìŠ¤íŠ¸: {json.dumps(context, ensure_ascii=False)}
        
        ë‹¤ìŒ ì˜ë„ ì¤‘ì—ì„œ ê°€ì¥ ì í•©í•œ ê²ƒì„ ì„ íƒí•˜ê³  ë¶„ì„í•´ì£¼ì„¸ìš”:
        - data_analysis: ë°ì´í„° ë¶„ì„ ë° íƒìƒ‰
        - data_loading: ë°ì´í„° ë¡œë”© ë° ê°€ì ¸ì˜¤ê¸°
        - data_visualization: ë°ì´í„° ì‹œê°í™”
        - web_scraping: ì›¹ ë°ì´í„° ìˆ˜ì§‘
        - machine_learning: ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ë§
        - data_cleaning: ë°ì´í„° ì •ë¦¬ ë° ì „ì²˜ë¦¬
        - comprehensive_analysis: ì¢…í•©ì  ë¶„ì„
        
        ì‘ë‹µ í˜•ì‹:
        {{
            "intent": "ì„ íƒëœ_ì˜ë„",
            "confidence": 0.0-1.0,
            "reasoning": "ì„ íƒ ê·¼ê±°",
            "additional_requirements": ["ì¶”ê°€ ìš”êµ¬ì‚¬í•­ë“¤"]
        }}
        """
        
        try:
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=300,
                temperature=0.3
            )
            
            result = json.loads(response.choices[0].message.content)
            return result
        except Exception as e:
            logger.error(f"LLM ë¶„ì„ ì˜¤ë¥˜: {e}")
            return {}
    
    def _determine_workflow_type(self, required_agents: List[str], required_mcp_tools: List[str]) -> str:
        """ì›Œí¬í”Œë¡œìš° íƒ€ì… ê²°ì •"""
        total_components = len(required_agents) + len(required_mcp_tools)
        
        if total_components <= 2:
            return "simple"
        elif total_components <= 4:
            return "complex"
        else:
            return "collaborative"
    
    def _estimate_complexity(self, user_request: str, required_agents: List[str], required_mcp_tools: List[str]) -> str:
        """ë³µì¡ì„± ì¶”ì •"""
        complexity_indicators = ["ì¢…í•©", "ì „ì²´", "ëª¨ë“ ", "ë³µì¡í•œ", "ê³ ê¸‰", "ìƒì„¸í•œ"]
        
        has_complexity_keywords = any(keyword in user_request for keyword in complexity_indicators)
        total_components = len(required_agents) + len(required_mcp_tools)
        
        if has_complexity_keywords or total_components > 5:
            return "high"
        elif total_components > 3:
            return "medium"
        else:
            return "low"
    
    def _calculate_priority(self, confidence: float, complexity: str) -> int:
        """ìš°ì„ ìˆœìœ„ ê³„ì‚°"""
        base_priority = int(confidence * 10)
        
        if complexity == "high":
            return min(base_priority + 3, 10)
        elif complexity == "medium":
            return min(base_priority + 1, 10)
        else:
            return base_priority

class MCPEnhancedAgentDiscovery:
    """MCP í†µí•© ì—ì´ì „íŠ¸ ë°œê²¬ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.mcp_integration = get_mcp_integration()
        self.last_discovery = None
        self.discovery_cache = {}
    
    async def discover_all_resources(self) -> Dict[str, Any]:
        """A2A ì—ì´ì „íŠ¸ì™€ MCP ë„êµ¬ ëª¨ë‘ ë°œê²¬"""
        logger.info("ğŸ” Enhanced ë¦¬ì†ŒìŠ¤ ë°œê²¬ ì‹œì‘ (A2A + MCP)")
        
        # ë³‘ë ¬ë¡œ A2A ì—ì´ì „íŠ¸ì™€ MCP ë„êµ¬ ë°œê²¬
        a2a_discovery_task = asyncio.create_task(self._discover_a2a_agents())
        mcp_discovery_task = asyncio.create_task(self._discover_mcp_tools())
        
        a2a_agents, mcp_tools = await asyncio.gather(a2a_discovery_task, mcp_discovery_task)
        
        discovery_result = {
            "a2a_agents": a2a_agents,
            "mcp_tools": mcp_tools,
            "total_a2a_agents": len(a2a_agents),
            "total_mcp_tools": len(mcp_tools),
            "total_resources": len(a2a_agents) + len(mcp_tools),
            "discovery_time": datetime.now().isoformat(),
            "integration_status": "enhanced" if len(a2a_agents) > 0 and len(mcp_tools) > 0 else "partial"
        }
        
        self.last_discovery = discovery_result
        logger.info(f"âœ… Enhanced ë¦¬ì†ŒìŠ¤ ë°œê²¬ ì™„ë£Œ: {discovery_result['total_a2a_agents']}ê°œ A2A ì—ì´ì „íŠ¸ + {discovery_result['total_mcp_tools']}ê°œ MCP ë„êµ¬")
        
        return discovery_result
    
    async def _discover_a2a_agents(self) -> Dict[str, Any]:
        """A2A ì—ì´ì „íŠ¸ ë°œê²¬"""
        agents = {}
        
        for agent_id, port in AGENT_PORTS.items():
            try:
                url = f"http://localhost:{port}"
                
                # Agent Card í™•ì¸
                async with httpx.AsyncClient(timeout=5.0) as client:
                    response = await client.get(f"{url}/.well-known/agent.json")
                    if response.status_code == 200:
                        agent_card = response.json()
                        agents[agent_id] = {
                            "id": agent_id,
                            "name": agent_card.get("name", f"Agent {agent_id}"),
                            "url": url,
                            "port": port,
                            "description": agent_card.get("description", ""),
                            "capabilities": agent_card.get("capabilities", {}),
                            "skills": agent_card.get("skills", []),
                            "status": "available",
                            "type": "a2a_agent"
                        }
                        logger.info(f"âœ… A2A ì—ì´ì „íŠ¸ ë°œê²¬: {agent_id} ({url})")
                    else:
                        logger.warning(f"âš ï¸ A2A ì—ì´ì „íŠ¸ ì‘ë‹µ ì—†ìŒ: {agent_id} ({url})")
                        
            except Exception as e:
                logger.warning(f"âŒ A2A ì—ì´ì „íŠ¸ ì—°ê²° ì‹¤íŒ¨: {agent_id} - {e}")
        
        return agents
    
    async def _discover_mcp_tools(self) -> Dict[str, Any]:
        """MCP ë„êµ¬ ë°œê²¬"""
        try:
            mcp_discovery_result = await self.mcp_integration.initialize_mcp_tools()
            
            # MCP ë„êµ¬ ì •ë³´ë¥¼ í†µì¼ëœ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            mcp_tools = {}
            for tool_id, tool_info in mcp_discovery_result.get("tool_details", {}).items():
                mcp_tools[tool_id] = {
                    "id": tool_id,
                    "name": tool_info.get("name", tool_id),
                    "type": "mcp_tool",
                    "tool_type": tool_info.get("type", "unknown"),
                    "capabilities": tool_info.get("capabilities", []),
                    "status": tool_info.get("status", "unknown"),
                    "port": MCP_TOOL_PORTS.get(tool_id, 3000)
                }
            
            return mcp_tools
            
        except Exception as e:
            logger.error(f"âŒ MCP ë„êµ¬ ë°œê²¬ ì‹¤íŒ¨: {e}")
            return {}

class EnhancedCollaborationEngine:
    """í–¥ìƒëœ í˜‘ì—… ì—”ì§„ (A2A + MCP í†µí•©)"""
    
    def __init__(self, openai_client: Optional[AsyncOpenAI] = None):
        self.openai_client = openai_client
        self.collaboration_hub = get_enhanced_collaboration_hub()
        self.mcp_integration = get_mcp_integration()
        
        # í™œì„± ì„¸ì…˜ ê´€ë¦¬
        self.active_sessions: Dict[str, CollaborationSession] = {}
        
    async def create_collaboration_session(self, user_request: str, intent_analysis: IntentAnalysisResult) -> CollaborationSession:
        """í˜‘ì—… ì„¸ì…˜ ìƒì„±"""
        session_id = f"collab_{uuid.uuid4().hex[:12]}"
        
        logger.info(f"ğŸš€ í˜‘ì—… ì„¸ì…˜ ìƒì„±: {session_id}")
        
        # ì›Œí¬í”Œë¡œìš° ë‹¨ê³„ ìƒì„±
        workflow_steps = await self._generate_workflow_steps(user_request, intent_analysis)
        
        session = CollaborationSession(
            session_id=session_id,
            user_request=user_request,
            intent_analysis=intent_analysis,
            workflow_steps=workflow_steps,
            active_agents=set(intent_analysis.required_agents),
            active_mcp_tools=set(intent_analysis.required_mcp_tools),
            status="pending",
            created_at=datetime.now(),
            updated_at=datetime.now(),
            results={}
        )
        
        self.active_sessions[session_id] = session
        
        logger.info(f"âœ… í˜‘ì—… ì„¸ì…˜ ìƒì„± ì™„ë£Œ: {session_id} ({len(workflow_steps)}ê°œ ë‹¨ê³„)")
        return session
    
    async def _generate_workflow_steps(self, user_request: str, intent_analysis: IntentAnalysisResult) -> List[EnhancedWorkflowStep]:
        """ì›Œí¬í”Œë¡œìš° ë‹¨ê³„ ìƒì„±"""
        steps = []
        
        # 1ë‹¨ê³„: MCP ë„êµ¬ ì‚¬ì „ ì‹¤í–‰ (ë°ì´í„° ìˆ˜ì§‘, ë¶„ì„ ì¤€ë¹„)
        if intent_analysis.required_mcp_tools:
            for i, tool_id in enumerate(intent_analysis.required_mcp_tools):
                action = self._determine_mcp_action(tool_id, user_request)
                step = EnhancedWorkflowStep(
                    step_id=f"mcp_{i+1}_{tool_id}",
                    step_type="mcp_tool",
                    executor=tool_id,
                    action=action,
                    parameters=self._generate_mcp_parameters(tool_id, action, user_request),
                    dependencies=[],
                    estimated_duration=2.0,
                    parallel_execution=True
                )
                steps.append(step)
        
        # 2ë‹¨ê³„: A2A ì—ì´ì „íŠ¸ ì‹¤í–‰ (MCP ê²°ê³¼ í™œìš©)
        if intent_analysis.required_agents:
            mcp_dependencies = [step.step_id for step in steps if step.step_type == "mcp_tool"]
            
            for i, agent_id in enumerate(intent_analysis.required_agents):
                step = EnhancedWorkflowStep(
                    step_id=f"agent_{i+1}_{agent_id}",
                    step_type="agent",
                    executor=agent_id,
                    action="analyze_with_mcp_results",
                    parameters={"request": user_request, "mcp_enhanced": True},
                    dependencies=mcp_dependencies,
                    estimated_duration=5.0,
                    parallel_execution=agent_id != "pandas_collaboration_hub"  # í—ˆë¸ŒëŠ” ì¡°ì • ì—­í• 
                )
                steps.append(step)
        
        # 3ë‹¨ê³„: ê²°ê³¼ í†µí•© (í˜‘ì—… í—ˆë¸Œê°€ ë‹´ë‹¹)
        if len(steps) > 1:
            integration_step = EnhancedWorkflowStep(
                step_id="integration_final",
                step_type="collaboration",
                executor="pandas_collaboration_hub",
                action="integrate_results",
                parameters={"session_type": "mcp_enhanced"},
                dependencies=[step.step_id for step in steps],
                estimated_duration=3.0,
                parallel_execution=False
            )
            steps.append(integration_step)
        
        return steps
    
    def _determine_mcp_action(self, tool_id: str, user_request: str) -> str:
        """MCP ë„êµ¬ë³„ ì•¡ì…˜ ê²°ì •"""
        action_mapping = {
            "playwright": "extract_data" if "ë°ì´í„°" in user_request else "navigate",
            "file_manager": "read_file" if "ì½ê¸°" in user_request else "list_directory",
            "database_connector": "execute_query",
            "api_gateway": "http_request",
            "data_analyzer": "statistical_analysis",
            "chart_generator": "create_chart",
            "llm_gateway": "generate_text"
        }
        
        return action_mapping.get(tool_id, "default_action")
    
    def _generate_mcp_parameters(self, tool_id: str, action: str, user_request: str) -> Dict[str, Any]:
        """MCP ë„êµ¬ ë§¤ê°œë³€ìˆ˜ ìƒì„±"""
        # ê¸°ë³¸ ë§¤ê°œë³€ìˆ˜ (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë” ì •êµí•˜ê²Œ)
        base_params = {
            "user_request": user_request,
            "timestamp": datetime.now().isoformat()
        }
        
        # ë„êµ¬ë³„ íŠ¹í™” ë§¤ê°œë³€ìˆ˜
        if tool_id == "playwright":
            base_params["url"] = "https://example.com"
        elif tool_id == "data_analyzer":
            base_params["analysis_type"] = "comprehensive"
        elif tool_id == "chart_generator":
            base_params["chart_type"] = "auto"
        
        return base_params
    
    async def execute_collaboration_session(self, session: CollaborationSession, task_updater: TaskUpdater) -> Dict[str, Any]:
        """í˜‘ì—… ì„¸ì…˜ ì‹¤í–‰"""
        logger.info(f"âš¡ í˜‘ì—… ì„¸ì…˜ ì‹¤í–‰ ì‹œì‘: {session.session_id}")
        
        session.status = "in_progress"
        session.updated_at = datetime.now()
        
        execution_results = {
            "session_id": session.session_id,
            "mcp_results": {},
            "agent_results": {},
            "integration_result": None,
            "execution_timeline": []
        }
        
        try:
            # ì›Œí¬í”Œë¡œìš° ë‹¨ê³„ë³„ ì‹¤í–‰
            for step in session.workflow_steps:
                step_start = time.time()
                
                await task_updater.update_status(
                    TaskState.working,
                    message=task_updater.new_agent_message(parts=[TextPart(text=f"ğŸ”„ ì‹¤í–‰ ì¤‘: {step.step_type} - {step.executor}")])
                )
                
                if step.step_type == "mcp_tool":
                    # MCP ë„êµ¬ ì‹¤í–‰
                    result = await self._execute_mcp_step(step, session)
                    execution_results["mcp_results"][step.step_id] = result
                    
                elif step.step_type == "agent":
                    # A2A ì—ì´ì „íŠ¸ ì‹¤í–‰
                    result = await self._execute_agent_step(step, session, execution_results["mcp_results"])
                    execution_results["agent_results"][step.step_id] = result
                    
                elif step.step_type == "collaboration":
                    # í˜‘ì—… í†µí•©
                    result = await self._execute_collaboration_step(step, session, execution_results)
                    execution_results["integration_result"] = result
                
                step_duration = time.time() - step_start
                execution_results["execution_timeline"].append({
                    "step_id": step.step_id,
                    "duration": step_duration,
                    "status": "completed"
                })
                
                logger.info(f"âœ… ë‹¨ê³„ ì™„ë£Œ: {step.step_id} ({step_duration:.2f}ì´ˆ)")
            
            session.status = "completed"
            session.results = execution_results
            
        except Exception as e:
            logger.error(f"âŒ í˜‘ì—… ì„¸ì…˜ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            session.status = "failed"
            execution_results["error"] = str(e)
        
        session.updated_at = datetime.now()
        
        return execution_results
    
    async def _execute_mcp_step(self, step: EnhancedWorkflowStep, session: CollaborationSession) -> Dict[str, Any]:
        """MCP ë„êµ¬ ë‹¨ê³„ ì‹¤í–‰"""
        logger.info(f"ğŸ”§ MCP ë„êµ¬ ì‹¤í–‰: {step.executor}.{step.action}")
        
        # MCP ì„¸ì…˜ ìƒì„± (í•„ìš”ì‹œ)
        mcp_session = await self.mcp_integration.create_mcp_session(
            agent_id=f"orchestrator_{session.session_id}",
            required_tools=[step.executor]
        )
        
        # MCP ë„êµ¬ í˜¸ì¶œ
        result = await self.mcp_integration.call_mcp_tool(
            session_id=mcp_session.session_id,
            tool_id=step.executor,
            action=step.action,
            parameters=step.parameters
        )
        
        return result
    
    async def _execute_agent_step(self, step: EnhancedWorkflowStep, session: CollaborationSession, mcp_results: Dict[str, Any]) -> Dict[str, Any]:
        """A2A ì—ì´ì „íŠ¸ ë‹¨ê³„ ì‹¤í–‰"""
        logger.info(f"ğŸ¤– A2A ì—ì´ì „íŠ¸ ì‹¤í–‰: {step.executor}")
        
        # MCP ê²°ê³¼ë¥¼ í¬í•¨í•œ í–¥ìƒëœ ìš”ì²­ ìƒì„±
        enhanced_request = self._create_enhanced_request(session.user_request, mcp_results)
        
        # A2A ì—ì´ì „íŠ¸ í˜¸ì¶œ (ê°„ë‹¨í•œ Mock êµ¬í˜„)
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” A2A í´ë¼ì´ì–¸íŠ¸ë¡œ ì‹¤ì œ í˜¸ì¶œ
        result = {
            "agent_id": step.executor,
            "status": "completed",
            "response": f"Mock response from {step.executor} with MCP enhancement",
            "processing_time": 2.0,
            "mcp_enhanced": True
        }
        
        return result
    
    async def _execute_collaboration_step(self, step: EnhancedWorkflowStep, session: CollaborationSession, execution_results: Dict[str, Any]) -> Dict[str, Any]:
        """í˜‘ì—… í†µí•© ë‹¨ê³„ ì‹¤í–‰"""
        logger.info(f"ğŸ¤ í˜‘ì—… í†µí•© ì‹¤í–‰: {step.executor}")
        
        # ëª¨ë“  ê²°ê³¼ë¥¼ í†µí•©
        integrated_result = {
            "session_id": session.session_id,
            "integration_type": "mcp_enhanced_collaboration",
            "mcp_contributions": len(execution_results["mcp_results"]),
            "agent_contributions": len(execution_results["agent_results"]),
            "final_summary": f"Enhanced collaboration completed with {len(session.active_mcp_tools)} MCP tools and {len(session.active_agents)} A2A agents",
            "timestamp": datetime.now().isoformat()
        }
        
        return integrated_result
    
    def _create_enhanced_request(self, original_request: str, mcp_results: Dict[str, Any]) -> str:
        """MCP ê²°ê³¼ë¥¼ í¬í•¨í•œ í–¥ìƒëœ ìš”ì²­ ìƒì„±"""
        enhanced_request = f"{original_request}\n\n--- MCP ë„êµ¬ ë¶„ì„ ê²°ê³¼ ---\n"
        
        for step_id, result in mcp_results.items():
            if result.get("success"):
                enhanced_request += f"ğŸ”§ {step_id}: {result.get('result', {})}\n"
            else:
                enhanced_request += f"âš ï¸ {step_id}: ì‹¤í–‰ ì‹¤íŒ¨\n"
        
        enhanced_request += "\nìœ„ MCP ë„êµ¬ ê²°ê³¼ë¥¼ ì°¸ê³ í•˜ì—¬ ë¶„ì„ì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”."
        
        return enhanced_request

class UniversalIntelligentOrchestratorV9(AgentExecutor):
    """v9.0 - MCP Enhanced Universal Intelligent Orchestrator"""
    
    def __init__(self):
        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        try:
            api_key = os.getenv("OPENAI_API_KEY")
            if api_key and api_key.strip():
                self.openai_client = AsyncOpenAI(api_key=api_key)
                logger.info("ğŸ¤– Universal Intelligent Orchestrator v9.0 with LLM + MCP")
            else:
                self.openai_client = None
                logger.info("ğŸ“Š Universal Orchestrator v9.0 with MCP (No LLM)")
        except Exception as e:
            logger.warning(f"OpenAI client initialization failed: {e}")
            self.openai_client = None
        
        # v9.0 í•µì‹¬ ì»´í¬ë„ŒíŠ¸
        self.intent_analyzer = IntelligentIntentAnalyzer(self.openai_client)
        self.resource_discovery = MCPEnhancedAgentDiscovery()
        self.collaboration_engine = EnhancedCollaborationEngine(self.openai_client)
        
        # ìƒíƒœ ê´€ë¦¬
        self.available_resources = {}
        self.active_sessions = {}
        self.performance_metrics = {}
        
        # ì´ˆê¸°í™” ì™„ë£Œ
        logger.info("ğŸš€ Universal Intelligent Orchestrator v9.0 (MCP Enhanced) ì´ˆê¸°í™” ì™„ë£Œ")
    
    async def execute(self, context: RequestContext, event_queue: EventQueue) -> None:
        """v9.0 Enhanced ì‹¤í–‰ - MCP í†µí•© + ì§€ëŠ¥í˜• ë¼ìš°íŒ…"""
        task_updater = TaskUpdater(event_queue, context.task_id, context.context_id)
        
        try:
            await task_updater.submit()
            await task_updater.start_work()
            
            # ì‚¬ìš©ì ìš”ì²­ ì¶”ì¶œ
            user_request = self._extract_user_request(context)
            if not user_request:
                await task_updater.update_status(
                    TaskState.failed,
                    message=task_updater.new_agent_message(parts=[TextPart(text="âŒ ì‚¬ìš©ì ìš”ì²­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")])
                )
                return
            
            logger.info(f"ğŸ“¥ v9.0 ì²˜ë¦¬ ì‹œì‘: {user_request}")
            
            # 1ë‹¨ê³„: ë¦¬ì†ŒìŠ¤ ë°œê²¬ (A2A + MCP)
            await task_updater.update_status(
                TaskState.working,
                message=task_updater.new_agent_message(parts=[TextPart(text="ğŸ” Enhanced ë¦¬ì†ŒìŠ¤ ë°œê²¬ ì¤‘ (A2A ì—ì´ì „íŠ¸ + MCP ë„êµ¬)...")])
            )
            
            self.available_resources = await self.resource_discovery.discover_all_resources()
            
            if self.available_resources["total_resources"] == 0:
                await task_updater.update_status(
                    TaskState.failed,
                    message=task_updater.new_agent_message(parts=[TextPart(text="âŒ ì‚¬ìš© ê°€ëŠ¥í•œ ë¦¬ì†ŒìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")])
                )
                return
            
            # 2ë‹¨ê³„: ì˜ë„ ë¶„ì„
            await task_updater.update_status(
                TaskState.working,
                message=task_updater.new_agent_message(parts=[TextPart(text="ğŸ§  ì§€ëŠ¥í˜• ì˜ë„ ë¶„ì„ ì¤‘...")])
            )
            
            intent_analysis = await self.intent_analyzer.analyze_intent(
                user_request, 
                {"available_resources": self.available_resources}
            )
            
            # 3ë‹¨ê³„: í˜‘ì—… ì„¸ì…˜ ìƒì„±
            await task_updater.update_status(
                TaskState.working,
                message=task_updater.new_agent_message(parts=[TextPart(text="ğŸš€ Enhanced í˜‘ì—… ì„¸ì…˜ ìƒì„± ì¤‘...")])
            )
            
            collaboration_session = await self.collaboration_engine.create_collaboration_session(
                user_request, intent_analysis
            )
            
            # 4ë‹¨ê³„: í˜‘ì—… ì‹¤í–‰
            await task_updater.update_status(
                TaskState.working,
                message=task_updater.new_agent_message(parts=[TextPart(text="âš¡ MCP Enhanced í˜‘ì—… ì‹¤í–‰ ì¤‘...")])
            )
            
            execution_results = await self.collaboration_engine.execute_collaboration_session(
                collaboration_session, task_updater
            )
            
            # 5ë‹¨ê³„: ìµœì¢… ê²°ê³¼ ìƒì„±
            final_response = self._generate_final_response(
                user_request, intent_analysis, execution_results, collaboration_session
            )
            
            await task_updater.update_status(
                TaskState.completed,
                message=task_updater.new_agent_message(parts=[TextPart(text=final_response)])
            )
            
            logger.info(f"âœ… v9.0 ì²˜ë¦¬ ì™„ë£Œ: {collaboration_session.session_id}")
            
        except Exception as e:
            logger.error(f"âŒ v9.0 ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            await task_updater.update_status(
                TaskState.failed,
                message=task_updater.new_agent_message(parts=[TextPart(text=f"âŒ ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}")])
            )
    
    def _extract_user_request(self, context: RequestContext) -> str:
        """ì‚¬ìš©ì ìš”ì²­ ì¶”ì¶œ"""
        if not context.message or not context.message.parts:
            return ""
        
        user_request = ""
        for part in context.message.parts:
            if hasattr(part, 'root') and hasattr(part.root, 'text'):
                user_request += part.root.text + " "
            elif hasattr(part, 'text'):
                user_request += part.text + " "
        
        return user_request.strip()
    
    def _generate_final_response(self, user_request: str, intent_analysis: IntentAnalysisResult, 
                               execution_results: Dict[str, Any], session: CollaborationSession) -> str:
        """ìµœì¢… ì‘ë‹µ ìƒì„±"""
        response = f"""ğŸŒŸ **A2A v9.0 MCP Enhanced í˜‘ì—… ì™„ë£Œ**

**ìš”ì²­**: {user_request}

**ğŸ§  ì˜ë„ ë¶„ì„ ê²°ê³¼**:
- ì£¼ìš” ì˜ë„: {intent_analysis.primary_intent}
- ì‹ ë¢°ë„: {intent_analysis.confidence:.2f}
- ì›Œí¬í”Œë¡œìš° íƒ€ì…: {intent_analysis.workflow_type}
- ë³µì¡ì„±: {intent_analysis.estimated_complexity}

**ğŸ”— í™œìš©ëœ ë¦¬ì†ŒìŠ¤**:
- A2A ì—ì´ì „íŠ¸: {len(session.active_agents)}ê°œ ({', '.join(session.active_agents)})
- MCP ë„êµ¬: {len(session.active_mcp_tools)}ê°œ ({', '.join(session.active_mcp_tools)})

**âš¡ ì‹¤í–‰ ê²°ê³¼**:
- MCP ë„êµ¬ ê²°ê³¼: {len(execution_results['mcp_results'])}ê°œ ì™„ë£Œ
- A2A ì—ì´ì „íŠ¸ ê²°ê³¼: {len(execution_results['agent_results'])}ê°œ ì™„ë£Œ
- ì´ ì‹¤í–‰ ì‹œê°„: {sum(step['duration'] for step in execution_results['execution_timeline']):.2f}ì´ˆ

**ğŸ¯ Enhanced í˜‘ì—… íŠ¹ì§•**:
- Context Engineering 6 Data Layers í™œìš©
- ì§€ëŠ¥í˜• ì˜ë„ ë¶„ì„ ê¸°ë°˜ ë¼ìš°íŒ…
- MCP ë„êµ¬ì™€ A2A ì—ì´ì „íŠ¸ ì™„ì „ í†µí•©
- ì‹¤ì‹œê°„ í˜‘ì—… ëª¨ë‹ˆí„°ë§

**ì„¸ì…˜ ID**: {session.session_id}
**ì™„ë£Œ ì‹œê°„**: {session.updated_at.strftime('%Y-%m-%d %H:%M:%S')}

ğŸš€ **A2A v9.0 + MCP í†µí•©**ìœ¼ë¡œ ê°•ë ¥í•œ ë©€í‹°ì—ì´ì „íŠ¸ í˜‘ì—…ì„ ê²½í—˜í•˜ì„¸ìš”!
"""
        
        return response
    
    async def cancel(self, context: RequestContext) -> None:
        """ì‹¤í–‰ ì·¨ì†Œ ì²˜ë¦¬"""
        logger.info(f"ğŸ›‘ ì‘ì—… ì·¨ì†Œ: {context.task_id}")

def create_agent_card() -> AgentCard:
    """A2A Agent Card ìƒì„±"""
    skill = AgentSkill(
        id="universal_mcp_orchestration",
        name="Universal MCP Enhanced Orchestration",
        description="A2A ì—ì´ì „íŠ¸ì™€ MCP ë„êµ¬ë¥¼ í†µí•©í•œ ì§€ëŠ¥í˜• ë©€í‹°ì—ì´ì „íŠ¸ í˜‘ì—… ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜",
        tags=["orchestration", "mcp", "a2a", "collaboration", "intelligent-routing"],
        examples=[
            "ë°ì´í„°ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”",
            "ì›¹ì—ì„œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³  ì‹œê°í™”í•´ì£¼ì„¸ìš”", 
            "íŒŒì¼ì„ ì½ê³  ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”",
            "ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ ë¶„ì„í•˜ê³  ì°¨íŠ¸ë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”"
        ]
    )
    
    return AgentCard(
        name="Universal Intelligent Orchestrator v9.0",
        description="A2A ì—ì´ì „íŠ¸ì™€ MCP ë„êµ¬ë¥¼ í†µí•©í•œ ì§€ëŠ¥í˜• ë©€í‹°ì—ì´ì „íŠ¸ í˜‘ì—… ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°. Context Engineering 6 Data Layers ì§€ì›, ì˜ë„ ë¶„ì„ ê¸°ë°˜ ë¼ìš°íŒ…, ì‹¤ì‹œê°„ í˜‘ì—… ëª¨ë‹ˆí„°ë§ ì œê³µ.",
        url="http://localhost:8100/",
        version="9.0.0",
        defaultInputModes=["text"],
        defaultOutputModes=["text"],
        capabilities=AgentCapabilities(streaming=True),
        skills=[skill],
        supportsAuthenticatedExtendedCard=False
    )

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # A2A ì„œë²„ ì„¤ì •
    task_store = InMemoryTaskStore()
    event_queue = EventQueue()
    
    # v9.0 ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ìƒì„±
    orchestrator = UniversalIntelligentOrchestratorV9()
    
    # ìš”ì²­ í•¸ë“¤ëŸ¬ ì„¤ì •
    request_handler = DefaultRequestHandler(
        agent_executor=orchestrator,
        task_store=task_store,
        event_queue=event_queue
    )
    
    # A2A ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒì„±
    app = A2AStarletteApplication(
        agent_card=create_agent_card(),
        request_handler=request_handler
    )
    
    print("ğŸŒŸ A2A Orchestrator v9.0 - MCP Enhanced Universal Intelligent Orchestrator")
    print("ğŸ”— Features: A2A + MCP Integration, Intelligent Routing, Context Engineering")
    print("ğŸŒ Server: http://localhost:8100")
    print("ğŸ“‹ Agent Card: http://localhost:8100/.well-known/agent.json")
    print("ğŸš€ Ready for enhanced multi-agent collaboration!")
    
    # ì„œë²„ ì‹¤í–‰
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8100,
        log_level="info"
    )

if __name__ == "__main__":
    main() 