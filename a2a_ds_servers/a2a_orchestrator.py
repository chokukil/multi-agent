#!/usr/bin/env python3
"""
A2A Orchestrator v8.0 - Universal Intelligent Orchestrator
A2A SDK 0.2.9 í‘œì¤€ ê¸°ëŠ¥ ê·¹ëŒ€í™” + ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° í˜ì‹ 
"""

import asyncio
import json
import logging
import os
import re
import time
from datetime import datetime
from typing import Any, Dict, List, Optional, AsyncGenerator, Set

import httpx
import uvicorn
from openai import AsyncOpenAI

# A2A SDK 0.2.9 í‘œì¤€ ì„í¬íŠ¸
from a2a.server.apps import A2AStarletteApplication
from a2a.server.request_handlers import DefaultRequestHandler
from a2a.server.tasks import InMemoryTaskStore, TaskUpdater
from a2a.server.agent_execution import AgentExecutor, RequestContext
from a2a.server.events import EventQueue
from a2a.types import (
    AgentCard,
    AgentSkill,
    AgentCapabilities,
    TaskState,
    TextPart,
    Message,
    Part,
    SendMessageRequest,
    MessageSendParams
)

# A2A í´ë¼ì´ì–¸íŠ¸ ë° ë””ìŠ¤ì»¤ë²„ë¦¬
from a2a.client import A2ACardResolver, A2AClient

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class RealTimeStreamingTaskUpdater(TaskUpdater):
    """ì‹¤ì‹œê°„ ë¬¸ì ë‹¨ìœ„ ìŠ¤íŠ¸ë¦¬ë°ì„ ì§€ì›í•˜ëŠ” í–¥ìƒëœ TaskUpdater"""
    
    def __init__(self, event_queue: EventQueue, task_id: str, context_id: str):
        super().__init__(event_queue, task_id, context_id)
        self._buffer = ""
        self._last_update_time = 0
        self._min_update_interval = 0.05  # 50ms ìµœì†Œ ê°„ê²©
    
    async def stream_character(self, char: str):
        """ë‹¨ì¼ ë¬¸ì ìŠ¤íŠ¸ë¦¬ë° (ë²„í¼ë§ í¬í•¨)"""
        self._buffer += char
        current_time = time.time()
        
        # ìµœì†Œ ê°„ê²©ì´ ì§€ë‚¬ê±°ë‚˜ íŠ¹ì • ë¬¸ìì¸ ê²½ìš° ì¦‰ì‹œ ì „ì†¡
        if (current_time - self._last_update_time >= self._min_update_interval or
            char in ['\n', '.', '!', '?', ':', ';']):
            await self._flush_buffer()
    
    async def stream_chunk(self, chunk: str):
        """ì²­í¬ ë‹¨ìœ„ ìŠ¤íŠ¸ë¦¬ë°"""
        for char in chunk:
            await self.stream_character(char)
    
    async def stream_line(self, line: str):
        """ë¼ì¸ ë‹¨ìœ„ ìŠ¤íŠ¸ë¦¬ë° (ì¦‰ì‹œ í”ŒëŸ¬ì‹œ)"""
        self._buffer += line + '\n'
        await self._flush_buffer()
    
    async def _flush_buffer(self):
        """ë²„í¼ í”ŒëŸ¬ì‹œ"""
        if self._buffer:
            await self.update_status(
                TaskState.working,
                message=self.new_agent_message(parts=[TextPart(text=self._buffer)])
            )
            self._buffer = ""
            self._last_update_time = time.time()
    
    async def stream_markdown_section(self, section_type: str, content: str):
        """Markdown ì„¹ì…˜ë³„ ìŠ¤íŠ¸ë¦¬ë°"""
        if section_type == "header":
            await self.stream_line(f"\n{content}\n")
        elif section_type == "bullet":
            await self.stream_line(f"- {content}")
        elif section_type == "code":
            await self.stream_line(f"```\n{content}\n```")
        elif section_type == "quote":
            await self.stream_line(f"> {content}")
        else:
            await self.stream_chunk(content)
    
    async def stream_final_response(self, response: str):
        """ìµœì¢… ì‘ë‹µ ì™„ë£Œ (ë²„í¼ í”ŒëŸ¬ì‹œ í›„)"""
        await self._flush_buffer()
        await self.update_status(
            TaskState.completed,
            message=self.new_agent_message(parts=[TextPart(text=response)])
        )
    
    async def stream_from_llm(self, stream: AsyncGenerator):
        """LLM ìŠ¤íŠ¸ë¦¼ ì§ì ‘ ì—°ë™"""
        try:
            async for chunk in stream:
                if chunk.choices[0].delta.content:
                    await self.stream_chunk(chunk.choices[0].delta.content)
            await self._flush_buffer()
        except Exception as e:
            logger.error(f"LLM streaming error: {e}")
            await self._flush_buffer()
    
    # A2A SDK 0.2.9 í‘œì¤€: add_artifact ë©”ì„œë“œ ì¶”ê°€
    async def add_artifact(self, parts: List[Part], artifact_id: str = None, 
                          name: str = None, metadata: Dict = None) -> None:
        """A2A SDK 0.2.9 í‘œì¤€ add_artifact ë©”ì„œë“œ êµ¬í˜„"""
        try:
            # ë¶€ëª¨ í´ë˜ìŠ¤ì˜ add_artifact ë©”ì„œë“œ í˜¸ì¶œ
            await super().add_artifact(parts, artifact_id, name, metadata)
            logger.info(f"âœ… Artifact '{name}' ì „ì†¡ ì™„ë£Œ (parts: {len(parts)})")
        except Exception as e:
            logger.error(f"âŒ Artifact ì „ì†¡ ì‹¤íŒ¨: {e}")
            # í´ë°±: ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ë‚´ìš© ì „ì†¡
            if parts and len(parts) > 0:
                for part in parts:
                    if hasattr(part, 'root') and hasattr(part.root, 'text'):
                        await self.stream_line(f"ğŸ“‹ Artifact '{name}': {part.root.text[:200]}...")
                    elif hasattr(part, 'text'):
                        await self.stream_line(f"ğŸ“‹ Artifact '{name}': {part.text[:200]}...")


class DynamicAgentDiscovery:
    """A2A CardResolverë¥¼ í™œìš©í•œ ë™ì  ì—ì´ì „íŠ¸ ë°œê²¬ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.discovered_agents = {}
        self.agent_health_status = {}
        self.last_discovery_time = {}
        self.discovery_interval = 60  # 60ì´ˆë§ˆë‹¤ ì¬ë°œê²¬
    
    async def discover_all_agents(self, base_ports: List[int] = None) -> Dict[str, Dict]:
        """ëª¨ë“  ì—ì´ì „íŠ¸ ë™ì  ë°œê²¬"""
        if base_ports is None:
            # AI DS Team í‘œì¤€ í¬íŠ¸ + ì¶”ê°€ ìŠ¤ìº” ë²”ìœ„
            base_ports = list(range(8300, 8320))
        
        discovered = {}
        
        async with httpx.AsyncClient(timeout=5.0) as client:
            for port in base_ports:
                agent_url = f"http://localhost:{port}"
                
                try:
                    # A2A í‘œì¤€ ì—ì´ì „íŠ¸ ì¹´ë“œ ì¡°íšŒ
                    card_resolver = A2ACardResolver(
                        httpx_client=client,
                        base_url=agent_url
                    )
                    agent_card = await card_resolver.get_agent_card()
                    
                    if agent_card:
                        agent_name = agent_card.name
                        
                        discovered[agent_name] = {
                            'url': agent_url,
                            'port': port,
                            'card': agent_card,
                            'skills': [skill.model_dump() for skill in agent_card.skills],
                            'capabilities': agent_card.capabilities.model_dump() if agent_card.capabilities else {},
                            'description': agent_card.description,
                            'version': agent_card.version,
                            'discovered_at': datetime.now().isoformat()
                        }
                        
                        # í—¬ìŠ¤ ì²´í¬
                        health = await self._check_agent_health(agent_url)
                        self.agent_health_status[agent_name] = health
                        
                        logger.info(f"âœ… Discovered: {agent_name} on port {port} (Health: {health['status']})")
                        
                except Exception as e:
                    logger.debug(f"Port {port} scan failed: {e}")
        
        self.discovered_agents = discovered
        self.last_discovery_time[datetime.now()] = len(discovered)
        
        logger.info(f"ğŸ” Total discovered agents: {len(discovered)}")
        return discovered
    
    async def _check_agent_health(self, agent_url: str) -> Dict:
        """ì—ì´ì „íŠ¸ í—¬ìŠ¤ ì²´í¬"""
        try:
            async with httpx.AsyncClient(timeout=3.0) as client:
                start_time = time.time()
                
                # ê°„ë‹¨í•œ í—¬ìŠ¤ ì²´í¬ - Agent Card ì¡°íšŒë¡œ ëŒ€ì²´
                card_resolver = A2ACardResolver(
                    httpx_client=client,
                    base_url=agent_url
                )
                agent_card = await card_resolver.get_agent_card()
                
                response_time = (time.time() - start_time) * 1000  # ms
                
                if agent_card:
                    return {
                        'status': 'healthy',
                        'response_time_ms': round(response_time, 2),
                        'last_check': datetime.now().isoformat()
                    }
                else:
                    return {
                        'status': 'unhealthy',
                        'error': 'No agent card',
                        'last_check': datetime.now().isoformat()
                    }
                    
        except Exception as e:
            return {
                'status': 'unreachable',
                'error': str(e),
                'last_check': datetime.now().isoformat()
            }
    
    async def find_best_agent_for_task(self, task_description: str, required_skills: List[str]) -> Optional[str]:
        """ì‘ì—…ì— ê°€ì¥ ì í•©í•œ ì—ì´ì „íŠ¸ ì°¾ê¸°"""
        best_match = None
        best_score = 0
        
        for agent_name, agent_info in self.discovered_agents.items():
            # í—¬ìŠ¤ ì²´í¬
            if self.agent_health_status.get(agent_name, {}).get('status') != 'healthy':
                continue
            
            score = 0
            
            # ìŠ¤í‚¬ ë§¤ì¹­
            agent_skills = {skill.get('id', '') for skill in agent_info.get('skills', [])}
            for required_skill in required_skills:
                if required_skill in agent_skills:
                    score += 10
            
            # ì„¤ëª… ë§¤ì¹­
            description = agent_info.get('description', '').lower()
            task_lower = task_description.lower()
            
            # í‚¤ì›Œë“œ ë§¤ì¹­
            keywords = task_lower.split()
            for keyword in keywords:
                if len(keyword) > 3 and keyword in description:
                    score += 1
            
            if score > best_score:
                best_score = score
                best_match = agent_name
        
        return best_match
    
    async def get_healthy_agents(self) -> List[str]:
        """ê±´ê°•í•œ ì—ì´ì „íŠ¸ ëª©ë¡ ë°˜í™˜"""
        healthy = []
        for agent_name, health in self.agent_health_status.items():
            if health.get('status') == 'healthy':
                healthy.append(agent_name)
        return healthy


class StandardA2ACommunicator:
    """A2A Clientë¥¼ í™œìš©í•œ í‘œì¤€ í†µì‹  ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.clients = {}  # ì—ì´ì „íŠ¸ë³„ í´ë¼ì´ì–¸íŠ¸ ìºì‹œ
    
    async def get_client(self, agent_url: str) -> A2AClient:
        """ì—ì´ì „íŠ¸ë³„ A2A í´ë¼ì´ì–¸íŠ¸ íšë“ (ìºì‹±)"""
        if agent_url not in self.clients:
            async with httpx.AsyncClient() as client:
                self.clients[agent_url] = A2AClient(
                    httpx_client=client,
                    url=agent_url
                )
        return self.clients[agent_url]
    
    async def send_message(self, agent_url: str, message: str, 
                          stream_callback=None) -> Dict:
        """í‘œì¤€ A2A ë©”ì‹œì§€ ì „ì†¡"""
        try:
            async with httpx.AsyncClient() as client:
                a2a_client = A2AClient(
                    httpx_client=client,
                    url=agent_url
                )
                
                # ë©”ì‹œì§€ ìƒì„±
                msg = Message(
                    messageId=f"orchestrator_{int(time.time() * 1000)}",
                    role="user",
                    parts=[TextPart(text=message)]
                )
                
                # SendMessageRequest ìƒì„±
                params = MessageSendParams(message=msg)
                request = SendMessageRequest(
                    id=f"req_{int(time.time() * 1000)}",
                    jsonrpc="2.0",
                    method="message/send",
                    params=params
                )
                
                # ìŠ¤íŠ¸ë¦¬ë° ëŒ€ì‹  ì¼ë°˜ ì „ì†¡ ì‚¬ìš© (ì„ì‹œ ìˆ˜ì •)
                # TODO: A2A SDK ìŠ¤íŠ¸ë¦¬ë° ì´ìŠˆ í•´ê²° í›„ ë‹¤ì‹œ í™œì„±í™”
                response = await a2a_client.send_message(request)
                result = self._parse_a2a_response(response)
                
                # ìŠ¤íŠ¸ë¦¬ë° ì½œë°±ì´ ìˆìœ¼ë©´ ì „ì²´ ì‘ë‹µì„ í•œ ë²ˆì— ì „ë‹¬
                if stream_callback and result.get('status') == 'success':
                    content = ""
                    if hasattr(result.get('result'), 'history'):
                        # A2A ì‘ë‹µì—ì„œ ë§ˆì§€ë§‰ ì—ì´ì „íŠ¸ ë©”ì‹œì§€ ì¶”ì¶œ
                        for msg in result['result'].history:
                            if msg.role == 'agent' and msg.parts:
                                for part in msg.parts:
                                    if hasattr(part, 'root') and hasattr(part.root, 'text'):
                                        content += part.root.text
                                    elif hasattr(part, 'text'):
                                        content += part.text
                    
                    if content:
                        await stream_callback(content)
                
                return result
            
        except Exception as e:
            logger.error(f"A2A communication error with {agent_url}: {e}")
            return {
                'status': 'failed',
                'error': str(e),
                'summary': f'í†µì‹  ì˜¤ë¥˜: {str(e)}'
            }
    
    async def _handle_streaming_response(self, client: A2AClient, 
                                       request: SendMessageRequest, 
                                       stream_callback) -> Dict:
        """ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²˜ë¦¬"""
        try:
            # A2A ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²˜ë¦¬ - send_message_streaming ì‚¬ìš©
            full_response = ""
            async for chunk in client.send_message_streaming(request):
                if isinstance(chunk, dict):
                    content = chunk.get('content', '')
                    if content:
                        full_response += content
                        await stream_callback(content)
                elif hasattr(chunk, 'content'):
                    content = chunk.content
                    if content:
                        full_response += content
                        await stream_callback(content)
            
            return {
                'status': 'success',
                'result': {'content': full_response},
                'summary': 'ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ'
            }
            
        except Exception as e:
            logger.error(f"Streaming error: {e}")
            return {
                'status': 'failed',
                'error': str(e),
                'summary': 'ìŠ¤íŠ¸ë¦¬ë° ì˜¤ë¥˜'
            }
    
    def _parse_a2a_response(self, response: Any) -> Dict:
        """A2A ì‘ë‹µ íŒŒì‹±"""
        try:
            if hasattr(response, 'status'):
                return {
                    'status': 'success' if response.status.state == 'completed' else 'partial',
                    'result': response,
                    'summary': 'ì‘ì—… ì™„ë£Œ'
                }
            else:
                return {
                    'status': 'success',
                    'result': response,
                    'summary': 'ì‘ì—… ì™„ë£Œ'
                }
        except Exception as e:
            return {
                'status': 'failed',
                'error': str(e),
                'summary': 'ì‘ë‹µ íŒŒì‹± ì˜¤ë¥˜'
            }


class UniversalIntelligentOrchestratorV8(AgentExecutor):
    """v8.0 - A2A SDK ê·¹ëŒ€í™” + ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° í˜ì‹ """
    
    def __init__(self):
        # OpenAI í´ë¼ì´ì–¸íŠ¸
        try:
            api_key = os.getenv("OPENAI_API_KEY")
            if api_key and api_key.strip():
                self.openai_client = AsyncOpenAI(api_key=api_key)
                logger.info("ğŸ¤– Universal Intelligent Orchestrator v8.0 with LLM")
            else:
                self.openai_client = None
                logger.info("ğŸ“Š Universal Orchestrator v8.0 (No LLM)")
        except Exception as e:
            logger.warning(f"OpenAI client initialization failed: {e}")
            self.openai_client = None
        
        # A2A ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        self.agent_discovery = DynamicAgentDiscovery()
        self.a2a_communicator = StandardA2ACommunicator()
        
        # ìƒíƒœ ê´€ë¦¬
        self.available_agents = {}
        self.agent_capabilities = {}
        self.execution_monitor = None
        self.replanning_engine = None
        
        # ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬
        self._discovery_task = None
    
    async def initialize(self):
        """ì‹œìŠ¤í…œ ì´ˆê¸°í™” ë° ì²« ë°œê²¬"""
        logger.info("ğŸš€ Initializing Universal Orchestrator v8.0...")
        
        # ì´ˆê¸° ì—ì´ì „íŠ¸ ë°œê²¬
        self.available_agents = await self.agent_discovery.discover_all_agents()
        
        # ë°±ê·¸ë¼ìš´ë“œ ë°œê²¬ íƒœìŠ¤í¬ ì‹œì‘
        if not self._discovery_task:
            self._discovery_task = asyncio.create_task(
                self._periodic_agent_discovery()
            )
        
        logger.info(f"âœ… Initialization complete with {len(self.available_agents)} agents")
    
    async def _periodic_agent_discovery(self):
        """ì£¼ê¸°ì  ì—ì´ì „íŠ¸ ì¬ë°œê²¬"""
        while True:
            await asyncio.sleep(60)  # 60ì´ˆë§ˆë‹¤
            try:
                new_agents = await self.agent_discovery.discover_all_agents()
                if len(new_agents) != len(self.available_agents):
                    logger.info(f"ğŸ”„ Agent landscape changed: {len(new_agents)} agents")
                    self.available_agents = new_agents
            except Exception as e:
                logger.error(f"Periodic discovery error: {e}")
    
    async def execute(self, context: RequestContext, event_queue: EventQueue) -> None:
        """A2A SDK 0.2.9 í‘œì¤€ ì¤€ìˆ˜ ì‹¤í–‰"""
        
        # ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° TaskUpdater ìƒì„±
        task_updater = RealTimeStreamingTaskUpdater(
            event_queue, 
            context.task_id, 
            context.context_id
        )
        
        try:
            # ì‚¬ìš©ì ì…ë ¥ ì¶”ì¶œ
            user_input = ""
            if context.message and context.message.parts:
                for part in context.message.parts:
                    if hasattr(part, 'root') and part.root.kind == "text":
                        user_input += part.root.text
                    elif hasattr(part, 'text'):
                        user_input += part.text
            
            if not user_input.strip():
                await task_updater.stream_line("âŒ ì…ë ¥ ë©”ì‹œì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
                await task_updater.stream_final_response("ì˜¤ë¥˜: ë¹ˆ ë©”ì‹œì§€")
                return
            
            # ì‹¤ì‹œê°„ ë³µì¡ë„ í‰ê°€
            await task_updater.stream_markdown_section("header", "### ğŸ§  ìš”ì²­ ë¶„ì„ ì¤‘...")
            complexity_result = await self._assess_request_complexity_streaming(user_input, task_updater)
            
            # êµ¬ì¡°í™”ëœ ì‘ë‹µì„ Artifactë¡œ ì „ì†¡
            await self._send_structured_response_as_artifact(user_input, complexity_result, task_updater)
            
            # ë³µì¡ë„ë³„ ì²˜ë¦¬
            complexity = complexity_result.get('level', 'complex')
            
            if complexity == 'simple':
                await self._handle_simple_request_streaming(user_input, task_updater)
            elif complexity == 'single_agent':
                recommended_agent = complexity_result.get('recommended_agent')
                if recommended_agent:
                    await self._handle_single_agent_streaming(user_input, recommended_agent, task_updater)
                else:
                    # ëŒ€ì•ˆ ì—ì´ì „íŠ¸ ì°¾ê¸°
                    alternative = await self._find_alternative_agent_streaming(user_input, task_updater)
                    if alternative:
                        await self._handle_single_agent_streaming(user_input, alternative, task_updater)
                    else:
                        await self._handle_complex_request_streaming(user_input, task_updater)
            else:
                await self._handle_complex_request_streaming(user_input, task_updater)
            
        except Exception as e:
            logger.error(f"Orchestrator execution error: {e}")
            await task_updater.stream_line(f"âŒ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            await task_updater.stream_final_response("ì˜¤ë¥˜ ë°œìƒìœ¼ë¡œ ì¸í•´ ì²˜ë¦¬ë¥¼ ì™„ë£Œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    async def cancel(self, context: RequestContext) -> None:
        """ì‘ì—… ì·¨ì†Œ ì²˜ë¦¬"""
        logger.info(f"Task {context.task_id} cancellation requested")
        # ì·¨ì†Œ ë¡œì§ êµ¬í˜„ (í•„ìš”ì‹œ ì—ì´ì „íŠ¸ í†µì‹  ì¤‘ë‹¨ ë“±)
    
    async def _send_structured_response_as_artifact(self, 
                                                  user_input: str, 
                                                  complexity_result: Dict,
                                                  task_updater: RealTimeStreamingTaskUpdater):
        """A2A SDK 0.2.9 í‘œì¤€: êµ¬ì¡°í™”ëœ ì‘ë‹µì„ artifactë¡œ ì „ì†¡"""
        
        try:
            # Streamlit í´ë¼ì´ì–¸íŠ¸ í˜¸í™˜ ì‹¤í–‰ ê³„íš ìƒì„±
            execution_plan = {
                "plan_type": "ai_ds_team_orchestration",
                "complexity": complexity_result.get('level', 'complex'),
                "reasoning": complexity_result.get('reasoning', ''),
                "steps": []
            }
            
            if complexity_result.get('level', 'complex') == 'simple':
                # Simple ìš”ì²­: ì§ì ‘ ì‘ë‹µìœ¼ë¡œ ì²˜ë¦¬ë¨ì„ ëª…ì‹œ
                execution_plan["steps"] = [{
                    "step_number": 1,
                    "agent_name": "ğŸ§  Universal Orchestrator v8.0",
                    "task_description": "ì§ì ‘ ì‘ë‹µ ì œê³µ",
                    "reasoning": "ì¼ë°˜ ì§€ì‹ ì§ˆë¬¸ìœ¼ë¡œ LLMì´ ì§ì ‘ ì‘ë‹µ",
                    "expected_result": "ì™„ë£Œëœ ì‘ë‹µ",
                    "status": "completed"
                }]
                
            elif complexity_result.get('level', 'complex') == 'single_agent':
                # Single Agent ìš”ì²­
                agent_name = complexity_result.get('recommended_agent', 'EDA Tools Agent')
                execution_plan["steps"] = [{
                    "step_number": 1,
                    "agent_name": agent_name,
                    "task_description": user_input,
                    "reasoning": f"{agent_name}ì˜ ì „ë¬¸ ì—­ëŸ‰ìœ¼ë¡œ ì²˜ë¦¬",
                    "expected_result": "ì „ë¬¸ ë¶„ì„ ê²°ê³¼",
                    "status": "completed"
                }]
                
            else:  # complex
                # Complex ìš”ì²­: ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ê³„íš
                available_agents = await self.agent_discovery.get_healthy_agents()
                
                # í‘œì¤€ ë°ì´í„° ë¶„ì„ ì›Œí¬í”Œë¡œìš°
                standard_workflow = [
                    ("AI_DS_Team DataLoaderToolsAgent", "ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬"),
                    ("AI_DS_Team DataCleaningAgent", "ë°ì´í„° ì •ë¦¬ ë° í’ˆì§ˆ ê°œì„ "),
                    ("SessionEDAToolsAgent", "ë°ì´í„° íƒìƒ‰ì  ë¶„ì„"),
                    ("AI_DS_Team DataVisualizationAgent", "ë°ì´í„° ì‹œê°í™”"),
                    ("AI_DS_Team SQLDatabaseAgent", "ì¥ë¹„ ê°„ ë¶„í¬ ë¹„êµ ë° ì´ìƒ íƒì§€"),
                    ("AI_DS_Team DataWranglingAgent", "ì´ìƒ ì›ì¸ í•´ì„ ë° ì¡°ì¹˜ ë°©í–¥ ì œì•ˆ")
                ]
                
                for i, (agent, purpose) in enumerate(standard_workflow, 1):
                    execution_plan["steps"].append({
                        "step_number": i,
                        "agent_name": agent,
                        "task_description": purpose,
                        "reasoning": f"{agent}ì˜ ì „ë¬¸ì„±ì„ í™œìš©í•˜ì—¬ {purpose} ìˆ˜í–‰",
                        "expected_result": f"{purpose} ì™„ë£Œ ê²°ê³¼",
                        "status": "planned"
                    })
            
            # A2A SDK 0.2.9: add_artifact ë©”ì„œë“œë¡œ êµ¬ì¡°í™”ëœ ê³„íš ì „ì†¡
            await task_updater.add_artifact(
                parts=[Part(root=TextPart(text=json.dumps(execution_plan, ensure_ascii=False, indent=2)))],
                name="execution_plan",
                metadata={
                    "content_type": "application/json",
                    "plan_type": "ai_ds_team_orchestration",
                    "complexity": complexity_result.get('level', 'complex')
                }
            )
            
            logger.info(f"âœ… êµ¬ì¡°í™”ëœ ì‹¤í–‰ ê³„íš artifact ì „ì†¡ ì™„ë£Œ: {complexity_result.get('level', 'complex')}")
            
        except Exception as e:
            logger.error(f"âŒ Structured response artifact ì „ì†¡ ì‹¤íŒ¨: {e}")
            # í´ë°±: ê¸°ë³¸ í…ìŠ¤íŠ¸ ì‘ë‹µ
            await task_updater.stream_line(f"âš ï¸ êµ¬ì¡°í™”ëœ ì‘ë‹µ ìƒì„± ì‹¤íŒ¨, ê¸°ë³¸ ì‘ë‹µìœ¼ë¡œ ëŒ€ì²´")
    
    async def _assess_request_complexity_streaming(self, 
                                                 user_input: str,
                                                 task_updater: RealTimeStreamingTaskUpdater) -> Dict:
        """ìš”ì²­ ë³µì¡ë„ í‰ê°€ (ë°ì´í„° ì»¨í…ìŠ¤íŠ¸ ê³ ë ¤) - ìŠ¤íŠ¸ë¦¬ë°"""
        
        if not self.openai_client:
            await task_updater.stream_line("- LLM ì—†ì´ ê¸°ë³¸ ë³µì¡ë„ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
            return {'level': 'complex', 'reasoning': 'No LLM available'}
        
        # 1ë‹¨ê³„: ë°ì´í„° ê´€ë ¨ì„± ì‚¬ì „ ê²€ì‚¬
        await task_updater.stream_line("- ë°ì´í„° ê´€ë ¨ì„±ì„ í™•ì¸í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
        data_related = await self._check_data_requirement(user_input)
        
        if data_related:
            await task_updater.stream_line("- ğŸ“Š ë°ì´í„° ì ‘ê·¼ì´ í•„ìš”í•œ ìš”ì²­ìœ¼ë¡œ ê°ì§€ë¨")
            # ë°ì´í„° ê´€ë ¨ ìš”ì²­ì€ ìµœì†Œ single_agent ì´ìƒ
            return await self._assess_data_request_complexity(user_input, task_updater)
        else:
            await task_updater.stream_line("- ğŸ’­ ì¼ë°˜ì  ì§€ì‹ ê¸°ë°˜ ìš”ì²­ìœ¼ë¡œ ê°ì§€ë¨")
            # ì¼ë°˜ì  ì§€ì‹ë§Œìœ¼ë¡œ ë‹µë³€ ê°€ëŠ¥í•œ ìš”ì²­
            return await self._assess_general_request_complexity(user_input, task_updater)
    
    async def _check_data_requirement(self, user_input: str) -> bool:
        """ë°ì´í„° ì ‘ê·¼ í•„ìš”ì„± ê²€ì‚¬"""
        try:
            check_prompt = f"""
            ë‹¤ìŒ ìš”ì²­ì´ ë°ì´í„° ì ‘ê·¼ì„ í•„ìš”ë¡œ í•˜ëŠ”ì§€ íŒë‹¨í•˜ì„¸ìš”:
            "{user_input}"
            
            ë°ì´í„° ì ‘ê·¼ì´ í•„ìš”í•œ ê²½ìš°:
            - íŠ¹ì • ë°ì´í„°ì…‹ì˜ ê°’, ê°œìˆ˜, í†µê³„ ì¡°íšŒ
            - ë°ì´í„° ë¶„ì„, ì‹œê°í™”, ëª¨ë¸ë§
            - ë°ì´í„° ê¸°ë°˜ ë¹„êµ, íŠ¸ë Œë“œ ë¶„ì„
            - "ì´ ë°ì´í„°", "ë°ì´í„°ì…‹", "LOT", "ì»¬ëŸ¼" ë“± ì–¸ê¸‰
            
            ì¼ë°˜ ì§€ì‹ìœ¼ë¡œ ë‹µë³€ ê°€ëŠ¥í•œ ê²½ìš°:
            - ê°œë… ì •ì˜, ìš©ì–´ ì„¤ëª…
            - ì¼ë°˜ì  ë°©ë²•ë¡ , ì´ë¡  ì„¤ëª…
            - ì¶”ìƒì  ì§ˆë¬¸, ì˜ê²¬ ìš”ì²­
            
            JSON ì‘ë‹µ:
            {{
                "requires_data": true/false,
                "reasoning": "íŒë‹¨ ê·¼ê±°",
                "data_keywords": ["ê°ì§€ëœ ë°ì´í„° ê´€ë ¨ í‚¤ì›Œë“œë“¤"]
            }}
            """
            
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": check_prompt}],
                response_format={"type": "json_object"},
                temperature=0.1,
                timeout=15.0
            )
            
            result = json.loads(response.choices[0].message.content)
            return result.get('requires_data', False)
            
        except Exception as e:
            logger.warning(f"Data requirement check failed: {e}")
            # ì‹¤íŒ¨ ì‹œ ì•ˆì „í•˜ê²Œ ë°ì´í„° í•„ìš”ë¡œ ê°€ì •
            return True
    
    async def _assess_data_request_complexity(self, 
                                            user_input: str,
                                            task_updater: RealTimeStreamingTaskUpdater) -> Dict:
        """ë°ì´í„° ê´€ë ¨ ìš”ì²­ì˜ ë³µì¡ë„ í‰ê°€"""
        
        assessment_prompt = f"""
        ë‹¤ìŒì€ ë°ì´í„° ì ‘ê·¼ì´ í•„ìš”í•œ ìš”ì²­ì…ë‹ˆë‹¤. ë³µì¡ë„ë¥¼ í‰ê°€í•˜ì„¸ìš”:
        "{user_input}"
        
        í‰ê°€ ê¸°ì¤€:
        1. **single_agent**: ë‹¨ìˆœ ë°ì´í„° ì¡°íšŒ/ê³„ì‚° (ê°œìˆ˜, ê¸°ë³¸ í†µê³„, ë‹¨ì¼ ì»¬ëŸ¼ ë¶„ì„)
        2. **complex**: ë³µí•© ë¶„ì„ (ë‹¤ì¤‘ ë³€ìˆ˜ ë¶„ì„, ì‹œê°í™”, ëª¨ë¸ë§, ì¢…í•© ë¦¬í¬íŠ¸)
        
        ì¤‘ìš”: ë°ì´í„° ê´€ë ¨ ìš”ì²­ì€ 'simple' ë¶„ë¥˜ ê¸ˆì§€!
        
        JSON ì‘ë‹µ:
        {{
            "level": "single_agent/complex",
            "reasoning": "íŒë‹¨ ê·¼ê±°",
            "recommended_agent": "single_agentì¸ ê²½ìš° ì¶”ì²œ ì—ì´ì „íŠ¸",
            "data_operations": ["í•„ìš”í•œ ë°ì´í„° ì‘ì—…ë“¤"]
        }}
        """
        
        try:
            await task_updater.stream_line("- ë°ì´í„° ìš”ì²­ ë³µì¡ë„ë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
            
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": assessment_prompt}],
                response_format={"type": "json_object"},
                temperature=0.2,
                timeout=30.0
            )
            
            complexity = json.loads(response.choices[0].message.content)
            
            # ê²°ê³¼ ìŠ¤íŠ¸ë¦¬ë°
            level_emoji = {
                'single_agent': 'ğŸ¤–', 
                'complex': 'ğŸ¯'
            }
            
            await task_updater.stream_line(
                f"- ë³µì¡ë„: {level_emoji.get(complexity['level'], 'ğŸ“Š')} "
                f"**{complexity['level'].upper()}** (ë°ì´í„° ìš”ì²­)"
            )
            await task_updater.stream_line(f"- íŒë‹¨ ê·¼ê±°: {complexity['reasoning']}")
            
            return complexity
            
        except Exception as e:
            logger.warning(f"Data request complexity assessment failed: {e}")
            await task_updater.stream_line("- ë³µì¡ë„ í‰ê°€ ì‹¤íŒ¨, ë³µí•© ë¶„ì„ ëª¨ë“œë¡œ ì§„í–‰")
            return {'level': 'complex', 'reasoning': 'Assessment failed - defaulting to complex for data requests'}
    
    async def _assess_general_request_complexity(self, 
                                               user_input: str,
                                               task_updater: RealTimeStreamingTaskUpdater) -> Dict:
        """ì¼ë°˜ì  ì§€ì‹ ê¸°ë°˜ ìš”ì²­ì˜ ë³µì¡ë„ í‰ê°€"""
        
        assessment_prompt = f"""
        ë‹¤ìŒì€ ì¼ë°˜ì  ì§€ì‹ìœ¼ë¡œ ë‹µë³€ ê°€ëŠ¥í•œ ìš”ì²­ì…ë‹ˆë‹¤. ë³µì¡ë„ë¥¼ í‰ê°€í•˜ì„¸ìš”:
        "{user_input}"
        
        í‰ê°€ ê¸°ì¤€:
        1. **simple**: ê°„ë‹¨í•œ ì •ì˜, ê°œë… ì„¤ëª…, ì‚¬ì‹¤ í™•ì¸
        2. **single_agent**: ì „ë¬¸ì  ì„¤ëª…, ë°©ë²•ë¡  ê°€ì´ë“œ, ë¹„êµ ë¶„ì„
        3. **complex**: ë‹¤ë©´ì  ë¶„ì„, ì¢…í•©ì  ê°€ì´ë“œ, ë³µí•© ê°œë… ì„¤ëª…
        
        JSON ì‘ë‹µ:
        {{
            "level": "simple/single_agent/complex",
            "reasoning": "íŒë‹¨ ê·¼ê±°",
            "recommended_agent": "single_agentì¸ ê²½ìš° ì¶”ì²œ ì—ì´ì „íŠ¸",
            "knowledge_areas": ["í•„ìš”í•œ ì§€ì‹ ì˜ì—­ë“¤"]
        }}
        """
        
        try:
            await task_updater.stream_line("- ì¼ë°˜ ìš”ì²­ ë³µì¡ë„ë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
            
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": assessment_prompt}],
                response_format={"type": "json_object"},
                temperature=0.2,
                timeout=30.0
            )
            
            complexity = json.loads(response.choices[0].message.content)
            
            # ê²°ê³¼ ìŠ¤íŠ¸ë¦¬ë°
            level_emoji = {
                'simple': 'ğŸ’¬',
                'single_agent': 'ğŸ¤–', 
                'complex': 'ğŸ¯'
            }
            
            await task_updater.stream_line(
                f"- ë³µì¡ë„: {level_emoji.get(complexity['level'], 'ğŸ“Š')} "
                f"**{complexity['level'].upper()}** (ì¼ë°˜ ì§€ì‹)"
            )
            await task_updater.stream_line(f"- íŒë‹¨ ê·¼ê±°: {complexity['reasoning']}")
            
            return complexity
            
        except Exception as e:
            logger.warning(f"General request complexity assessment failed: {e}")
            await task_updater.stream_line("- ë³µì¡ë„ í‰ê°€ ì‹¤íŒ¨, ê¸°ë³¸ ëª¨ë“œë¡œ ì§„í–‰")
            return {'level': 'simple', 'reasoning': 'Assessment failed - defaulting to simple for general requests'}
    
    async def _handle_simple_request_streaming(self,
                                             user_input: str,
                                             task_updater: RealTimeStreamingTaskUpdater):
        """ê°„ë‹¨í•œ ìš”ì²­ ì¦‰ë‹µ (ìŠ¤íŠ¸ë¦¬ë°)"""
        await task_updater.stream_markdown_section(
            "header", "### ğŸ’¬ ì¦‰ì‹œ ë‹µë³€"
        )
        
        if self.openai_client:
            try:
                # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ
                stream = await self.openai_client.chat.completions.create(
                    model="gpt-4o",
                    messages=[{
                        "role": "system",
                        "content": "ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ê°„ê²°í•˜ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”."
                    }, {
                        "role": "user",
                        "content": user_input
                    }],
                    temperature=0.3,
                    max_tokens=1000,
                    stream=True
                )
                
                await task_updater.stream_line("")
                full_response = ""
                
                async for chunk in stream:
                    if chunk.choices[0].delta.content:
                        content = chunk.choices[0].delta.content
                        full_response += content
                        await task_updater.stream_chunk(content)
                
                await task_updater._flush_buffer()
                
                # ì™„ë£Œ
                await task_updater.update_status(
                    TaskState.completed,
                    message=task_updater.new_agent_message(
                        parts=[TextPart(text=full_response)]
                    )
                )
                
            except Exception as e:
                logger.error(f"Simple request streaming failed: {e}")
                await task_updater.stream_line(f"\nâŒ ì˜¤ë¥˜: {str(e)}")
                await task_updater.update_status(
                    TaskState.failed,
                    message=task_updater.new_agent_message(
                        parts=[TextPart(text=f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}")]
                    )
                )
        else:
            response = "ì£„ì†¡í•©ë‹ˆë‹¤. LLMì´ ì„¤ì •ë˜ì§€ ì•Šì•„ ì¦‰ë‹µì„ ì œê³µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            await task_updater.stream_line(response)
            await task_updater.update_status(
                TaskState.completed,
                message=task_updater.new_agent_message(
                    parts=[TextPart(text=response)]
                )
            )
    
    async def _handle_single_agent_streaming(self,
                                           user_input: str,
                                           agent_name: str,
                                           task_updater: RealTimeStreamingTaskUpdater):
        """ë‹¨ì¼ ì—ì´ì „íŠ¸ ì²˜ë¦¬ (ìŠ¤íŠ¸ë¦¬ë°)"""
        await task_updater.stream_markdown_section(
            "header", f"### ğŸ¤– {agent_name} ì—ì´ì „íŠ¸ ì‹¤í–‰"
        )
        
        # ì—ì´ì „íŠ¸ í™•ì¸
        if agent_name not in self.available_agents:
            # ëŒ€ì²´ ì—ì´ì „íŠ¸ ì°¾ê¸°
            await task_updater.stream_line("- ì§€ì •ëœ ì—ì´ì „íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ëŒ€ì²´ ì—ì´ì „íŠ¸ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤...")
            
            agent_name = await self._find_alternative_agent_streaming(
                user_input, task_updater
            )
            
            if not agent_name:
                await task_updater.stream_line("âŒ ì í•©í•œ ì—ì´ì „íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                await task_updater.update_status(
                    TaskState.failed,
                    message=task_updater.new_agent_message(
                        parts=[TextPart(text="ì—ì´ì „íŠ¸ ì—†ìŒ")]
                    )
                )
                return
        
        # ì—ì´ì „íŠ¸ ì •ë³´
        agent_info = self.available_agents[agent_name]
        agent_url = agent_info['url']
        
        await task_updater.stream_line(f"- ì—ì´ì „íŠ¸: **{agent_name}**")
        await task_updater.stream_line(f"- ìƒíƒœ: âœ… {agent_info.get('version', 'unknown')}")
        
        # ì‚¬ìš©ì ì˜ë„ ì¶”ì¶œ
        await task_updater.stream_line("- ìš”ì²­ ë‚´ìš©ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
        user_intent = await self._extract_user_intent_precisely(user_input)
        
        # ì •ë°€í•œ ì§€ì‹œ ìƒì„±
        await task_updater.stream_line("- ìµœì ì˜ ì‘ì—… ì§€ì‹œë¥¼ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
        instruction = await self._create_precise_instruction_for_agent(
            agent_name, user_intent, agent_info
        )
        
        # A2A í‘œì¤€ í†µì‹ ìœ¼ë¡œ ì‹¤í–‰ (ìŠ¤íŠ¸ë¦¬ë°)
        await task_updater.stream_line(f"\n**ì‹¤í–‰ ì¤‘...**")
        
        # ìŠ¤íŠ¸ë¦¬ë° ì½œë°±
        async def stream_callback(content: str):
            await task_updater.stream_chunk(content)
        
        result = await self.a2a_communicator.send_message(
            agent_url,
            instruction,
            stream_callback=stream_callback
        )
        
        # ê²°ê³¼ ê²€ì¦
        if result['status'] == 'success':
            await task_updater.stream_line(f"\nâœ… {agent_name} ì‘ì—… ì™„ë£Œ")
            
            # ìµœì¢… ì‘ë‹µ ìƒì„±
            final_response = await self._create_final_response_single(
                user_input, agent_name, result, user_intent
            )
            
            await task_updater.update_status(
                TaskState.completed,
                message=task_updater.new_agent_message(
                    parts=[TextPart(text=final_response)]
                )
            )
        else:
            await task_updater.stream_line(f"\nâŒ ì‹¤í–‰ ì‹¤íŒ¨: {result.get('error', 'Unknown')}")
            await task_updater.update_status(
                TaskState.failed,
                message=task_updater.new_agent_message(
                    parts=[TextPart(text=f"ì—ì´ì „íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨: {result.get('error')}")]
                )
            )
    
    async def _handle_complex_request_streaming(self,
                                              user_input: str,
                                              task_updater: RealTimeStreamingTaskUpdater):
        """ë³µì¡í•œ ìš”ì²­ ì²˜ë¦¬ (ìŠ¤íŠ¸ë¦¬ë°)"""
        await task_updater.stream_markdown_section(
            "header", "### ğŸ¯ ë³µì¡í•œ ë¶„ì„ ì‹œì‘"
        )
        
        # Phase 1: ê¹Šì´ ìˆëŠ” ë¶„ì„
        await task_updater.stream_line("\n**1ë‹¨ê³„: ìš”ì²­ ì‹¬ì¸µ ë¶„ì„**")
        
        request_analysis = await self._analyze_request_depth(user_input)
        user_intent = await self._extract_user_intent_precisely(user_input)
        
        await task_updater.stream_line(f"- ì£¼ìš” ëª©í‘œ: {user_intent['main_goal']}")
        await task_updater.stream_line(f"- ì•¡ì…˜ íƒ€ì…: {user_intent['action_type']}")
        
        # Phase 2: ì—ì´ì „íŠ¸ ì¤€ë¹„
        await task_updater.stream_line("\n**2ë‹¨ê³„: AI ì—ì´ì „íŠ¸ ì¤€ë¹„**")
        
        # ê±´ê°•í•œ ì—ì´ì „íŠ¸ë§Œ ì‚¬ìš©
        healthy_agents = await self.agent_discovery.get_healthy_agents()
        await task_updater.stream_line(f"- ì‚¬ìš© ê°€ëŠ¥í•œ ì—ì´ì „íŠ¸: {len(healthy_agents)}ê°œ")
        
        for agent_name in healthy_agents[:5]:  # ìƒìœ„ 5ê°œë§Œ í‘œì‹œ
            health = self.agent_discovery.agent_health_status.get(agent_name, {})
            response_time = health.get('response_time_ms', 'N/A')
            await task_updater.stream_line(f"  - âœ… {agent_name} ({response_time}ms)")
        
        # Phase 3: ì‹¤í–‰ ê³„íš ìˆ˜ë¦½
        await task_updater.stream_line("\n**3ë‹¨ê³„: ìµœì  ì‹¤í–‰ ê³„íš ìˆ˜ë¦½**")
        
        plan = await self._create_streaming_execution_plan(
            user_input, user_intent, healthy_agents, task_updater
        )
        
        if not plan or not plan.get('steps'):
            await task_updater.stream_line("âŒ ì‹¤í–‰ ê³„íš ìˆ˜ë¦½ ì‹¤íŒ¨")
            await task_updater.update_status(
                TaskState.failed,
                message=task_updater.new_agent_message(
                    parts=[TextPart(text="ê³„íš ìˆ˜ë¦½ ì‹¤íŒ¨")]
                )
            )
            return
        
        # ê³„íš í‘œì‹œ
        await task_updater.stream_line(f"\nğŸ“‹ **ì‹¤í–‰ ê³„íš** ({len(plan['steps'])}ë‹¨ê³„)")
        for i, step in enumerate(plan['steps']):
            await task_updater.stream_line(
                f"{i+1}. **{step['agent']}**: {step['purpose']}"
            )
        
        # Phase 4: ì ì‘ì  ì‹¤í–‰
        await task_updater.stream_line("\n**4ë‹¨ê³„: ì‹¤í–‰ ì‹œì‘**")
        
        execution_result = await self._execute_with_streaming_and_replanning(
            plan, user_intent, task_updater
        )
        
        # Phase 5: ê²°ê³¼ ì¢…í•©
        await task_updater.stream_line("\n**5ë‹¨ê³„: ê²°ê³¼ ì¢…í•©**")
        
        final_response = await self._create_comprehensive_response_streaming(
            user_input, user_intent, execution_result, task_updater
        )
        
        # ì™„ë£Œ
        await task_updater.stream_line("\nğŸ‰ **ë¶„ì„ ì™„ë£Œ!**")
        
        await task_updater.update_status(
            TaskState.completed,
            message=task_updater.new_agent_message(
                parts=[TextPart(text=final_response)]
            )
        )
    
    async def _find_alternative_agent_streaming(self,
                                              user_input: str,
                                              task_updater: RealTimeStreamingTaskUpdater) -> Optional[str]:
        """ëŒ€ì²´ ì—ì´ì „íŠ¸ ì°¾ê¸° (ì§€ëŠ¥í˜• ë§¤ì¹­) - ìŠ¤íŠ¸ë¦¬ë°"""
        
        # ê±´ê°•í•œ ì—ì´ì „íŠ¸ ëª©ë¡ í™•ì¸
        healthy_agents = await self.agent_discovery.get_healthy_agents()
        if not healthy_agents:
            await task_updater.stream_line("- âŒ ì‚¬ìš© ê°€ëŠ¥í•œ ì—ì´ì „íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤")
            return None
        
        # LLM ê¸°ë°˜ ì§€ëŠ¥í˜• ì—ì´ì „íŠ¸ ë§¤ì¹­
        if self.openai_client:
            try:
                # ì—ì´ì „íŠ¸ ì •ë³´ ìˆ˜ì§‘
                agent_details = {}
                for agent_name in healthy_agents:
                    if agent_name in self.available_agents:
                        info = self.available_agents[agent_name]
                        agent_details[agent_name] = {
                            'description': info.get('description', ''),
                            'skills': [s.get('name', '') for s in info.get('skills', [])]
                        }
                
                matching_prompt = f"""
                ì‚¬ìš©ì ìš”ì²­: "{user_input}"
                
                ì‚¬ìš© ê°€ëŠ¥í•œ ì—ì´ì „íŠ¸ë“¤:
                {json.dumps(agent_details, ensure_ascii=False, indent=2)}
                
                ì´ ìš”ì²­ì— ê°€ì¥ ì í•©í•œ ì—ì´ì „íŠ¸ë¥¼ ì„ íƒí•˜ì„¸ìš”.
                
                ì„ íƒ ê¸°ì¤€:
                1. ë°ì´í„° ì¡°íšŒ/ê³„ì‚°: data_loader, eda_tools
                2. ë°ì´í„° ì •ì œ: data_cleaning, data_wrangling  
                3. ì‹œê°í™”: data_visualization
                4. ë¶„ì„: eda_tools, feature_engineering
                5. ëª¨ë¸ë§: h2o_ml, mlflow_tools
                6. SQL: sql_database
                
                JSON ì‘ë‹µ:
                {{
                    "selected_agent": "ì„ íƒëœ ì—ì´ì „íŠ¸ëª…",
                    "reasoning": "ì„ íƒ ê·¼ê±°",
                    "confidence": 0.0-1.0
                }}
                """
                
                response = await self.openai_client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[{"role": "user", "content": matching_prompt}],
                    response_format={"type": "json_object"},
                    temperature=0.2,
                    timeout=20.0
                )
                
                result = json.loads(response.choices[0].message.content)
                selected_agent = result.get('selected_agent')
                confidence = result.get('confidence', 0.5)
                reasoning = result.get('reasoning', '')
                
                if selected_agent in healthy_agents and confidence > 0.3:
                    await task_updater.stream_line(f"- ğŸ¯ ìµœì  ì—ì´ì „íŠ¸ ì„ íƒ: **{selected_agent}** (ì‹ ë¢°ë„: {confidence:.1%})")
                    await task_updater.stream_line(f"- ì„ íƒ ê·¼ê±°: {reasoning}")
                    return selected_agent
                    
            except Exception as e:
                logger.warning(f"Intelligent agent matching failed: {e}")
                await task_updater.stream_line("- âš ï¸ ì§€ëŠ¥í˜• ë§¤ì¹­ ì‹¤íŒ¨, í‚¤ì›Œë“œ ê¸°ë°˜ìœ¼ë¡œ ì§„í–‰")
        
        # í´ë°±: í‚¤ì›Œë“œ ê¸°ë°˜ ë§¤ì¹­
        await task_updater.stream_line("- í‚¤ì›Œë“œ ê¸°ë°˜ ì—ì´ì „íŠ¸ ì„ íƒ ì¤‘...")
        
        # ë°ì´í„° ê´€ë ¨ í‚¤ì›Œë“œ ìš°ì„ ìˆœìœ„ ë§¤ì¹­
        data_keywords = {
            'count': ['data_loader', 'eda_tools'],
            'lot': ['data_loader', 'eda_tools'], 
            'column': ['data_loader', 'eda_tools'],
            'statistic': ['eda_tools', 'data_visualization'],
            'analysis': ['eda_tools', 'feature_engineering'],
            'visual': ['data_visualization'],
            'chart': ['data_visualization'],
            'plot': ['data_visualization'],
            'clean': ['data_cleaning', 'data_wrangling'],
            'model': ['h2o_ml', 'mlflow_tools'],
            'sql': ['sql_database'],
            'database': ['sql_database']
        }
        
        user_lower = user_input.lower()
        matched_agents = []
        
        for keyword, agents in data_keywords.items():
            if keyword in user_lower:
                for agent in agents:
                    if agent in healthy_agents:
                        matched_agents.append(agent)
        
        if matched_agents:
            # ê°€ì¥ ë§ì´ ë§¤ì¹­ëœ ì—ì´ì „íŠ¸ ì„ íƒ
            from collections import Counter
            agent_counts = Counter(matched_agents)
            best_agent = agent_counts.most_common(1)[0][0]
            
            await task_updater.stream_line(f"- í‚¤ì›Œë“œ ë§¤ì¹­ ê²°ê³¼: **{best_agent}**")
            return best_agent
        
        # ìµœì¢… í´ë°±: ë°ì´í„° ê´€ë ¨ ê¸°ë³¸ ì—ì´ì „íŠ¸
        default_data_agents = ['data_loader', 'eda_tools', 'data_cleaning']
        for agent in default_data_agents:
            if agent in healthy_agents:
                await task_updater.stream_line(f"- ê¸°ë³¸ ë°ì´í„° ì—ì´ì „íŠ¸ ì‚¬ìš©: **{agent}**")
                return agent
        
        # ë§ˆì§€ë§‰ í´ë°±: ì²« ë²ˆì§¸ ê±´ê°•í•œ ì—ì´ì „íŠ¸
        if healthy_agents:
            await task_updater.stream_line(f"- ì²« ë²ˆì§¸ ì‚¬ìš© ê°€ëŠ¥ ì—ì´ì „íŠ¸: **{healthy_agents[0]}**")
            return healthy_agents[0]
        
        return None
    
    async def _create_streaming_execution_plan(self,
                                             user_input: str,
                                             user_intent: Dict,
                                             healthy_agents: List[str],
                                             task_updater: RealTimeStreamingTaskUpdater) -> Dict:
        """ì‹¤í–‰ ê³„íš ìˆ˜ë¦½ (ìŠ¤íŠ¸ë¦¬ë° í”¼ë“œë°±)"""
        
        if not self.openai_client or not healthy_agents:
            return self._create_basic_plan(healthy_agents)
        
        await task_updater.stream_line("- AIê°€ ìµœì ì˜ ì‹¤í–‰ ê²½ë¡œë¥¼ ì„¤ê³„í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
        
        # ì—ì´ì „íŠ¸ ì •ë³´ ìˆ˜ì§‘
        agent_details = {}
        for agent_name in healthy_agents:
            if agent_name in self.available_agents:
                info = self.available_agents[agent_name]
                agent_details[agent_name] = {
                    'description': info.get('description', ''),
                    'skills': [s.get('name', '') for s in info.get('skills', [])]
                }
        
        planning_prompt = f"""
        ì‚¬ìš©ì ìš”ì²­: {user_input}
        ì‚¬ìš©ì ì˜ë„: {json.dumps(user_intent, ensure_ascii=False)}
        
        ì‚¬ìš© ê°€ëŠ¥í•œ ì—ì´ì „íŠ¸:
        {json.dumps(agent_details, ensure_ascii=False, indent=2)}
        
        ì´ ìš”ì²­ì„ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ ìµœì ì˜ ì‹¤í–‰ ê³„íšì„ ìˆ˜ë¦½í•˜ì„¸ìš”.
        
        ì¤‘ìš”:
        - ì‚¬ìš©ì ì˜ë„ì— í•„ìš”í•œ ì—ì´ì „íŠ¸ë§Œ ì„ íƒ
        - ë…¼ë¦¬ì ì¸ ì‹¤í–‰ ìˆœì„œ ê³ ë ¤
        - ê° ë‹¨ê³„ë³„ ëª…í™•í•œ ëª©ì  ì„¤ì •
        
        JSON í˜•ì‹:
        {{
            "execution_strategy": "ì „ì²´ ì „ëµ",
            "steps": [
                {{
                    "agent": "ì—ì´ì „íŠ¸ëª…",
                    "purpose": "ì´ ë‹¨ê³„ì˜ ëª©ì ",
                    "instruction": "êµ¬ì²´ì  ì‘ì—… ì§€ì‹œ"
                }}
            ]
        }}
        """
        
        try:
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": planning_prompt}],
                response_format={"type": "json_object"},
                temperature=0.3,
                max_tokens=2000
            )
            
            plan = json.loads(response.choices[0].message.content)
            
            # ê³„íš ê²€ì¦
            valid_steps = []
            for step in plan.get('steps', []):
                if step.get('agent') in healthy_agents:
                    valid_steps.append(step)
            
            plan['steps'] = valid_steps
            
            await task_updater.stream_line("- âœ… ì‹¤í–‰ ê³„íš ìˆ˜ë¦½ ì™„ë£Œ")
            return plan
            
        except Exception as e:
            logger.error(f"Planning failed: {e}")
            await task_updater.stream_line("- âš ï¸ ê¸°ë³¸ ê³„íšìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤")
            return self._create_basic_plan(healthy_agents)
    
    async def _execute_with_streaming_and_replanning(self,
                                                    plan: Dict,
                                                    user_intent: Dict,
                                                    task_updater: RealTimeStreamingTaskUpdater) -> Dict:
        """ì ì‘ì  ì‹¤í–‰ - ìŠ¤íŠ¸ë¦¬ë°ê³¼ ì¬ê³„íš"""
        
        execution_results = []
        current_data_file = None  # í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ ë°ì´í„° íŒŒì¼ ì¶”ì 
        
        for i, step in enumerate(plan['steps']):
            agent_name = step['agent']
            purpose = step['purpose']
            
            await task_updater.stream_line(f"\n### ë‹¨ê³„ {i+1}: {agent_name}")
            await task_updater.stream_line(f"**ëª©ì **: {purpose}")
            
            # ì—ì´ì „íŠ¸ ì •ë³´ í™•ì¸
            if agent_name not in self.available_agents:
                await task_updater.stream_line(f"âŒ ì—ì´ì „íŠ¸ '{agent_name}' ì‚¬ìš© ë¶ˆê°€ëŠ¥")
                continue
            
            agent_info = self.available_agents[agent_name]
            agent_url = agent_info['url']
            
            # ë°ì´í„° íŒŒì¼ ì •ë³´ë¥¼ í¬í•¨í•œ ì§€ì‹œì‚¬í•­ ìƒì„±
            instruction = await self._create_data_aware_instruction(
                agent_name, purpose, user_intent, current_data_file
            )
            
            await task_updater.stream_line(f"**ì‹¤í–‰ ì¤‘...**")
            
            # ìŠ¤íŠ¸ë¦¬ë° ì½œë°±
            async def agent_stream_callback(content: str):
                # ì—ì´ì „íŠ¸ ì¶œë ¥ì„ ë“¤ì—¬ì“°ê¸°ë¡œ í‘œì‹œ
                lines = content.split('\n')
                for line in lines:
                    if line.strip():
                        await task_updater.stream_chunk(f"  {line}\n")
            
            try:
                result = await self.a2a_communicator.send_message(
                    agent_url,
                    instruction,
                    stream_callback=agent_stream_callback
                )
                
                if result['status'] == 'success':
                    await task_updater.stream_line(f"âœ… {agent_name} ì™„ë£Œ")
                    
                    # Data Loader ê²°ê³¼ì—ì„œ ë°ì´í„° íŒŒì¼ëª… ì¶”ì¶œ
                    if "data loader" in agent_name.lower() or "dataloader" in agent_name.lower():
                        extracted_file = self._extract_data_file_from_result(result)
                        if extracted_file:
                            current_data_file = extracted_file
                            await task_updater.stream_line(f"ğŸ“ ë°ì´í„° íŒŒì¼ ì„¤ì •: {current_data_file}")
                    
                    execution_results.append({
                        'step': i + 1,
                        'agent': agent_name,
                        'purpose': purpose,
                        'result': result,
                        'status': 'success',
                        'data_file': current_data_file  # ë°ì´í„° íŒŒì¼ ì •ë³´ í¬í•¨
                    })
                else:
                    await task_updater.stream_line(f"âŒ {agent_name} ì‹¤íŒ¨: {result.get('error', 'Unknown')}")
                    execution_results.append({
                        'step': i + 1,
                        'agent': agent_name,
                        'purpose': purpose,
                        'result': result,
                        'status': 'failed',
                        'data_file': current_data_file
                    })
                
            except Exception as e:
                await task_updater.stream_line(f"âŒ {agent_name} ì˜¤ë¥˜: {str(e)}")
                execution_results.append({
                    'step': i + 1,
                    'agent': agent_name,
                    'purpose': purpose,
                    'error': str(e),
                    'status': 'error',
                    'data_file': current_data_file
                })
        
        return {
            'steps': execution_results,
            'final_data_file': current_data_file,
            'success_count': len([r for r in execution_results if r['status'] == 'success']),
            'total_count': len(execution_results)
        }

    async def _create_data_aware_instruction(self,
                                           agent_name: str,
                                           purpose: str,
                                           user_intent: Dict,
                                           current_data_file: Optional[str]) -> str:
        """ë°ì´í„° ì¸ì‹ ì§€ì‹œ ìƒì„± - ëª…ì‹œì  ë°ì´í„° íŒŒì¼ ì§€ì •"""
        
        base_instruction = f"{purpose} ì‘ì—…ì„ ìˆ˜í–‰í•˜ì„¸ìš”."
        
        # 1. ì‚¬ìš©ì ìš”ì²­ì—ì„œ íŠ¹ì • ë°ì´í„° íŒŒì¼ ì¶”ì¶œ
        user_input = user_intent.get('original_request', '')
        specified_file = None
        
        # ì‚¬ìš©ìê°€ ëª…ì‹œí•œ íŒŒì¼ëª… í™•ì¸
        import re
        file_patterns = [
            r'([a-zA-Z0-9_]+\.csv)',
            r'([a-zA-Z0-9_]+\.xlsx)',
            r'([a-zA-Z0-9_]+\.pkl)',
            r'ion_implant[^\\s]*',
            r'dataset[^\\s]*'
        ]
        
        for pattern in file_patterns:
            match = re.search(pattern, user_input, re.IGNORECASE)
            if match:
                specified_file = match.group(1) if match.group(1).endswith(('.csv', '.xlsx', '.pkl')) else match.group(0)
                break
        
        # 2. ë°ì´í„° íŒŒì¼ ì§€ì‹œ ì¶”ê°€
        if specified_file:
            data_instruction = f"""

ğŸ”¬ **ì‚¬ìš©í•  ë°ì´í„° íŒŒì¼**: {specified_file}
ğŸ“ **ë°ì´í„° íŒŒì¼ ìš°ì„ ìˆœìœ„**: 
   1. {specified_file} (ì‚¬ìš©ì ì§€ì •)
   2. ion_implant ê´€ë ¨ íŒŒì¼ (ë°˜ë„ì²´ ë¶„ì„ìš©)
   3. ê°€ì¥ ìµœê·¼ íŒŒì¼

âš ï¸ **ì¤‘ìš”**: ë°˜ë“œì‹œ ìœ„ ìš°ì„ ìˆœìœ„ì— ë”°ë¼ ë°ì´í„° íŒŒì¼ì„ ì„ íƒí•˜ê³ , ì„ íƒëœ íŒŒì¼ëª…ì„ ì‘ë‹µì— ëª…ì‹œí•´ì£¼ì„¸ìš”.
"""
        elif current_data_file:
            data_instruction = f"""

ğŸ”¬ **ì‚¬ìš©í•  ë°ì´í„° íŒŒì¼**: {current_data_file}
ğŸ“ **ë°ì´í„° ì—°ì†ì„±**: ì´ì „ ë‹¨ê³„ì—ì„œ ì‚¬ìš©ëœ íŒŒì¼ê³¼ ë™ì¼í•œ íŒŒì¼ì„ ì‚¬ìš©í•˜ì„¸ìš”.

âš ï¸ **ì¤‘ìš”**: ë°˜ë“œì‹œ {current_data_file} íŒŒì¼ì„ ì‚¬ìš©í•˜ê³ , ì‘ë‹µì— íŒŒì¼ëª…ì„ ëª…ì‹œí•´ì£¼ì„¸ìš”.
"""
        else:
            data_instruction = f"""

ğŸ”¬ **ë°ì´í„° íŒŒì¼ ì„ íƒ ê¸°ì¤€**:
   1. ion_implant ê´€ë ¨ íŒŒì¼ ìš°ì„  (ë°˜ë„ì²´ ë¶„ì„ íŠ¹í™”)
   2. ê°€ì¥ ìµœê·¼ ìˆ˜ì •ëœ íŒŒì¼
   3. ì‚¬ìš© ê°€ëŠ¥í•œ ì²« ë²ˆì§¸ íŒŒì¼

âš ï¸ **ì¤‘ìš”**: ì„ íƒëœ ë°ì´í„° íŒŒì¼ëª…ì„ ì‘ë‹µì— ë°˜ë“œì‹œ ëª…ì‹œí•´ì£¼ì„¸ìš”.
"""
        
        # 3. ì—ì´ì „íŠ¸ë³„ ë§ì¶¤ ì§€ì‹œ
        agent_specific_instructions = {
            "AI_DS_Team DataLoaderToolsAgent": f"""
{base_instruction}

{data_instruction}

ğŸ“‹ **ì‘ì—… ì„¸ë¶€ì‚¬í•­**:
- ë°ì´í„° íŒŒì¼ì„ ë¡œë“œí•˜ê³  ê¸°ë³¸ ì •ë³´ë¥¼ í™•ì¸
- ë°ì´í„° í¬ê¸°, ì»¬ëŸ¼ ì •ë³´, ë°ì´í„° íƒ€ì… í™•ì¸
- ì‚¬ìš©ëœ íŒŒì¼ëª…ì„ ëª…í™•íˆ í‘œì‹œ
""",
            "AI_DS_Team DataCleaningAgent": f"""
{base_instruction}

{data_instruction}

ğŸ“‹ **ì‘ì—… ì„¸ë¶€ì‚¬í•­**:
- ë°ì´í„° í’ˆì§ˆ ê²€ì‚¬ ë° ì •ë¦¬
- ê²°ì¸¡ê°’, ì¤‘ë³µê°’, ì´ìƒê°’ í™•ì¸
- ì‚¬ìš©ëœ íŒŒì¼ëª…ì„ ëª…í™•íˆ í‘œì‹œ
""",
            "SessionEDAToolsAgent": f"""
{base_instruction}

{data_instruction}

ğŸ“‹ **ì‘ì—… ì„¸ë¶€ì‚¬í•­**:
- íƒìƒ‰ì  ë°ì´í„° ë¶„ì„ ìˆ˜í–‰
- ê¸°ìˆ í†µê³„, ë¶„í¬ ë¶„ì„, ìƒê´€ê´€ê³„ ë¶„ì„
- ì‚¬ìš©ëœ íŒŒì¼ëª…ì„ ëª…í™•íˆ í‘œì‹œ
""",
            "AI_DS_Team DataVisualizationAgent": f"""
{base_instruction}

{data_instruction}

ğŸ“‹ **ì‘ì—… ì„¸ë¶€ì‚¬í•­**:
- ë°ì´í„° ì‹œê°í™” ì°¨íŠ¸ ìƒì„±
- ë¶„í¬ë„, íŠ¸ë Œë“œ ì°¨íŠ¸, ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ
- ì‚¬ìš©ëœ íŒŒì¼ëª…ì„ ëª…í™•íˆ í‘œì‹œ
""",
            "AI_DS_Team DataWranglingAgent": f"""
{base_instruction}

{data_instruction}

ğŸ“‹ **ì‘ì—… ì„¸ë¶€ì‚¬í•­**:
- ë°ì´í„° ë³€í™˜ ë° ê°€ê³µ
- íŒŒìƒ ë³€ìˆ˜ ìƒì„±, ë°ì´í„° í˜•íƒœ ë³€í™˜
- ì‚¬ìš©ëœ íŒŒì¼ëª…ì„ ëª…í™•íˆ í‘œì‹œ
""",
            "AI_DS_Team SQLDatabaseAgent": f"""
{base_instruction}

{data_instruction}

ğŸ“‹ **ì‘ì—… ì„¸ë¶€ì‚¬í•­**:
- SQL ì¿¼ë¦¬ë¥¼ í†µí•œ ë°ì´í„° ë¶„ì„
- ì§‘ê³„, í•„í„°ë§, ì¡°ì¸ ë“±ì˜ ë°ì´í„° ì²˜ë¦¬
- ì‚¬ìš©ëœ íŒŒì¼ëª…ì„ ëª…í™•íˆ í‘œì‹œ
"""
        }
        
        # 4. ìµœì¢… ì§€ì‹œ ë°˜í™˜
        final_instruction = agent_specific_instructions.get(agent_name, f"{base_instruction}{data_instruction}")
        
        return final_instruction

    def _extract_data_file_from_result(self, result: Dict) -> Optional[str]:
        """ì—ì´ì „íŠ¸ ê²°ê³¼ì—ì„œ ë°ì´í„° íŒŒì¼ëª… ì¶”ì¶œ"""
        try:
            # ì‘ë‹µ í…ìŠ¤íŠ¸ì—ì„œ íŒŒì¼ëª… íŒ¨í„´ ì°¾ê¸°
            response_text = str(result.get('content', ''))
            
            # CSV íŒŒì¼ íŒ¨í„´ ê²€ìƒ‰
            import re
            csv_pattern = r'([a-zA-Z0-9_]+\.csv)'
            matches = re.findall(csv_pattern, response_text)
            
            if matches:
                # ion_implant íŒŒì¼ ìš°ì„  ë°˜í™˜
                for match in matches:
                    if 'ion_implant' in match.lower():
                        return match
                # ì²« ë²ˆì§¸ ë§¤ì¹˜ ë°˜í™˜
                return matches[0]
            
            # íŠ¹ì • í‚¤ì›Œë“œë¡œ íŒŒì¼ëª… ì¶”ë¡ 
            if 'ion_implant' in response_text.lower():
                return 'ion_implant_3lot_dataset.csv'
            
            return None
            
        except Exception as e:
            logger.warning(f"ë°ì´í„° íŒŒì¼ëª… ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return None
    
    async def _create_comprehensive_response_streaming(self,
                                                     user_input: str,
                                                     user_intent: Dict,
                                                     execution_result: Dict,
                                                     task_updater: RealTimeStreamingTaskUpdater) -> str:
        """ì¢…í•© ì‘ë‹µ ìƒì„± (ìŠ¤íŠ¸ë¦¬ë°)"""
        
        await task_updater.stream_line("- ë¶„ì„ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
        
        if not self.openai_client:
            return self._create_basic_summary(execution_result)
        
        # execution_result êµ¬ì¡° ìˆ˜ì •: stepsì—ì„œ ì„±ê³µí•œ ê²°ê³¼ë§Œ ì¶”ì¶œ
        successful_results = {}
        failed_agents = []
        
        if 'steps' in execution_result:
            for step in execution_result['steps']:
                agent_name = step.get('agent', 'Unknown')
                if step.get('status') == 'success':
                    successful_results[agent_name] = step
                elif step.get('status') == 'failed':
                    failed_agents.append(f"- {agent_name}: {step.get('error', 'Unknown error')}")
        
        if not successful_results:
            # LLMì„ ì‚¬ìš©í•˜ì—¬ ëŒ€ì•ˆ ì‘ë‹µ ìƒì„±
            if self.openai_client:
                try:
                    fallback_prompt = f"""
                    ì‚¬ìš©ì ìš”ì²­: {user_input}
                    
                    AI ì—ì´ì „íŠ¸ë“¤ê³¼ì˜ í†µì‹ ì´ ì‹¤íŒ¨í–ˆì§€ë§Œ, ë‹¹ì‹ ì˜ ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ì ìš”ì²­ì— ìµœëŒ€í•œ ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.
                    
                    ì‹¤íŒ¨í•œ ì—ì´ì „íŠ¸ë“¤:
                    {chr(10).join(failed_agents) if failed_agents else '- ëª¨ë“  ì—ì´ì „íŠ¸ í†µì‹  ì‹¤íŒ¨'}
                    
                    ì§€ì¹¨:
                    1. ì‚¬ìš©ì ìš”ì²­ì˜ í•µì‹¬ ë‚´ìš©ì— ëŒ€í•´ ì§ì ‘ ë‹µë³€
                    2. ì¼ë°˜ì ì¸ ì ‘ê·¼ ë°©ë²•ê³¼ ê³ ë ¤ì‚¬í•­ ì œì‹œ
                    3. ì‹¤ë¬´ì—ì„œ í™œìš©í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì¸ ì¡°ì–¸ í¬í•¨
                    4. ì¶”ê°€ ì •ë³´ê°€ í•„ìš”í•œ ë¶€ë¶„ ëª…ì‹œ
                    """
                    
                    response = await self.openai_client.chat.completions.create(
                        model="gpt-4o",
                        messages=[{"role": "user", "content": fallback_prompt}],
                        temperature=0.3,
                        max_tokens=2000
                    )
                    
                    await task_updater.stream_line("- âš ï¸ ì—ì´ì „íŠ¸ í†µì‹  ì‹¤íŒ¨, LLM ê¸°ë°˜ ëŒ€ì•ˆ ì‘ë‹µ ìƒì„±")
                    return response.choices[0].message.content
                    
                except Exception as e:
                    logger.error(f"Fallback response generation failed: {e}")
            
            # ìµœí›„ ìˆ˜ë‹¨: ê¸°ë³¸ ì‘ë‹µ
            return f"""
## ë¶„ì„ ìš”ì²­ ì²˜ë¦¬ ê²°ê³¼

âš ï¸ **AI ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œê³¼ì˜ í†µì‹ ì— ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.**

### ìš”ì²­ ë‚´ìš©
{user_input[:200]}{"..." if len(user_input) > 200 else ""}

### ë°œìƒí•œ ë¬¸ì œ
{chr(10).join(failed_agents) if failed_agents else "- ëª¨ë“  AI ì—ì´ì „íŠ¸ì™€ì˜ í†µì‹ ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."}

### ê¶Œì¥ ì¡°ì¹˜
1. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”
2. ìš”ì²­ì„ ë” êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•´ ë³´ì„¸ìš”
3. ë‹¨ê³„ë³„ë¡œ ë‚˜ëˆ„ì–´ ìš”ì²­í•´ ë³´ì„¸ìš”

ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ì‹œìŠ¤í…œ ìƒíƒœë¡œëŠ” ì™„ì „í•œ ë¶„ì„ì„ ì œê³µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
            """
        
        synthesis_prompt = f"""
        ì‚¬ìš©ì ìš”ì²­: {user_input}
        ì‚¬ìš©ì ì˜ë„: {json.dumps(user_intent, ensure_ascii=False)}
        
        ë¶„ì„ ê²°ê³¼:
        {json.dumps(successful_results, ensure_ascii=False, indent=2)[:3000]}
        
        ìœ„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ì ìš”ì²­ì— ëŒ€í•œ ì¢…í•©ì ì¸ ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”.
        
        ì§€ì¹¨:
        1. ì‚¬ìš©ìì˜ {user_intent['action_type']} ìš”ì²­ì— ì§ì ‘ ë‹µë³€
        2. êµ¬ì²´ì ì¸ ë°ì´í„°ì™€ ê·¼ê±° ì œì‹œ
        3. í•µì‹¬ ë°œê²¬ì‚¬í•­ ê°•ì¡°
        4. ì‹¤ìš©ì ì¸ ì¸ì‚¬ì´íŠ¸ ì œê³µ
        """
        
        try:
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": synthesis_prompt}],
                temperature=0.3,
                max_tokens=3000
            )
            
            await task_updater.stream_line("- âœ… ì¢…í•© ì™„ë£Œ")
            
            return response.choices[0].message.content
            
        except Exception as e:
            logger.error(f"Synthesis failed: {e}")
            return self._create_basic_summary(execution_result)
    
    async def _extract_user_intent_precisely(self, user_input: str) -> Dict:
        """ì‚¬ìš©ì ì˜ë„ ì •ë°€ ì¶”ì¶œ"""
        
        if not self.openai_client:
            return {
                'main_goal': user_input,
                'action_type': 'analyze',
                'specific_requirements': [],
                'expected_outcomes': ['ë¶„ì„ ê²°ê³¼']
            }
        
        intent_prompt = f"""
        ì‚¬ìš©ì ì…ë ¥: "{user_input}"
        
        ì˜ë„ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”:
        1. action_type: analyze/verify/recommend/diagnose/predict/compare/explain
        2. main_goal: í•œ ë¬¸ì¥ ìš”ì•½
        3. specific_requirements: êµ¬ì²´ì  ìš”êµ¬ì‚¬í•­
        4. expected_outcomes: ê¸°ëŒ€ ê²°ê³¼
        
        JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”.
        """
        
        try:
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": intent_prompt}],
                response_format={"type": "json_object"},
                temperature=0.2,
                max_tokens=500
            )
            
            return json.loads(response.choices[0].message.content)
            
        except Exception as e:
            logger.warning(f"Intent extraction failed: {e}")
            return {
                'main_goal': user_input,
                'action_type': 'analyze',
                'specific_requirements': [],
                'expected_outcomes': ['ë¶„ì„ ê²°ê³¼']
            }
    
    async def _analyze_request_depth(self, user_input: str) -> Dict:
        """ìš”ì²­ ê¹Šì´ ë¶„ì„"""
        
        if not self.openai_client:
            return {
                'detail_level': 5,
                'has_role_description': False,
                'explicit_requirements': ['ê¸°ë³¸ ë¶„ì„'],
                'implicit_needs': ['ë°ì´í„° ì´í•´']
            }
        
        try:
            analysis_prompt = f"""
            ìš”ì²­ ë¶„ì„: "{user_input}"
            
            ë¶„ì„ í•­ëª©:
            1. êµ¬ì²´ì„± ìˆ˜ì¤€ (1-10)
            2. ëª…ì‹œì  vs ì•”ì‹œì  ìš”êµ¬ì‚¬í•­
            3. ì˜ˆìƒ ì‘ë‹µ ê¹Šì´
            
            JSON ì‘ë‹µ ìš”ì²­
            """
            
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": analysis_prompt}],
                response_format={"type": "json_object"},
                temperature=0.3,
                max_tokens=500
            )
            
            return json.loads(response.choices[0].message.content)
            
        except Exception as e:
            logger.warning(f"Depth analysis failed: {e}")
            return {
                'detail_level': 5,
                'explicit_requirements': ['ê¸°ë³¸ ë¶„ì„']
            }
    
    async def _create_precise_instruction_for_agent(self,
                                                  agent_name: str,
                                                  user_intent: Dict,
                                                  agent_info: Dict) -> str:
        """ì—ì´ì „íŠ¸ë³„ ì •ë°€ ì§€ì‹œ ìƒì„±"""
        
        if not self.openai_client:
            return f"{user_intent['main_goal']}ì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”."
        
        # ì—ì´ì „íŠ¸ ìŠ¤í‚¬ ì •ë³´
        skills = agent_info.get('skills', [])
        skill_names = [s.get('name', '') for s in skills]
        
        instruction_prompt = f"""
        ì—ì´ì „íŠ¸: {agent_name}
        ì—ì´ì „íŠ¸ ìŠ¤í‚¬: {skill_names}
        
        ì‚¬ìš©ì ëª©í‘œ: {user_intent['main_goal']}
        ì•¡ì…˜ íƒ€ì…: {user_intent['action_type']}
        
        ì´ ì—ì´ì „íŠ¸ê°€ ìˆ˜í–‰í•´ì•¼ í•  êµ¬ì²´ì ì¸ ì‘ì—… ì§€ì‹œë¥¼ ì‘ì„±í•˜ì„¸ìš”.
        ì—ì´ì „íŠ¸ì˜ ìŠ¤í‚¬ì„ ìµœëŒ€í•œ í™œìš©í•˜ë„ë¡ ì§€ì‹œí•˜ì„¸ìš”.
        """
        
        try:
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": instruction_prompt}],
                temperature=0.3,
                max_tokens=1000
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            logger.warning(f"Instruction generation failed: {e}")
            return f"{user_intent['main_goal']}ì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”."
    
    async def _create_final_response_single(self,
                                          user_input: str,
                                          agent_name: str,
                                          result: Dict,
                                          user_intent: Dict) -> str:
        """ë‹¨ì¼ ì—ì´ì „íŠ¸ ìµœì¢… ì‘ë‹µ"""
        
        if not self.openai_client:
            return f"{agent_name} ì—ì´ì „íŠ¸ ì‹¤í–‰ ì™„ë£Œ:\n{result.get('summary', 'ì‘ì—… ì™„ë£Œ')}"
        
        response_prompt = f"""
        ì‚¬ìš©ì ìš”ì²­: {user_input}
        ì‚¬ìš©ì ì˜ë„: {user_intent['main_goal']}
        
        {agent_name} ì—ì´ì „íŠ¸ ì‹¤í–‰ ê²°ê³¼:
        {json.dumps(result, ensure_ascii=False)[:2000]}
        
        ì‚¬ìš©ì ìš”ì²­ì— ì§ì ‘ ë‹µë³€í•˜ëŠ” ì‘ë‹µì„ ì‘ì„±í•˜ì„¸ìš”.
        """
        
        try:
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": response_prompt}],
                temperature=0.3,
                max_tokens=2000
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            logger.error(f"Response generation failed: {e}")
            return f"{agent_name} ì‘ì—… ì™„ë£Œ"
    
    def _create_basic_plan(self, available_agents: List[str]) -> Dict:
        """ê¸°ë³¸ ì‹¤í–‰ ê³„íš"""
        steps = []
        
        # ê¸°ë³¸ ì›Œí¬í”Œë¡œìš°
        basic_flow = [
            ('data_loader', 'ë°ì´í„° ë¡œë“œ'),
            ('data_cleaning', 'ë°ì´í„° ì •ì œ'),
            ('eda_tools', 'íƒìƒ‰ì  ë¶„ì„'),
            ('data_visualization', 'ì‹œê°í™”')
        ]
        
        for agent, purpose in basic_flow:
            if agent in available_agents:
                steps.append({
                    'agent': agent,
                    'purpose': purpose,
                    'instruction': f'{purpose} ì‘ì—…ì„ ìˆ˜í–‰í•˜ì„¸ìš”'
                })
        
        return {
            'execution_strategy': 'í‘œì¤€ ë°ì´í„° ë¶„ì„',
            'steps': steps
        }
    
    def _create_basic_summary(self, execution_result: Dict) -> str:
        """ê¸°ë³¸ ìš”ì•½"""
        total = execution_result.get('total_count', 0)
        success = execution_result.get('success_count', 0)
        
        summary = f"## ë¶„ì„ ì™„ë£Œ\n\n"
        summary += f"- ì´ {total}ë‹¨ê³„ ì¤‘ {success}ë‹¨ê³„ ì„±ê³µ\n"
        
        # steps êµ¬ì¡°ì—ì„œ ì •ë³´ ì¶”ì¶œ
        if 'steps' in execution_result:
            for step in execution_result['steps']:
                agent_name = step.get('agent', 'Unknown')
                if step.get('status') == 'success':
                    summary += f"- âœ… {agent_name}: ì™„ë£Œ\n"
                else:
                    summary += f"- âŒ {agent_name}: ì‹¤íŒ¨\n"
        
        return summary


def create_orchestrator_v8_server():
    """v8.0 ì„œë²„ ìƒì„±"""
    
    agent_card = AgentCard(
        name="Universal Intelligent Orchestrator v8.0",
        description="A2A SDK 0.2.9 í‘œì¤€ ê¸°ëŠ¥ ê·¹ëŒ€í™” + ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° í˜ì‹ ",
        url="http://localhost:8100",
        version="8.0.0",
        capabilities=AgentCapabilities(
            streaming=True,
            pushNotifications=True,
            stateTransitionHistory=True
        ),
        defaultInputModes=["text/plain"],
        defaultOutputModes=["text/plain", "application/json"],
        skills=[
            AgentSkill(
                id="real_time_streaming",
                name="Real-Time Character Streaming",
                description="ë¬¸ì ë‹¨ìœ„ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì¦‰ê°ì ì¸ í”¼ë“œë°± ì œê³µ",
                tags=["streaming", "real-time", "responsive"]
            ),
            AgentSkill(
                id="dynamic_discovery",
                name="Dynamic Agent Discovery with A2A",
                description="A2A CardResolverë¥¼ í™œìš©í•œ ì‹¤ì‹œê°„ ì—ì´ì „íŠ¸ ë°œê²¬ ë° í—¬ìŠ¤ ì²´í¬",
                tags=["discovery", "a2a", "health-check"]
            ),
            AgentSkill(
                id="standard_a2a_communication",
                name="Standard A2A Protocol Communication",
                description="A2AClientë¥¼ í†µí•œ í‘œì¤€í™”ëœ ì—ì´ì „íŠ¸ í†µì‹ ",
                tags=["a2a", "protocol", "standard"]
            ),
            AgentSkill(
                id="adaptive_complexity_handling",
                name="Adaptive Complexity Processing",
                description="ìš”ì²­ ë³µì¡ë„ì— ë”°ë¥¸ ì ì‘ì  ì²˜ë¦¬ (Simple/Single/Complex)",
                tags=["adaptive", "intelligent", "complexity"]
            ),
            AgentSkill(
                id="llm_streaming_integration",
                name="LLM Streaming Integration",
                description="OpenAI ìŠ¤íŠ¸ë¦¬ë°ê³¼ ì§ì ‘ í†µí•©ëœ ì‹¤ì‹œê°„ ì‘ë‹µ",
                tags=["llm", "streaming", "openai"]
            )
        ]
    )
    
    executor = UniversalIntelligentOrchestratorV8()
    
    # ì´ˆê¸°í™”ë¥¼ ìœ„í•œ ë¹„ë™ê¸° íƒœìŠ¤í¬
    async def startup():
        await executor.initialize()
    
    task_store = InMemoryTaskStore()
    request_handler = DefaultRequestHandler(
        agent_executor=executor,
        task_store=task_store
    )
    
    app = A2AStarletteApplication(
        agent_card=agent_card,
        http_handler=request_handler
    )
    
    # Starlette ì•±ì— startup ì´ë²¤íŠ¸ ì¶”ê°€
    starlette_app = app.build()
    starlette_app.add_event_handler("startup", startup)
    
    return starlette_app


def main():
    """ë©”ì¸ ì‹¤í–‰"""
    logger.info("ğŸš€ Starting Universal Intelligent Orchestrator v8.0")
    logger.info("ğŸ“¡ A2A SDK 0.2.9 Features: Dynamic Discovery + Real-Time Streaming")
    
    app = create_orchestrator_v8_server()
    
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8100,
        log_level="info"
    )


if __name__ == "__main__":
    main()