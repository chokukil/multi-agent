 class CherryAI_v8_UniversalIntelligentOrchestrator(AgentExecutor):
    """
    CherryAI v8 - Universal Intelligent Orchestrator
    v7 ì¥ì  + A2A í”„ë¡œí† ì½œ ê·¹ëŒ€í™” + v8 ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° í†µí•©
    """
    
    def __init__(self):
        super().__init__()
        
        # v7 í•µì‹¬ ì»´í¬ë„ŒíŠ¸ ìœ ì§€
        self.openai_client = self._initialize_openai_client()
        self.execution_monitor = ExecutionMonitor(self.openai_client)
        self.replanning_engine = A2AEnhancedReplanningEngine(self.openai_client)
        
        # v8 A2A í”„ë¡œí† ì½œ ê·¹ëŒ€í™” ì»´í¬ë„ŒíŠ¸
        self.a2a_discovery = A2AIntelligentAgentDiscovery()
        self.intelligent_matcher = IntelligentAgentMatcher(self.openai_client)
        self.discovered_agents = {}
        
        # v8 ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì»´í¬ë„ŒíŠ¸
        self.streaming_updater = None  # executeì—ì„œ ì´ˆê¸°í™”
        
        logger.info("ğŸš€ CherryAI v8 Universal Intelligent Orchestrator ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _initialize_openai_client(self) -> Optional[AsyncOpenAI]:
        """OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        try:
            api_key = os.getenv("OPENAI_API_KEY")
            if not api_key:
                logger.warning("âš ï¸ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
                return None
            
            return AsyncOpenAI(api_key=api_key)
        except Exception as e:
            logger.error(f"âŒ OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return None
    
    async def execute(self, context: RequestContext) -> None:
        """v8 ë©”ì¸ ì‹¤í–‰ ë¡œì§"""
        
        # v8 ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì´ˆê¸°í™”
        self.streaming_updater = RealTimeStreamingTaskUpdater(
            context.task_updater.task_store,
            context.task_updater.task_id,
            context.task_updater.event_queue
        )
        
        try:
            # ì‚¬ìš©ì ì…ë ¥ ì¶”ì¶œ
            user_input = self._extract_user_input(context)
            if not user_input:
                await self.streaming_updater.stream_update("âŒ ì‚¬ìš©ì ì…ë ¥ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            logger.info(f"ğŸ“ ì‚¬ìš©ì ìš”ì²­: {user_input[:100]}...")
            
            # Phase 1: A2A ë™ì  ì—ì´ì „íŠ¸ ë°œê²¬
            await self.streaming_updater.stream_update("ğŸ” A2A í”„ë¡œí† ì½œë¡œ ì—ì´ì „íŠ¸ë¥¼ ë°œê²¬í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
            self.discovered_agents = await self.a2a_discovery.discover_agents_dynamically()
            
            if not self.discovered_agents:
                await self.streaming_updater.stream_update("âš ï¸ ì‚¬ìš© ê°€ëŠ¥í•œ ì—ì´ì „íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            await self.streaming_updater.stream_update(
                f"âœ… {len(self.discovered_agents)}ê°œì˜ A2A ì—ì´ì „íŠ¸ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤!"
            )
            
            # Phase 2: v7 ì ì‘ì  ë³µì¡ë„ ì²˜ë¦¬ (ìœ ì§€)
            await self.streaming_updater.stream_update("ğŸ§  ìš”ì²­ ë³µì¡ë„ë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
            complexity_assessment = await self._assess_request_complexity(user_input)
            
            complexity_level = complexity_assessment.get('complexity_level', 'complex')
            await self.streaming_updater.stream_update(
                f"ğŸ“Š ìš”ì²­ ë³µì¡ë„: {complexity_level} (ì ìˆ˜: {complexity_assessment.get('complexity_score', 0)})"
            )
            
            # Phase 3: ë³µì¡ë„ë³„ ì²˜ë¦¬ ë¶„ê¸°
            if complexity_level == 'simple':
                await self._handle_simple_request(user_input, complexity_assessment)
            elif complexity_level == 'single_agent':
                await self._handle_single_agent_request(user_input, complexity_assessment)
            else:
                await self._handle_complex_request(user_input, complexity_assessment)
                
        except Exception as e:
            logger.error(f"âŒ v8 ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
            await self.streaming_updater.stream_update(f"âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    
    def _extract_user_input(self, context: RequestContext) -> str:
        """ì‚¬ìš©ì ì…ë ¥ ì¶”ì¶œ"""
        try:
            if context.message and context.message.parts:
                for part in context.message.parts:
                    if hasattr(part.root, 'kind') and part.root.kind == 'text':
                        return part.root.text
                    elif hasattr(part.root, 'type') and part.root.type == 'text':
                        return part.root.text
            return ""
        except Exception as e:
            logger.error(f"ì‚¬ìš©ì ì…ë ¥ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return ""
    
    async def _assess_request_complexity(self, user_input: str) -> Dict:
        """v7 ì ì‘ì  ë³µì¡ë„ ì²˜ë¦¬ ì‹œìŠ¤í…œ (ìœ ì§€)"""
        
        if not self.openai_client:
            return self._create_fallback_complexity_assessment(user_input)
        
        complexity_prompt = f"""
        ë‹¤ìŒ ì‚¬ìš©ì ìš”ì²­ì˜ ë³µì¡ë„ë¥¼ ë¶„ì„í•˜ì„¸ìš”:
        "{user_input}"
        
        ë³µì¡ë„ ê¸°ì¤€:
        1. **Simple (1-3ì )**: ê°„ë‹¨í•œ ì§ˆë¬¸, ì •ë³´ ìš”ì²­, ê¸°ë³¸ ì„¤ëª…
        2. **Single Agent (4-6ì )**: íŠ¹ì • ë„êµ¬ë‚˜ ì—ì´ì „íŠ¸ í•˜ë‚˜ë¡œ í•´ê²° ê°€ëŠ¥
        3. **Complex (7-10ì )**: ì—¬ëŸ¬ ë‹¨ê³„, ë‹¤ì¤‘ ì—ì´ì „íŠ¸, ì¢…í•©ì  ë¶„ì„ í•„ìš”
        
        í‰ê°€ ìš”ì†Œ:
        - ìš”ì²­ì˜ êµ¬ì²´ì„±ê³¼ ë²”ìœ„
        - í•„ìš”í•œ ë°ì´í„° ì²˜ë¦¬ ë‹¨ê³„ ìˆ˜
        - ìš”êµ¬ë˜ëŠ” ì „ë¬¸ì„± ìˆ˜ì¤€
        - ì˜ˆìƒ ì†Œìš” ì‹œê°„ê³¼ ë¦¬ì†ŒìŠ¤
        
        JSON ì‘ë‹µ:
        {{
            "complexity_level": "simple|single_agent|complex",
            "complexity_score": 1-10,
            "reasoning": "ë³µì¡ë„ íŒë‹¨ ê·¼ê±°",
            "estimated_steps": ì˜ˆìƒ_ë‹¨ê³„_ìˆ˜,
            "required_expertise": ["í•„ìš”í•œ_ì „ë¬¸_ì˜ì—­ë“¤"],
            "processing_approach": "ê¶Œì¥_ì²˜ë¦¬_ë°©ì‹"
        }}
        """
        
        try:
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": complexity_prompt}],
                response_format={"type": "json_object"},
                temperature=0.3,
                timeout=30.0
            )
            
            return json.loads(response.choices[0].message.content)
            
        except Exception as e:
            logger.warning(f"ë³µì¡ë„ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return self._create_fallback_complexity_assessment(user_input)
    
    def _create_fallback_complexity_assessment(self, user_input: str) -> Dict:
        """í´ë°± ë³µì¡ë„ í‰ê°€"""
        # ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹± ê¸°ë°˜ í‰ê°€
        word_count = len(user_input.split())
        question_marks = user_input.count('?')
        keywords = ['ë¶„ì„', 'ì˜ˆì¸¡', 'ëª¨ë¸ë§', 'ì‹œê°í™”', 'ë¹„êµ', 'ì¶”ì²œ']
        keyword_count = sum(1 for keyword in keywords if keyword in user_input)
        
        if word_count < 10 and question_marks > 0:
            return {
                'complexity_level': 'simple',
                'complexity_score': 2,
                'reasoning': 'ì§§ì€ ì§ˆë¬¸',
                'estimated_steps': 1,
                'required_expertise': ['general'],
                'processing_approach': 'direct_answer'
            }
        elif keyword_count == 1 and word_count < 30:
            return {
                'complexity_level': 'single_agent',
                'complexity_score': 5,
                'reasoning': 'ë‹¨ì¼ ì‘ì—… ìš”ì²­',
                'estimated_steps': 2,
                'required_expertise': ['data_analysis'],
                'processing_approach': 'single_agent'
            }
        else:
            return {
                'complexity_level': 'complex',
                'complexity_score': 8,
                'reasoning': 'ë³µí•©ì  ìš”ì²­',
                'estimated_steps': 5,
                'required_expertise': ['data_analysis', 'visualization'],
                'processing_approach': 'multi_agent'
            }
    
    async def _handle_simple_request(self, user_input: str, complexity_assessment: Dict):
        """Simple ìš”ì²­ ì²˜ë¦¬ - ì¦‰ì‹œ ë‹µë³€"""
        
        await self.streaming_updater.stream_update("ğŸ’¡ ê°„ë‹¨í•œ ìš”ì²­ìœ¼ë¡œ íŒë‹¨ë˜ì–´ ì¦‰ì‹œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤...")
        
        if not self.openai_client:
            await self.streaming_updater.stream_response_progressively(
                "ì£„ì†¡í•©ë‹ˆë‹¤. OpenAI APIê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            )
            return
        
        simple_prompt = f"""
        ë‹¤ìŒ ì§ˆë¬¸ì— ëª…í™•í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”:
        "{user_input}"
        
        ë‹µë³€ ìš”êµ¬ì‚¬í•­:
        - ì •í™•í•˜ê³  êµ¬ì²´ì ì¸ ì •ë³´ ì œê³µ
        - í•„ìš”ì‹œ ì˜ˆì‹œë‚˜ ì„¤ëª… í¬í•¨
        - ì¶”ê°€ ë„ì›€ì´ í•„ìš”í•œ ê²½ìš° ì•ˆë‚´
        """
        
        try:
            # LLM ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ
            stream = await self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": simple_prompt}],
                stream=True,
                temperature=0.5,
                timeout=60.0
            )
            
            # ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ë‹µë³€ ì „ë‹¬
            final_response = await self.streaming_updater.stream_llm_response_realtime(stream)
            
            logger.info(f"âœ… Simple ìš”ì²­ ì²˜ë¦¬ ì™„ë£Œ: {len(final_response)} ë¬¸ì")
            
        except Exception as e:
            logger.error(f"Simple ìš”ì²­ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            await self.streaming_updater.stream_response_progressively(
                f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            )
    
    async def _handle_single_agent_request(self, user_input: str, complexity_assessment: Dict):
        """Single Agent ìš”ì²­ ì²˜ë¦¬ - ìµœì  ì—ì´ì „íŠ¸ ì§ì ‘ ì‹¤í–‰"""
        
        await self.streaming_updater.stream_update("ğŸ¯ ë‹¨ì¼ ì—ì´ì „íŠ¸ë¡œ ì²˜ë¦¬ ê°€ëŠ¥í•œ ìš”ì²­ì…ë‹ˆë‹¤...")
        
        # 1. ì‚¬ìš©ì ì˜ë„ ì •ë°€ ì¶”ì¶œ
        user_intent = await self._extract_user_intent_precisely(user_input)
        
        # 2. A2A ì§€ëŠ¥ì  ì—ì´ì „íŠ¸ ë§¤ì¹­
        agent_matching = await self.intelligent_matcher.match_agents_to_intent(
            user_intent, self.discovered_agents
        )
        
        if not agent_matching.get('primary_workflow'):
            await self.streaming_updater.stream_response_progressively(
                "ì í•©í•œ ì—ì´ì „íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë³µí•© ì²˜ë¦¬ë¡œ ì „í™˜í•©ë‹ˆë‹¤."
            )
            await self._handle_complex_request(user_input, complexity_assessment)
            return
        
        # 3. ìµœì  ì—ì´ì „íŠ¸ ì‹¤í–‰
        best_agent = agent_matching['primary_workflow'][0]
        agent_name = best_agent['agent_name']
        
        await self.streaming_updater.stream_update(f"ğŸ¤– {agent_name} ì—ì´ì „íŠ¸ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤...")
        
        # 4. ì •ë°€í•œ ì—ì´ì „íŠ¸ ì§€ì‹œ ìƒì„±
        precise_instruction = await self._create_precise_agent_instruction(
            user_intent, best_agent, context={}
        )
        
        # 5. ì—ì´ì „íŠ¸ ì‹¤í–‰
        agent_result = await self._execute_single_agent(
            agent_name, precise_instruction, user_intent
        )
        
        # 6. ê²°ê³¼ ê²€ì¦ ë° ìµœì¢… ì‘ë‹µ
        if agent_result.get('status') == 'success':
            final_response = await self._create_evidence_based_response(
                [agent_result], user_intent, agent_matching
            )
            await self.streaming_updater.stream_with_sections(final_response)
        else:
            await self.streaming_updater.stream_response_progressively(
                f"ì—ì´ì „íŠ¸ ì‹¤í–‰ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì˜¤ë¥˜: {agent_result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}"
            )
    
    async def _handle_complex_request(self, user_input: str, complexity_assessment: Dict):
        """Complex ìš”ì²­ ì²˜ë¦¬ - v7 ì „ì²´ ì›Œí¬í”Œë¡œìš° + A2A ê°•í™”"""
        
        await self.streaming_updater.stream_update("ğŸ”„ ë³µí•©ì ì¸ ìš”ì²­ìœ¼ë¡œ ì „ì²´ ì›Œí¬í”Œë¡œìš°ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤...")
        
        # 1. v7 ì •ë°€í•œ ì‚¬ìš©ì ì˜ë„ ì¶”ì¶œ (ìœ ì§€)
        await self.streaming_updater.stream_update("ğŸ¯ ì‚¬ìš©ì ì˜ë„ë¥¼ ì •ë°€í•˜ê²Œ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
        user_intent = await self._extract_user_intent_precisely(user_input)
        
        # 2. A2A ì§€ëŠ¥ì  ì—ì´ì „íŠ¸ ë§¤ì¹­ (ì‹ ê·œ)
        await self.streaming_updater.stream_update("ğŸ¤– ìµœì ì˜ ì—ì´ì „íŠ¸ ì¡°í•©ì„ ì°¾ê³  ìˆìŠµë‹ˆë‹¤...")
        agent_matching = await self.intelligent_matcher.match_agents_to_intent(
            user_intent, self.discovered_agents
        )
        
        if not agent_matching.get('primary_workflow'):
            await self.streaming_updater.stream_response_progressively(
                "ì í•©í•œ ì—ì´ì „íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            )
            return
        
        # 3. ì‹¤í–‰ ê³„íš ìƒì„±
        execution_plan = agent_matching['primary_workflow']
        await self.streaming_updater.stream_update(
            f"ğŸ“‹ {len(execution_plan)}ë‹¨ê³„ ì‹¤í–‰ ê³„íšì„ ìˆ˜ë¦½í–ˆìŠµë‹ˆë‹¤."
        )
        
        # 4. ìˆœì°¨ ì‹¤í–‰ with ë¦¬í”Œë˜ë‹
        execution_results = []
        execution_context = {'user_intent': user_intent}
        
        for step_idx, step in enumerate(execution_plan):
            agent_name = step['agent_name']
            
            await self.streaming_updater.stream_update(
                f"ğŸ”„ ë‹¨ê³„ {step_idx + 1}/{len(execution_plan)}: {agent_name} ì‹¤í–‰ ì¤‘..."
            )
            
            # ì •ë°€í•œ ì—ì´ì „íŠ¸ ì§€ì‹œ ìƒì„±
            precise_instruction = await self._create_precise_agent_instruction(
                user_intent, step, execution_context
            )
            
            # ì—ì´ì „íŠ¸ ì‹¤í–‰
            agent_result = await self._execute_single_agent(
                agent_name, precise_instruction, user_intent
            )
            
            # ê²°ê³¼ ê²€ì¦
            validation_result = await self._validate_agent_response(
                agent_result, step, user_intent
            )
            
            agent_result['validation'] = validation_result
            execution_results.append({
                'step': step_idx + 1,
                'agent': agent_name,
                'result': agent_result
            })
            
            # ë¦¬í”Œë˜ë‹ í•„ìš”ì„± ê²€í† 
            should_replan = await self.execution_monitor.should_replan(
                step_idx, agent_result, execution_plan[step_idx+1:], user_intent
            )
            
            if should_replan.get('should_replan'):
                await self.streaming_updater.stream_update(
                    f"ğŸ”„ ë¦¬í”Œë˜ë‹ì´ í•„ìš”í•©ë‹ˆë‹¤: {should_replan.get('reason')}"
                )
                
                # A2A ê°•í™” ë¦¬í”Œë˜ë‹
                replan_result = await self.replanning_engine.create_a2a_enhanced_replan(
                    should_replan, 
                    {'failed_agent': agent_name if agent_result.get('status') == 'failed' else None},
                    execution_plan[step_idx+1:],
                    user_intent,
                    execution_results,
                    self.discovered_agents
                )
                
                if replan_result.get('strategy') != 'continue':
                    execution_plan = execution_plan[:step_idx+1] + replan_result.get('steps', [])
                    await self.streaming_updater.stream_update(
                        f"ğŸ“‹ ì‹¤í–‰ ê³„íšì´ ìˆ˜ì •ë˜ì—ˆìŠµë‹ˆë‹¤. ì „ëµ: {replan_result.get('strategy')}"
                    )
            
            # ì‹¤í–‰ ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
            execution_context[f'step_{step_idx+1}_result'] = agent_result
        
        # 5. ìµœì¢… ì¢…í•© ì‘ë‹µ ìƒì„±
        await self.streaming_updater.stream_update("ğŸ“ ìµœì¢… ì¢…í•© ë¶„ì„ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
        
        final_response = await self._create_evidence_based_response(
            execution_results, user_intent, agent_matching
        )
        
        # 6. v8 ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ìµœì¢… ì‘ë‹µ ì „ë‹¬
        await self.streaming_updater.stream_with_sections(final_response)
        
        logger.info(f"âœ… Complex ìš”ì²­ ì²˜ë¦¬ ì™„ë£Œ: {len(execution_results)}ë‹¨ê³„ ì‹¤í–‰")
    
    async def _extract_user_intent_precisely(self, user_input: str) -> Dict:
        """v7 ì •ë°€í•œ ì‚¬ìš©ì ì˜ë„ ì¶”ì¶œ (ìœ ì§€)"""
        
        if not self.openai_client:
            return self._create_fallback_intent(user_input)
        
        intent_prompt = f"""
        ë‹¤ìŒ ì‚¬ìš©ì ìš”ì²­ì„ ì •ë°€í•˜ê²Œ ë¶„ì„í•˜ì—¬ ì˜ë„ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”:
        "{user_input}"
        
        ì¶”ì¶œí•  ì •ë³´:
        1. **ì£¼ìš” ëª©í‘œ**: ì‚¬ìš©ìê°€ ê¶ê·¹ì ìœ¼ë¡œ ì›í•˜ëŠ” ê²ƒ
        2. **í–‰ë™ ìœ í˜•**: analyze|verify|recommend|diagnose|predict|compare|explain
        3. **ë¶„ì„ ì´ˆì **: ì–´ë–¤ ì¸¡ë©´ì— ì§‘ì¤‘í•´ì•¼ í•˜ëŠ”ê°€
        4. **ê¸°ëŒ€ ê²°ê³¼**: ì‚¬ìš©ìê°€ ê¸°ëŒ€í•˜ëŠ” êµ¬ì²´ì  ì‚°ì¶œë¬¼
        5. **ê¸´ê¸‰ì„±**: immediate|normal|thorough
        6. **ì „ë¬¸ì„± ìˆ˜ì¤€**: beginner|intermediate|expert
        
        JSON ì‘ë‹µ:
        {{
            "main_goal": "êµ¬ì²´ì ì¸ ëª©í‘œ",
            "action_type": "í–‰ë™_ìœ í˜•",
            "analysis_focus": ["ì´ˆì _ì˜ì—­ë“¤"],
            "expected_outcomes": ["ê¸°ëŒ€_ê²°ê³¼ë“¤"],
            "urgency": "ê¸´ê¸‰ì„±_ìˆ˜ì¤€",
            "expertise_level": "ì „ë¬¸ì„±_ìˆ˜ì¤€",
            "domain": "ì£¼ìš”_ë„ë©”ì¸",
            "specific_requirements": ["êµ¬ì²´ì _ìš”êµ¬ì‚¬í•­ë“¤"]
        }}
        """
        
        try:
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": intent_prompt}],
                response_format={"type": "json_object"},
                temperature=0.3,
                timeout=45.0
            )
            
            return json.loads(response.choices[0].message.content)
            
        except Exception as e:
            logger.warning(f"ì˜ë„ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return self._create_fallback_intent(user_input)
    
    def _create_fallback_intent(self, user_input: str) -> Dict:
        """í´ë°± ì˜ë„ ì¶”ì¶œ"""
        return {
            "main_goal": user_input,
            "action_type": "analyze",
            "analysis_focus": ["general"],
            "expected_outcomes": ["analysis_result"],
            "urgency": "normal",
            "expertise_level": "intermediate",
            "domain": "data_analysis",
            "specific_requirements": []
        }
    
    async def _create_precise_agent_instruction(self, 
                                              user_intent: Dict,
                                              agent_step: Dict,
                                              context: Dict) -> str:
        """v7 ì •ë°€í•œ ì—ì´ì „íŠ¸ ì§€ì‹œ ìƒì„± (A2A ê°•í™”)"""
        
        agent_name = agent_step.get('agent_name', '')
        skill_id = agent_step.get('skill_id', '')
        
        # A2A Agent Cardì—ì„œ ì‹¤ì œ ìŠ¤í‚¬ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        agent_info = self.discovered_agents.get(agent_name, {})
        skill_info = {}
        if hasattr(agent_info, 'skills') and skill_id in agent_info.skills:
            skill_info = agent_info.skills[skill_id]
        
        if not self.openai_client:
            return self._create_fallback_instruction(user_intent, agent_name)
        
        instruction_prompt = f"""
        A2A ì—ì´ì „íŠ¸ë¥¼ ìœ„í•œ ì •ë°€í•œ ì‘ì—… ì§€ì‹œë¥¼ ìƒì„±í•˜ì„¸ìš”.
        
        ì—ì´ì „íŠ¸ ì •ë³´:
        - ì´ë¦„: {agent_name}
        - ì‚¬ìš©í•  ìŠ¤í‚¬: {skill_id}
        - ìŠ¤í‚¬ ì„¤ëª…: {skill_info.get('description', '')}
        - ìŠ¤í‚¬ ì˜ˆì‹œ: {skill_info.get('examples', [])}
        
        ì‚¬ìš©ì ì˜ë„:
        {json.dumps(user_intent, ensure_ascii=False, indent=2)}
        
        ì‹¤í–‰ ì»¨í…ìŠ¤íŠ¸:
        {json.dumps({k: str(v)[:200] for k, v in context.items()}, ensure_ascii=False, indent=2)}
        
        ë‹¤ìŒ ìš”êµ¬ì‚¬í•­ì„ ì¶©ì¡±í•˜ëŠ” êµ¬ì²´ì  ì§€ì‹œë¥¼ ìƒì„±í•˜ì„¸ìš”:
        1. **ëª…í™•í•œ ì‘ì—… ì •ì˜**: ì •í™•íˆ ë¬´ì—‡ì„ í•´ì•¼ í•˜ëŠ”ì§€
        2. **ì…ë ¥ ë°ì´í„° ëª…ì‹œ**: ì–´ë–¤ ë°ì´í„°ë¥¼ ì‚¬ìš©í• ì§€
        3. **ì¶œë ¥ í˜•ì‹ ì§€ì •**: ê²°ê³¼ë¥¼ ì–´ë–¤ í˜•íƒœë¡œ ì œê³µí• ì§€
        4. **í’ˆì§ˆ ê¸°ì¤€**: ê²°ê³¼ê°€ ë§Œì¡±í•´ì•¼ í•  ì¡°ê±´
        5. **ì—ëŸ¬ ì²˜ë¦¬**: ë¬¸ì œ ë°œìƒì‹œ ëŒ€ì‘ ë°©ë²•
        
        ì—ì´ì „íŠ¸ê°€ ì´í•´í•˜ê¸° ì‰¬ìš´ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”.
        """
        
        try:
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": instruction_prompt}],
                temperature=0.4,
                timeout=45.0
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            logger.warning(f"ì •ë°€ ì§€ì‹œ ìƒì„± ì‹¤íŒ¨: {e}")
            return self._create_fallback_instruction(user_intent, agent_name)
    
    def _create_fallback_instruction(self, user_intent: Dict, agent_name: str) -> str:
        """í´ë°± ì§€ì‹œ ìƒì„±"""
        main_goal = user_intent.get('main_goal', '')
        action_type = user_intent.get('action_type', 'analyze')
        
        return f"""
        {agent_name} ì—ì´ì „íŠ¸ ì‘ì—… ìš”ì²­:
        
        ëª©í‘œ: {main_goal}
        ì‘ì—… ìœ í˜•: {action_type}
        
        ìš”ì²­ì‚¬í•­:
        1. ì œê³µëœ ë°ì´í„°ë¥¼ {action_type}í•˜ì„¸ìš”
        2. ê²°ê³¼ë¥¼ ëª…í™•í•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ ì œê³µí•˜ì„¸ìš”
        3. ë¬¸ì œê°€ ìˆìœ¼ë©´ ìƒì„¸í•œ ì˜¤ë¥˜ ì •ë³´ë¥¼ í¬í•¨í•˜ì„¸ìš”
        """
    
    async def _execute_single_agent(self, agent_name: str, instruction: str, user_intent: Dict) -> Dict:
        """ë‹¨ì¼ ì—ì´ì „íŠ¸ ì‹¤í–‰"""
        
        # A2A ì—ì´ì „íŠ¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        agent_info = self.discovered_agents.get(agent_name)
        if not agent_info:
            return {
                'status': 'failed',
                'error': f'ì—ì´ì „íŠ¸ {agent_name}ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤',
                'result': None
            }
        
        try:
            # A2A í´ë¼ì´ì–¸íŠ¸ë¡œ ì—ì´ì „íŠ¸ í˜¸ì¶œ
            async with httpx.AsyncClient(timeout=120.0) as client:
                a2a_client = A2AClient(httpx_client=client, base_url=agent_info.url)
                
                # A2A í‘œì¤€ ë©”ì‹œì§€ ìƒì„±
                message = {
                    "parts": [{"kind": "text", "text": instruction}],
                    "messageId": f"msg_{int(time.time())}",
                    "role": "user"
                }
                
                # ì—ì´ì „íŠ¸ ì‹¤í–‰
                response = await a2a_client.send_message(message)
                
                if response and hasattr(response, 'parts') and response.parts:
                    result_text = ""
                    for part in response.parts:
                        if hasattr(part.root, 'text'):
                            result_text += part.root.text
                    
                    return {
                        'status': 'success',
                        'result': result_text,
                        'agent_name': agent_name,
                        'instruction': instruction
                    }
                else:
                    return {
                        'status': 'failed',
                        'error': 'ì—ì´ì „íŠ¸ì—ì„œ ì‘ë‹µì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤',
                        'result': None
                    }
                    
        except Exception as e:
            logger.error(f"ì—ì´ì „íŠ¸ {agent_name} ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return {
                'status': 'failed',
                'error': str(e),
                'result': None
            }
    
    async def _validate_agent_response(self, agent_result: Dict, step: Dict, user_intent: Dict) -> Dict:
        """ì—ì´ì „íŠ¸ ì‘ë‹µ ê²€ì¦"""
        
        if agent_result.get('status') != 'success':
            return {
                'is_valid': False,
                'confidence': 0.0,
                'warnings': ['ì—ì´ì „íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨'],
                'evidence_score': 0.0
            }
        
        result_text = agent_result.get('result', '')
        
        # ê¸°ë³¸ì ì¸ ê²€ì¦
        if not result_text or len(result_text.strip()) < 10:
            return {
                'is_valid': False,
                'confidence': 0.2,
                'warnings': ['ì‘ë‹µì´ ë„ˆë¬´ ì§§ê±°ë‚˜ ë¹„ì–´ìˆìŒ'],
                'evidence_score': 0.1
            }
        
        # ì˜¤ë¥˜ ë©”ì‹œì§€ ê²€ì¶œ
        error_indicators = ['ì˜¤ë¥˜', 'error', 'ì‹¤íŒ¨', 'ë¬¸ì œ', 'ë¶ˆê°€ëŠ¥']
        if any(indicator in result_text.lower() for indicator in error_indicators):
            return {
                'is_valid': False,
                'confidence': 0.3,
                'warnings': ['ì˜¤ë¥˜ ë©”ì‹œì§€ í¬í•¨'],
                'evidence_score': 0.2
            }
        
        return {
            'is_valid': True,
            'confidence': 0.8,
            'warnings': [],
            'evidence_score': 0.8
        }
    
    async def _create_evidence_based_response(self, 
                                            execution_results: List[Dict],
                                            user_intent: Dict,
                                            agent_matching: Dict) -> str:
        """ì¦ê±° ê¸°ë°˜ ìµœì¢… ì‘ë‹µ ìƒì„±"""
        
        if not self.openai_client:
            return self._create_fallback_final_response(execution_results, user_intent)
        
        # ì‹¤í–‰ ê²°ê³¼ ìš”ì•½
        results_summary = []
        for exec_result in execution_results:
            result_info = {
                'step': exec_result['step'],
                'agent': exec_result['agent'],
                'status': exec_result['result'].get('status'),
                'content': exec_result['result'].get('result', '')[:500],  # ì²˜ìŒ 500ìë§Œ
                'validation': exec_result['result'].get('validation', {})
            }
            results_summary.append(result_info)
        
        synthesis_prompt = f"""
        ë‹¤ìŒ A2A ì—ì´ì „íŠ¸ ì‹¤í–‰ ê²°ê³¼ë“¤ì„ ì¢…í•©í•˜ì—¬ ì‚¬ìš©ì ìš”ì²­ì— ëŒ€í•œ ì™„ì „í•œ ë‹µë³€ì„ ìƒì„±í•˜ì„¸ìš”.
        
        ì‚¬ìš©ì ì˜ë„:
        {json.dumps(user_intent, ensure_ascii=False, indent=2)}
        
        ì—ì´ì „íŠ¸ ì‹¤í–‰ ê²°ê³¼:
        {json.dumps(results_summary, ensure_ascii=False, indent=2)}
        
        ì‘ë‹µ ìš”êµ¬ì‚¬í•­:
        1. **ì‚¬ìš©ì ëª©í‘œ ë‹¬ì„±**: {user_intent.get('main_goal', '')}ì— ì§ì ‘ì ìœ¼ë¡œ ë‹µë³€
        2. **ì¦ê±° ê¸°ë°˜**: ì‹¤ì œ ì—ì´ì „íŠ¸ ê²°ê³¼ë§Œ ì‚¬ìš©, ì¶”ì¸¡ ê¸ˆì§€
        3. **êµ¬ì¡°í™”ëœ ë‹µë³€**: ëª…í™•í•œ ì„¹ì…˜ê³¼ í—¤ë” ì‚¬ìš©
        4. **ì‹¤í–‰ ê°€ëŠ¥í•œ ì¸ì‚¬ì´íŠ¸**: êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì •ë³´ ì œê³µ
        5. **í•œê³„ì  ëª…ì‹œ**: ë¶€ì¡±í•œ ë¶€ë¶„ì´ë‚˜ ì¶”ê°€ ë¶„ì„ í•„ìš” ì‚¬í•­ í‘œì‹œ
        
        Markdown í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
        """
        
        try:
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": synthesis_prompt}],
                temperature=0.5,
                timeout=90.0
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            logger.error(f"ìµœì¢… ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
            return self._create_fallback_final_response(execution_results, user_intent)
    
    def _create_fallback_final_response(self, execution_results: List[Dict], user_intent: Dict) -> str:
        """í´ë°± ìµœì¢… ì‘ë‹µ"""
        response = f"# {user_intent.get('main_goal', 'ë¶„ì„ ê²°ê³¼')}\n\n"
        
        for exec_result in execution_results:
            agent_name = exec_result['agent']
            result = exec_result['result']
            
            response += f"## {agent_name} ê²°ê³¼\n\n"
            
            if result.get('status') == 'success':
                response += f"{result.get('result', 'ê²°ê³¼ ì—†ìŒ')}\n\n"
            else:
                response += f"âš ï¸ ì‹¤í–‰ ì‹¤íŒ¨: {result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}\n\n"
        
        response += "---\n\n*CherryAI v8 Universal Intelligent Orchestratorë¡œ ìƒì„±ëœ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤.*"
        
        return response
    
    async def cancel(self, context: RequestContext) -> None:
        """ì‘ì—… ì·¨ì†Œ"""
        logger.info("ğŸ›‘ CherryAI v8 ì‘ì—…ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤")
        if self.streaming_updater:
            await self.streaming_updater.stream_update("ğŸ›‘ ì‘ì—…ì´ ì‚¬ìš©ìì— ì˜í•´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")


# Agent Card ì •ì˜
def create_agent_card() -> AgentCard:
    """CherryAI v8 Agent Card ìƒì„±"""
    return AgentCard(
        name="CherryAI v8 Universal Intelligent Orchestrator",
        description="v7 ì¥ì  + A2A í”„ë¡œí† ì½œ ê·¹ëŒ€í™” + v8 ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°ì„ í†µí•©í•œ ë²”ìš© ì§€ëŠ¥í˜• ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°",
        skills=[
            AgentSkill(
                id="universal_analysis",
                name="ë²”ìš© ë°ì´í„° ë¶„ì„",
                description="ëª¨ë“  ì¢…ë¥˜ì˜ ë°ì´í„° ë¶„ì„ ìš”ì²­ì„ A2A ì—ì´ì „íŠ¸ë“¤ê³¼ í˜‘ë ¥í•˜ì—¬ ì²˜ë¦¬",
                tags=["data-analysis", "orchestration", "a2a", "streaming"],
                examples=[
                    "ë°ì´í„°ì…‹ì˜ íŒ¨í„´ê³¼ ì´ìƒì¹˜ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”",
                    "ë§¤ì¶œ ë°ì´í„°ì˜ íŠ¸ë Œë“œë¥¼ ì˜ˆì¸¡í•´ì£¼ì„¸ìš”", 
                    "ê³ ê° ì„¸ë¶„í™” ë¶„ì„ì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”"
                ]
            ),
            AgentSkill(
                id="intelligent_replanning",
                name="ì§€ëŠ¥ì  ë¦¬í”Œë˜ë‹",
                description="ì‹¤í–‰ ì¤‘ ë¬¸ì œ ë°œìƒì‹œ A2A ì—ì´ì „íŠ¸ ì •ë³´ë¥¼ í™œìš©í•œ ë™ì  ê³„íš ìˆ˜ì •",
                tags=["replanning", "adaptive", "a2a-discovery"],
                examples=[
                    "ì—ì´ì „íŠ¸ ì‹¤íŒ¨ì‹œ ëŒ€ì²´ ì—ì´ì „íŠ¸ë¡œ ìë™ ì „í™˜",
                    "ìƒˆë¡œìš´ ë°œê²¬ì— ë”°ë¥¸ ë¶„ì„ ë°©í–¥ ì¡°ì •"
                ]
            ),
            AgentSkill(
                id="realtime_streaming",
                name="ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°",
                description="ë¶„ì„ ê³¼ì •ê³¼ ê²°ê³¼ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ìŠ¤íŠ¸ë¦¬ë°í•˜ì—¬ ì‚¬ìš©ì ê²½í—˜ í–¥ìƒ",
                tags=["streaming", "realtime", "progressive"],
                examples=[
                    "ë¶„ì„ ì§„í–‰ ìƒí™©ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ í™•ì¸",
                    "ê²°ê³¼ë¥¼ ì ì§„ì ìœ¼ë¡œ ë°›ì•„ë³´ê¸°"
                ]
            )
        ],
        capabilities=AgentCapabilities(
            streaming=True,
            pushNotifications=False,
            supportsAuthenticatedExtendedCard=False
        )
    )


# ì„œë²„ ì‹¤í–‰ ë¶€ë¶„
if __name__ == "__main__":
    # A2A ì„œë²„ ì„¤ì •
    task_store = InMemoryTaskStore()
    event_queue = EventQueue()
    
    # ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ìƒì„±
    orchestrator = CherryAI_v8_UniversalIntelligentOrchestrator()
    
    # ìš”ì²­ í•¸ë“¤ëŸ¬ ì„¤ì •
    request_handler = DefaultRequestHandler(
        agent_executor=orchestrator,
        task_store=task_store,
        event_queue=event_queue
    )
    
    # A2A ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒì„±
    app = A2AStarletteApplication(
        agent_card=create_agent_card(),
        request_handler=request_handler
    )
    
    # ì„œë²„ ì‹¤í–‰
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8100,
        log_level="info"
    ) 