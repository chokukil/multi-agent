#!/usr/bin/env python3
"""
MLflow Tools Server - A2A SDK 0.2.9 ë˜í•‘ êµ¬í˜„

ì›ë³¸ ai-data-science-team MLflowToolsAgentë¥¼ A2A SDK 0.2.9ë¡œ ë˜í•‘í•˜ì—¬
8ê°œ í•µì‹¬ ê¸°ëŠ¥ì„ 100% ë³´ì¡´í•©ë‹ˆë‹¤.

í¬íŠ¸: 8314
"""

import sys
import os
import logging
from pathlib import Path
import pandas as pd
import numpy as np
import io
import json
import time
from typing import Dict, Any

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# A2A SDK imports
from a2a.server.apps import A2AStarletteApplication
from a2a.server.agent_execution import AgentExecutor, RequestContext
from a2a.server.request_handlers import DefaultRequestHandler
from a2a.server.tasks import InMemoryTaskStore
from a2a.server.events import EventQueue
from a2a.types import AgentCard, AgentSkill, AgentCapabilities, TaskState
from a2a.utils import new_agent_text_message
from a2a.server.tasks.task_updater import TaskUpdater
import uvicorn
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Langfuse í†µí•© ëª¨ë“ˆ ì„í¬íŠ¸
try:
    from core.universal_engine.langfuse_integration import SessionBasedTracer, LangfuseEnhancedA2AExecutor
    LANGFUSE_AVAILABLE = True
    logger.info("âœ… Langfuse í†µí•© ëª¨ë“ˆ ë¡œë“œ ì„±ê³µ")
except ImportError as e:
    LANGFUSE_AVAILABLE = False
    logger.warning(f"âš ï¸ Langfuse í†µí•© ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")


class MLflowAIDataProcessor:
    """pandas-ai ìŠ¤íƒ€ì¼ ë°ì´í„° í”„ë¡œì„¸ì„œ"""
    
    def parse_data_from_message(self, user_instructions: str) -> pd.DataFrame:
        """ì‚¬ìš©ì ë©”ì‹œì§€ì—ì„œ ë°ì´í„° íŒŒì‹±"""
        logger.info("ğŸ” ë°ì´í„° íŒŒì‹± ì‹œì‘")
        
        # CSV ë°ì´í„° ê²€ìƒ‰ (ì¼ë°˜ ê°œí–‰ ë¬¸ì í¬í•¨)
        if ',' in user_instructions and ('\n' in user_instructions or '\\n' in user_instructions):
            try:
                # ì‹¤ì œ ê°œí–‰ë¬¸ìì™€ ì´ìŠ¤ì¼€ì´í”„ëœ ê°œí–‰ë¬¸ì ëª¨ë‘ ì²˜ë¦¬
                normalized_text = user_instructions.replace('\\n', '\n')
                lines = normalized_text.strip().split('\n')
                
                # CSV íŒ¨í„´ ì°¾ê¸° - í—¤ë”ì™€ ë°ì´í„° í–‰ êµ¬ë¶„
                csv_lines = []
                for line in lines:
                    line = line.strip()
                    if ',' in line and line:  # ì‰¼í‘œê°€ ìˆê³  ë¹„ì–´ìˆì§€ ì•Šì€ í–‰
                        csv_lines.append(line)
                
                if len(csv_lines) >= 2:  # í—¤ë” + ìµœì†Œ 1ê°œ ë°ì´í„° í–‰
                    csv_data = '\n'.join(csv_lines)
                    df = pd.read_csv(io.StringIO(csv_data))
                    logger.info(f"âœ… CSV ë°ì´í„° íŒŒì‹± ì„±ê³µ: {df.shape}")
                    return df
            except Exception as e:
                logger.warning(f"CSV íŒŒì‹± ì‹¤íŒ¨: {e}")
        
        # JSON ë°ì´í„° ê²€ìƒ‰
        try:
            import re
            json_pattern = r'\[.*?\]|\{.*?\}'
            json_matches = re.findall(json_pattern, user_instructions, re.DOTALL)
            
            for json_str in json_matches:
                try:
                    data = json.loads(json_str)
                    if isinstance(data, list) and data:
                        df = pd.DataFrame(data)
                        logger.info(f"âœ… JSON ë°ì´í„° íŒŒì‹± ì„±ê³µ: {df.shape}")
                        return df
                    elif isinstance(data, dict):
                        df = pd.DataFrame([data])
                        logger.info(f"âœ… JSON ê°ì²´ íŒŒì‹± ì„±ê³µ: {df.shape}")
                        return df
                except:
                    continue
        except Exception as e:
            logger.warning(f"JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
        
        logger.info("âš ï¸ íŒŒì‹± ê°€ëŠ¥í•œ ë°ì´í„° ì—†ìŒ")
        return None


class MLflowToolsServerAgent(AgentExecutor):
    """
    LLM-First MLflow Tools ì„œë²„ ì—ì´ì „íŠ¸ (A2A Executor)
    
    ì™„ì „íˆ ìƒˆë¡œìš´ LLM-first ì ‘ê·¼ë°©ì‹ìœ¼ë¡œ MLOps ì „ ì˜ì—­ì„ ì»¤ë²„í•©ë‹ˆë‹¤.
    ì›ë³¸ ì—ì´ì „íŠ¸ ì—†ì´ ìˆœìˆ˜ LLM ê¸°ë°˜ ë™ì  MLflow ì‘ì—…ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤.
    """
    
    def __init__(self):
        # MLflowToolsAgent A2A ë˜í¼ ì„í¬íŠ¸
        from a2a_ds_servers.base.mlflow_tools_a2a_wrapper import MLflowToolsA2AWrapper
        
        self.mlflow_wrapper = MLflowToolsA2AWrapper()
        self.data_processor = MLflowAIDataProcessor()
        
        # Langfuse í†µí•© ì´ˆê¸°í™”
        self.langfuse_tracer = None
        if LANGFUSE_AVAILABLE:
            try:
                self.langfuse_tracer = SessionBasedTracer()
                if self.langfuse_tracer.langfuse:
                    logger.info("âœ… MLflowTools Langfuse í†µí•© ì™„ë£Œ")
                else:
                    logger.warning("âš ï¸ Langfuse ì„¤ì • ëˆ„ë½ - ê¸°ë³¸ ëª¨ë“œë¡œ ì‹¤í–‰")
            except Exception as e:
                logger.error(f"âŒ Langfuse ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self.langfuse_tracer = None
        
        logger.info("ğŸ“Š MLflow Tools ì„œë²„ ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
        logger.info("ğŸš€ LLM-First MLflow ì‘ì—… ì‹œìŠ¤í…œ")
        logger.info("ğŸ”§ 8ê°œ í•µì‹¬ MLOps ê¸°ëŠ¥ í™œì„±í™”")
    
    async def process_mlflow_operations(self, user_input: str) -> str:
        """MLflow ì‘ì—… ì²˜ë¦¬ ì‹¤í–‰ (í…ŒìŠ¤íŠ¸ìš© í—¬í¼ ë©”ì„œë“œ)"""
        try:
            logger.info(f"ğŸš€ MLflow ì‘ì—… ìš”ì²­ ì²˜ë¦¬: {user_input[:100]}...")
            
            # ë°ì´í„° íŒŒì‹± ì‹œë„
            df = self.data_processor.parse_data_from_message(user_input)
            
            # ë°ì´í„° ìœ ë¬´ì— ê´€ê³„ì—†ì´ MLflow ì‘ì—… ìˆ˜í–‰
            if df is not None and not df.empty:
                logger.info("ğŸ“Š ë°ì´í„° ê¸°ë°˜ MLflow ì‘ì—…")
            else:
                logger.info("ğŸ“‹ MLflow ê°€ì´ë“œ ë˜ëŠ” ì‹¤í—˜ ê´€ë¦¬")
            
            # MLflowToolsë¡œ ì²˜ë¦¬
            result = await self.mlflow_wrapper.process_request(user_input)
            
            return result
            
        except Exception as e:
            logger.error(f"MLflow ì‘ì—… ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return f"MLflow ì‘ì—… ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    async def execute(self, context: RequestContext, event_queue: EventQueue) -> None:
        """MLflow Tools ìš”ì²­ ì²˜ë¦¬ ë° ì‹¤í–‰ with Langfuse integration"""
        task_updater = TaskUpdater(event_queue, context.task_id, context.context_id)
        
        # Langfuse ë©”ì¸ íŠ¸ë ˆì´ìŠ¤ ì‹œì‘
        main_trace = None
        if self.langfuse_tracer and self.langfuse_tracer.langfuse:
            try:
                # ì „ì²´ ì‚¬ìš©ì ì¿¼ë¦¬ ì¶”ì¶œ
                full_user_query = ""
                if context.message and hasattr(context.message, 'parts') and context.message.parts:
                    for part in context.message.parts:
                        if hasattr(part, 'root') and part.root.kind == "text":
                            full_user_query += part.root.text + " "
                        elif hasattr(part, 'text'):
                            full_user_query += part.text + " "
                full_user_query = full_user_query.strip()
                
                # ë©”ì¸ íŠ¸ë ˆì´ìŠ¤ ìƒì„± (task_idë¥¼ íŠ¸ë ˆì´ìŠ¤ IDë¡œ ì‚¬ìš©)
                main_trace = self.langfuse_tracer.langfuse.trace(
                    id=context.task_id,
                    name="MLflowToolsAgent_Execution",
                    input=full_user_query,
                    user_id="2055186",
                    metadata={
                        "agent": "MLflowToolsAgent",
                        "port": 8314,
                        "context_id": context.context_id,
                        "timestamp": str(context.task_id),
                        "server_type": "llm_first"
                    }
                )
                logger.info(f"ğŸ”§ Langfuse ë©”ì¸ íŠ¸ë ˆì´ìŠ¤ ì‹œì‘: {context.task_id}")
            except Exception as e:
                logger.warning(f"âš ï¸ Langfuse íŠ¸ë ˆì´ìŠ¤ ìƒì„± ì‹¤íŒ¨: {e}")
        
        try:
            # ì‘ì—… ì‹œì‘
            await task_updater.submit()
            await task_updater.start_work()
            
            # 1ë‹¨ê³„: ìš”ì²­ íŒŒì‹± (Langfuse ì¶”ì )
            parsing_span = None
            if main_trace:
                parsing_span = self.langfuse_tracer.langfuse.span(
                    trace_id=context.task_id,
                    name="request_parsing",
                    input={"user_request": full_user_query[:500]},
                    metadata={"step": "1", "description": "Parse MLflow request"}
                )
            
            # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ì¶œ
            user_message = ""
            if context.message and context.message.parts:
                for part in context.message.parts:
                    if part.root.kind == "text":
                        user_message += part.root.text
            
            logger.info(f"ğŸ“ MLflow ìš”ì²­: {user_message[:100]}...")
            
            # íŒŒì‹± ê²°ê³¼ ì—…ë°ì´íŠ¸
            if parsing_span:
                parsing_span.update(
                    output={
                        "success": True,
                        "query_extracted": user_message[:200],
                        "request_length": len(user_message),
                        "mlflow_type": "mlops_operations"
                    }
                )
            
            # 2ë‹¨ê³„: MLflow ì‘ì—… ì‹¤í–‰ (Langfuse ì¶”ì )
            mlflow_span = None
            if main_trace:
                mlflow_span = self.langfuse_tracer.langfuse.span(
                    trace_id=context.task_id,
                    name="mlflow_operations",
                    input={
                        "query": user_message[:200],
                        "operation_type": "llm_first_mlflow"
                    },
                    metadata={"step": "2", "description": "Execute MLflow operations"}
                )
            
            # MLflow ì‘ì—… ì‹¤í–‰
            result = await self.mlflow_wrapper.process_request(user_message)
            
            # MLflow ì‘ì—… ê²°ê³¼ ì—…ë°ì´íŠ¸
            if mlflow_span:
                mlflow_span.update(
                    output={
                        "success": True,
                        "result_length": len(result),
                        "mlflow_operations_completed": True,
                        "execution_method": "llm_first_wrapper"
                    }
                )
            
            # 3ë‹¨ê³„: ê²°ê³¼ ì €ì¥/ë°˜í™˜ (Langfuse ì¶”ì )
            save_span = None
            if main_trace:
                save_span = self.langfuse_tracer.langfuse.span(
                    trace_id=context.task_id,
                    name="save_results",
                    input={
                        "result_size": len(result),
                        "mlflow_success": True
                    },
                    metadata={"step": "3", "description": "Prepare MLflow results"}
                )
            
            # ì €ì¥ ê²°ê³¼ ì—…ë°ì´íŠ¸
            if save_span:
                save_span.update(
                    output={
                        "response_prepared": True,
                        "mlflow_operations_delivered": True,
                        "final_status": "completed"
                    }
                )
            
            # ì„±ê³µ ì‘ë‹µ
            await task_updater.update_status(
                TaskState.completed,
                message=new_agent_text_message(result)
            )
            
            logger.info("âœ… MLflow Tools ì‘ì—… ì™„ë£Œ")
            
            # Langfuse ë©”ì¸ íŠ¸ë ˆì´ìŠ¤ ì™„ë£Œ
            if main_trace:
                try:
                    # Outputì„ ìš”ì•½ëœ í˜•íƒœë¡œ ì œê³µ
                    output_summary = {
                        "status": "completed",
                        "result_preview": result[:1000] + "..." if len(result) > 1000 else result,
                        "full_result_length": len(result)
                    }
                    
                    main_trace.update(
                        output=output_summary,
                        metadata={
                            "status": "completed",
                            "result_length": len(result),
                            "success": True,
                            "completion_timestamp": str(context.task_id),
                            "agent": "MLflowToolsAgent",
                            "port": 8314,
                            "server_type": "llm_first"
                        }
                    )
                    logger.info(f"ğŸ”§ Langfuse íŠ¸ë ˆì´ìŠ¤ ì™„ë£Œ: {context.task_id}")
                except Exception as e:
                    logger.warning(f"âš ï¸ Langfuse íŠ¸ë ˆì´ìŠ¤ ì™„ë£Œ ì‹¤íŒ¨: {e}")
            
        except Exception as e:
            error_msg = f"MLflow Tools ì‘ì—… ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            logger.error(f"âŒ {error_msg}")
            
            # Langfuse ë©”ì¸ íŠ¸ë ˆì´ìŠ¤ ì˜¤ë¥˜ ê¸°ë¡
            if main_trace:
                try:
                    main_trace.update(
                        output=f"Error: {str(e)}",
                        metadata={
                            "status": "failed",
                            "error": str(e),
                            "error_type": type(e).__name__,
                            "success": False,
                            "agent": "MLflowToolsAgent",
                            "port": 8314,
                            "server_type": "llm_first"
                        }
                    )
                except Exception as langfuse_error:
                    logger.warning(f"âš ï¸ Langfuse ì˜¤ë¥˜ ê¸°ë¡ ì‹¤íŒ¨: {langfuse_error}")
            
            await task_updater.update_status(
                TaskState.failed,
                message=new_agent_text_message(error_msg)
            )
    
    async def cancel(self, context: RequestContext, event_queue: EventQueue) -> None:
        """ì‘ì—… ì·¨ì†Œ ì²˜ë¦¬"""
        task_updater = TaskUpdater(event_queue, context.task_id, context.context_id)
        await task_updater.reject()
        logger.info("ğŸš« MLflow Tools ì‘ì—…ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤")


# A2A SDK 0.2.9 í‘œì¤€ êµ¬í˜„

def create_agent_card() -> AgentCard:
    """MLflowToolsAgentìš© Agent Card ìƒì„±"""
    
    # MLflow Tools ìŠ¤í‚¬ ì •ì˜
    mlflow_skill = AgentSkill(
        id="mlflow_tools_operations",
        name="MLflow Tools Operations",
        description="MLflowë¥¼ í™œìš©í•œ ì‹¤í—˜ ì¶”ì , ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ê´€ë¦¬, ëª¨ë¸ ì„œë¹™, íŒŒì´í”„ë¼ì¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ë“± ML ë¼ì´í”„ì‚¬ì´í´ ì „ë°˜ì„ ê´€ë¦¬í•©ë‹ˆë‹¤.",
        tags=["mlflow", "mlops", "experiment-tracking", "model-registry", "model-serving", "ml-lifecycle"],
        examples=[
            "ìƒˆë¡œìš´ ì‹¤í—˜ì„ ì‹œì‘í•˜ê³  íŒŒë¼ë¯¸í„°ë¥¼ ì¶”ì í•´ì£¼ì„¸ìš”",
            "í•™ìŠµëœ ëª¨ë¸ì„ ë“±ë¡í•˜ê³  ë ˆì§€ìŠ¤íŠ¸ë¦¬ì—ì„œ ê´€ë¦¬í•´ì£¼ì„¸ìš”",
            "Production ëª¨ë¸ì„ REST APIë¡œ ë°°í¬í•´ì£¼ì„¸ìš”",
            "ì—¬ëŸ¬ ì‹¤í—˜ ê²°ê³¼ë¥¼ ë¹„êµë¶„ì„í•´ì£¼ì„¸ìš”",
            "ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ë¥¼ ë²„ì „ë³„ë¡œ ê´€ë¦¬í•´ì£¼ì„¸ìš”",
            "íŒ€ ì›Œí¬ìŠ¤í˜ì´ìŠ¤ë¥¼ ì„¤ì •í•˜ê³  í˜‘ì—… í™˜ê²½ì„ êµ¬ì¶•í•´ì£¼ì„¸ìš”"
        ]
    )
    
    # Agent Card ìƒì„±
    agent_card = AgentCard(
        name="MLflow Tools Agent",
        description="MLflowë¥¼ í™œìš©í•œ ML ë¼ì´í”„ì‚¬ì´í´ ê´€ë¦¬ ì „ë¬¸ ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤. ì‹¤í—˜ ì¶”ì , ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬, ëª¨ë¸ ì„œë¹™, ì•„í‹°íŒ©íŠ¸ ê´€ë¦¬, íŒ€ í˜‘ì—…ê¹Œì§€ MLOps ì „ ì˜ì—­ì„ ì§€ì›í•©ë‹ˆë‹¤.",
        url="http://localhost:8314/",
        version="1.0.0",
        defaultInputModes=["text"],
        defaultOutputModes=["text"],
        capabilities=AgentCapabilities(streaming=False),
        skills=[mlflow_skill],
        supportsAuthenticatedExtendedCard=False
    )
    
    return agent_card


def main():
    """ë©”ì¸ ì„œë²„ ì‹¤í–‰ í•¨ìˆ˜"""
    # Agent Card ìƒì„±
    agent_card = create_agent_card()
    
    # Request Handler ìƒì„±  
    request_handler = DefaultRequestHandler(
        agent_executor=MLflowToolsServerAgent(),
        task_store=InMemoryTaskStore(),
    )
    
    # A2A Server ìƒì„±
    server = A2AStarletteApplication(
        agent_card=agent_card,
        http_handler=request_handler,
    )
    
    # ì„œë²„ ì‹œì‘ ë©”ì‹œì§€
    print("ğŸš€ MLflow Tools Server ì‹œì‘ ì¤‘...")
    print("ğŸ“Š Agent: MLflowToolsAgent (LLM-First)")
    print("ğŸ”§ ê¸°ëŠ¥: ì‹¤í—˜ ì¶”ì , ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬, ëª¨ë¸ ì„œë¹™, MLOps ì „ì²´ ë¼ì´í”„ì‚¬ì´í´")
    print("ğŸ“¡ Port: 8314")
    print("ğŸ¯ 8ê°œ í•µì‹¬ ê¸°ëŠ¥:")
    print("   1. start_experiment() - ì‹¤í—˜ ì‹œì‘ ë° ì¶”ì ")
    print("   2. log_parameters_metrics() - íŒŒë¼ë¯¸í„° ë° ë©”íŠ¸ë¦­ ë¡œê¹…")
    print("   3. register_models() - ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ë“±ë¡")
    print("   4. deploy_models() - ëª¨ë¸ ë°°í¬ ë° ì„œë¹™")
    print("   5. compare_experiments() - ì‹¤í—˜ ê²°ê³¼ ë¹„êµ")
    print("   6. manage_artifacts() - ì•„í‹°íŒ©íŠ¸ ê´€ë¦¬")
    print("   7. setup_team_workspace() - íŒ€ ì›Œí¬ìŠ¤í˜ì´ìŠ¤ ì„¤ì •")
    print("   8. track_model_versions() - ëª¨ë¸ ë²„ì „ ì¶”ì ")
    print("âœ… MLflow Tools ì„œë²„ ì¤€ë¹„ ì™„ë£Œ!")
    
    # Uvicorn ì„œë²„ ì‹¤í–‰
    uvicorn.run(
        server.build(),
        host="0.0.0.0", 
        port=8314,
        log_level="info"
    )

if __name__ == "__main__":
    main()