#!/usr/bin/env python3
"""
ğŸ­ Agent Persona Manager - Context Engineering INSTRUCTIONS Layer

A2A ê¸°ë°˜ Context Engineering í”Œë«í¼ì—ì„œ ì—ì´ì „íŠ¸ë³„ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì™€ í˜ë¥´ì†Œë‚˜ë¥¼ ê´€ë¦¬í•˜ëŠ” í•µì‹¬ ì‹œìŠ¤í…œ
INSTRUCTIONS Data Layerì˜ ì¤‘ì‹¬ êµ¬ì„± ìš”ì†Œë¡œ ë™ì  í˜ë¥´ì†Œë‚˜ í• ë‹¹, ì—­í• ë³„ ì „ë¬¸í™”, ì»¨í…ìŠ¤íŠ¸ ì ì‘ ì œê³µ

Key Features:
- ë™ì  í˜ë¥´ì†Œë‚˜ í• ë‹¹ - ì‘ì—… ìœ í˜•ì— ë”°ë¥¸ ìµœì  í˜ë¥´ì†Œë‚˜ ìë™ ì„ íƒ
- ì—­í• ë³„ ì „ë¬¸í™” - ì—ì´ì „íŠ¸ë³„ ì „ë¬¸ ë„ë©”ì¸ ê°•í™”
- ì»¨í…ìŠ¤íŠ¸ ì ì‘ - ì‹¤ì‹œê°„ ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ í˜ë¥´ì†Œë‚˜ ì¡°ì •
- í˜ë¥´ì†Œë‚˜ í•™ìŠµ - ì„±ê³µ íŒ¨í„´ ê¸°ë°˜ í˜ë¥´ì†Œë‚˜ ê°œì„ 
- í˜‘ì—… í˜ë¥´ì†Œë‚˜ - ë©€í‹°ì—ì´ì „íŠ¸ í˜‘ì—… ìµœì í™”

Architecture:
- Persona Registry: í˜ë¥´ì†Œë‚˜ ì €ì¥ì†Œ ë° ê´€ë¦¬
- Dynamic Persona Selector: ì§€ëŠ¥í˜• í˜ë¥´ì†Œë‚˜ ì„ íƒ
- Context Adaptation Engine: ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ í˜ë¥´ì†Œë‚˜ ì¡°ì •
- Performance Tracker: í˜ë¥´ì†Œë‚˜ ì„±ëŠ¥ ì¶”ì  ë° í•™ìŠµ
"""

import asyncio
import json
import logging
import os
import time
import uuid
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Set, Tuple
from dataclasses import dataclass, asdict
from enum import Enum
from pathlib import Path

import aiofiles
from openai import AsyncOpenAI

# A2A SDK ì„í¬íŠ¸
from a2a.types import AgentCard, AgentSkill

# Context Engineering ì„í¬íŠ¸
import sys
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class PersonaType(Enum):
    """í˜ë¥´ì†Œë‚˜ íƒ€ì… ë¶„ë¥˜"""
    EXPERT = "expert"                    # ì „ë¬¸ê°€ í˜ë¥´ì†Œë‚˜
    COLLABORATIVE = "collaborative"     # í˜‘ì—… í˜ë¥´ì†Œë‚˜
    ANALYTICAL = "analytical"           # ë¶„ì„ í˜ë¥´ì†Œë‚˜
    CREATIVE = "creative"               # ì°½ì˜ì  í˜ë¥´ì†Œë‚˜
    METHODICAL = "methodical"           # ì²´ê³„ì  í˜ë¥´ì†Œë‚˜
    ADAPTIVE = "adaptive"               # ì ì‘í˜• í˜ë¥´ì†Œë‚˜
    MENTOR = "mentor"                   # ë©˜í†  í˜ë¥´ì†Œë‚˜
    SPECIALIST = "specialist"           # íŠ¹í™” í˜ë¥´ì†Œë‚˜

class PersonaScope(Enum):
    """í˜ë¥´ì†Œë‚˜ ì ìš© ë²”ìœ„"""
    GLOBAL = "global"                   # ì „ì—­ í˜ë¥´ì†Œë‚˜
    DOMAIN = "domain"                   # ë„ë©”ì¸ë³„ í˜ë¥´ì†Œë‚˜
    TASK = "task"                       # ì‘ì—…ë³„ í˜ë¥´ì†Œë‚˜
    SESSION = "session"                 # ì„¸ì…˜ë³„ í˜ë¥´ì†Œë‚˜
    COLLABORATION = "collaboration"     # í˜‘ì—…ë³„ í˜ë¥´ì†Œë‚˜

@dataclass
class AgentPersona:
    """ì—ì´ì „íŠ¸ í˜ë¥´ì†Œë‚˜ ì •ì˜"""
    persona_id: str
    agent_id: str
    persona_type: PersonaType
    scope: PersonaScope
    name: str
    description: str
    system_prompt: str
    behavioral_traits: List[str]
    expertise_areas: List[str]
    communication_style: str
    collaboration_preferences: Dict[str, Any]
    context_adaptations: Dict[str, str]
    performance_metrics: Dict[str, float]
    usage_count: int
    success_rate: float
    created_at: datetime
    updated_at: datetime
    is_active: bool = True
    priority: int = 1

@dataclass
class PersonaContext:
    """í˜ë¥´ì†Œë‚˜ ì»¨í…ìŠ¤íŠ¸ ì •ë³´"""
    context_id: str
    user_request: str
    task_type: str
    complexity_level: str
    collaboration_type: str
    required_skills: List[str]
    session_history: List[Dict[str, Any]]
    user_preferences: Dict[str, Any]
    performance_requirements: Dict[str, Any]
    timestamp: datetime

@dataclass
class PersonaRecommendation:
    """í˜ë¥´ì†Œë‚˜ ì¶”ì²œ ê²°ê³¼"""
    persona_id: str
    agent_id: str
    confidence: float
    reasoning: str
    adaptation_suggestions: List[str]
    estimated_performance: float
    context_fit_score: float

class PersonaRegistry:
    """í˜ë¥´ì†Œë‚˜ ì €ì¥ì†Œ ë° ê´€ë¦¬"""
    
    def __init__(self, registry_path: str = "persona_registry.json"):
        self.registry_path = registry_path
        self.personas: Dict[str, AgentPersona] = {}
        self.persona_templates: Dict[str, Dict[str, Any]] = {}
        self.performance_history: Dict[str, List[Dict[str, Any]]] = {}
        
        # ê¸°ë³¸ í˜ë¥´ì†Œë‚˜ í…œí”Œë¦¿ ë¡œë“œ
        self._load_default_persona_templates()
        
        logger.info("ğŸ­ Persona Registry ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _load_default_persona_templates(self):
        """ê¸°ë³¸ í˜ë¥´ì†Œë‚˜ í…œí”Œë¦¿ ë¡œë“œ"""
        self.persona_templates = {
            "data_scientist_expert": {
                "persona_type": PersonaType.EXPERT,
                "name": "Data Science Expert",
                "description": "ê¹Šì´ ìˆëŠ” ë°ì´í„° ê³¼í•™ ì „ë¬¸ ì§€ì‹ì„ ë³´ìœ í•œ ì „ë¬¸ê°€",
                "system_prompt": """ë‹¹ì‹ ì€ ë°ì´í„° ì‚¬ì´ì–¸ìŠ¤ ë¶„ì•¼ì˜ ì„¸ê³„ì  ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
                
**ì „ë¬¸ ì˜ì—­:**
- ê³ ê¸‰ í†µê³„ ë¶„ì„ ë° ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ë§
- ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ë° ìµœì í™”
- ì‹¤í—˜ ì„¤ê³„ ë° A/B í…ŒìŠ¤íŠ¸
- ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ ë„ì¶œ

**í–‰ë™ íŠ¹ì„±:**
- ë°ì´í„° ê¸°ë°˜ ì˜ì‚¬ê²°ì • ê°•ì¡°
- ì—„ë°€í•œ í†µê³„ì  ê²€ì¦ ìˆ˜í–‰
- ë³µì¡í•œ ê°œë…ì˜ ëª…í™•í•œ ì„¤ëª…
- ì‹¤ë¬´ ì ìš© ê°€ëŠ¥í•œ ì†”ë£¨ì…˜ ì œì‹œ

**ì˜ì‚¬ì†Œí†µ ìŠ¤íƒ€ì¼:**
- ì •í™•í•˜ê³  êµ¬ì²´ì ì¸ ì„¤ëª…
- ì‹œê°ì  ìë£Œ í™œìš©
- ë‹¨ê³„ë³„ ì ‘ê·¼ ë°©ì‹
- ê²€ì¦ ê°€ëŠ¥í•œ ê²°ê³¼ ì œì‹œ""",
                "behavioral_traits": ["methodical", "analytical", "precise", "thorough"],
                "expertise_areas": ["statistics", "machine_learning", "data_visualization", "business_intelligence"],
                "communication_style": "professional_detailed",
                "collaboration_preferences": {
                    "leadership_style": "expertise_based",
                    "feedback_approach": "constructive_detailed",
                    "knowledge_sharing": "proactive"
                }
            },
            
            "collaborative_facilitator": {
                "persona_type": PersonaType.COLLABORATIVE,
                "name": "Collaborative Facilitator",
                "description": "íŒ€ í˜‘ì—…ì„ ìµœì í™”í•˜ëŠ” í˜‘ì—… ì´‰ì§„ì",
                "system_prompt": """ë‹¹ì‹ ì€ ë©€í‹°ì—ì´ì „íŠ¸ í˜‘ì—…ì„ ì¡°ìœ¨í•˜ëŠ” ì „ë¬¸ ì´‰ì§„ìì…ë‹ˆë‹¤.

**í•µì‹¬ ì—­í• :**
- ì—ì´ì „íŠ¸ ê°„ íš¨ê³¼ì ì¸ ì†Œí†µ ì´‰ì§„
- ì‘ì—… ë¶„ë°° ë° ì¼ì • ì¡°ì •
- ê°ˆë“± í•´ê²° ë° í•©ì˜ ë„ì¶œ
- í˜‘ì—… ì„±ê³¼ ìµœì í™”

**í–‰ë™ íŠ¹ì„±:**
- ì ê·¹ì ì¸ ì†Œí†µ ë° ì¡°ì •
- ê° ì—ì´ì „íŠ¸ì˜ ê°•ì  í™œìš©
- ì „ì²´ ëª©í‘œ ì¤‘ì‹¬ ì‚¬ê³ 
- ìœ ì—°í•œ ë¬¸ì œ í•´ê²°

**ì˜ì‚¬ì†Œí†µ ìŠ¤íƒ€ì¼:**
- ëª…í™•í•˜ê³  ì¹œí™”ì ì¸ í†¤
- ëª¨ë“  ì°¸ì—¬ì í¬ìš©
- ê±´ì„¤ì ì¸ í”¼ë“œë°± ì œê³µ
- ì§„í–‰ ìƒí™© íˆ¬ëª… ê³µìœ """,
                "behavioral_traits": ["collaborative", "diplomatic", "organized", "adaptive"],
                "expertise_areas": ["project_management", "team_coordination", "conflict_resolution", "process_optimization"],
                "communication_style": "collaborative_inclusive",
                "collaboration_preferences": {
                    "leadership_style": "facilitative",
                    "feedback_approach": "encouraging_constructive",
                    "knowledge_sharing": "inclusive"
                }
            },
            
            "analytical_investigator": {
                "persona_type": PersonaType.ANALYTICAL,
                "name": "Analytical Investigator",
                "description": "ì²´ê³„ì ì´ê³  ë…¼ë¦¬ì ì¸ ë¶„ì„ ì „ë¬¸ê°€",
                "system_prompt": """ë‹¹ì‹ ì€ ë°ì´í„°ì™€ í˜„ìƒì„ ê¹Šì´ ìˆê²Œ ë¶„ì„í•˜ëŠ” ì¡°ì‚¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

**ë¶„ì„ ì ‘ê·¼ë²•:**
- ê°€ì„¤ ì„¤ì • ë° ì²´ê³„ì  ê²€ì¦
- ë‹¤ê°ë„ ê´€ì ì—ì„œì˜ ë¶„ì„
- íŒ¨í„´ ë°œê²¬ ë° ì´ìƒì¹˜ íƒì§€
- ì¸ê³¼ê´€ê³„ ê·œëª…

**í–‰ë™ íŠ¹ì„±:**
- ë…¼ë¦¬ì ì´ê³  ì²´ê³„ì ì¸ ì‚¬ê³ 
- ì„¸ì‹¬í•œ ê´€ì°° ë° ê²€í† 
- ê°ê´€ì  ì¦ê±° ê¸°ë°˜ ê²°ë¡ 
- ì§€ì†ì ì¸ ì§ˆë¬¸ê³¼ íƒêµ¬

**ì˜ì‚¬ì†Œí†µ ìŠ¤íƒ€ì¼:**
- ë…¼ë¦¬ì  êµ¬ì¡°ì˜ ì„¤ëª…
- ì¦ê±° ê¸°ë°˜ ì£¼ì¥
- ë‹¨ê³„ë³„ ì¶”ë¡  ê³¼ì • ì œì‹œ
- ëª…í™•í•œ ê²°ë¡  ë° ê¶Œê³ ì‚¬í•­""",
                "behavioral_traits": ["logical", "thorough", "curious", "objective"],
                "expertise_areas": ["exploratory_data_analysis", "statistical_inference", "pattern_recognition", "hypothesis_testing"],
                "communication_style": "analytical_structured",
                "collaboration_preferences": {
                    "leadership_style": "evidence_based",
                    "feedback_approach": "fact_based",
                    "knowledge_sharing": "systematic"
                }
            },
            
            "creative_innovator": {
                "persona_type": PersonaType.CREATIVE,
                "name": "Creative Innovator",
                "description": "ì°½ì˜ì ì´ê³  í˜ì‹ ì ì¸ ì†”ë£¨ì…˜ ì œì‹œì",
                "system_prompt": """ë‹¹ì‹ ì€ ì°½ì˜ì  ì‚¬ê³ ì™€ í˜ì‹ ì  ì ‘ê·¼ìœ¼ë¡œ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

**ì°½ì˜ì  ì ‘ê·¼ë²•:**
- ê¸°ì¡´ ê´€ì ì„ ë²—ì–´ë‚œ ì‚¬ê³ 
- ë‹¤ì–‘í•œ ì†”ë£¨ì…˜ ëŒ€ì•ˆ ì œì‹œ
- ì‹œê°ì ì´ê³  ì§ê´€ì ì¸ í‘œí˜„
- ì‹¤í—˜ì  ë°©ë²•ë¡  ì ìš©

**í–‰ë™ íŠ¹ì„±:**
- ì—´ë¦° ë§ˆìŒê³¼ í˜¸ê¸°ì‹¬
- ë¸Œë ˆì¸ìŠ¤í† ë° ë° ì•„ì´ë””ì–´ ë°œì‚°
- í”„ë¡œí† íƒ€ì… ë° ì‹¤í—˜ ì„ í˜¸
- ì‹¤íŒ¨ë¥¼ í•™ìŠµ ê¸°íšŒë¡œ í™œìš©

**ì˜ì‚¬ì†Œí†µ ìŠ¤íƒ€ì¼:**
- ì‹œê°ì  ìŠ¤í† ë¦¬í…”ë§
- ì€ìœ ì™€ ë¹„ìœ  í™œìš©
- ì¸í„°ë™í‹°ë¸Œí•œ ì„¤ëª…
- ì˜ê°ì„ ì£¼ëŠ” í‘œí˜„""",
                "behavioral_traits": ["innovative", "flexible", "imaginative", "experimental"],
                "expertise_areas": ["data_visualization", "storytelling", "prototype_development", "design_thinking"],
                "communication_style": "creative_engaging",
                "collaboration_preferences": {
                    "leadership_style": "inspirational",
                    "feedback_approach": "encouraging_creative",
                    "knowledge_sharing": "interactive"
                }
            },
            
            "methodical_executor": {
                "persona_type": PersonaType.METHODICAL,
                "name": "Methodical Executor",
                "description": "ì²´ê³„ì ì´ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì‹¤í–‰ ì „ë¬¸ê°€",
                "system_prompt": """ë‹¹ì‹ ì€ ì²´ê³„ì ì´ê³  ì •í™•í•œ ì‹¤í–‰ì„ í†µí•´ ì•ˆì •ì ì¸ ê²°ê³¼ë¥¼ ë³´ì¥í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

**ì‹¤í–‰ ì›ì¹™:**
- ë‹¨ê³„ë³„ ì²´ê³„ì  ì ‘ê·¼
- í’ˆì§ˆ ê´€ë¦¬ ë° ê²€ì¦
- ì¼ì • ì¤€ìˆ˜ ë° ë¦¬ìŠ¤í¬ ê´€ë¦¬
- ë¬¸ì„œí™” ë° ì¶”ì  ê°€ëŠ¥ì„±

**í–‰ë™ íŠ¹ì„±:**
- ì‹ ì¤‘í•˜ê³  ì •í™•í•œ ì‘ì—…
- í‘œì¤€ ì ˆì°¨ ì¤€ìˆ˜
- ì§€ì†ì ì¸ í’ˆì§ˆ ì ê²€
- ì˜ˆì¸¡ ê°€ëŠ¥í•œ ê²°ê³¼ ì œê³µ

**ì˜ì‚¬ì†Œí†µ ìŠ¤íƒ€ì¼:**
- ëª…í™•í•˜ê³  êµ¬ì¡°í™”ëœ ì„¤ëª…
- ì§„í–‰ ìƒí™© ì •ê¸° ë³´ê³ 
- êµ¬ì²´ì ì¸ ê³„íš ë° ì¼ì • ì œì‹œ
- ë¦¬ìŠ¤í¬ ë° ëŒ€ì‘ ë°©ì•ˆ ì•ˆë‚´""",
                "behavioral_traits": ["systematic", "reliable", "detail_oriented", "quality_focused"],
                "expertise_areas": ["process_management", "quality_assurance", "project_execution", "risk_management"],
                "communication_style": "methodical_clear",
                "collaboration_preferences": {
                    "leadership_style": "process_oriented",
                    "feedback_approach": "structured_detailed",
                    "knowledge_sharing": "systematic"
                }
            },
            
            "adaptive_learner": {
                "persona_type": PersonaType.ADAPTIVE,
                "name": "Adaptive Learner",
                "description": "ìƒí™©ì— ë§ê²Œ ìœ ì—°í•˜ê²Œ ì ì‘í•˜ëŠ” í•™ìŠµì",
                "system_prompt": """ë‹¹ì‹ ì€ ìƒˆë¡œìš´ ìƒí™©ì— ë¹ ë¥´ê²Œ ì ì‘í•˜ê³  ì§€ì†ì ìœ¼ë¡œ í•™ìŠµí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

**ì ì‘ ëŠ¥ë ¥:**
- ì‹¤ì‹œê°„ ìƒí™© ë¶„ì„ ë° ëŒ€ì‘
- í”¼ë“œë°± ê¸°ë°˜ ë¹ ë¥¸ í•™ìŠµ
- ë‹¤ì–‘í•œ ì ‘ê·¼ ë°©ì‹ ì‹œë„
- ë³€í™”í•˜ëŠ” ìš”êµ¬ì‚¬í•­ ëŒ€ì‘

**í–‰ë™ íŠ¹ì„±:**
- ê°œë°©ì ì´ê³  ìœ ì—°í•œ ì‚¬ê³ 
- ë¹ ë¥¸ í•™ìŠµ ë° ì ìš©
- ì‹¤í—˜ê³¼ ê°œì„ ì˜ ë°˜ë³µ
- ë‹¤ì–‘í•œ ê´€ì  ìˆ˜ìš©

**ì˜ì‚¬ì†Œí†µ ìŠ¤íƒ€ì¼:**
- ìƒí™©ì— ë§ëŠ” í†¤ ì¡°ì ˆ
- í”¼ë“œë°± ìš”ì²­ ë° ë°˜ì˜
- í•™ìŠµ ê³¼ì • ê³µìœ 
- ê°œì„  ë°©í–¥ ì œì•ˆ""",
                "behavioral_traits": ["flexible", "curious", "responsive", "growth_oriented"],
                "expertise_areas": ["adaptive_analysis", "rapid_learning", "multi_modal_processing", "context_switching"],
                "communication_style": "adaptive_responsive",
                "collaboration_preferences": {
                    "leadership_style": "situational",
                    "feedback_approach": "iterative_improvement",
                    "knowledge_sharing": "contextual"
                }
            },
            
            "mentor_guide": {
                "persona_type": PersonaType.MENTOR,
                "name": "Mentor Guide",
                "description": "ì§€ì‹ ì „ìˆ˜ì™€ ì„±ì¥ì„ ë•ëŠ” ë©˜í† ",
                "system_prompt": """ë‹¹ì‹ ì€ ë‹¤ë¥¸ ì—ì´ì „íŠ¸ì™€ ì‚¬ìš©ìì˜ ì„±ì¥ì„ ë•ëŠ” ì§€í˜œë¡œìš´ ë©˜í† ì…ë‹ˆë‹¤.

**ë©˜í† ë§ ì ‘ê·¼ë²•:**
- ë‹¨ê³„ë³„ í•™ìŠµ ê°€ì´ë“œ ì œê³µ
- ì‹¤ë¬´ ê²½í—˜ ê¸°ë°˜ ì¡°ì–¸
- ê²©ë ¤ì™€ ë™ê¸° ë¶€ì—¬
- ê°œì¸ë³„ ë§ì¶¤ ì§€ë„

**í–‰ë™ íŠ¹ì„±:**
- ì¸ë‚´ì‹¬ ìˆê³  ì¹œì ˆí•œ íƒœë„
- ê²½í—˜ ê¸°ë°˜ ì§€í˜œ ê³µìœ 
- í•™ìŠµì ì¤‘ì‹¬ ì ‘ê·¼
- ê¸ì •ì  í”¼ë“œë°± ê°•ì¡°

**ì˜ì‚¬ì†Œí†µ ìŠ¤íƒ€ì¼:**
- ë”°ëœ»í•˜ê³  ê²©ë ¤í•˜ëŠ” í†¤
- êµ¬ì²´ì ì¸ ì˜ˆì‹œ ì œê³µ
- ë‹¨ê³„ë³„ ì„¤ëª…
- ì„±ì¥ ê³¼ì • ì¸ì •""",
                "behavioral_traits": ["patient", "encouraging", "wise", "supportive"],
                "expertise_areas": ["knowledge_transfer", "skill_development", "guidance", "motivation"],
                "communication_style": "mentoring_supportive",
                "collaboration_preferences": {
                    "leadership_style": "nurturing",
                    "feedback_approach": "developmental",
                    "knowledge_sharing": "educational"
                }
            }
        }
    
    async def load_personas(self) -> Dict[str, AgentPersona]:
        """í˜ë¥´ì†Œë‚˜ ë¡œë“œ"""
        try:
            if os.path.exists(self.registry_path):
                async with aiofiles.open(self.registry_path, 'r', encoding='utf-8') as f:
                    content = await f.read()
                    data = json.loads(content)
                    
                    for persona_data in data.get('personas', []):
                        persona = AgentPersona(
                            persona_id=persona_data['persona_id'],
                            agent_id=persona_data['agent_id'],
                            persona_type=PersonaType(persona_data['persona_type']),
                            scope=PersonaScope(persona_data['scope']),
                            name=persona_data['name'],
                            description=persona_data['description'],
                            system_prompt=persona_data['system_prompt'],
                            behavioral_traits=persona_data['behavioral_traits'],
                            expertise_areas=persona_data['expertise_areas'],
                            communication_style=persona_data['communication_style'],
                            collaboration_preferences=persona_data['collaboration_preferences'],
                            context_adaptations=persona_data.get('context_adaptations', {}),
                            performance_metrics=persona_data.get('performance_metrics', {}),
                            usage_count=persona_data.get('usage_count', 0),
                            success_rate=persona_data.get('success_rate', 0.0),
                            created_at=datetime.fromisoformat(persona_data['created_at']),
                            updated_at=datetime.fromisoformat(persona_data['updated_at']),
                            is_active=persona_data.get('is_active', True),
                            priority=persona_data.get('priority', 1)
                        )
                        self.personas[persona.persona_id] = persona
                        
                logger.info(f"ğŸ“š {len(self.personas)}ê°œ í˜ë¥´ì†Œë‚˜ ë¡œë“œ ì™„ë£Œ")
            else:
                logger.info("ğŸ“š ê¸°ë³¸ í˜ë¥´ì†Œë‚˜ ìƒì„± ì¤‘...")
                await self._create_default_personas()
                
        except Exception as e:
            logger.error(f"âŒ í˜ë¥´ì†Œë‚˜ ë¡œë“œ ì‹¤íŒ¨: {e}")
            await self._create_default_personas()
        
        return self.personas
    
    async def _create_default_personas(self):
        """ê¸°ë³¸ í˜ë¥´ì†Œë‚˜ ìƒì„±"""
        # A2A ì—ì´ì „íŠ¸ë³„ ê¸°ë³¸ í˜ë¥´ì†Œë‚˜ ìƒì„±
        agent_persona_mappings = {
            "orchestrator": ["collaborative_facilitator", "methodical_executor"],
            "data_cleaning": ["methodical_executor", "analytical_investigator"],
            "data_loader": ["methodical_executor", "adaptive_learner"],
            "data_visualization": ["creative_innovator", "analytical_investigator"],
            "data_wrangling": ["methodical_executor", "analytical_investigator"],
            "feature_engineering": ["data_scientist_expert", "analytical_investigator"],
            "sql_database": ["methodical_executor", "analytical_investigator"],
            "eda_tools": ["analytical_investigator", "data_scientist_expert"],
            "h2o_ml": ["data_scientist_expert", "methodical_executor"],
            "mlflow_tools": ["methodical_executor", "data_scientist_expert"],
            "pandas_collaboration_hub": ["collaborative_facilitator", "data_scientist_expert"]
        }
        
        for agent_id, template_ids in agent_persona_mappings.items():
            for i, template_id in enumerate(template_ids):
                if template_id in self.persona_templates:
                    template = self.persona_templates[template_id]
                    
                    persona = AgentPersona(
                        persona_id=f"{agent_id}_{template_id}_{i+1}",
                        agent_id=agent_id,
                        persona_type=template["persona_type"],
                        scope=PersonaScope.DOMAIN,
                        name=f"{template['name']} for {agent_id}",
                        description=f"{template['description']} - {agent_id} ì „ìš©",
                        system_prompt=template["system_prompt"],
                        behavioral_traits=template["behavioral_traits"],
                        expertise_areas=template["expertise_areas"],
                        communication_style=template["communication_style"],
                        collaboration_preferences=template["collaboration_preferences"],
                        context_adaptations={},
                        performance_metrics={},
                        usage_count=0,
                        success_rate=0.0,
                        created_at=datetime.now(),
                        updated_at=datetime.now(),
                        is_active=True,
                        priority=1 if i == 0 else 2  # ì²« ë²ˆì§¸ í˜ë¥´ì†Œë‚˜ê°€ ê¸°ë³¸
                    )
                    
                    self.personas[persona.persona_id] = persona
        
        # í˜ë¥´ì†Œë‚˜ ì €ì¥
        await self.save_personas()
        
        logger.info(f"ğŸ­ {len(self.personas)}ê°œ ê¸°ë³¸ í˜ë¥´ì†Œë‚˜ ìƒì„± ì™„ë£Œ")
    
    async def save_personas(self):
        """í˜ë¥´ì†Œë‚˜ ì €ì¥"""
        try:
            data = {
                "personas": [
                    {
                        "persona_id": persona.persona_id,
                        "agent_id": persona.agent_id,
                        "persona_type": persona.persona_type.value,
                        "scope": persona.scope.value,
                        "name": persona.name,
                        "description": persona.description,
                        "system_prompt": persona.system_prompt,
                        "behavioral_traits": persona.behavioral_traits,
                        "expertise_areas": persona.expertise_areas,
                        "communication_style": persona.communication_style,
                        "collaboration_preferences": persona.collaboration_preferences,
                        "context_adaptations": persona.context_adaptations,
                        "performance_metrics": persona.performance_metrics,
                        "usage_count": persona.usage_count,
                        "success_rate": persona.success_rate,
                        "created_at": persona.created_at.isoformat(),
                        "updated_at": persona.updated_at.isoformat(),
                        "is_active": persona.is_active,
                        "priority": persona.priority
                    }
                    for persona in self.personas.values()
                ],
                "updated_at": datetime.now().isoformat()
            }
            
            async with aiofiles.open(self.registry_path, 'w', encoding='utf-8') as f:
                await f.write(json.dumps(data, ensure_ascii=False, indent=2))
                
            logger.info(f"ğŸ’¾ {len(self.personas)}ê°œ í˜ë¥´ì†Œë‚˜ ì €ì¥ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ í˜ë¥´ì†Œë‚˜ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    async def get_personas_by_agent(self, agent_id: str) -> List[AgentPersona]:
        """ì—ì´ì „íŠ¸ë³„ í˜ë¥´ì†Œë‚˜ ì¡°íšŒ"""
        return [persona for persona in self.personas.values() 
                if persona.agent_id == agent_id and persona.is_active]
    
    async def get_persona(self, persona_id: str) -> Optional[AgentPersona]:
        """í˜ë¥´ì†Œë‚˜ ì¡°íšŒ"""
        return self.personas.get(persona_id)
    
    async def update_persona_performance(self, persona_id: str, success: bool, 
                                       performance_score: float = None):
        """í˜ë¥´ì†Œë‚˜ ì„±ëŠ¥ ì—…ë°ì´íŠ¸"""
        if persona_id in self.personas:
            persona = self.personas[persona_id]
            persona.usage_count += 1
            
            if success:
                # ì„±ê³µë¥  ì—…ë°ì´íŠ¸
                current_success_count = persona.success_rate * (persona.usage_count - 1)
                new_success_count = current_success_count + 1
                persona.success_rate = new_success_count / persona.usage_count
                
                # ì„±ëŠ¥ ì ìˆ˜ ì—…ë°ì´íŠ¸
                if performance_score is not None:
                    if "average_performance" not in persona.performance_metrics:
                        persona.performance_metrics["average_performance"] = performance_score
                    else:
                        current_avg = persona.performance_metrics["average_performance"]
                        persona.performance_metrics["average_performance"] = (
                            current_avg * (persona.usage_count - 1) + performance_score
                        ) / persona.usage_count
            
            persona.updated_at = datetime.now()
            await self.save_personas()

class DynamicPersonaSelector:
    """ë™ì  í˜ë¥´ì†Œë‚˜ ì„ íƒê¸°"""
    
    def __init__(self, persona_registry: PersonaRegistry, openai_client: Optional[AsyncOpenAI] = None):
        self.persona_registry = persona_registry
        self.openai_client = openai_client
        self.selection_history: List[Dict[str, Any]] = []
        
    async def select_persona(self, agent_id: str, context: PersonaContext) -> PersonaRecommendation:
        """ìµœì  í˜ë¥´ì†Œë‚˜ ì„ íƒ"""
        logger.info(f"ğŸ¯ í˜ë¥´ì†Œë‚˜ ì„ íƒ: {agent_id} (ì‘ì—…: {context.task_type})")
        
        # í•´ë‹¹ ì—ì´ì „íŠ¸ì˜ ì‚¬ìš© ê°€ëŠ¥í•œ í˜ë¥´ì†Œë‚˜ ì¡°íšŒ
        available_personas = await self.persona_registry.get_personas_by_agent(agent_id)
        
        if not available_personas:
            logger.warning(f"âš ï¸ {agent_id}ì— ëŒ€í•œ í˜ë¥´ì†Œë‚˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        # 1ë‹¨ê³„: ê¸°ë³¸ ì í•©ì„± ì ìˆ˜ ê³„ì‚°
        scored_personas = []
        for persona in available_personas:
            base_score = self._calculate_base_fitness_score(persona, context)
            scored_personas.append((persona, base_score))
        
        # 2ë‹¨ê³„: LLM ê¸°ë°˜ ê³ ê¸‰ ë¶„ì„ (ê°€ëŠ¥í•œ ê²½ìš°)
        if self.openai_client and len(scored_personas) > 1:
            try:
                enhanced_scores = await self._llm_enhanced_selection(scored_personas, context)
                if enhanced_scores:
                    scored_personas = enhanced_scores
            except Exception as e:
                logger.warning(f"LLM ê¸°ë°˜ í˜ë¥´ì†Œë‚˜ ì„ íƒ ì‹¤íŒ¨: {e}")
        
        # 3ë‹¨ê³„: ìµœì  í˜ë¥´ì†Œë‚˜ ì„ íƒ
        scored_personas.sort(key=lambda x: x[1], reverse=True)
        best_persona, best_score = scored_personas[0]
        
        # 4ë‹¨ê³„: ì ì‘ ì œì•ˆ ìƒì„±
        adaptation_suggestions = self._generate_adaptation_suggestions(best_persona, context)
        
        recommendation = PersonaRecommendation(
            persona_id=best_persona.persona_id,
            agent_id=agent_id,
            confidence=best_score,
            reasoning=self._generate_selection_reasoning(best_persona, context, best_score),
            adaptation_suggestions=adaptation_suggestions,
            estimated_performance=self._estimate_performance(best_persona, context),
            context_fit_score=best_score
        )
        
        # ì„ íƒ ê¸°ë¡ ì €ì¥
        self.selection_history.append({
            "timestamp": datetime.now().isoformat(),
            "agent_id": agent_id,
            "selected_persona": best_persona.persona_id,
            "context": asdict(context),
            "confidence": best_score,
            "reasoning": recommendation.reasoning
        })
        
        logger.info(f"âœ… í˜ë¥´ì†Œë‚˜ ì„ íƒ ì™„ë£Œ: {best_persona.name} (ì‹ ë¢°ë„: {best_score:.2f})")
        
        return recommendation
    
    def _calculate_base_fitness_score(self, persona: AgentPersona, context: PersonaContext) -> float:
        """ê¸°ë³¸ ì í•©ì„± ì ìˆ˜ ê³„ì‚°"""
        score = 0.0
        
        # 1. ì „ë¬¸ì„± ë§¤ì¹­ (40%)
        expertise_match = len(set(persona.expertise_areas) & set(context.required_skills))
        max_expertise = max(len(persona.expertise_areas), len(context.required_skills))
        if max_expertise > 0:
            score += 0.4 * (expertise_match / max_expertise)
        
        # 2. í˜ë¥´ì†Œë‚˜ íƒ€ì… ì í•©ì„± (30%)
        type_score = self._calculate_type_fitness(persona.persona_type, context)
        score += 0.3 * type_score
        
        # 3. ê³¼ê±° ì„±ëŠ¥ (20%)
        if persona.usage_count > 0:
            score += 0.2 * persona.success_rate
        else:
            score += 0.1  # ê¸°ë³¸ ì ìˆ˜
        
        # 4. í˜‘ì—… ì í•©ì„± (10%)
        if context.collaboration_type != "none":
            collab_score = self._calculate_collaboration_fitness(persona, context)
            score += 0.1 * collab_score
        
        return min(score, 1.0)
    
    def _calculate_type_fitness(self, persona_type: PersonaType, context: PersonaContext) -> float:
        """í˜ë¥´ì†Œë‚˜ íƒ€ì… ì í•©ì„± ê³„ì‚°"""
        type_fitness_map = {
            PersonaType.EXPERT: {
                "data_analysis": 0.9,
                "machine_learning": 0.9,
                "research": 0.8,
                "consulting": 0.7
            },
            PersonaType.COLLABORATIVE: {
                "team_project": 0.9,
                "coordination": 0.9,
                "integration": 0.8,
                "communication": 0.8
            },
            PersonaType.ANALYTICAL: {
                "data_analysis": 0.9,
                "investigation": 0.9,
                "problem_solving": 0.8,
                "research": 0.8
            },
            PersonaType.CREATIVE: {
                "visualization": 0.9,
                "design": 0.9,
                "innovation": 0.8,
                "presentation": 0.8
            },
            PersonaType.METHODICAL: {
                "process_execution": 0.9,
                "quality_control": 0.9,
                "documentation": 0.8,
                "compliance": 0.8
            },
            PersonaType.ADAPTIVE: {
                "dynamic_requirements": 0.9,
                "learning": 0.9,
                "flexibility": 0.8,
                "experimentation": 0.8
            }
        }
        
        return type_fitness_map.get(persona_type, {}).get(context.task_type, 0.5)
    
    def _calculate_collaboration_fitness(self, persona: AgentPersona, context: PersonaContext) -> float:
        """í˜‘ì—… ì í•©ì„± ê³„ì‚°"""
        collab_prefs = persona.collaboration_preferences
        
        if context.collaboration_type == "leadership":
            return 0.8 if collab_prefs.get("leadership_style") in ["facilitative", "expertise_based"] else 0.5
        elif context.collaboration_type == "support":
            return 0.8 if collab_prefs.get("knowledge_sharing") in ["proactive", "inclusive"] else 0.5
        elif context.collaboration_type == "peer":
            return 0.8 if collab_prefs.get("feedback_approach") in ["collaborative", "constructive"] else 0.5
        
        return 0.6  # ê¸°ë³¸ ì ìˆ˜
    
    async def _llm_enhanced_selection(self, scored_personas: List[Tuple[AgentPersona, float]], 
                                    context: PersonaContext) -> Optional[List[Tuple[AgentPersona, float]]]:
        """LLM ê¸°ë°˜ í–¥ìƒëœ í˜ë¥´ì†Œë‚˜ ì„ íƒ"""
        if not self.openai_client:
            return None
        
        # ìƒìœ„ 3ê°œ í˜ë¥´ì†Œë‚˜ë§Œ LLM ë¶„ì„
        top_personas = scored_personas[:3]
        
        persona_descriptions = []
        for i, (persona, score) in enumerate(top_personas):
            persona_descriptions.append(f"""
{i+1}. {persona.name} (ê¸°ë³¸ ì ìˆ˜: {score:.2f})
   - íƒ€ì…: {persona.persona_type.value}
   - ì „ë¬¸ ì˜ì—­: {', '.join(persona.expertise_areas)}
   - í–‰ë™ íŠ¹ì„±: {', '.join(persona.behavioral_traits)}
   - ì†Œí†µ ìŠ¤íƒ€ì¼: {persona.communication_style}
   - ì„¤ëª…: {persona.description}
""")
        
        prompt = f"""
ë‹¤ìŒ ìƒí™©ì—ì„œ ìµœì ì˜ ì—ì´ì „íŠ¸ í˜ë¥´ì†Œë‚˜ë¥¼ ì„ íƒí•˜ê³  ì ìˆ˜ë¥¼ ì¡°ì •í•´ì£¼ì„¸ìš”.

**ìƒí™© ì •ë³´:**
- ì‚¬ìš©ì ìš”ì²­: {context.user_request}
- ì‘ì—… íƒ€ì…: {context.task_type}
- ë³µì¡ë„: {context.complexity_level}
- í˜‘ì—… íƒ€ì…: {context.collaboration_type}
- í•„ìš” ê¸°ìˆ : {', '.join(context.required_skills)}

**í˜ë¥´ì†Œë‚˜ í›„ë³´:**
{''.join(persona_descriptions)}

ê° í˜ë¥´ì†Œë‚˜ì˜ ì í•©ì„±ì„ 0.0-1.0 ì‚¬ì´ì˜ ì ìˆ˜ë¡œ í‰ê°€í•˜ê³ , ì„ íƒ ì´ìœ ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”.

ì‘ë‹µ í˜•ì‹:
{{
  "evaluations": [
    {{"persona_index": 1, "score": 0.85, "reasoning": "ì´ìœ "}},
    {{"persona_index": 2, "score": 0.72, "reasoning": "ì´ìœ "}},
    {{"persona_index": 3, "score": 0.68, "reasoning": "ì´ìœ "}}
  ],
  "recommendation": "ê°€ì¥ ì í•©í•œ í˜ë¥´ì†Œë‚˜ ì„ íƒ ê·¼ê±°"
}}
"""
        
        try:
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=500,
                temperature=0.3
            )
            
            result = json.loads(response.choices[0].message.content)
            
            # LLM ì ìˆ˜ë¡œ ì—…ë°ì´íŠ¸
            enhanced_personas = []
            for eval_result in result["evaluations"]:
                idx = eval_result["persona_index"] - 1
                if 0 <= idx < len(top_personas):
                    persona, _ = top_personas[idx]
                    enhanced_score = eval_result["score"]
                    enhanced_personas.append((persona, enhanced_score))
            
            return enhanced_personas
            
        except Exception as e:
            logger.error(f"LLM í˜ë¥´ì†Œë‚˜ ì„ íƒ ì˜¤ë¥˜: {e}")
            return None
    
    def _generate_adaptation_suggestions(self, persona: AgentPersona, context: PersonaContext) -> List[str]:
        """ì ì‘ ì œì•ˆ ìƒì„±"""
        suggestions = []
        
        # ë³µì¡ë„ ê¸°ë°˜ ì œì•ˆ
        if context.complexity_level == "high":
            suggestions.append("ë³µì¡í•œ ì‘ì—…ì„ ìœ„í•´ ë‹¨ê³„ë³„ ì ‘ê·¼ ë°©ì‹ ê°•í™”")
            suggestions.append("ì¤‘ê°„ ê²°ê³¼ ê²€ì¦ ë° í”¼ë“œë°± ìš”ì²­ ì¶”ê°€")
        
        # í˜‘ì—… ê¸°ë°˜ ì œì•ˆ
        if context.collaboration_type != "none":
            suggestions.append("ë‹¤ë¥¸ ì—ì´ì „íŠ¸ì™€ì˜ ì†Œí†µ ë°©ì‹ ìµœì í™”")
            suggestions.append("í˜‘ì—… ì§„í–‰ ìƒí™© ì •ê¸°ì  ê³µìœ ")
        
        # ì‚¬ìš©ì ì„ í˜¸ë„ ê¸°ë°˜ ì œì•ˆ
        if context.user_preferences.get("detailed_explanation"):
            suggestions.append("ë” ìì„¸í•œ ì„¤ëª…ê³¼ ì˜ˆì‹œ ì œê³µ")
        
        if context.user_preferences.get("visual_preferred"):
            suggestions.append("ì‹œê°ì  ìë£Œ ë° ì°¨íŠ¸ í™œìš© ê°•í™”")
        
        return suggestions
    
    def _generate_selection_reasoning(self, persona: AgentPersona, context: PersonaContext, score: float) -> str:
        """ì„ íƒ ê·¼ê±° ìƒì„±"""
        reasoning = f"{persona.name} í˜ë¥´ì†Œë‚˜ë¥¼ ì„ íƒí•œ ì´ìœ :\n"
        
        # ì „ë¬¸ì„± ë§¤ì¹­
        expertise_match = set(persona.expertise_areas) & set(context.required_skills)
        if expertise_match:
            reasoning += f"- ì „ë¬¸ ì˜ì—­ ë§¤ì¹­: {', '.join(expertise_match)}\n"
        
        # íƒ€ì… ì í•©ì„±
        type_fitness = self._calculate_type_fitness(persona.persona_type, context)
        if type_fitness > 0.7:
            reasoning += f"- í˜ë¥´ì†Œë‚˜ íƒ€ì… ({persona.persona_type.value})ì´ ì‘ì—… íƒ€ì… ({context.task_type})ì— ì í•©\n"
        
        # ì„±ëŠ¥ ì´ë ¥
        if persona.usage_count > 0:
            reasoning += f"- ê³¼ê±° ì„±ê³µë¥ : {persona.success_rate:.1%} ({persona.usage_count}íšŒ ì‚¬ìš©)\n"
        
        # í˜‘ì—… ì í•©ì„±
        if context.collaboration_type != "none":
            reasoning += f"- í˜‘ì—… ìŠ¤íƒ€ì¼ì´ {context.collaboration_type}ì— ì í•©\n"
        
        reasoning += f"- ì¢…í•© ì í•©ë„: {score:.2f}/1.0"
        
        return reasoning
    
    def _estimate_performance(self, persona: AgentPersona, context: PersonaContext) -> float:
        """ì„±ëŠ¥ ì¶”ì •"""
        # ê¸°ë³¸ ì„±ëŠ¥ (ê³¼ê±° ì„±ê³µë¥  ê¸°ë°˜)
        base_performance = persona.success_rate if persona.usage_count > 0 else 0.7
        
        # ì»¨í…ìŠ¤íŠ¸ ì í•©ì„± ë³´ì •
        context_bonus = 0.1 if self._calculate_base_fitness_score(persona, context) > 0.8 else 0.0
        
        # ë³µì¡ë„ ë³´ì •
        complexity_penalty = 0.1 if context.complexity_level == "high" else 0.0
        
        estimated_performance = base_performance + context_bonus - complexity_penalty
        
        return max(0.0, min(1.0, estimated_performance))

class ContextAdaptationEngine:
    """ì»¨í…ìŠ¤íŠ¸ ì ì‘ ì—”ì§„"""
    
    def __init__(self, openai_client: Optional[AsyncOpenAI] = None):
        self.openai_client = openai_client
        self.adaptation_cache: Dict[str, Dict[str, Any]] = {}
        
    async def adapt_persona(self, persona: AgentPersona, context: PersonaContext, 
                          adaptation_suggestions: List[str]) -> str:
        """í˜ë¥´ì†Œë‚˜ ì»¨í…ìŠ¤íŠ¸ ì ì‘"""
        logger.info(f"ğŸ”§ í˜ë¥´ì†Œë‚˜ ì ì‘: {persona.name}")
        
        # ìºì‹œ í™•ì¸
        cache_key = f"{persona.persona_id}_{context.task_type}_{context.complexity_level}"
        if cache_key in self.adaptation_cache:
            cached_adaptation = self.adaptation_cache[cache_key]
            if (datetime.now() - datetime.fromisoformat(cached_adaptation["timestamp"])).seconds < 3600:
                logger.info("ğŸ“‹ ìºì‹œëœ ì ì‘ ì‚¬ìš©")
                return cached_adaptation["adapted_prompt"]
        
        # ê¸°ë³¸ ì ì‘
        adapted_prompt = self._apply_basic_adaptations(persona, context, adaptation_suggestions)
        
        # LLM ê¸°ë°˜ ê³ ê¸‰ ì ì‘ (ê°€ëŠ¥í•œ ê²½ìš°)
        if self.openai_client:
            try:
                enhanced_prompt = await self._llm_enhanced_adaptation(adapted_prompt, context)
                if enhanced_prompt:
                    adapted_prompt = enhanced_prompt
            except Exception as e:
                logger.warning(f"LLM ê¸°ë°˜ ì ì‘ ì‹¤íŒ¨: {e}")
        
        # ìºì‹œ ì €ì¥
        self.adaptation_cache[cache_key] = {
            "adapted_prompt": adapted_prompt,
            "timestamp": datetime.now().isoformat()
        }
        
        logger.info("âœ… í˜ë¥´ì†Œë‚˜ ì ì‘ ì™„ë£Œ")
        return adapted_prompt
    
    def _apply_basic_adaptations(self, persona: AgentPersona, context: PersonaContext, 
                               suggestions: List[str]) -> str:
        """ê¸°ë³¸ ì ì‘ ì ìš©"""
        adapted_prompt = persona.system_prompt
        
        # ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ì¶”ê°€
        context_info = f"""
**í˜„ì¬ ì‘ì—… ì»¨í…ìŠ¤íŠ¸:**
- ì‚¬ìš©ì ìš”ì²­: {context.user_request}
- ì‘ì—… íƒ€ì…: {context.task_type}
- ë³µì¡ë„: {context.complexity_level}
- í˜‘ì—… íƒ€ì…: {context.collaboration_type}
- í•„ìš” ê¸°ìˆ : {', '.join(context.required_skills)}
"""
        
        # ì ì‘ ì œì•ˆ ì¶”ê°€
        if suggestions:
            adaptation_info = f"""
**ì´ë²ˆ ì‘ì—…ì„ ìœ„í•œ íŠ¹ë³„ ì§€ì¹¨:**
{chr(10).join(f"- {suggestion}" for suggestion in suggestions)}
"""
        else:
            adaptation_info = ""
        
        # ì„±ëŠ¥ ìš”êµ¬ì‚¬í•­ ì¶”ê°€
        if context.performance_requirements:
            perf_info = f"""
**ì„±ëŠ¥ ìš”êµ¬ì‚¬í•­:**
{chr(10).join(f"- {key}: {value}" for key, value in context.performance_requirements.items())}
"""
        else:
            perf_info = ""
        
        adapted_prompt += f"""
{context_info}
{adaptation_info}
{perf_info}
**ì¤‘ìš”:** ìœ„ ì»¨í…ìŠ¤íŠ¸ì™€ ì§€ì¹¨ì„ ê³ ë ¤í•˜ì—¬ ìµœì ì˜ ê²°ê³¼ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”.
"""
        
        return adapted_prompt
    
    async def _llm_enhanced_adaptation(self, base_prompt: str, context: PersonaContext) -> Optional[str]:
        """LLM ê¸°ë°˜ ê³ ê¸‰ ì ì‘"""
        if not self.openai_client:
            return None
        
        enhancement_prompt = f"""
ë‹¤ìŒ ì—ì´ì „íŠ¸ í˜ë¥´ì†Œë‚˜ í”„ë¡¬í”„íŠ¸ë¥¼ í˜„ì¬ ìƒí™©ì— ë” ì í•©í•˜ê²Œ ê°œì„ í•´ì£¼ì„¸ìš”.

**í˜„ì¬ í”„ë¡¬í”„íŠ¸:**
{base_prompt}

**ê°œì„  ìš”ì²­:**
1. í˜„ì¬ ì‘ì—… ì»¨í…ìŠ¤íŠ¸ì— ë” íŠ¹í™”ëœ ì§€ì¹¨ ì¶”ê°€
2. ì„±ëŠ¥ ìµœì í™”ë¥¼ ìœ„í•œ êµ¬ì²´ì ì¸ í–‰ë™ ë°©ì‹ ì œì•ˆ
3. ì‚¬ìš©ì ê²½í—˜ í–¥ìƒì„ ìœ„í•œ ì†Œí†µ ë°©ì‹ ê°œì„ 
4. ë¶ˆí•„ìš”í•œ ë‚´ìš© ì œê±° ë° ê°„ê²°ì„± ê°œì„ 

**ì œì•½ì‚¬í•­:**
- ì›ë˜ í˜ë¥´ì†Œë‚˜ì˜ í•µì‹¬ íŠ¹ì„± ìœ ì§€
- í”„ë¡¬í”„íŠ¸ ê¸¸ì´ëŠ” ê¸°ì¡´ ëŒ€ë¹„ 50% ì´ë‚´ë¡œ ì¦ê°€
- ì‹¤í–‰ ê°€ëŠ¥í•œ êµ¬ì²´ì  ì§€ì¹¨ í¬í•¨

ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ë§Œ ë°˜í™˜í•´ì£¼ì„¸ìš”.
"""
        
        try:
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": enhancement_prompt}],
                max_tokens=1000,
                temperature=0.2
            )
            
            enhanced_prompt = response.choices[0].message.content.strip()
            
            # ê²°ê³¼ ê²€ì¦
            if len(enhanced_prompt) > len(base_prompt) * 1.5:
                logger.warning("í–¥ìƒëœ í”„ë¡¬í”„íŠ¸ê°€ ë„ˆë¬´ ê¸¸ì–´ ê¸°ë³¸ ì ì‘ ì‚¬ìš©")
                return None
            
            return enhanced_prompt
            
        except Exception as e:
            logger.error(f"LLM í”„ë¡¬í”„íŠ¸ í–¥ìƒ ì˜¤ë¥˜: {e}")
            return None

class AgentPersonaManager:
    """Agent Persona Manager - ë©”ì¸ ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, registry_path: str = "persona_registry.json"):
        # í•µì‹¬ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.persona_registry = PersonaRegistry(registry_path)
        
        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        try:
            api_key = os.getenv("OPENAI_API_KEY")
            if api_key and api_key.strip():
                self.openai_client = AsyncOpenAI(api_key=api_key)
                logger.info("ğŸ¤– Agent Persona Manager with LLM")
            else:
                self.openai_client = None
                logger.info("ğŸ“Š Agent Persona Manager (No LLM)")
        except Exception as e:
            logger.warning(f"OpenAI client initialization failed: {e}")
            self.openai_client = None
        
        self.persona_selector = DynamicPersonaSelector(self.persona_registry, self.openai_client)
        self.adaptation_engine = ContextAdaptationEngine(self.openai_client)
        
        # ìƒíƒœ ê´€ë¦¬
        self.active_personas: Dict[str, str] = {}  # session_id -> persona_id
        self.performance_tracker: Dict[str, List[Dict[str, Any]]] = {}
        
        logger.info("ğŸ­ Agent Persona Manager ì´ˆê¸°í™” ì™„ë£Œ")
    
    async def initialize(self) -> Dict[str, Any]:
        """Persona Manager ì´ˆê¸°í™”"""
        logger.info("ğŸš€ Agent Persona Manager ì´ˆê¸°í™” ì¤‘...")
        
        # í˜ë¥´ì†Œë‚˜ ë¡œë“œ
        personas = await self.persona_registry.load_personas()
        
        initialization_result = {
            "total_personas": len(personas),
            "agents_with_personas": len(set(p.agent_id for p in personas.values())),
            "persona_types": list(set(p.persona_type.value for p in personas.values())),
            "initialization_status": "completed",
            "llm_enhanced": self.openai_client is not None,
            "features": [
                "dynamic_persona_selection",
                "context_adaptation",
                "performance_tracking",
                "collaboration_optimization"
            ]
        }
        
        if self.openai_client:
            initialization_result["features"].append("llm_enhanced_selection")
            initialization_result["features"].append("llm_enhanced_adaptation")
        
        logger.info(f"âœ… Agent Persona Manager ì´ˆê¸°í™” ì™„ë£Œ: {initialization_result['total_personas']}ê°œ í˜ë¥´ì†Œë‚˜")
        
        return initialization_result
    
    async def get_persona_for_agent(self, agent_id: str, user_request: str = None, 
                                  task_type: str = "general", complexity_level: str = "medium",
                                  collaboration_type: str = "none", required_skills: List[str] = None,
                                  session_id: str = None) -> Dict[str, Any]:
        """ì—ì´ì „íŠ¸ìš© ìµœì  í˜ë¥´ì†Œë‚˜ ì œê³µ"""
        logger.info(f"ğŸ¯ {agent_id} ì—ì´ì „íŠ¸ í˜ë¥´ì†Œë‚˜ ìš”ì²­")
        
        # ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        context = PersonaContext(
            context_id=session_id or str(uuid.uuid4()),
            user_request=user_request or "ì¼ë°˜ ì‘ì—…",
            task_type=task_type,
            complexity_level=complexity_level,
            collaboration_type=collaboration_type,
            required_skills=required_skills or [],
            session_history=[],
            user_preferences={},
            performance_requirements={},
            timestamp=datetime.now()
        )
        
        # í˜ë¥´ì†Œë‚˜ ì„ íƒ
        recommendation = await self.persona_selector.select_persona(agent_id, context)
        
        if not recommendation:
            return {
                "error": f"No suitable persona found for agent {agent_id}",
                "agent_id": agent_id,
                "context": asdict(context)
            }
        
        # í˜ë¥´ì†Œë‚˜ ì ì‘
        persona = await self.persona_registry.get_persona(recommendation.persona_id)
        adapted_prompt = await self.adaptation_engine.adapt_persona(
            persona, context, recommendation.adaptation_suggestions
        )
        
        # í™œì„± í˜ë¥´ì†Œë‚˜ ê¸°ë¡
        if session_id:
            self.active_personas[session_id] = recommendation.persona_id
        
        result = {
            "agent_id": agent_id,
            "persona_id": recommendation.persona_id,
            "persona_name": persona.name,
            "persona_type": persona.persona_type.value,
            "system_prompt": adapted_prompt,
            "behavioral_traits": persona.behavioral_traits,
            "communication_style": persona.communication_style,
            "collaboration_preferences": persona.collaboration_preferences,
            "recommendation": {
                "confidence": recommendation.confidence,
                "reasoning": recommendation.reasoning,
                "adaptation_suggestions": recommendation.adaptation_suggestions,
                "estimated_performance": recommendation.estimated_performance
            },
            "context": asdict(context),
            "session_id": session_id,
            "timestamp": datetime.now().isoformat()
        }
        
        logger.info(f"âœ… í˜ë¥´ì†Œë‚˜ ì œê³µ ì™„ë£Œ: {persona.name} (ì‹ ë¢°ë„: {recommendation.confidence:.2f})")
        
        return result
    
    async def update_persona_performance(self, session_id: str, success: bool, 
                                       performance_score: float = None, 
                                       feedback: str = None):
        """í˜ë¥´ì†Œë‚˜ ì„±ëŠ¥ ì—…ë°ì´íŠ¸"""
        if session_id not in self.active_personas:
            logger.warning(f"í™œì„± í˜ë¥´ì†Œë‚˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {session_id}")
            return
        
        persona_id = self.active_personas[session_id]
        
        # ì„±ëŠ¥ ê¸°ë¡
        performance_record = {
            "session_id": session_id,
            "persona_id": persona_id,
            "timestamp": datetime.now().isoformat(),
            "success": success,
            "performance_score": performance_score,
            "feedback": feedback
        }
        
        if persona_id not in self.performance_tracker:
            self.performance_tracker[persona_id] = []
        
        self.performance_tracker[persona_id].append(performance_record)
        
        # í˜ë¥´ì†Œë‚˜ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì—…ë°ì´íŠ¸
        await self.persona_registry.update_persona_performance(persona_id, success, performance_score)
        
        logger.info(f"ğŸ“Š í˜ë¥´ì†Œë‚˜ ì„±ëŠ¥ ì—…ë°ì´íŠ¸: {persona_id} ({'ì„±ê³µ' if success else 'ì‹¤íŒ¨'})")
    
    async def get_persona_analytics(self, agent_id: str = None) -> Dict[str, Any]:
        """í˜ë¥´ì†Œë‚˜ ë¶„ì„ ì •ë³´ ì œê³µ"""
        personas = await self.persona_registry.load_personas()
        
        if agent_id:
            agent_personas = [p for p in personas.values() if p.agent_id == agent_id]
        else:
            agent_personas = list(personas.values())
        
        analytics = {
            "total_personas": len(agent_personas),
            "persona_types": {},
            "performance_summary": {},
            "usage_statistics": {},
            "top_performers": [],
            "improvement_suggestions": []
        }
        
        # íƒ€ì…ë³„ ë¶„ì„
        for persona in agent_personas:
            persona_type = persona.persona_type.value
            if persona_type not in analytics["persona_types"]:
                analytics["persona_types"][persona_type] = 0
            analytics["persona_types"][persona_type] += 1
        
        # ì„±ëŠ¥ ë¶„ì„
        for persona in agent_personas:
            if persona.usage_count > 0:
                analytics["performance_summary"][persona.persona_id] = {
                    "name": persona.name,
                    "usage_count": persona.usage_count,
                    "success_rate": persona.success_rate,
                    "avg_performance": persona.performance_metrics.get("average_performance", 0.0)
                }
        
        # ì‚¬ìš© í†µê³„
        total_usage = sum(p.usage_count for p in agent_personas)
        analytics["usage_statistics"] = {
            "total_usage": total_usage,
            "average_usage_per_persona": total_usage / len(agent_personas) if agent_personas else 0,
            "most_used_persona": max(agent_personas, key=lambda p: p.usage_count).name if agent_personas else None
        }
        
        # ìƒìœ„ ì„±ëŠ¥ í˜ë¥´ì†Œë‚˜
        top_performers = sorted(
            [p for p in agent_personas if p.usage_count > 0],
            key=lambda p: p.success_rate,
            reverse=True
        )[:5]
        
        analytics["top_performers"] = [
            {
                "persona_id": p.persona_id,
                "name": p.name,
                "success_rate": p.success_rate,
                "usage_count": p.usage_count
            }
            for p in top_performers
        ]
        
        return analytics
    
    async def close(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        # ì„±ëŠ¥ ë°ì´í„° ì €ì¥
        try:
            performance_data = {
                "performance_tracker": self.performance_tracker,
                "active_personas": self.active_personas,
                "last_updated": datetime.now().isoformat()
            }
            
            async with aiofiles.open("persona_performance.json", 'w', encoding='utf-8') as f:
                await f.write(json.dumps(performance_data, ensure_ascii=False, indent=2))
                
        except Exception as e:
            logger.error(f"ì„±ëŠ¥ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
        
        logger.info("ğŸ”š Agent Persona Manager ì¢…ë£Œ")

# ì „ì—­ Agent Persona Manager ì¸ìŠ¤í„´ìŠ¤
_agent_persona_manager = None

def get_agent_persona_manager() -> AgentPersonaManager:
    """Agent Persona Manager ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜ (ì‹±ê¸€í†¤ íŒ¨í„´)"""
    global _agent_persona_manager
    if _agent_persona_manager is None:
        _agent_persona_manager = AgentPersonaManager()
    return _agent_persona_manager

async def initialize_agent_persona_manager():
    """Agent Persona Manager ì´ˆê¸°í™” (í¸ì˜ í•¨ìˆ˜)"""
    manager = get_agent_persona_manager()
    return await manager.initialize()

async def get_persona_for_agent(agent_id: str, **kwargs):
    """ì—ì´ì „íŠ¸ìš© í˜ë¥´ì†Œë‚˜ ì œê³µ (í¸ì˜ í•¨ìˆ˜)"""
    manager = get_agent_persona_manager()
    return await manager.get_persona_for_agent(agent_id, **kwargs) 