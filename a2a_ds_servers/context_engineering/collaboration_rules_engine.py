#!/usr/bin/env python3
"""
ğŸ¤ Collaboration Rules Engine - Context Engineering ì›Œí¬í”Œë¡œìš° ê´€ë¦¬

A2A ê¸°ë°˜ Context Engineering í”Œë«í¼ì—ì„œ ì—ì´ì „íŠ¸ ê°„ í˜‘ì—… ê·œì¹™ ë° ì›Œí¬í”Œë¡œìš°ë¥¼ ì •ì˜í•˜ê³  ê´€ë¦¬í•˜ëŠ” í•µì‹¬ ì‹œìŠ¤í…œ
Agent Persona Managerì™€ ì—°ê³„í•˜ì—¬ ìµœì í™”ëœ ë©€í‹°ì—ì´ì „íŠ¸ í˜‘ì—… í™˜ê²½ ì œê³µ

Key Features:
- í˜‘ì—… íŒ¨í„´ í•™ìŠµ - ì„±ê³µì ì¸ í˜‘ì—… íŒ¨í„´ ìë™ í•™ìŠµ
- ì¶©ëŒ í•´ê²° - ì—ì´ì „íŠ¸ ê°„ ì¶©ëŒ ìƒí™© ìë™ ê°ì§€ ë° í•´ê²°
- íš¨ìœ¨ì„± ìµœì í™” - ì›Œí¬í”Œë¡œìš° ì„±ëŠ¥ ìµœì í™”
- ë™ì  ê·œì¹™ ìƒì„± - ìƒí™©ì— ë”°ë¥¸ ë™ì  í˜‘ì—… ê·œì¹™ ìƒì„±
- ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ - í˜‘ì—… ìƒíƒœ ì‹¤ì‹œê°„ ì¶”ì  ë° ì¡°ì •

Architecture:
- Rule Registry: í˜‘ì—… ê·œì¹™ ì €ì¥ì†Œ ë° ê´€ë¦¬
- Pattern Learning Engine: í˜‘ì—… íŒ¨í„´ í•™ìŠµ ë° ë¶„ì„
- Conflict Resolution System: ì¶©ëŒ ê°ì§€ ë° í•´ê²°
- Workflow Optimizer: ì›Œí¬í”Œë¡œìš° ì„±ëŠ¥ ìµœì í™”
- Real-time Monitor: ì‹¤ì‹œê°„ í˜‘ì—… ëª¨ë‹ˆí„°ë§
"""

import asyncio
import json
import logging
import os
import time
import uuid
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Set, Tuple, Union
from dataclasses import dataclass, asdict, field
from enum import Enum
from collections import defaultdict, deque
import statistics

import aiofiles
from openai import AsyncOpenAI

# Context Engineering ê´€ë ¨ ì„í¬íŠ¸
import sys
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class RuleType(Enum):
    """í˜‘ì—… ê·œì¹™ íƒ€ì…"""
    WORKFLOW = "workflow"               # ì›Œí¬í”Œë¡œìš° ê·œì¹™
    PRIORITY = "priority"               # ìš°ì„ ìˆœìœ„ ê·œì¹™
    RESOURCE = "resource"               # ë¦¬ì†ŒìŠ¤ í• ë‹¹ ê·œì¹™
    DEPENDENCY = "dependency"           # ì˜ì¡´ì„± ê·œì¹™
    CONFLICT_RESOLUTION = "conflict"    # ì¶©ëŒ í•´ê²° ê·œì¹™
    PERFORMANCE = "performance"         # ì„±ëŠ¥ ìµœì í™” ê·œì¹™
    COMMUNICATION = "communication"     # ì†Œí†µ ê·œì¹™
    QUALITY = "quality"                 # í’ˆì§ˆ ë³´ì¦ ê·œì¹™

class CollaborationStatus(Enum):
    """í˜‘ì—… ìƒíƒœ"""
    PENDING = "pending"
    ACTIVE = "active"
    PAUSED = "paused"
    COMPLETED = "completed"
    FAILED = "failed"
    CONFLICT = "conflict"
    OPTIMIZING = "optimizing"

class ConflictType(Enum):
    """ì¶©ëŒ íƒ€ì…"""
    RESOURCE_CONTENTION = "resource_contention"
    PRIORITY_CONFLICT = "priority_conflict"
    DEPENDENCY_CYCLE = "dependency_cycle"
    COMMUNICATION_BREAKDOWN = "communication_breakdown"
    PERFORMANCE_DEGRADATION = "performance_degradation"
    QUALITY_MISMATCH = "quality_mismatch"

@dataclass
class CollaborationRule:
    """í˜‘ì—… ê·œì¹™ ì •ì˜"""
    rule_id: str
    rule_type: RuleType
    name: str
    description: str
    conditions: Dict[str, Any]
    actions: List[Dict[str, Any]]
    priority: int
    scope: str  # "global", "domain", "session"
    applicable_agents: List[str]
    success_rate: float
    usage_count: int
    created_at: datetime
    updated_at: datetime
    is_active: bool = True
    learned_pattern: bool = False

@dataclass
class CollaborationEvent:
    """í˜‘ì—… ì´ë²¤íŠ¸"""
    event_id: str
    event_type: str
    timestamp: datetime
    agents_involved: List[str]
    event_data: Dict[str, Any]
    duration: float
    success: bool
    performance_metrics: Dict[str, float]
    rule_applied: Optional[str] = None
    conflict_detected: Optional[str] = None

@dataclass
class WorkflowPattern:
    """ì›Œí¬í”Œë¡œìš° íŒ¨í„´"""
    pattern_id: str
    pattern_name: str
    agent_sequence: List[str]
    typical_duration: float
    success_rate: float
    usage_frequency: int
    performance_score: float
    context_requirements: Dict[str, Any]
    learned_rules: List[str]
    last_updated: datetime

@dataclass
class ConflictSituation:
    """ì¶©ëŒ ìƒí™©"""
    conflict_id: str
    conflict_type: ConflictType
    involved_agents: List[str]
    description: str
    detected_at: datetime
    resolution_strategy: str
    resolution_actions: List[Dict[str, Any]]
    resolution_time: Optional[float] = None
    resolved: bool = False
    success: bool = False

class RuleRegistry:
    """í˜‘ì—… ê·œì¹™ ì €ì¥ì†Œ"""
    
    def __init__(self, registry_path: str = "collaboration_rules.json"):
        self.registry_path = registry_path
        self.rules: Dict[str, CollaborationRule] = {}
        self.rule_templates: Dict[str, Dict[str, Any]] = {}
        
        # ê¸°ë³¸ ê·œì¹™ í…œí”Œë¦¿ ë¡œë“œ
        self._load_default_rule_templates()
        
        logger.info("ğŸ¤ Rule Registry ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _load_default_rule_templates(self):
        """ê¸°ë³¸ ê·œì¹™ í…œí”Œë¦¿ ë¡œë“œ"""
        self.rule_templates = {
            "sequential_data_processing": {
                "rule_type": RuleType.WORKFLOW,
                "name": "Sequential Data Processing",
                "description": "ë°ì´í„° ì²˜ë¦¬ë¥¼ ìœ„í•œ ìˆœì°¨ì  ì›Œí¬í”Œë¡œìš°",
                "conditions": {
                    "task_type": "data_processing",
                    "data_size": "large",
                    "complexity": "high"
                },
                "actions": [
                    {"action": "assign_agent", "agent": "data_loader", "phase": 1},
                    {"action": "assign_agent", "agent": "data_cleaning", "phase": 2},
                    {"action": "assign_agent", "agent": "eda_tools", "phase": 3},
                    {"action": "assign_agent", "agent": "data_visualization", "phase": 4}
                ],
                "priority": 8,
                "scope": "domain"
            },
            
            "parallel_analysis": {
                "rule_type": RuleType.WORKFLOW,
                "name": "Parallel Analysis Workflow",
                "description": "ë³‘ë ¬ ë¶„ì„ì„ ìœ„í•œ ì›Œí¬í”Œë¡œìš°",
                "conditions": {
                    "task_type": "analysis",
                    "urgency": "high",
                    "agents_available": ">=3"
                },
                "actions": [
                    {"action": "parallel_assign", "agents": ["eda_tools", "data_visualization", "feature_engineering"]},
                    {"action": "sync_point", "wait_for": "all"},
                    {"action": "aggregate_results", "coordinator": "pandas_collaboration_hub"}
                ],
                "priority": 7,
                "scope": "session"
            },
            
            "resource_priority": {
                "rule_type": RuleType.PRIORITY,
                "name": "Resource Priority Management",
                "description": "ë¦¬ì†ŒìŠ¤ ìš°ì„ ìˆœìœ„ ê´€ë¦¬",
                "conditions": {
                    "resource_contention": True,
                    "priority_conflict": True
                },
                "actions": [
                    {"action": "evaluate_priority", "criteria": ["urgency", "complexity", "user_importance"]},
                    {"action": "allocate_resource", "method": "highest_priority_first"},
                    {"action": "queue_remaining", "strategy": "fifo"}
                ],
                "priority": 9,
                "scope": "global"
            },
            
            "dependency_resolution": {
                "rule_type": RuleType.DEPENDENCY,
                "name": "Dependency Resolution",
                "description": "ì˜ì¡´ì„± í•´ê²° ê·œì¹™",
                "conditions": {
                    "dependency_conflict": True,
                    "circular_dependency": True
                },
                "actions": [
                    {"action": "detect_cycle", "algorithm": "dfs"},
                    {"action": "break_cycle", "strategy": "lowest_priority_edge"},
                    {"action": "reorder_workflow", "optimization": "topological_sort"}
                ],
                "priority": 10,
                "scope": "session"
            },
            
            "performance_optimization": {
                "rule_type": RuleType.PERFORMANCE,
                "name": "Performance Optimization",
                "description": "ì„±ëŠ¥ ìµœì í™” ê·œì¹™",
                "conditions": {
                    "performance_degradation": True,
                    "response_time": ">threshold"
                },
                "actions": [
                    {"action": "identify_bottleneck", "method": "performance_profiling"},
                    {"action": "optimize_agent_load", "strategy": "load_balancing"},
                    {"action": "adjust_parallelism", "target": "optimal_throughput"}
                ],
                "priority": 6,
                "scope": "global"
            },
            
            "conflict_mediation": {
                "rule_type": RuleType.CONFLICT_RESOLUTION,
                "name": "Conflict Mediation",
                "description": "ì—ì´ì „íŠ¸ ê°„ ì¶©ëŒ ì¡°ì •",
                "conditions": {
                    "communication_conflict": True,
                    "result_inconsistency": True
                },
                "actions": [
                    {"action": "pause_conflicting_agents", "duration": "5s"},
                    {"action": "analyze_conflict", "method": "context_comparison"},
                    {"action": "mediate_resolution", "mediator": "orchestrator"},
                    {"action": "resume_with_agreement", "verification": True}
                ],
                "priority": 9,
                "scope": "session"
            },
            
            "quality_assurance": {
                "rule_type": RuleType.QUALITY,
                "name": "Quality Assurance Protocol",
                "description": "í’ˆì§ˆ ë³´ì¦ í”„ë¡œí† ì½œ",
                "conditions": {
                    "quality_check": "required",
                    "critical_task": True
                },
                "actions": [
                    {"action": "validate_input", "validator": "data_cleaning"},
                    {"action": "cross_validate", "method": "peer_review"},
                    {"action": "quality_gate", "threshold": 0.95},
                    {"action": "approve_or_retry", "max_retries": 3}
                ],
                "priority": 8,
                "scope": "domain"
            }
        }
    
    async def load_rules(self) -> Dict[str, CollaborationRule]:
        """ê·œì¹™ ë¡œë“œ"""
        try:
            if os.path.exists(self.registry_path):
                async with aiofiles.open(self.registry_path, 'r', encoding='utf-8') as f:
                    content = await f.read()
                    data = json.loads(content)
                    
                    for rule_data in data.get('rules', []):
                        rule = CollaborationRule(
                            rule_id=rule_data['rule_id'],
                            rule_type=RuleType(rule_data['rule_type']),
                            name=rule_data['name'],
                            description=rule_data['description'],
                            conditions=rule_data['conditions'],
                            actions=rule_data['actions'],
                            priority=rule_data['priority'],
                            scope=rule_data['scope'],
                            applicable_agents=rule_data['applicable_agents'],
                            success_rate=rule_data.get('success_rate', 0.0),
                            usage_count=rule_data.get('usage_count', 0),
                            created_at=datetime.fromisoformat(rule_data['created_at']),
                            updated_at=datetime.fromisoformat(rule_data['updated_at']),
                            is_active=rule_data.get('is_active', True),
                            learned_pattern=rule_data.get('learned_pattern', False)
                        )
                        self.rules[rule.rule_id] = rule
                        
                logger.info(f"ğŸ“š {len(self.rules)}ê°œ í˜‘ì—… ê·œì¹™ ë¡œë“œ ì™„ë£Œ")
            else:
                logger.info("ğŸ“š ê¸°ë³¸ í˜‘ì—… ê·œì¹™ ìƒì„± ì¤‘...")
                await self._create_default_rules()
                
        except Exception as e:
            logger.error(f"âŒ í˜‘ì—… ê·œì¹™ ë¡œë“œ ì‹¤íŒ¨: {e}")
            await self._create_default_rules()
        
        return self.rules
    
    async def _create_default_rules(self):
        """ê¸°ë³¸ í˜‘ì—… ê·œì¹™ ìƒì„±"""
        for template_id, template in self.rule_templates.items():
            rule = CollaborationRule(
                rule_id=f"default_{template_id}",
                rule_type=template["rule_type"],
                name=template["name"],
                description=template["description"],
                conditions=template["conditions"],
                actions=template["actions"],
                priority=template["priority"],
                scope=template["scope"],
                applicable_agents=[],  # ëª¨ë“  ì—ì´ì „íŠ¸ì— ì ìš© ê°€ëŠ¥
                success_rate=0.0,
                usage_count=0,
                created_at=datetime.now(),
                updated_at=datetime.now(),
                is_active=True,
                learned_pattern=False
            )
            
            self.rules[rule.rule_id] = rule
        
        await self.save_rules()
        logger.info(f"ğŸ¤ {len(self.rules)}ê°œ ê¸°ë³¸ í˜‘ì—… ê·œì¹™ ìƒì„± ì™„ë£Œ")
    
    async def save_rules(self):
        """ê·œì¹™ ì €ì¥"""
        try:
            data = {
                "rules": [
                    {
                        "rule_id": rule.rule_id,
                        "rule_type": rule.rule_type.value,
                        "name": rule.name,
                        "description": rule.description,
                        "conditions": rule.conditions,
                        "actions": rule.actions,
                        "priority": rule.priority,
                        "scope": rule.scope,
                        "applicable_agents": rule.applicable_agents,
                        "success_rate": rule.success_rate,
                        "usage_count": rule.usage_count,
                        "created_at": rule.created_at.isoformat(),
                        "updated_at": rule.updated_at.isoformat(),
                        "is_active": rule.is_active,
                        "learned_pattern": rule.learned_pattern
                    }
                    for rule in self.rules.values()
                ],
                "updated_at": datetime.now().isoformat()
            }
            
            async with aiofiles.open(self.registry_path, 'w', encoding='utf-8') as f:
                await f.write(json.dumps(data, ensure_ascii=False, indent=2))
                
            logger.info(f"ğŸ’¾ {len(self.rules)}ê°œ í˜‘ì—… ê·œì¹™ ì €ì¥ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ í˜‘ì—… ê·œì¹™ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    async def add_rule(self, rule: CollaborationRule):
        """ê·œì¹™ ì¶”ê°€"""
        self.rules[rule.rule_id] = rule
        await self.save_rules()
    
    async def update_rule_performance(self, rule_id: str, success: bool):
        """ê·œì¹™ ì„±ëŠ¥ ì—…ë°ì´íŠ¸"""
        if rule_id in self.rules:
            rule = self.rules[rule_id]
            rule.usage_count += 1
            
            if success:
                current_success_count = rule.success_rate * (rule.usage_count - 1)
                new_success_count = current_success_count + 1
                rule.success_rate = new_success_count / rule.usage_count
            
            rule.updated_at = datetime.now()
            await self.save_rules()
    
    async def get_applicable_rules(self, context: Dict[str, Any], agents: List[str]) -> List[CollaborationRule]:
        """ì ìš© ê°€ëŠ¥í•œ ê·œì¹™ ì¡°íšŒ"""
        applicable_rules = []
        
        for rule in self.rules.values():
            if not rule.is_active:
                continue
            
            # ì¡°ê±´ ë§¤ì¹­ í™•ì¸
            if self._matches_conditions(rule.conditions, context):
                # ì—ì´ì „íŠ¸ ì ìš© ë²”ìœ„ í™•ì¸
                if not rule.applicable_agents or any(agent in rule.applicable_agents for agent in agents):
                    applicable_rules.append(rule)
        
        # ìš°ì„ ìˆœìœ„ë¡œ ì •ë ¬
        applicable_rules.sort(key=lambda r: r.priority, reverse=True)
        
        return applicable_rules
    
    def _matches_conditions(self, rule_conditions: Dict[str, Any], context: Dict[str, Any]) -> bool:
        """ì¡°ê±´ ë§¤ì¹­ í™•ì¸"""
        for key, expected_value in rule_conditions.items():
            if key not in context:
                continue
            
            actual_value = context[key]
            
            # ë¬¸ìì—´ ë¹„êµ
            if isinstance(expected_value, str):
                if isinstance(actual_value, str) and expected_value != actual_value:
                    return False
            
            # ë¶ˆë¦° ë¹„êµ
            elif isinstance(expected_value, bool):
                if isinstance(actual_value, bool) and expected_value != actual_value:
                    return False
            
            # ìˆ«ì ë¹„êµ (ë¬¸ìì—´ë¡œ í‘œí˜„ëœ ì¡°ê±´ í¬í•¨)
            elif isinstance(expected_value, str) and expected_value.startswith((">=", "<=", ">", "<", "==")):
                try:
                    operator = expected_value[:2] if expected_value.startswith((">=", "<=")) else expected_value[0]
                    threshold = float(expected_value[len(operator):])
                    
                    if operator == ">=":
                        if actual_value < threshold:
                            return False
                    elif operator == "<=":
                        if actual_value > threshold:
                            return False
                    elif operator == ">":
                        if actual_value <= threshold:
                            return False
                    elif operator == "<":
                        if actual_value >= threshold:
                            return False
                    elif operator == "==":
                        if actual_value != threshold:
                            return False
                except (ValueError, TypeError):
                    continue
        
        return True

class PatternLearningEngine:
    """í˜‘ì—… íŒ¨í„´ í•™ìŠµ ì—”ì§„"""
    
    def __init__(self, rule_registry: RuleRegistry):
        self.rule_registry = rule_registry
        self.collaboration_history: List[CollaborationEvent] = []
        self.learned_patterns: Dict[str, WorkflowPattern] = {}
        self.learning_threshold = 5  # íŒ¨í„´ í•™ìŠµì„ ìœ„í•œ ìµœì†Œ ê´€ì°° íšŸìˆ˜
        
    async def record_collaboration_event(self, event: CollaborationEvent):
        """í˜‘ì—… ì´ë²¤íŠ¸ ê¸°ë¡"""
        self.collaboration_history.append(event)
        
        # ìµœê·¼ 1000ê°œ ì´ë²¤íŠ¸ë§Œ ìœ ì§€
        if len(self.collaboration_history) > 1000:
            self.collaboration_history = self.collaboration_history[-1000:]
        
        # íŒ¨í„´ í•™ìŠµ íŠ¸ë¦¬ê±°
        if len(self.collaboration_history) % 10 == 0:  # 10ê°œ ì´ë²¤íŠ¸ë§ˆë‹¤ í•™ìŠµ
            await self._analyze_patterns()
    
    async def _analyze_patterns(self):
        """íŒ¨í„´ ë¶„ì„ ë° í•™ìŠµ"""
        logger.info("ğŸ§  í˜‘ì—… íŒ¨í„´ ë¶„ì„ ì‹œì‘")
        
        # ìµœê·¼ ì´ë²¤íŠ¸ë“¤ì„ ë¶„ì„í•˜ì—¬ íŒ¨í„´ ì¶”ì¶œ
        recent_events = self.collaboration_history[-50:]  # ìµœê·¼ 50ê°œ ì´ë²¤íŠ¸
        
        # ì—ì´ì „íŠ¸ ì‹œí€€ìŠ¤ íŒ¨í„´ ë¶„ì„
        sequence_patterns = self._extract_sequence_patterns(recent_events)
        
        # ì„±ê³µì ì¸ íŒ¨í„´ ì‹ë³„
        successful_patterns = self._identify_successful_patterns(sequence_patterns)
        
        # ìƒˆë¡œìš´ ê·œì¹™ ìƒì„±
        for pattern in successful_patterns:
            if pattern.usage_frequency >= self.learning_threshold and pattern.success_rate > 0.8:
                await self._create_learned_rule(pattern)
        
        logger.info(f"âœ… íŒ¨í„´ ë¶„ì„ ì™„ë£Œ: {len(successful_patterns)}ê°œ ì„±ê³µ íŒ¨í„´ ë°œê²¬")
    
    def _extract_sequence_patterns(self, events: List[CollaborationEvent]) -> Dict[str, WorkflowPattern]:
        """ì‹œí€€ìŠ¤ íŒ¨í„´ ì¶”ì¶œ"""
        patterns = {}
        
        # ì—°ì†ëœ ì´ë²¤íŠ¸ë“¤ì„ ê·¸ë£¹í™”
        for i in range(len(events) - 2):
            sequence = []
            for j in range(i, min(i + 5, len(events))):  # ìµœëŒ€ 5ê°œ ì—ì´ì „íŠ¸ ì‹œí€€ìŠ¤
                sequence.extend(events[j].agents_involved)
            
            if len(sequence) >= 2:
                pattern_key = "_".join(sequence[:4])  # ìµœëŒ€ 4ê°œ ì—ì´ì „íŠ¸
                
                if pattern_key not in patterns:
                    patterns[pattern_key] = WorkflowPattern(
                        pattern_id=f"learned_{pattern_key}_{int(time.time())}",
                        pattern_name=f"Learned Pattern: {pattern_key}",
                        agent_sequence=sequence[:4],
                        typical_duration=0.0,
                        success_rate=0.0,
                        usage_frequency=0,
                        performance_score=0.0,
                        context_requirements={},
                        learned_rules=[],
                        last_updated=datetime.now()
                    )
                
                patterns[pattern_key].usage_frequency += 1
        
        return patterns
    
    def _identify_successful_patterns(self, patterns: Dict[str, WorkflowPattern]) -> List[WorkflowPattern]:
        """ì„±ê³µì ì¸ íŒ¨í„´ ì‹ë³„"""
        successful_patterns = []
        
        for pattern in patterns.values():
            # í•´ë‹¹ íŒ¨í„´ê³¼ ê´€ë ¨ëœ ì´ë²¤íŠ¸ë“¤ ì°¾ê¸°
            related_events = [
                event for event in self.collaboration_history
                if any(agent in pattern.agent_sequence for agent in event.agents_involved)
            ]
            
            if related_events:
                # ì„±ê³µë¥  ê³„ì‚°
                successful_events = [e for e in related_events if e.success]
                pattern.success_rate = len(successful_events) / len(related_events)
                
                # í‰ê·  ì§€ì† ì‹œê°„ ê³„ì‚°
                pattern.typical_duration = statistics.mean([e.duration for e in related_events])
                
                # ì„±ëŠ¥ ì ìˆ˜ ê³„ì‚°
                if successful_events:
                    avg_performance = statistics.mean([
                        statistics.mean(list(e.performance_metrics.values()))
                        for e in successful_events
                        if e.performance_metrics
                    ])
                    pattern.performance_score = avg_performance
                
                if pattern.success_rate > 0.6 and pattern.usage_frequency >= 3:
                    successful_patterns.append(pattern)
        
        return successful_patterns
    
    async def _create_learned_rule(self, pattern: WorkflowPattern):
        """í•™ìŠµëœ íŒ¨í„´ìœ¼ë¡œë¶€í„° ê·œì¹™ ìƒì„±"""
        rule_id = f"learned_pattern_{pattern.pattern_id}"
        
        # ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ê·œì¹™ì¸ì§€ í™•ì¸
        if rule_id in self.rule_registry.rules:
            return
        
        # ìƒˆë¡œìš´ ê·œì¹™ ìƒì„±
        learned_rule = CollaborationRule(
            rule_id=rule_id,
            rule_type=RuleType.WORKFLOW,
            name=f"Learned: {pattern.pattern_name}",
            description=f"íŒ¨í„´ í•™ìŠµìœ¼ë¡œ ìƒì„±ëœ ê·œì¹™ (ì„±ê³µë¥ : {pattern.success_rate:.1%})",
            conditions={
                "pattern_match": True,
                "agents_available": pattern.agent_sequence,
                "performance_requirement": "high" if pattern.performance_score > 0.8 else "medium"
            },
            actions=[
                {
                    "action": "apply_learned_sequence",
                    "sequence": pattern.agent_sequence,
                    "expected_duration": pattern.typical_duration,
                    "confidence": pattern.success_rate
                }
            ],
            priority=int(pattern.success_rate * 10),  # ì„±ê³µë¥ ì— ë¹„ë¡€í•œ ìš°ì„ ìˆœìœ„
            scope="session",
            applicable_agents=pattern.agent_sequence,
            success_rate=pattern.success_rate,
            usage_count=pattern.usage_frequency,
            created_at=datetime.now(),
            updated_at=datetime.now(),
            is_active=True,
            learned_pattern=True
        )
        
        await self.rule_registry.add_rule(learned_rule)
        pattern.learned_rules.append(rule_id)
        
        logger.info(f"ğŸ“ ìƒˆë¡œìš´ í•™ìŠµ ê·œì¹™ ìƒì„±: {learned_rule.name}")

class ConflictResolutionSystem:
    """ì¶©ëŒ í•´ê²° ì‹œìŠ¤í…œ"""
    
    def __init__(self, rule_registry: RuleRegistry):
        self.rule_registry = rule_registry
        self.active_conflicts: Dict[str, ConflictSituation] = {}
        self.resolution_strategies: Dict[ConflictType, List[str]] = {}
        self.conflict_history: List[ConflictSituation] = []
        
        self._initialize_resolution_strategies()
    
    def _initialize_resolution_strategies(self):
        """í•´ê²° ì „ëµ ì´ˆê¸°í™”"""
        self.resolution_strategies = {
            ConflictType.RESOURCE_CONTENTION: [
                "priority_based_allocation",
                "time_slicing",
                "resource_scaling",
                "queue_management"
            ],
            ConflictType.PRIORITY_CONFLICT: [
                "priority_reevaluation",
                "escalation_to_orchestrator",
                "user_intervention",
                "automatic_resolution"
            ],
            ConflictType.DEPENDENCY_CYCLE: [
                "cycle_detection",
                "dependency_breaking",
                "workflow_reordering",
                "parallel_execution"
            ],
            ConflictType.COMMUNICATION_BREAKDOWN: [
                "communication_retry",
                "alternative_channel",
                "mediator_intervention",
                "isolation_and_restart"
            ],
            ConflictType.PERFORMANCE_DEGRADATION: [
                "load_balancing",
                "resource_optimization",
                "caching_strategy",
                "algorithm_switching"
            ],
            ConflictType.QUALITY_MISMATCH: [
                "quality_validation",
                "result_reconciliation",
                "expert_review",
                "quality_threshold_adjustment"
            ]
        }
    
    async def detect_conflict(self, context: Dict[str, Any], agents: List[str]) -> Optional[ConflictSituation]:
        """ì¶©ëŒ ê°ì§€"""
        # ë¦¬ì†ŒìŠ¤ ê²½í•© ê°ì§€
        if context.get("resource_contention", False):
            return await self._create_conflict(
                ConflictType.RESOURCE_CONTENTION,
                agents,
                "Multiple agents competing for the same resource"
            )
        
        # ìš°ì„ ìˆœìœ„ ì¶©ëŒ ê°ì§€
        if context.get("priority_conflict", False):
            return await self._create_conflict(
                ConflictType.PRIORITY_CONFLICT,
                agents,
                "Conflicting priority assignments detected"
            )
        
        # ì˜ì¡´ì„± ì‚¬ì´í´ ê°ì§€
        if context.get("dependency_cycle", False):
            return await self._create_conflict(
                ConflictType.DEPENDENCY_CYCLE,
                agents,
                "Circular dependency detected in workflow"
            )
        
        # ì„±ëŠ¥ ì €í•˜ ê°ì§€
        if context.get("performance_degradation", False):
            return await self._create_conflict(
                ConflictType.PERFORMANCE_DEGRADATION,
                agents,
                "Performance degradation detected"
            )
        
        return None
    
    async def _create_conflict(self, conflict_type: ConflictType, agents: List[str], description: str) -> ConflictSituation:
        """ì¶©ëŒ ìƒí™© ìƒì„±"""
        conflict_id = f"conflict_{uuid.uuid4().hex[:8]}"
        
        conflict = ConflictSituation(
            conflict_id=conflict_id,
            conflict_type=conflict_type,
            involved_agents=agents,
            description=description,
            detected_at=datetime.now(),
            resolution_strategy="",
            resolution_actions=[]
        )
        
        self.active_conflicts[conflict_id] = conflict
        
        logger.warning(f"âš ï¸ ì¶©ëŒ ê°ì§€: {conflict_type.value} (ì—ì´ì „íŠ¸: {', '.join(agents)})")
        
        return conflict
    
    async def resolve_conflict(self, conflict: ConflictSituation) -> bool:
        """ì¶©ëŒ í•´ê²°"""
        logger.info(f"ğŸ”§ ì¶©ëŒ í•´ê²° ì‹œì‘: {conflict.conflict_id}")
        
        resolution_start = time.time()
        
        # í•´ê²° ì „ëµ ì„ íƒ
        strategies = self.resolution_strategies.get(conflict.conflict_type, ["default_resolution"])
        
        for strategy in strategies:
            try:
                success = await self._apply_resolution_strategy(conflict, strategy)
                if success:
                    conflict.resolution_strategy = strategy
                    conflict.resolution_time = time.time() - resolution_start
                    conflict.resolved = True
                    conflict.success = True
                    
                    # ì¶©ëŒ í•´ê²° ì™„ë£Œ
                    if conflict.conflict_id in self.active_conflicts:
                        del self.active_conflicts[conflict.conflict_id]
                    
                    self.conflict_history.append(conflict)
                    
                    logger.info(f"âœ… ì¶©ëŒ í•´ê²° ì™„ë£Œ: {conflict.conflict_id} ({strategy})")
                    return True
                    
            except Exception as e:
                logger.error(f"âŒ í•´ê²° ì „ëµ ì‹¤íŒ¨: {strategy} - {e}")
                continue
        
        # ëª¨ë“  ì „ëµ ì‹¤íŒ¨
        conflict.resolution_time = time.time() - resolution_start
        conflict.resolved = True
        conflict.success = False
        
        logger.error(f"âŒ ì¶©ëŒ í•´ê²° ì‹¤íŒ¨: {conflict.conflict_id}")
        return False
    
    async def _apply_resolution_strategy(self, conflict: ConflictSituation, strategy: str) -> bool:
        """í•´ê²° ì „ëµ ì ìš©"""
        # Mock êµ¬í˜„ - ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” êµ¬ì²´ì ì¸ í•´ê²° ë¡œì§ êµ¬í˜„
        if strategy == "priority_based_allocation":
            conflict.resolution_actions.append({
                "action": "reallocate_resources",
                "method": "priority_based",
                "agents": conflict.involved_agents
            })
            return True
        
        elif strategy == "communication_retry":
            conflict.resolution_actions.append({
                "action": "retry_communication",
                "attempts": 3,
                "agents": conflict.involved_agents
            })
            return True
        
        elif strategy == "load_balancing":
            conflict.resolution_actions.append({
                "action": "redistribute_load",
                "method": "even_distribution",
                "agents": conflict.involved_agents
            })
            return True
        
        elif strategy == "dependency_breaking":
            conflict.resolution_actions.append({
                "action": "break_dependency_cycle",
                "method": "topological_sort",
                "agents": conflict.involved_agents
            })
            return True
        
        else:
            # ê¸°ë³¸ í•´ê²° ì „ëµ
            conflict.resolution_actions.append({
                "action": "default_resolution",
                "method": "restart_agents",
                "agents": conflict.involved_agents
            })
            return True
    
    async def get_conflict_analytics(self) -> Dict[str, Any]:
        """ì¶©ëŒ ë¶„ì„ ì •ë³´"""
        total_conflicts = len(self.conflict_history) + len(self.active_conflicts)
        resolved_conflicts = len([c for c in self.conflict_history if c.resolved])
        successful_resolutions = len([c for c in self.conflict_history if c.success])
        
        analytics = {
            "total_conflicts": total_conflicts,
            "active_conflicts": len(self.active_conflicts),
            "resolved_conflicts": resolved_conflicts,
            "resolution_rate": resolved_conflicts / total_conflicts if total_conflicts > 0 else 0,
            "success_rate": successful_resolutions / resolved_conflicts if resolved_conflicts > 0 else 0,
            "conflict_types": {},
            "resolution_strategies": {},
            "average_resolution_time": 0.0
        }
        
        # ì¶©ëŒ íƒ€ì…ë³„ ë¶„ì„
        for conflict in self.conflict_history:
            conflict_type = conflict.conflict_type.value
            if conflict_type not in analytics["conflict_types"]:
                analytics["conflict_types"][conflict_type] = {"count": 0, "success_rate": 0.0}
            
            analytics["conflict_types"][conflict_type]["count"] += 1
            if conflict.success:
                analytics["conflict_types"][conflict_type]["success_rate"] += 1
        
        # ì„±ê³µë¥  ê³„ì‚°
        for conflict_type in analytics["conflict_types"]:
            count = analytics["conflict_types"][conflict_type]["count"]
            success_count = analytics["conflict_types"][conflict_type]["success_rate"]
            analytics["conflict_types"][conflict_type]["success_rate"] = success_count / count if count > 0 else 0
        
        # í‰ê·  í•´ê²° ì‹œê°„ ê³„ì‚°
        resolution_times = [c.resolution_time for c in self.conflict_history if c.resolution_time is not None]
        if resolution_times:
            analytics["average_resolution_time"] = statistics.mean(resolution_times)
        
        return analytics

class WorkflowOptimizer:
    """ì›Œí¬í”Œë¡œìš° ìµœì í™”ê¸°"""
    
    def __init__(self, rule_registry: RuleRegistry, pattern_learning: PatternLearningEngine):
        self.rule_registry = rule_registry
        self.pattern_learning = pattern_learning
        self.optimization_history: List[Dict[str, Any]] = []
        
    async def optimize_workflow(self, workflow_context: Dict[str, Any], agents: List[str]) -> Dict[str, Any]:
        """ì›Œí¬í”Œë¡œìš° ìµœì í™”"""
        logger.info(f"âš¡ ì›Œí¬í”Œë¡œìš° ìµœì í™” ì‹œì‘: {len(agents)}ê°œ ì—ì´ì „íŠ¸")
        
        optimization_start = time.time()
        
        # í˜„ì¬ ìƒíƒœ ë¶„ì„
        current_state = await self._analyze_current_state(workflow_context, agents)
        
        # ìµœì í™” ê¸°íšŒ ì‹ë³„
        optimization_opportunities = await self._identify_optimization_opportunities(current_state)
        
        # ìµœì í™” ì ìš©
        optimized_workflow = await self._apply_optimizations(workflow_context, optimization_opportunities)
        
        optimization_time = time.time() - optimization_start
        
        # ìµœì í™” ê²°ê³¼ ê¸°ë¡
        optimization_record = {
            "timestamp": datetime.now().isoformat(),
            "original_workflow": workflow_context,
            "optimized_workflow": optimized_workflow,
            "optimization_opportunities": optimization_opportunities,
            "optimization_time": optimization_time,
            "expected_improvement": optimization_opportunities.get("expected_improvement", 0.0)
        }
        
        self.optimization_history.append(optimization_record)
        
        logger.info(f"âœ… ì›Œí¬í”Œë¡œìš° ìµœì í™” ì™„ë£Œ ({optimization_time:.2f}ì´ˆ)")
        
        return optimized_workflow
    
    async def _analyze_current_state(self, context: Dict[str, Any], agents: List[str]) -> Dict[str, Any]:
        """í˜„ì¬ ìƒíƒœ ë¶„ì„"""
        return {
            "agent_count": len(agents),
            "complexity": context.get("complexity", "medium"),
            "estimated_duration": context.get("estimated_duration", 10.0),
            "resource_usage": context.get("resource_usage", "medium"),
            "parallel_potential": self._calculate_parallel_potential(agents),
            "bottlenecks": self._identify_bottlenecks(context, agents)
        }
    
    async def _identify_optimization_opportunities(self, current_state: Dict[str, Any]) -> Dict[str, Any]:
        """ìµœì í™” ê¸°íšŒ ì‹ë³„"""
        opportunities = {
            "parallelization": 0.0,
            "load_balancing": 0.0,
            "resource_optimization": 0.0,
            "workflow_reordering": 0.0,
            "expected_improvement": 0.0
        }
        
        # ë³‘ë ¬í™” ê¸°íšŒ
        if current_state["parallel_potential"] > 0.7:
            opportunities["parallelization"] = 0.3  # 30% ê°œì„  ê¸°ëŒ€
        
        # ë¡œë“œ ë°¸ëŸ°ì‹± ê¸°íšŒ
        if current_state.get("bottlenecks"):
            opportunities["load_balancing"] = 0.2  # 20% ê°œì„  ê¸°ëŒ€
        
        # ë¦¬ì†ŒìŠ¤ ìµœì í™” ê¸°íšŒ
        if current_state["resource_usage"] == "high":
            opportunities["resource_optimization"] = 0.15  # 15% ê°œì„  ê¸°ëŒ€
        
        # ì „ì²´ ì˜ˆìƒ ê°œì„ ë„ ê³„ì‚°
        opportunities["expected_improvement"] = sum([
            opportunities["parallelization"],
            opportunities["load_balancing"],
            opportunities["resource_optimization"]
        ])
        
        return opportunities
    
    async def _apply_optimizations(self, context: Dict[str, Any], opportunities: Dict[str, Any]) -> Dict[str, Any]:
        """ìµœì í™” ì ìš©"""
        optimized_context = context.copy()
        
        # ë³‘ë ¬í™” ì ìš©
        if opportunities["parallelization"] > 0:
            optimized_context["parallel_execution"] = True
            optimized_context["parallel_degree"] = min(4, optimized_context.get("agent_count", 1))
        
        # ë¡œë“œ ë°¸ëŸ°ì‹± ì ìš©
        if opportunities["load_balancing"] > 0:
            optimized_context["load_balancing"] = True
            optimized_context["load_distribution"] = "even"
        
        # ë¦¬ì†ŒìŠ¤ ìµœì í™” ì ìš©
        if opportunities["resource_optimization"] > 0:
            optimized_context["resource_optimization"] = True
            optimized_context["resource_allocation"] = "dynamic"
        
        # ì˜ˆìƒ ì„±ëŠ¥ ê°œì„  ì ìš©
        if "estimated_duration" in optimized_context:
            improvement_factor = 1 - opportunities["expected_improvement"]
            optimized_context["estimated_duration"] *= improvement_factor
        
        return optimized_context
    
    def _calculate_parallel_potential(self, agents: List[str]) -> float:
        """ë³‘ë ¬ ì²˜ë¦¬ ì ì¬ë ¥ ê³„ì‚°"""
        # ì—ì´ì „íŠ¸ ê°„ ë…ë¦½ì„± í‰ê°€ (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±)
        if len(agents) <= 1:
            return 0.0
        elif len(agents) <= 3:
            return 0.6
        else:
            return 0.8
    
    def _identify_bottlenecks(self, context: Dict[str, Any], agents: List[str]) -> List[str]:
        """ë³‘ëª© ì§€ì  ì‹ë³„"""
        bottlenecks = []
        
        # ë³µì¡ë„ ê¸°ë°˜ ë³‘ëª© ì‹ë³„
        if context.get("complexity") == "high":
            bottlenecks.append("high_complexity_processing")
        
        # ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ê¸°ë°˜ ë³‘ëª© ì‹ë³„
        if context.get("resource_usage") == "high":
            bottlenecks.append("resource_contention")
        
        # ì—ì´ì „íŠ¸ ìˆ˜ ê¸°ë°˜ ë³‘ëª© ì‹ë³„
        if len(agents) > 5:
            bottlenecks.append("coordination_overhead")
        
        return bottlenecks

class CollaborationRulesEngine:
    """Collaboration Rules Engine - ë©”ì¸ ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, rules_path: str = "collaboration_rules.json"):
        # í•µì‹¬ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.rule_registry = RuleRegistry(rules_path)
        self.pattern_learning = PatternLearningEngine(self.rule_registry)
        self.conflict_resolution = ConflictResolutionSystem(self.rule_registry)
        self.workflow_optimizer = WorkflowOptimizer(self.rule_registry, self.pattern_learning)
        
        # ìƒíƒœ ê´€ë¦¬
        self.active_collaborations: Dict[str, Dict[str, Any]] = {}
        self.performance_metrics: Dict[str, float] = {}
        
        logger.info("ğŸ¤ Collaboration Rules Engine ì´ˆê¸°í™” ì™„ë£Œ")
    
    async def initialize(self) -> Dict[str, Any]:
        """Collaboration Rules Engine ì´ˆê¸°í™”"""
        logger.info("ğŸš€ Collaboration Rules Engine ì´ˆê¸°í™” ì¤‘...")
        
        # ê·œì¹™ ë¡œë“œ
        rules = await self.rule_registry.load_rules()
        
        initialization_result = {
            "total_rules": len(rules),
            "rule_types": list(set(rule.rule_type.value for rule in rules.values())),
            "learned_rules": len([rule for rule in rules.values() if rule.learned_pattern]),
            "initialization_status": "completed",
            "features": [
                "pattern_learning",
                "conflict_resolution",
                "workflow_optimization",
                "real_time_monitoring"
            ]
        }
        
        logger.info(f"âœ… Collaboration Rules Engine ì´ˆê¸°í™” ì™„ë£Œ: {initialization_result['total_rules']}ê°œ ê·œì¹™")
        
        return initialization_result
    
    async def start_collaboration(self, collaboration_id: str, context: Dict[str, Any], 
                                agents: List[str]) -> Dict[str, Any]:
        """í˜‘ì—… ì‹œì‘"""
        logger.info(f"ğŸš€ í˜‘ì—… ì‹œì‘: {collaboration_id} (ì—ì´ì „íŠ¸: {len(agents)}ê°œ)")
        
        collaboration_start = time.time()
        
        # ì¶©ëŒ ê°ì§€
        conflict = await self.conflict_resolution.detect_conflict(context, agents)
        
        if conflict:
            # ì¶©ëŒ í•´ê²° ì‹œë„
            resolution_success = await self.conflict_resolution.resolve_conflict(conflict)
            if not resolution_success:
                return {
                    "collaboration_id": collaboration_id,
                    "status": CollaborationStatus.CONFLICT.value,
                    "error": "Unresolved conflict detected",
                    "conflict": asdict(conflict)
                }
        
        # ì ìš© ê°€ëŠ¥í•œ ê·œì¹™ ì¡°íšŒ
        applicable_rules = await self.rule_registry.get_applicable_rules(context, agents)
        
        # ì›Œí¬í”Œë¡œìš° ìµœì í™”
        optimized_context = await self.workflow_optimizer.optimize_workflow(context, agents)
        
        # í˜‘ì—… ì„¸ì…˜ ìƒì„±
        collaboration_session = {
            "collaboration_id": collaboration_id,
            "start_time": collaboration_start,
            "context": optimized_context,
            "agents": agents,
            "applicable_rules": [rule.rule_id for rule in applicable_rules],
            "status": CollaborationStatus.ACTIVE.value,
            "conflict_resolved": conflict is not None and conflict.success,
            "optimization_applied": True
        }
        
        self.active_collaborations[collaboration_id] = collaboration_session
        
        result = {
            "collaboration_id": collaboration_id,
            "status": CollaborationStatus.ACTIVE.value,
            "agents": agents,
            "applied_rules": len(applicable_rules),
            "optimization_improvement": optimized_context.get("expected_improvement", 0.0),
            "conflict_detected": conflict is not None,
            "conflict_resolved": conflict is not None and conflict.success,
            "estimated_duration": optimized_context.get("estimated_duration", context.get("estimated_duration", 0.0)),
            "collaboration_features": {
                "rules_applied": [rule.name for rule in applicable_rules[:3]],
                "optimization_enabled": True,
                "conflict_resolution": True,
                "pattern_learning": True
            }
        }
        
        logger.info(f"âœ… í˜‘ì—… ì‹œì‘ ì™„ë£Œ: {collaboration_id}")
        
        return result
    
    async def update_collaboration_progress(self, collaboration_id: str, 
                                          progress_data: Dict[str, Any]) -> Dict[str, Any]:
        """í˜‘ì—… ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸"""
        if collaboration_id not in self.active_collaborations:
            return {"error": "Collaboration not found"}
        
        collaboration = self.active_collaborations[collaboration_id]
        
        # ì§„í–‰ ìƒí™© ê¸°ë¡
        if "events" not in collaboration:
            collaboration["events"] = []
        
        # ì´ë²¤íŠ¸ ìƒì„± ë° ê¸°ë¡
        event = CollaborationEvent(
            event_id=f"event_{uuid.uuid4().hex[:8]}",
            event_type=progress_data.get("event_type", "progress_update"),
            timestamp=datetime.now(),
            agents_involved=progress_data.get("agents", collaboration["agents"]),
            event_data=progress_data,
            duration=progress_data.get("duration", 0.0),
            success=progress_data.get("success", True),
            performance_metrics=progress_data.get("performance_metrics", {})
        )
        
        collaboration["events"].append(asdict(event))
        
        # íŒ¨í„´ í•™ìŠµì„ ìœ„í•œ ì´ë²¤íŠ¸ ê¸°ë¡
        await self.pattern_learning.record_collaboration_event(event)
        
        # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
        if event.performance_metrics:
            self._update_performance_metrics(event.performance_metrics)
        
        return {
            "collaboration_id": collaboration_id,
            "event_recorded": True,
            "total_events": len(collaboration["events"]),
            "learning_active": True
        }
    
    async def complete_collaboration(self, collaboration_id: str, 
                                   success: bool, final_metrics: Dict[str, Any] = None) -> Dict[str, Any]:
        """í˜‘ì—… ì™„ë£Œ"""
        if collaboration_id not in self.active_collaborations:
            return {"error": "Collaboration not found"}
        
        collaboration = self.active_collaborations[collaboration_id]
        
        # ì™„ë£Œ ì‹œê°„ ê¸°ë¡
        completion_time = time.time()
        total_duration = completion_time - collaboration["start_time"]
        
        collaboration["status"] = CollaborationStatus.COMPLETED.value if success else CollaborationStatus.FAILED.value
        collaboration["completion_time"] = completion_time
        collaboration["total_duration"] = total_duration
        collaboration["success"] = success
        collaboration["final_metrics"] = final_metrics or {}
        
        # ì ìš©ëœ ê·œì¹™ë“¤ì˜ ì„±ëŠ¥ ì—…ë°ì´íŠ¸
        for rule_id in collaboration["applicable_rules"]:
            await self.rule_registry.update_rule_performance(rule_id, success)
        
        # í˜‘ì—… ì„¸ì…˜ì„ í™œì„± ëª©ë¡ì—ì„œ ì œê±°
        completed_collaboration = self.active_collaborations.pop(collaboration_id)
        
        logger.info(f"ğŸ í˜‘ì—… ì™„ë£Œ: {collaboration_id} ({'ì„±ê³µ' if success else 'ì‹¤íŒ¨'}, {total_duration:.2f}ì´ˆ)")
        
        return {
            "collaboration_id": collaboration_id,
            "status": completed_collaboration["status"],
            "total_duration": total_duration,
            "success": success,
            "events_count": len(completed_collaboration.get("events", [])),
            "rules_updated": len(collaboration["applicable_rules"]),
            "performance_learned": True
        }
    
    def _update_performance_metrics(self, new_metrics: Dict[str, float]):
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸"""
        for metric_name, value in new_metrics.items():
            if metric_name not in self.performance_metrics:
                self.performance_metrics[metric_name] = value
            else:
                # ì§€ìˆ˜ ì´ë™ í‰ê· ìœ¼ë¡œ ì—…ë°ì´íŠ¸
                alpha = 0.3  # í•™ìŠµë¥ 
                self.performance_metrics[metric_name] = (
                    alpha * value + (1 - alpha) * self.performance_metrics[metric_name]
                )
    
    async def get_collaboration_analytics(self) -> Dict[str, Any]:
        """í˜‘ì—… ë¶„ì„ ì •ë³´"""
        rules = await self.rule_registry.load_rules()
        conflict_analytics = await self.conflict_resolution.get_conflict_analytics()
        
        analytics = {
            "rules_summary": {
                "total_rules": len(rules),
                "active_rules": len([r for r in rules.values() if r.is_active]),
                "learned_rules": len([r for r in rules.values() if r.learned_pattern]),
                "average_success_rate": statistics.mean([r.success_rate for r in rules.values() if r.usage_count > 0]) if rules else 0.0
            },
            "collaboration_summary": {
                "active_collaborations": len(self.active_collaborations),
                "total_patterns_learned": len(self.pattern_learning.learned_patterns),
                "pattern_learning_threshold": self.pattern_learning.learning_threshold
            },
            "conflict_analytics": conflict_analytics,
            "performance_metrics": self.performance_metrics,
            "optimization_history": len(self.workflow_optimizer.optimization_history)
        }
        
        return analytics
    
    async def close(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        # í™œì„± í˜‘ì—… ê°•ì œ ì™„ë£Œ
        for collaboration_id in list(self.active_collaborations.keys()):
            await self.complete_collaboration(collaboration_id, success=False)
        
        logger.info("ğŸ”š Collaboration Rules Engine ì¢…ë£Œ")

# ì „ì—­ Collaboration Rules Engine ì¸ìŠ¤í„´ìŠ¤
_collaboration_rules_engine = None

def get_collaboration_rules_engine() -> CollaborationRulesEngine:
    """Collaboration Rules Engine ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜ (ì‹±ê¸€í†¤ íŒ¨í„´)"""
    global _collaboration_rules_engine
    if _collaboration_rules_engine is None:
        _collaboration_rules_engine = CollaborationRulesEngine()
    return _collaboration_rules_engine

async def initialize_collaboration_rules_engine():
    """Collaboration Rules Engine ì´ˆê¸°í™” (í¸ì˜ í•¨ìˆ˜)"""
    engine = get_collaboration_rules_engine()
    return await engine.initialize()

async def start_collaboration(collaboration_id: str, context: Dict[str, Any], agents: List[str]):
    """í˜‘ì—… ì‹œì‘ (í¸ì˜ í•¨ìˆ˜)"""
    engine = get_collaboration_rules_engine()
    return await engine.start_collaboration(collaboration_id, context, agents) 