#!/usr/bin/env python3
"""
ì‹¤ì œë¡œ ì‘ë™í•˜ëŠ” A2A íŒ¨í„´ ê¸°ë°˜ Pandas Data Analyst ì„œë²„
mcp_dataloader_agent.pyì˜ ê²€ì¦ëœ êµ¬ì¡°ë¥¼ ì™„ì „íˆ ë³µì‚¬í•˜ì—¬ êµ¬í˜„
"""

import asyncio
import logging
import os
import sys
import uvicorn
import uuid
import pandas as pd
import numpy as np
from datetime import datetime
from typing import Dict, Any

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = os.path.abspath(os.path.dirname(os.path.dirname(__file__)))
sys.path.insert(0, project_root)

# A2A SDK imports (mcp_dataloader_agent.pyì™€ ë™ì¼)
from a2a.server.apps import A2AStarletteApplication
from a2a.server.request_handlers import DefaultRequestHandler
from a2a.server.agent_execution.agent_executor import AgentExecutor, RequestContext
from a2a.server.events.event_queue import EventQueue
from a2a.server.tasks.inmemory_task_store import InMemoryTaskStore
from a2a.types import AgentCard, AgentSkill, Message, Task, AgentCapabilities
from a2a.utils.message import new_agent_text_message, get_message_text

# CherryAI imports
from core.data_manager import DataManager

logger = logging.getLogger(__name__)

# Global instance
data_manager = DataManager()

# 1. Define the core agent (mcp_dataloader_agent.py íŒ¨í„´ ì •í™•íˆ ë³µì‚¬)
class PandasAnalysisAgent:
    """Pandas ë°ì´í„° ë¶„ì„ ì—ì´ì „íŠ¸ (mcp_dataloader_agent.py íŒ¨í„´)"""
    
    async def invoke(self, user_input: str = "") -> str:
        """ë°ì´í„° ë¶„ì„ ìˆ˜í–‰ (mcp_dataloader_agent.pyì˜ invoke íŒ¨í„´)"""
        try:
            # ê³ ì •ëœ ìŠ¤í‚¬ ì‹¤í–‰ - ë°ì´í„° ë¶„ì„
            return self.analyze_data(user_input)
        except Exception as e:
            logger.error(f"Error in PandasAnalysisAgent.invoke: {e}")
            return f"âŒ ë°ì´í„° ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

    def analyze_data(self, user_request: str = "", **kwargs) -> str:
        """ë°ì´í„° ë¶„ì„ ìŠ¤í‚¬ (mcp_dataloader_agent.py íŒ¨í„´)"""
        try:
            logger.info(f"ğŸ” ë°ì´í„° ë¶„ì„ ìš”ì²­: {user_request}")
            
            # 1. ë°ì´í„° ë¡œë“œ
            df, df_id = self._load_latest_dataset()
            if df is None:
                return "âŒ ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”."
            
            logger.info(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {df.shape}")
            
            # 2. ê¸°ë³¸ ì •ë³´ ìƒì„±
            basic_info = f"""# ğŸ“Š **ë°ì´í„° ë¶„ì„ ê²°ê³¼**

## ğŸ” **ë°ì´í„° ê°œìš”**
- **ë°ì´í„°ì…‹**: {df_id}
- **í¬ê¸°**: {df.shape[0]:,}í–‰ Ã— {df.shape[1]}ì—´
- **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰**: {df.memory_usage(deep=True).sum() / 1024**2:.1f} MB

## ğŸ“‹ **ì»¬ëŸ¼ ì •ë³´**
{self._get_column_info(df)}

## ğŸ“Š **ê¸°ìˆ í†µê³„**
{self._get_descriptive_stats(df)}

## ğŸ” **ë°ì´í„° í’ˆì§ˆ**
{self._get_data_quality(df)}

## ğŸ¯ **ì£¼ìš” ì¸ì‚¬ì´íŠ¸**
{self._get_key_insights(df, user_request)}
"""
            
            return basic_info
            
        except Exception as e:
            logger.error(f"âŒ ë°ì´í„° ë¶„ì„ ì˜¤ë¥˜: {e}")
            return f"âŒ ë°ì´í„° ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    def _load_latest_dataset(self):
        """ìµœì‹  ë°ì´í„°ì…‹ ë¡œë“œ"""
        try:
            datasets = data_manager.list_dataframes()
            if not datasets:
                return None, None
            
            # ê°€ì¥ ìµœê·¼ ë°ì´í„°ì…‹ ID ì‚¬ìš© (list_dataframesëŠ” ID ëª©ë¡ì„ ë°˜í™˜)
            latest_dataset_id = datasets[0] 
            df = data_manager.get_dataframe(latest_dataset_id)
            
            logger.info(f"âœ… ë°ì´í„°ì…‹ ë¡œë“œ ì„±ê³µ: {latest_dataset_id}")
            return df, latest_dataset_id
            
        except Exception as e:
            logger.error(f"âŒ ë°ì´í„°ì…‹ ë¡œë“œ ì˜¤ë¥˜: {e}")
            return None, None
    
    def _get_column_info(self, df):
        """ì»¬ëŸ¼ ì •ë³´ ìƒì„±"""
        try:
            info_lines = []
            for i, (col, dtype) in enumerate(zip(df.columns, df.dtypes)):
                non_null = df[col].count()
                null_count = df[col].isnull().sum()
                info_lines.append(f"  {i+1:2d}. **{col}**: {dtype} ({non_null:,} non-null, {null_count:,} null)")
            
            return "\n".join(info_lines)
        except:
            return "  (ì»¬ëŸ¼ ì •ë³´ ìƒì„± ì˜¤ë¥˜)"
    
    def _get_descriptive_stats(self, df):
        """ê¸°ìˆ í†µê³„ ìƒì„±"""
        try:
            numeric_cols = df.select_dtypes(include=[np.number]).columns
            if len(numeric_cols) == 0:
                return "  - ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤."
            
            stats_lines = []
            for col in numeric_cols[:5]:  # ìƒìœ„ 5ê°œë§Œ
                series = df[col]
                stats_lines.append(f"  **{col}**: í‰ê·  {series.mean():.2f}, í‘œì¤€í¸ì°¨ {series.std():.2f}, ìµœì†Œê°’ {series.min():.2f}, ìµœëŒ€ê°’ {series.max():.2f}")
            
            return "\n".join(stats_lines)
        except:
            return "  (ê¸°ìˆ í†µê³„ ìƒì„± ì˜¤ë¥˜)"
    
    def _get_data_quality(self, df):
        """ë°ì´í„° í’ˆì§ˆ ì •ë³´"""
        try:
            total_cells = df.shape[0] * df.shape[1]
            null_cells = df.isnull().sum().sum()
            null_percentage = (null_cells / total_cells) * 100
            
            return f"""  - **ê²°ì¸¡ê°’**: {null_cells:,}ê°œ ({null_percentage:.1f}%)
  - **ì¤‘ë³µí–‰**: {df.duplicated().sum():,}ê°œ
  - **ë°ì´í„° íƒ€ì…**: {len(df.select_dtypes(include=[np.number]).columns)}ê°œ ìˆ«ìí˜•, {len(df.select_dtypes(include=['object']).columns)}ê°œ í…ìŠ¤íŠ¸í˜•"""
        except:
            return "  (ë°ì´í„° í’ˆì§ˆ ì •ë³´ ìƒì„± ì˜¤ë¥˜)"
    
    def _get_key_insights(self, df, user_request):
        """ì£¼ìš” ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        try:
            insights = []
            
            # ë°ì´í„° í¬ê¸° ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸
            if df.shape[0] > 10000:
                insights.append("- ğŸ“Š **ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹**: 10,000í–‰ ì´ìƒì˜ ë°ì´í„°ë¡œ í†µê³„ì  ì‹ ë¢°ì„±ì´ ë†’ìŠµë‹ˆë‹¤.")
            
            # ê²°ì¸¡ê°’ ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸
            null_cols = df.isnull().sum()
            high_null_cols = null_cols[null_cols > len(df) * 0.3]
            if len(high_null_cols) > 0:
                insights.append(f"- âš ï¸ **ì£¼ì˜**: {len(high_null_cols)}ê°œ ì»¬ëŸ¼ì— 30% ì´ìƒ ê²°ì¸¡ê°’ ì¡´ì¬")
            
            # ìˆ˜ì¹˜í˜• ë°ì´í„° ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸
            numeric_cols = df.select_dtypes(include=[np.number]).columns
            if len(numeric_cols) > 0:
                insights.append(f"- ğŸ”¢ **ìˆ˜ì¹˜ ë¶„ì„ ê°€ëŠ¥**: {len(numeric_cols)}ê°œ ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ ë°œê²¬")
            
            if not insights:
                insights.append("- âœ… ë°ì´í„°ê°€ ì •ìƒì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
            
            return "\n".join(insights)
        except:
            return "- (ì¸ì‚¬ì´íŠ¸ ìƒì„± ì˜¤ë¥˜)"

# 2. AgentExecutor êµ¬í˜„ (mcp_dataloader_agent.py íŒ¨í„´ ì •í™•íˆ ë³µì‚¬)
class PandasAnalysisAgentExecutor(AgentExecutor):
    """mcp_dataloader_agent.py íŒ¨í„´ì„ ì‚¬ìš©í•˜ëŠ” Pandas AgentExecutor"""
    
    def __init__(self):
        self.agent = PandasAnalysisAgent()
        logger.info("PandasAnalysisAgentExecutor ì´ˆê¸°í™” ì™„ë£Œ")

    async def execute(self, context: RequestContext, event_queue: EventQueue) -> None:
        """A2A SDK í‘œì¤€ ì‹¤í–‰ (mcp_dataloader_agent.py íŒ¨í„´ ì •í™•íˆ ë³µì‚¬)"""
        logger.info("PandasAnalysisAgentExecutor.execute() í˜¸ì¶œë¨")
        
        try:
            # ì‚¬ìš©ì ì…ë ¥ ì¶”ì¶œ (mcp_dataloader_agent.py íŒ¨í„´)
            user_message = context.get_user_input()
            logger.info(f"ì‚¬ìš©ì ì…ë ¥: {user_message}")
            
            # ì—ì´ì „íŠ¸ ì‹¤í–‰ (mcp_dataloader_agent.py íŒ¨í„´)
            result = await self.agent.invoke(user_message)
            
            # ê²°ê³¼ ì „ì†¡ (ê³µì‹ íŒ¨í„´ - ì¤‘ìš”: await ì¶”ê°€!)
            message = new_agent_text_message(result)
            await event_queue.enqueue_event(message)
            
            logger.info("Task completed successfully")
            
        except Exception as e:
            logger.error(f"Error in execute: {e}", exc_info=True)
            error_message = new_agent_text_message(f"âŒ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            await event_queue.enqueue_event(error_message)

    async def cancel(self, context: RequestContext, event_queue: EventQueue) -> None:
        """Task ì·¨ì†Œ ì²˜ë¦¬ (mcp_dataloader_agent.py íŒ¨í„´)"""
        logger.info("PandasAnalysisAgentExecutor.cancel() í˜¸ì¶œë¨")
        raise Exception("Cancel not supported")

# 3. Agent Card ìƒì„± (mcp_dataloader_agent.py íŒ¨í„´)
def create_agent_card() -> AgentCard:
    """Agent Card ìƒì„± (mcp_dataloader_agent.py íŒ¨í„´)"""
    
    skill = AgentSkill(
        id="pandas_analysis",
        name="Pandas Data Analysis",
        description="Comprehensive data analysis using pandas with statistical insights",
        tags=["data", "analysis", "pandas", "statistics", "eda"],
        examples=["ë°ì´í„°ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”", "EDAë¥¼ ìˆ˜í–‰í•´ì£¼ì„¸ìš”", "ë°ì´í„° ì¸ì‚¬ì´íŠ¸ë¥¼ ë³´ì—¬ì£¼ì„¸ìš”"]
    )
    
    return AgentCard(
        name="Pandas Data Analyst (Working)",
        description="A working data analysis agent using proven patterns",
        url="http://localhost:10002/",
        version="1.0.0",
        capabilities=AgentCapabilities(streaming=False),  # ì‹¤ì œë¡œëŠ” ìŠ¤íŠ¸ë¦¬ë° ì•ˆí•¨
        defaultInputModes=["text"],
        defaultOutputModes=["text"],
        skills=[skill]
    )

# 4. Wire everything together (mcp_dataloader_agent.py íŒ¨í„´ ì •í™•íˆ ë³µì‚¬)
def main():
    """A2A í‘œì¤€ Pandas Analysis ì„œë²„ ì‹¤í–‰"""
    logging.basicConfig(level=logging.INFO)
    logger.info("ğŸš€ Starting Pandas Analysis A2A Server...")
    
    # Agent Card ìƒì„±
    agent_card = create_agent_card()
    
    # RequestHandler ì´ˆê¸°í™”
    request_handler = DefaultRequestHandler(
        agent_executor=PandasAnalysisAgentExecutor(),
        task_store=InMemoryTaskStore()
    )
    
    # A2A Starlette Application ìƒì„±
    a2a_app = A2AStarletteApplication(
        agent_card=agent_card,
        http_handler=request_handler
    )
    
    logger.info("ğŸŒ Server starting at http://localhost:10002")
    logger.info("ğŸ“‹ Agent Card available at /.well-known/agent.json")
    logger.info("âœ… Using proven mcp_dataloader_agent pattern")
    
    # Uvicornìœ¼ë¡œ ì„œë²„ ì‹¤í–‰
    uvicorn.run(a2a_app.build(), host="localhost", port=10002)

if __name__ == "__main__":
    main() 