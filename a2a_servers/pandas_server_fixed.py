#!/usr/bin/env python3
"""
ì‘ë™í•˜ëŠ” A2A íŒ¨í„´ì„ ì ìš©í•œ Pandas Data Analyst ì„œë²„
mcp_dataloader_agent.pyì™€ ë™ì¼í•œ êµ¬ì¡°ë¡œ êµ¬í˜„
"""

import asyncio
import uvicorn
import logging
import pandas as pd
import os
import sys
from typing import Dict, Any
from datetime import datetime

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# A2A SDK imports (ì‘ë™í•˜ëŠ” íŒ¨í„´)
from a2a.server.apps.jsonrpc.fastapi_app import A2AFastAPIApplication
from a2a.server.request_handlers.default_request_handler import DefaultRequestHandler
from a2a.types import AgentCard, AgentSkill, Message, Task
from a2a.utils.message import new_agent_text_message, get_message_text
from a2a.server.agent_execution.agent_executor import AgentExecutor, RequestContext
from a2a.server.events.event_queue import EventQueue
from a2a.server.tasks.inmemory_task_store import InMemoryTaskStore

# CherryAI imports
from core.data_manager import DataManager
from core.llm_factory import create_llm_instance

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/pandas_server_fixed.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# ì „ì—­ ê°ì²´ ì´ˆê¸°í™”
data_manager = DataManager()
llm = create_llm_instance()

# Skill Functions (ë‹¨ìˆœí•œ í•¨ìˆ˜ ê¸°ë°˜ ì ‘ê·¼)
async def analyze_data_skill(**kwargs) -> Message:
    """ë°ì´í„° ë¶„ì„ ìŠ¤í‚¬ í•¨ìˆ˜"""
    logger.info("ğŸ¯ analyze_data_skill í•¨ìˆ˜ í˜¸ì¶œë¨")
    
    try:
        # íŒŒë¼ë¯¸í„°ì—ì„œ ë©”ì‹œì§€ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        prompt = kwargs.get('prompt', 'Analyze the available dataset')
        user_request = kwargs.get('user_request', prompt)
        
        logger.info(f"ğŸ“ ë¶„ì„ ìš”ì²­: {user_request}")
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°í”„ë ˆì„ í™•ì¸
        available_dfs = data_manager.list_dataframes()
        logger.info(f"ğŸ’¾ ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°: {available_dfs}")
        
        if not available_dfs:
            return new_agent_text_message("""âŒ **ë°ì´í„° ì—†ìŒ**

**ë¬¸ì œ**: ì•„ì§ ì—…ë¡œë“œëœ ë°ì´í„°ì…‹ì´ ì—†ìŠµë‹ˆë‹¤.

**í•´ê²°ë°©ë²•:**
1. ğŸ”„ **ë°ì´í„° ë¡œë”** í˜ì´ì§€ë¡œ ì´ë™
2. ğŸ“ CSV, Excel ë“±ì˜ ë°ì´í„° íŒŒì¼ ì—…ë¡œë“œ  
3. ğŸ“Š ë‹¤ì‹œ ëŒì•„ì™€ì„œ ë°ì´í„° ë¶„ì„ ìš”ì²­

**í˜„ì¬ ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ì…‹**: ì—†ìŒ
""")
        
        # ì²« ë²ˆì§¸ ë°ì´í„°í”„ë ˆì„ ì‚¬ìš©
        df_id = available_dfs[0]
        df = data_manager.get_dataframe(df_id)
        
        if df is None:
            return new_agent_text_message(f"âŒ ë°ì´í„°ì…‹ '{df_id}'ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        logger.info(f"âœ… ë°ì´í„°ì…‹ ë¡œë“œ ì™„ë£Œ: {df_id} ({df.shape})")
        
        # ê¸°ë³¸ ë¶„ì„ ìˆ˜í–‰
        analysis_result = await perform_comprehensive_analysis(df, df_id, user_request)
        
        return new_agent_text_message(analysis_result)
        
    except Exception as e:
        logger.error(f"ğŸ’¥ ë¶„ì„ ì‹¤íŒ¨: {e}", exc_info=True)
        return new_agent_text_message(f"âŒ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")

async def perform_comprehensive_analysis(df: pd.DataFrame, df_id: str, prompt: str) -> str:
    """í¬ê´„ì ì¸ ë°ì´í„° ë¶„ì„ ìˆ˜í–‰"""
    import numpy as np
    
    logger.info(f"ğŸ” {df_id}ì— ëŒ€í•œ ì¢…í•© ë¶„ì„ ì‹œì‘")
    
    # ê¸°ë³¸ ì •ë³´
    total_rows, total_cols = df.shape
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()
    
    # ë°ì´í„° í’ˆì§ˆ
    missing_data = df.isnull().sum()
    completeness = ((total_rows * total_cols - missing_data.sum()) / (total_rows * total_cols)) * 100
    
    # ìµœì¢… ë³´ê³ ì„œ êµ¬ì„± (LLM ì—†ì´ ê¸°ë³¸ ë¶„ì„)
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    final_result = f"""# ğŸ“Š ë°ì´í„° ë¶„ì„ ë³´ê³ ì„œ

**ë¶„ì„ ëŒ€ìƒ**: {df_id}  
**ë¶„ì„ ì¼ì‹œ**: {timestamp}  
**ìš”ì²­**: {prompt}

## ğŸ“‹ ë°ì´í„° ê°œìš”

- **í¬ê¸°**: {total_rows:,}í–‰ Ã— {total_cols}ì—´
- **ì™„ì„±ë„**: {completeness:.1f}%
- **ìˆ«ìí˜• ë³€ìˆ˜**: {len(numeric_cols)}ê°œ
- **ë²”ì£¼í˜• ë³€ìˆ˜**: {len(categorical_cols)}ê°œ

## ğŸ” ê¸°ë³¸ í†µê³„

{df.describe().round(2).to_markdown() if not df.select_dtypes(include=[np.number]).empty else "ìˆ«ìí˜• ë°ì´í„° ì—†ìŒ"}

## ğŸ’¡ ì£¼ìš” ê´€ì°°

1. **ë°ì´í„° ê·œëª¨**: {total_rows:,}ê°œ ê´€ì¸¡ê°’ìœ¼ë¡œ {"ì¶©ë¶„í•œ" if total_rows > 1000 else "ì œí•œì ì¸"} ë¶„ì„ ê°€ëŠ¥
2. **ë°ì´í„° í’ˆì§ˆ**: {completeness:.1f}%ë¡œ {"ìš°ìˆ˜" if completeness > 95 else "ë³´í†µ" if completeness > 80 else "ê°œì„  í•„ìš”"}
3. **ë³€ìˆ˜ êµ¬ì„±**: ë‹¤ì–‘í•œ ë¶„ì„ ê´€ì  ì œê³µ

---
**ë¶„ì„ ì—”ì§„**: Pandas Data Analyst (Fixed)  
**ìƒíƒœ**: âœ… ê¸°ë³¸ ë¶„ì„ ì™„ë£Œ
"""
    
    logger.info("âœ… ê¸°ë³¸ ë¶„ì„ ì™„ë£Œ")
    return final_result

# Agent Executor êµ¬í˜„ (ì‘ë™í•˜ëŠ” íŒ¨í„´ ì •í™•íˆ ì ìš©)
class PandasSkillExecutor(AgentExecutor):
    def __init__(self, skill_handlers: Dict[str, Any]):
        self._skill_handlers = skill_handlers
        logger.info("ğŸ”§ PandasSkillExecutor ì´ˆê¸°í™” ì™„ë£Œ")

    async def execute(self, context: RequestContext, event_queue: EventQueue) -> None:
        """A2A SDK í‘œì¤€ ì‹¤í–‰ (ì‘ë™í•˜ëŠ” íŒ¨í„´)"""
        logger.info("ğŸ¯ PandasSkillExecutor.execute() í˜¸ì¶œë¨")
        
        try:
            # skill_id ì¶”ì¶œ (ì‘ë™í•˜ëŠ” íŒ¨í„´)
            skill_id = getattr(context, 'method', 'analyze_data')
            logger.info(f"ğŸ”§ ì‹¤í–‰í•  ìŠ¤í‚¬: {skill_id}")
            
            # ìŠ¤í‚¬ í•¸ë“¤ëŸ¬ í™•ì¸
            handler = self._skill_handlers.get(skill_id)
            if not handler:
                logger.error(f"âŒ ìŠ¤í‚¬ '{skill_id}' ì°¾ì„ ìˆ˜ ì—†ìŒ")
                error_message = new_agent_text_message(f"ìŠ¤í‚¬ '{skill_id}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                await event_queue.enqueue_event(error_message)
                return

            # íŒŒë¼ë¯¸í„° ì¶”ì¶œ (ì‘ë™í•˜ëŠ” íŒ¨í„´)
            params = getattr(context, 'params', {}) or {}
            
            # ë©”ì‹œì§€ì—ì„œ ì¶”ê°€ ì •ë³´ ì¶”ì¶œ
            if hasattr(context, 'request') and context.request:
                if hasattr(context.request, 'params') and hasattr(context.request.params, 'message'):
                    message = context.request.params.message
                    if message.parts:
                        user_text = ""
                        for part in message.parts:
                            if hasattr(part, 'text'):
                                user_text += part.text + " "
                        params['user_request'] = user_text.strip()
            
            logger.info(f"ğŸ“ íŒŒë¼ë¯¸í„°: {params}")
            
            # ìŠ¤í‚¬ ì‹¤í–‰
            result = await handler(**params)
            
            # ê²°ê³¼ ì „ì†¡ (ì˜¬ë°”ë¥¸ A2A API)
            await event_queue.enqueue_event(result)
            logger.info("âœ… ìŠ¤í‚¬ ì‹¤í–‰ ë° ì‘ë‹µ ì „ì†¡ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"ğŸ’¥ ìŠ¤í‚¬ ì‹¤í–‰ ì‹¤íŒ¨: {e}", exc_info=True)
            error_message = new_agent_text_message(f"ìŠ¤í‚¬ ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}")
            await event_queue.enqueue_event(error_message)

    async def cancel(self, context: RequestContext, event_queue: EventQueue) -> None:
        """ì·¨ì†Œ ì²˜ë¦¬ (í•„ìˆ˜ êµ¬í˜„)"""
        logger.info("ğŸ›‘ ì‘ì—… ì·¨ì†Œ ìš”ì²­")
        pass

# Skill Handlers ë§¤í•‘
skill_handlers: Dict[str, Any] = {
    "analyze_data": analyze_data_skill,
}

# ì„œë²„ ì„¤ì •
SERVER_HOST = "0.0.0.0"
SERVER_PORT = 10001

# Agent Card ìƒì„± (ì‘ë™í•˜ëŠ” íŒ¨í„´)
agent_card = AgentCard(
    name="Pandas Data Analyst (Fixed)",
    description="Expert data analyst using pandas for comprehensive dataset analysis - Fixed Version",
    version="1.0.1",
    url=f"http://{SERVER_HOST}:{SERVER_PORT}",
    capabilities={"streaming": True, "pushNotifications": False, "stateTransitionHistory": True},
    defaultInputModes=["text"],
    defaultOutputModes=["text"],
    skills=[
        AgentSkill(
            id="analyze_data",
            name="Data Analysis",
            description="Analyze datasets using pandas and provide comprehensive insights",
            tags=["data", "analysis", "pandas", "statistics"],
            examples=["analyze the titanic dataset", "show me insights about sales data"]
        ),
    ],
    provider={
        "organization": "CherryAI",
        "description": "AI-powered data analysis platform",
        "url": f"http://{SERVER_HOST}:{SERVER_PORT}"
    }
)

# A2A ì„œë²„ êµ¬ì„± (JSON-RPC í”„ë¡œí† ì½œ ì‚¬ìš©)
agent_executor = PandasSkillExecutor(skill_handlers=skill_handlers)
task_store = InMemoryTaskStore()

# A2A SDK JSON-RPC í•¸ë“¤ëŸ¬ ì‚¬ìš©
from a2a.server.request_handlers.jsonrpc_handler import JSONRPCHandler
jsonrpc_handler = JSONRPCHandler(agent_executor=agent_executor, task_store=task_store)

a2a_app = A2AFastAPIApplication(
    agent_card=agent_card, 
    jsonrpc_handler=jsonrpc_handler
)
app = a2a_app.build()

if __name__ == "__main__":
    logger.info("ğŸš€ Pandas Data Analyst A2A Server (Fixed) ì‹œì‘...")
    logger.info(f"ğŸŒ ì„œë²„ ì£¼ì†Œ: http://{SERVER_HOST}:{SERVER_PORT}")
    logger.info("ğŸ“Š ë¶„ì„ ì¤€ë¹„ ì™„ë£Œ!")
    
    try:
        uvicorn.run(app, host=SERVER_HOST, port=SERVER_PORT)
    except Exception as e:
        logger.exception(f"ğŸ’¥ ì„œë²„ ì‹œì‘ ì‹¤íŒ¨: {e}")
        exit(1)
