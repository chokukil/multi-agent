#!/usr/bin/env python3
"""
ê²€ì¦ëœ A2A íŒ¨í„´ìœ¼ë¡œ êµ¬í˜„í•œ Pandas Data Analyst ì„œë²„
mcp_dataloader_agent.pyì™€ ë™ì¼í•œ êµ¬ì¡° ì‚¬ìš©
"""

import pandas as pd
import os
import sys
import uvicorn
import logging
from typing import Dict, Any
from datetime import datetime

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# A2A SDK imports (ê²€ì¦ëœ íŒ¨í„´ ì •í™•íˆ ë³µì‚¬)
from a2a.server.apps.jsonrpc.fastapi_app import A2AFastAPIApplication
from a2a.server.request_handlers.default_request_handler import DefaultRequestHandler
from a2a.types import AgentCard, AgentSkill, Message, Task
from a2a.utils.message import new_agent_text_message, get_message_text
from a2a.server.agent_execution.agent_executor import AgentExecutor, RequestContext
from a2a.server.events.event_queue import EventQueue
from a2a.server.tasks.inmemory_task_store import InMemoryTaskStore

# CherryAI imports
from core.data_manager import DataManager

# ì „ì—­ ë°ì´í„° ë§¤ë‹ˆì €
data_manager = DataManager()

# 1. Skill Functions ì •ì˜ (mcp_dataloader_agent íŒ¨í„´)
def analyze_data(prompt: str = "Analyze this dataset", data_id: str = None) -> Message:
    """ë°ì´í„° ë¶„ì„ ìŠ¤í‚¬ - ê²€ì¦ëœ Message ë°˜í™˜ íŒ¨í„´"""
    
    try:
        # ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°í”„ë ˆì„ í™•ì¸
        available_dfs = data_manager.list_dataframes()
        
        if not available_dfs:
            return new_agent_text_message("""âŒ **ë°ì´í„° ì—†ìŒ**

**ë¬¸ì œ**: ì•„ì§ ì—…ë¡œë“œëœ ë°ì´í„°ì…‹ì´ ì—†ìŠµë‹ˆë‹¤.

**í•´ê²°ë°©ë²•:**
1. ğŸ”„ **ë°ì´í„° ë¡œë”** í˜ì´ì§€ë¡œ ì´ë™
2. ğŸ“ CSV, Excel ë“±ì˜ ë°ì´í„° íŒŒì¼ ì—…ë¡œë“œ  
3. ğŸ“Š ë‹¤ì‹œ ëŒì•„ì™€ì„œ ë°ì´í„° ë¶„ì„ ìš”ì²­

**í˜„ì¬ ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ì…‹**: ì—†ìŒ
""")
        
        # ì²« ë²ˆì§¸ ë°ì´í„°í”„ë ˆì„ ì‚¬ìš©
        df_id = data_id if data_id and data_id in available_dfs else available_dfs[0]
        df = data_manager.get_dataframe(df_id)
        
        if df is None:
            return new_agent_text_message(f"âŒ ë°ì´í„°ì…‹ '{df_id}'ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # ì‹¤ì œ ë¶„ì„ ìˆ˜í–‰
        analysis_result = perform_comprehensive_analysis(df, df_id, prompt)
        
        return new_agent_text_message(analysis_result)
        
    except Exception as e:
        return new_agent_text_message(f"âŒ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")

def perform_comprehensive_analysis(df: pd.DataFrame, df_id: str, prompt: str) -> str:
    """ìƒì„¸í•œ ë°ì´í„° ë¶„ì„ ìˆ˜í–‰"""
    import numpy as np
    
    # ê¸°ë³¸ ì •ë³´
    total_rows, total_cols = df.shape
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()
    
    # ë°ì´í„° í’ˆì§ˆ
    missing_data = df.isnull().sum()
    completeness = ((total_rows * total_cols - missing_data.sum()) / (total_rows * total_cols)) * 100
    
    # íƒ€ì„ìŠ¤íƒ¬í”„
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    # ê¸°ë³¸ í†µê³„
    stats_table = ""
    if numeric_cols:
        stats_table = df.describe().round(2).to_markdown()
    else:
        stats_table = "ìˆ«ìí˜• ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    # ê²°ì¸¡ê°’ ì •ë³´
    missing_info = ""
    if missing_data.sum() > 0:
        missing_info = "\n".join([f"- **{col}**: {count}ê°œ ({count/total_rows*100:.1f}%)" 
                                  for col, count in missing_data.items() if count > 0])
    else:
        missing_info = "âœ… ê²°ì¸¡ê°’ì´ ì—†ìŠµë‹ˆë‹¤."
    
    # ë²”ì£¼í˜• ë³€ìˆ˜ ë¶„í¬
    categorical_info = ""
    for col in categorical_cols[:3]:
        value_counts = df[col].value_counts().head(5)
        categorical_info += f"\n**{col}**:\n"
        for value, count in value_counts.items():
            categorical_info += f"- {value}: {count}ê°œ ({count/total_rows*100:.1f}%)\n"
    
    # ìƒê´€ê´€ê³„ ë¶„ì„
    correlation_info = ""
    if len(numeric_cols) > 1:
        corr_matrix = df[numeric_cols].corr()
        high_corr = []
        for i in range(len(corr_matrix.columns)):
            for j in range(i+1, len(corr_matrix.columns)):
                corr_val = corr_matrix.iloc[i, j]
                if abs(corr_val) > 0.5:
                    high_corr.append(f"- {corr_matrix.columns[i]} â†” {corr_matrix.columns[j]}: {corr_val:.3f}")
        
        if high_corr:
            correlation_info = "### ğŸ”— ì£¼ìš” ìƒê´€ê´€ê³„ (|r| > 0.5)\n" + "\n".join(high_corr)
        else:
            correlation_info = "### ğŸ”— ìƒê´€ê´€ê³„\nê°•í•œ ìƒê´€ê´€ê³„(|r| > 0.5)ë¥¼ ë³´ì´ëŠ” ë³€ìˆ˜ ìŒì´ ì—†ìŠµë‹ˆë‹¤."
    
    # ìƒì¡´ìœ¨ ë¶„ì„ (Titanic ë°ì´í„°ì˜ ê²½ìš°)
    survival_analysis = ""
    if 'Survived' in df.columns:
        survival_rate = df['Survived'].mean() * 100
        survival_analysis = f"""
### âš“ ìƒì¡´ìœ¨ ë¶„ì„

**ì „ì²´ ìƒì¡´ìœ¨**: {survival_rate:.1f}%

**ì„±ë³„ë³„ ìƒì¡´ìœ¨**:
"""
        if 'Sex' in df.columns:
            sex_survival = df.groupby('Sex')['Survived'].mean() * 100
            for sex, rate in sex_survival.items():
                survival_analysis += f"- {sex}: {rate:.1f}%\n"
        
        if 'Pclass' in df.columns:
            survival_analysis += "\n**ê°ì‹¤ ë“±ê¸‰ë³„ ìƒì¡´ìœ¨**:\n"
            class_survival = df.groupby('Pclass')['Survived'].mean() * 100
            for pclass, rate in class_survival.items():
                survival_analysis += f"- {pclass}ë“±ì„: {rate:.1f}%\n"
    
    # ìµœì¢… ë³´ê³ ì„œ êµ¬ì„±
    final_result = f"""# ğŸ“Š **ë°ì´í„° ë¶„ì„ ë³´ê³ ì„œ**

**ë¶„ì„ ëŒ€ìƒ**: `{df_id}`  
**ë¶„ì„ ì¼ì‹œ**: {timestamp}  
**ìš”ì²­**: {prompt}

---

## ğŸ“‹ **ë°ì´í„° ê°œìš”**

| í•­ëª© | ê°’ |
|------|-----|
| ğŸ“ ë°ì´í„° í¬ê¸° | **{total_rows:,}** í–‰ Ã— **{total_cols}** ì—´ |
| âœ… ì™„ì„±ë„ | **{completeness:.1f}%** |
| ğŸ”¢ ìˆ«ìí˜• ë³€ìˆ˜ | **{len(numeric_cols)}ê°œ** |
| ğŸ“ ë²”ì£¼í˜• ë³€ìˆ˜ | **{len(categorical_cols)}ê°œ** |
| ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ | **{df.memory_usage(deep=True).sum() / 1024**2:.1f} MB** |

---

## ğŸ” **ê¸°ë³¸ í†µê³„**

{stats_table}

---

## âŒ **ê²°ì¸¡ê°’ í˜„í™©**

{missing_info}

---

## ğŸ“Š **ë²”ì£¼í˜• ë³€ìˆ˜ ë¶„í¬**

{categorical_info}

---

{correlation_info}

{survival_analysis}

---

## ğŸ’¡ **í•µì‹¬ ì¸ì‚¬ì´íŠ¸**

1. **ğŸ“ ë°ì´í„° ê·œëª¨**: {total_rows:,}ê°œ ê´€ì¸¡ê°’ìœ¼ë¡œ {"**ì¶©ë¶„í•œ**" if total_rows > 1000 else "**ì œí•œì ì¸**"} ë¶„ì„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.

2. **âœ… ë°ì´í„° í’ˆì§ˆ**: {completeness:.1f}%ì˜ ì™„ì„±ë„ë¡œ {"**ìš°ìˆ˜í•œ**" if completeness > 95 else "**ë³´í†µ**" if completeness > 80 else "**ê°œì„ ì´ í•„ìš”í•œ**"} ìˆ˜ì¤€ì…ë‹ˆë‹¤.

3. **ğŸ”¢ ë³€ìˆ˜ êµ¬ì„±**: {len(numeric_cols)}ê°œì˜ ìˆ«ìí˜• ë³€ìˆ˜ì™€ {len(categorical_cols)}ê°œì˜ ë²”ì£¼í˜• ë³€ìˆ˜ë¡œ **ë‹¤ì–‘í•œ ê´€ì ì˜ ë¶„ì„**ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.

---

## ğŸ“‹ **ì¶”ì²œ ë¶„ì„ ë°©í–¥**

ğŸ¯ **ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰í•  ìˆ˜ ìˆëŠ” ë¶„ì„**:

1. **ğŸ“ˆ ì‹œê°í™” ë¶„ì„**: íˆìŠ¤í† ê·¸ë¨, ë°•ìŠ¤í”Œë¡¯ìœ¼ë¡œ ë¶„í¬ í™•ì¸
2. **ğŸ”— ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ**: ë³€ìˆ˜ ê°„ ê´€ê³„ì˜ ì‹œê°ì  í‘œí˜„  
3. **ğŸ¯ íƒ€ê²Ÿ ë¶„ì„**: íŠ¹ì • ê²°ê³¼ ë³€ìˆ˜ì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ìš”ì¸ íƒìƒ‰
4. **ğŸ§¹ ë°ì´í„° ì „ì²˜ë¦¬**: ê²°ì¸¡ê°’ ì²˜ë¦¬ ë° ì´ìƒê°’ ì œê±°
5. **ğŸ¤– ë¨¸ì‹ ëŸ¬ë‹**: ì˜ˆì¸¡ ëª¨ë¸ êµ¬ì¶• ê°€ëŠ¥ì„± ê²€í† 

---

âœ… **ë¶„ì„ ì™„ë£Œ**  
ğŸ• **ì²˜ë¦¬ ì‹œê°„**: < 2ì´ˆ  
ğŸ”§ **ë¶„ì„ ì—”ì§„**: Pandas Data Analyst (Final)
"""
    
    return final_result

# 2. AgentExecutor êµ¬í˜„ (ê²€ì¦ëœ íŒ¨í„´ ì •í™•íˆ ë³µì‚¬)
class SkillBasedAgentExecutor(AgentExecutor):
    def __init__(self, skill_handlers: Dict[str, Any]):
        self._skill_handlers = skill_handlers

    async def execute(self, context: RequestContext, event_queue: EventQueue) -> None:
        skill_id = context.method
        handler = self._skill_handlers.get(skill_id)
        
        if not handler:
            error_message = new_agent_text_message(f"Skill '{skill_id}' not found.")
            await event_queue.put(error_message)
            return

        try:
            params = context.params or {}
            result = handler(**params)
            await event_queue.put(result)
        except Exception as e:
            error_message = new_agent_text_message(f"Error executing skill '{skill_id}': {e}")
            await event_queue.put(error_message)

    async def cancel(self, context: RequestContext, event_queue: EventQueue) -> None:
        # Not implemented for this simple agent
        pass

# 3. ì„œë²„ êµ¬ì„± (ê²€ì¦ëœ íŒ¨í„´ ì •í™•íˆ ë³µì‚¬)
skill_handlers: Dict[str, Any] = {
    "analyze_data": analyze_data,
}

SERVER_HOST = "0.0.0.0"
SERVER_PORT = 10001

agent_card = AgentCard(
    name="Pandas Data Analyst (Final)",
    description="Expert data analyst using pandas for comprehensive dataset analysis - Final Working Version",
    version="2.0.0",
    url=f"http://{SERVER_HOST}:{SERVER_PORT}",
    capabilities={"streaming": False},
    defaultInputModes=["application/json"],
    defaultOutputModes=["application/json"],
    skills=[
        AgentSkill(
            id="analyze_data",
            name="Data Analysis",
            description="Analyze datasets using pandas and provide comprehensive insights with visualizations and statistical analysis",
            tags=["data", "analysis", "pandas", "statistics", "eda"],
            examples=["analyze the titanic dataset", "perform EDA on sales data", "show me insights about customer data"]
        ),
    ]
)

# Setup Server components (ê²€ì¦ëœ íŒ¨í„´ ì •í™•íˆ ë³µì‚¬)
agent_executor = SkillBasedAgentExecutor(skill_handlers=skill_handlers)
task_store = InMemoryTaskStore()
handler = DefaultRequestHandler(agent_executor=agent_executor, task_store=task_store)
a2a_app = A2AFastAPIApplication(agent_card=agent_card, http_handler=handler)
app = a2a_app.build()

if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    print(f"ğŸš€ Starting Pandas Data Analyst A2A Server at http://{SERVER_HOST}:{SERVER_PORT}...")
    print("ğŸ“Š ê²€ì¦ëœ íŒ¨í„´ìœ¼ë¡œ êµ¬í˜„ëœ ì™„ì „í•œ EDA ë¶„ì„ ì„œë²„!")
    print("âœ… mcp_dataloader_agentì™€ ë™ì¼í•œ ì•ˆì •ì ì¸ ì•„í‚¤í…ì²˜ ì‚¬ìš©")
    uvicorn.run(app, host=SERVER_HOST, port=SERVER_PORT) 