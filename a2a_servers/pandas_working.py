#!/usr/bin/env python3
"""
ì‘ë™í•˜ëŠ” A2A íŒ¨í„´ ê¸°ë°˜ Pandas Data Analyst ì„œë²„
mcp_dataloader_agent.pyì˜ ê²€ì¦ëœ êµ¬ì¡°ë¥¼ ì‚¬ìš©
"""

import pandas as pd
import os
import sys
import uvicorn
import logging
from typing import Dict, Any
from datetime import datetime

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# A2A SDK imports (ê²€ì¦ëœ íŒ¨í„´)
from a2a.server.apps.jsonrpc.fastapi_app import A2AFastAPIApplication
from a2a.server.request_handlers.default_request_handler import DefaultRequestHandler
from a2a.types import AgentCard, AgentSkill, Message, Task
from a2a.utils.message import new_agent_text_message, get_message_text
from a2a.server.agent_execution.agent_executor import AgentExecutor, RequestContext
from a2a.server.events.event_queue import EventQueue
from a2a.server.tasks.inmemory_task_store import InMemoryTaskStore

# CherryAI imports
from core.data_manager import DataManager

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ì „ì—­ ë°ì´í„° ë§¤ë‹ˆì €
data_manager = DataManager()

# 1. Skill Functions ì •ì˜
def analyze_data(prompt: str = "Analyze this dataset", data_id: str = None) -> Message:
    """ë°ì´í„° ë¶„ì„ ìŠ¤í‚¬ - mcp_dataloader_agent íŒ¨í„´ ì ìš©"""
    logger.info(f"ğŸ¯ analyze_data ìŠ¤í‚¬ ì‹¤í–‰: {prompt}")
    
    try:
        # ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°í”„ë ˆì„ í™•ì¸
        available_dfs = data_manager.list_dataframes()
        logger.info(f"ğŸ’¾ ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°: {available_dfs}")
        
        if not available_dfs:
            return new_agent_text_message("""âŒ **ë°ì´í„° ì—†ìŒ**

**ë¬¸ì œ**: ì•„ì§ ì—…ë¡œë“œëœ ë°ì´í„°ì…‹ì´ ì—†ìŠµë‹ˆë‹¤.

**í•´ê²°ë°©ë²•:**
1. ğŸ”„ **ë°ì´í„° ë¡œë”** í˜ì´ì§€ë¡œ ì´ë™
2. ğŸ“ CSV, Excel ë“±ì˜ ë°ì´í„° íŒŒì¼ ì—…ë¡œë“œ  
3. ğŸ“Š ë‹¤ì‹œ ëŒì•„ì™€ì„œ ë°ì´í„° ë¶„ì„ ìš”ì²­

**í˜„ì¬ ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ì…‹**: ì—†ìŒ
""")
        
        # ì²« ë²ˆì§¸ ë°ì´í„°í”„ë ˆì„ ì‚¬ìš© (ë˜ëŠ” ì§€ì •ëœ data_id)
        df_id = data_id if data_id and data_id in available_dfs else available_dfs[0]
        df = data_manager.get_dataframe(df_id)
        
        if df is None:
            return new_agent_text_message(f"âŒ ë°ì´í„°ì…‹ '{df_id}'ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        logger.info(f"âœ… ë°ì´í„°ì…‹ ë¡œë“œ ì™„ë£Œ: {df_id} ({df.shape})")
        
        # ê¸°ë³¸ ë¶„ì„ ìˆ˜í–‰
        analysis_result = perform_analysis(df, df_id, prompt)
        
        return new_agent_text_message(analysis_result)
        
    except Exception as e:
        logger.error(f"ğŸ’¥ ë¶„ì„ ì‹¤íŒ¨: {e}", exc_info=True)
        return new_agent_text_message(f"âŒ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")

def perform_analysis(df: pd.DataFrame, df_id: str, prompt: str) -> str:
    """ì‹¤ì œ ë°ì´í„° ë¶„ì„ ìˆ˜í–‰"""
    import numpy as np
    
    logger.info(f"ğŸ” {df_id}ì— ëŒ€í•œ ë¶„ì„ ì‹œì‘")
    
    # ê¸°ë³¸ ì •ë³´
    total_rows, total_cols = df.shape
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()
    
    # ë°ì´í„° í’ˆì§ˆ
    missing_data = df.isnull().sum()
    completeness = ((total_rows * total_cols - missing_data.sum()) / (total_rows * total_cols)) * 100
    
    # ìƒì„¸ ë¶„ì„ ë³´ê³ ì„œ
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    # ê¸°ë³¸ í†µê³„ ìƒì„±
    stats_table = ""
    if not df.select_dtypes(include=[np.number]).empty:
        stats_table = df.describe().round(2).to_markdown()
    else:
        stats_table = "ìˆ«ìí˜• ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    # ê²°ì¸¡ê°’ ë¶„ì„
    missing_info = ""
    missing_values = df.isnull().sum()
    if missing_values.sum() > 0:
        missing_info = "\n".join([f"- **{col}**: {count}ê°œ ({count/total_rows*100:.1f}%)" 
                                  for col, count in missing_values.items() if count > 0])
    else:
        missing_info = "âœ… ê²°ì¸¡ê°’ì´ ì—†ìŠµë‹ˆë‹¤."
    
    # ë²”ì£¼í˜• ë³€ìˆ˜ ë¶„ì„
    categorical_info = ""
    for col in categorical_cols[:3]:  # ìƒìœ„ 3ê°œë§Œ
        value_counts = df[col].value_counts().head(5)
        categorical_info += f"\n**{col}**:\n"
        for value, count in value_counts.items():
            categorical_info += f"- {value}: {count}ê°œ ({count/total_rows*100:.1f}%)\n"
    
    # ìµœì¢… ë³´ê³ ì„œ
    final_result = f"""# ğŸ“Š ë°ì´í„° ë¶„ì„ ë³´ê³ ì„œ

**ë¶„ì„ ëŒ€ìƒ**: {df_id}  
**ë¶„ì„ ì¼ì‹œ**: {timestamp}  
**ìš”ì²­**: {prompt}

## ğŸ“‹ ë°ì´í„° ê°œìš”

| í•­ëª© | ê°’ |
|------|-----|
| ë°ì´í„° í¬ê¸° | {total_rows:,} í–‰ Ã— {total_cols} ì—´ |
| ì™„ì„±ë„ | {completeness:.1f}% |
| ìˆ«ìí˜• ë³€ìˆ˜ | {len(numeric_cols)}ê°œ |
| ë²”ì£¼í˜• ë³€ìˆ˜ | {len(categorical_cols)}ê°œ |
| ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ | {df.memory_usage(deep=True).sum() / 1024**2:.1f} MB |

## ğŸ” ê¸°ë³¸ í†µê³„

{stats_table}

## âŒ ê²°ì¸¡ê°’ í˜„í™©

{missing_info}

## ğŸ“Š ë²”ì£¼í˜• ë³€ìˆ˜ ë¶„í¬

{categorical_info}

## ğŸ’¡ ì£¼ìš” ì¸ì‚¬ì´íŠ¸

1. **ë°ì´í„° ê·œëª¨**: {total_rows:,}ê°œ ê´€ì¸¡ê°’ìœ¼ë¡œ {"ì¶©ë¶„í•œ" if total_rows > 1000 else "ì œí•œì ì¸"} ë¶„ì„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.
2. **ë°ì´í„° í’ˆì§ˆ**: {completeness:.1f}%ì˜ ì™„ì„±ë„ë¡œ {"ìš°ìˆ˜í•œ" if completeness > 95 else "ë³´í†µ" if completeness > 80 else "ê°œì„ ì´ í•„ìš”í•œ"} ìˆ˜ì¤€ì…ë‹ˆë‹¤.
3. **ë³€ìˆ˜ êµ¬ì„±**: {len(numeric_cols)}ê°œì˜ ìˆ«ìí˜• ë³€ìˆ˜ì™€ {len(categorical_cols)}ê°œì˜ ë²”ì£¼í˜• ë³€ìˆ˜ë¡œ ë‹¤ì–‘í•œ ë¶„ì„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.

## ğŸ“‹ ì¶”ì²œ ë¶„ì„ ë°©í–¥

1. **ìƒê´€ê´€ê³„ ë¶„ì„**: ìˆ«ìí˜• ë³€ìˆ˜ ê°„ì˜ ê´€ê³„ íƒìƒ‰
2. **ë¶„í¬ ë¶„ì„**: ê° ë³€ìˆ˜ì˜ ë¶„í¬ íŒ¨í„´ í™•ì¸
3. **ì´ìƒê°’ íƒì§€**: ë°ì´í„° í’ˆì§ˆ ê°œì„  í¬ì¸íŠ¸ ì‹ë³„
4. **ì‹œê°í™”**: ì£¼ìš” íŒ¨í„´ì˜ ê·¸ë˜í”„ í‘œí˜„

---
**ë¶„ì„ ì—”ì§„**: Pandas Data Analyst (Working)  
**ìƒíƒœ**: âœ… ë¶„ì„ ì™„ë£Œ
**ì²˜ë¦¬ ì‹œê°„**: < 1ì´ˆ
"""
    
    logger.info("âœ… ë¶„ì„ ì™„ë£Œ")
    return final_result

# 2. AgentExecutor êµ¬í˜„ (ê²€ì¦ëœ íŒ¨í„´)
class SkillBasedAgentExecutor(AgentExecutor):
    def __init__(self, skill_handlers: Dict[str, Any]):
        self._skill_handlers = skill_handlers

    async def execute(self, context: RequestContext, event_queue: EventQueue) -> None:
        skill_id = context.method
        handler = self._skill_handlers.get(skill_id)
        
        if not handler:
            error_message = new_agent_text_message(f"Skill '{skill_id}' not found.")
            await event_queue.put(error_message)
            return

        try:
            params = context.params or {}
            result = handler(**params)
            await event_queue.put(result)
        except Exception as e:
            error_message = new_agent_text_message(f"Error executing skill '{skill_id}': {e}")
            await event_queue.put(error_message)

    async def cancel(self, context: RequestContext, event_queue: EventQueue) -> None:
        # Not implemented for this simple agent
        pass

# 3. ì„œë²„ êµ¬ì„± (ê²€ì¦ëœ íŒ¨í„´)
skill_handlers: Dict[str, Any] = {
    "analyze_data": analyze_data,
}

SERVER_HOST = "0.0.0.0"
SERVER_PORT = 10001

agent_card = AgentCard(
    name="Pandas Data Analyst (Working)",
    description="Expert data analyst using pandas for comprehensive dataset analysis - Working Version",
    version="1.0.2",
    url=f"http://{SERVER_HOST}:{SERVER_PORT}",
    capabilities={"streaming": False},
    defaultInputModes=["application/json"],
    defaultOutputModes=["application/json"],
    skills=[
        AgentSkill(
            id="analyze_data",
            name="Data Analysis",
            description="Analyze datasets using pandas and provide comprehensive insights",
            tags=["data", "analysis", "pandas", "statistics"],
            examples=["analyze the titanic dataset", "show me insights about sales data"]
        ),
    ]
)

# A2A ì„œë²„ êµ¬ì„± (ê²€ì¦ëœ íŒ¨í„´)
agent_executor = SkillBasedAgentExecutor(skill_handlers=skill_handlers)
task_store = InMemoryTaskStore()
handler = DefaultRequestHandler(agent_executor=agent_executor, task_store=task_store)
a2a_app = A2AFastAPIApplication(agent_card=agent_card, http_handler=handler)
app = a2a_app.build()

if __name__ == "__main__":
    logger.info("ğŸš€ Pandas Data Analyst A2A Server (Working) ì‹œì‘...")
    logger.info(f"ğŸŒ ì„œë²„ ì£¼ì†Œ: http://{SERVER_HOST}:{SERVER_PORT}")
    logger.info("ğŸ“Š ê²€ì¦ëœ íŒ¨í„´ìœ¼ë¡œ êµ¬í˜„ëœ ì•ˆì •ì ì¸ ë¶„ì„ ì„œë²„!")
    
    try:
        uvicorn.run(app, host=SERVER_HOST, port=SERVER_PORT)
    except Exception as e:
        logger.exception(f"ğŸ’¥ ì„œë²„ ì‹œì‘ ì‹¤íŒ¨: {e}")
        exit(1) 