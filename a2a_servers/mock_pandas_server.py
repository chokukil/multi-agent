#!/usr/bin/env python3
"""
Mock A2A Pandas Server - UI í…ŒìŠ¤íŠ¸ìš©
ì‹¤ì œ A2A í”„ë¡œí† ì½œê³¼ í˜¸í™˜ë˜ëŠ” ê°„ë‹¨í•œ êµ¬í˜„
"""

import pandas as pd
import os
import sys
import uvicorn
import logging
from typing import Dict, Any
from datetime import datetime
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# CherryAI imports
from core.data_manager import DataManager

# ì „ì—­ ë°ì´í„° ë§¤ë‹ˆì €
data_manager = DataManager()

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# FastAPI ì•± ìƒì„±
app = FastAPI(title="Mock Pandas A2A Server", version="1.0.0")

# Pydantic ëª¨ë¸
class MessagePart(BaseModel):
    text: str
    kind: str = "text"

class Message(BaseModel):
    messageId: str
    role: str
    parts: list[MessagePart]

class MessageParams(BaseModel):
    message: Message

class A2ARequest(BaseModel):
    id: str
    method: str = "message/send"  # A2A í‘œì¤€ ë©”ì„œë“œ
    params: MessageParams

class A2AResult(BaseModel):
    messageId: str
    role: str = "assistant" 
    parts: list[MessagePart]

class A2AResponse(BaseModel):
    id: str
    result: A2AResult

def perform_analysis(df: pd.DataFrame, df_id: str, prompt: str) -> str:
    """ì‹¤ì œ ë°ì´í„° ë¶„ì„ ìˆ˜í–‰"""
    import numpy as np
    
    # ê¸°ë³¸ ì •ë³´
    total_rows, total_cols = df.shape
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()
    
    # ë°ì´í„° í’ˆì§ˆ
    missing_data = df.isnull().sum()
    completeness = ((total_rows * total_cols - missing_data.sum()) / (total_rows * total_cols)) * 100
    
    # íƒ€ì„ìŠ¤íƒ¬í”„
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    # ê¸°ë³¸ í†µê³„
    stats_table = ""
    if numeric_cols:
        stats_table = df.describe().round(2).to_markdown()
    else:
        stats_table = "ìˆ«ìí˜• ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    # ê²°ì¸¡ê°’ ì •ë³´
    missing_info = ""
    if missing_data.sum() > 0:
        missing_info = "\n".join([f"- **{col}**: {count}ê°œ ({count/total_rows*100:.1f}%)" 
                                  for col, count in missing_data.items() if count > 0])
    else:
        missing_info = "âœ… ê²°ì¸¡ê°’ì´ ì—†ìŠµë‹ˆë‹¤."
    
    # ë²”ì£¼í˜• ë³€ìˆ˜ ë¶„í¬
    categorical_info = ""
    for col in categorical_cols[:3]:
        value_counts = df[col].value_counts().head(5)
        categorical_info += f"\n**{col}**:\n"
        for value, count in value_counts.items():
            categorical_info += f"- {value}: {count}ê°œ ({count/total_rows*100:.1f}%)\n"
    
    # ìƒê´€ê´€ê³„ ë¶„ì„
    correlation_info = ""
    if len(numeric_cols) > 1:
        corr_matrix = df[numeric_cols].corr()
        high_corr = []
        for i in range(len(corr_matrix.columns)):
            for j in range(i+1, len(corr_matrix.columns)):
                corr_val = corr_matrix.iloc[i, j]
                if abs(corr_val) > 0.5:
                    high_corr.append(f"- {corr_matrix.columns[i]} â†” {corr_matrix.columns[j]}: {corr_val:.3f}")
        
        if high_corr:
            correlation_info = "### ğŸ”— ì£¼ìš” ìƒê´€ê´€ê³„ (|r| > 0.5)\n" + "\n".join(high_corr)
        else:
            correlation_info = "### ğŸ”— ìƒê´€ê´€ê³„\nê°•í•œ ìƒê´€ê´€ê³„(|r| > 0.5)ë¥¼ ë³´ì´ëŠ” ë³€ìˆ˜ ìŒì´ ì—†ìŠµë‹ˆë‹¤."
    
    # ìƒì¡´ìœ¨ ë¶„ì„ (Titanic ë°ì´í„°ì˜ ê²½ìš°)
    survival_analysis = ""
    if 'Survived' in df.columns:
        survival_rate = df['Survived'].mean() * 100
        survival_analysis = f"""
### âš“ ìƒì¡´ìœ¨ ë¶„ì„

**ì „ì²´ ìƒì¡´ìœ¨**: {survival_rate:.1f}%

**ì„±ë³„ë³„ ìƒì¡´ìœ¨**:
"""
        if 'Sex' in df.columns:
            sex_survival = df.groupby('Sex')['Survived'].mean() * 100
            for sex, rate in sex_survival.items():
                survival_analysis += f"- {sex}: {rate:.1f}%\n"
        
        if 'Pclass' in df.columns:
            survival_analysis += "\n**ê°ì‹¤ ë“±ê¸‰ë³„ ìƒì¡´ìœ¨**:\n"
            class_survival = df.groupby('Pclass')['Survived'].mean() * 100
            for pclass, rate in class_survival.items():
                survival_analysis += f"- {pclass}ë“±ì„: {rate:.1f}%\n"
    
    # ìµœì¢… ë³´ê³ ì„œ êµ¬ì„±
    final_result = f"""# ğŸ“Š **ì™„ì „í•œ EDA ë¶„ì„ ë³´ê³ ì„œ**

**ë¶„ì„ ëŒ€ìƒ**: `{df_id}`  
**ë¶„ì„ ì¼ì‹œ**: {timestamp}  
**ìš”ì²­**: {prompt}

---

## ğŸ“‹ **ë°ì´í„° ê°œìš”**

| í•­ëª© | ê°’ |
|------|-----|
| ğŸ“ ë°ì´í„° í¬ê¸° | **{total_rows:,}** í–‰ Ã— **{total_cols}** ì—´ |
| âœ… ì™„ì„±ë„ | **{completeness:.1f}%** |
| ğŸ”¢ ìˆ«ìí˜• ë³€ìˆ˜ | **{len(numeric_cols)}ê°œ** |
| ğŸ“ ë²”ì£¼í˜• ë³€ìˆ˜ | **{len(categorical_cols)}ê°œ** |
| ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ | **{df.memory_usage(deep=True).sum() / 1024**2:.1f} MB** |

---

## ğŸ” **ê¸°ë³¸ í†µê³„**

{stats_table}

---

## âŒ **ê²°ì¸¡ê°’ í˜„í™©**

{missing_info}

---

## ğŸ“Š **ë²”ì£¼í˜• ë³€ìˆ˜ ë¶„í¬**

{categorical_info}

---

{correlation_info}

{survival_analysis}

---

## ğŸ’¡ **í•µì‹¬ ì¸ì‚¬ì´íŠ¸**

1. **ğŸ“ ë°ì´í„° ê·œëª¨**: {total_rows:,}ê°œ ê´€ì¸¡ê°’ìœ¼ë¡œ {"**ì¶©ë¶„í•œ**" if total_rows > 1000 else "**ì œí•œì ì¸**"} ë¶„ì„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.

2. **âœ… ë°ì´í„° í’ˆì§ˆ**: {completeness:.1f}%ì˜ ì™„ì„±ë„ë¡œ {"**ìš°ìˆ˜í•œ**" if completeness > 95 else "**ë³´í†µ**" if completeness > 80 else "**ê°œì„ ì´ í•„ìš”í•œ**"} ìˆ˜ì¤€ì…ë‹ˆë‹¤.

3. **ğŸ”¢ ë³€ìˆ˜ êµ¬ì„±**: {len(numeric_cols)}ê°œì˜ ìˆ«ìí˜• ë³€ìˆ˜ì™€ {len(categorical_cols)}ê°œì˜ ë²”ì£¼í˜• ë³€ìˆ˜ë¡œ **ë‹¤ì–‘í•œ ê´€ì ì˜ ë¶„ì„**ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.

---

## ğŸ“‹ **ì¶”ì²œ ë¶„ì„ ë°©í–¥**

ğŸ¯ **ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰í•  ìˆ˜ ìˆëŠ” ë¶„ì„**:

1. **ğŸ“ˆ ì‹œê°í™” ë¶„ì„**: íˆìŠ¤í† ê·¸ë¨, ë°•ìŠ¤í”Œë¡¯ìœ¼ë¡œ ë¶„í¬ í™•ì¸
2. **ğŸ”— ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ**: ë³€ìˆ˜ ê°„ ê´€ê³„ì˜ ì‹œê°ì  í‘œí˜„  
3. **ğŸ¯ íƒ€ê²Ÿ ë¶„ì„**: íŠ¹ì • ê²°ê³¼ ë³€ìˆ˜ì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ìš”ì¸ íƒìƒ‰
4. **ğŸ§¹ ë°ì´í„° ì „ì²˜ë¦¬**: ê²°ì¸¡ê°’ ì²˜ë¦¬ ë° ì´ìƒê°’ ì œê±°
5. **ğŸ¤– ë¨¸ì‹ ëŸ¬ë‹**: ì˜ˆì¸¡ ëª¨ë¸ êµ¬ì¶• ê°€ëŠ¥ì„± ê²€í† 

---

âœ… **ë¶„ì„ ì™„ë£Œ**  
ğŸ• **ì²˜ë¦¬ ì‹œê°„**: < 2ì´ˆ  
ğŸ”§ **ë¶„ì„ ì—”ì§„**: Mock Pandas A2A Server
"""
    
    return final_result

@app.get("/.well-known/agent.json")
async def get_agent_card():
    """A2A í‘œì¤€ Agent Card"""
    return {
        "name": "Pandas Data Analyst (Mock)",
        "description": "Mock A2A server for testing - Expert data analyst using pandas",
        "version": "1.0.0-mock",
        "url": "http://localhost:10001",
        "capabilities": {"streaming": False},
        "defaultInputModes": ["application/json"],
        "defaultOutputModes": ["application/json"],
        "skills": [
            {
                "id": "analyze_data",
                "name": "Data Analysis",
                "description": "Analyze datasets using pandas and provide comprehensive insights",
                "tags": ["data", "analysis", "pandas", "statistics", "eda"],
                "examples": ["analyze the titanic dataset", "perform EDA on sales data"]
            }
        ]
    }

@app.post("/")
async def handle_a2a_request(request: A2ARequest) -> A2AResponse:
    """A2A ë©”ì‹œì§€ ì²˜ë¦¬ - í‘œì¤€ message/send í”„ë¡œí† ì½œ"""
    logger.info(f"ğŸ¯ A2A Request received: {request.method}")
    
    try:
        # ë©”ì‹œì§€ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        user_text = ""
        if request.params.message.parts:
            for part in request.params.message.parts:
                user_text += part.text + " "
        user_text = user_text.strip()
        
        logger.info(f"ğŸ“ User request: {user_text}")
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°í”„ë ˆì„ í™•ì¸
        available_dfs = data_manager.list_dataframes()
        logger.info(f"ğŸ’¾ Available dataframes: {available_dfs}")
        
        if not available_dfs:
            analysis_result = """âŒ **ë°ì´í„° ì—†ìŒ**

**ë¬¸ì œ**: ì•„ì§ ì—…ë¡œë“œëœ ë°ì´í„°ì…‹ì´ ì—†ìŠµë‹ˆë‹¤.

**í•´ê²°ë°©ë²•:**
1. ğŸ”„ **ë°ì´í„° ë¡œë”** í˜ì´ì§€ë¡œ ì´ë™
2. ğŸ“ CSV, Excel ë“±ì˜ ë°ì´í„° íŒŒì¼ ì—…ë¡œë“œ  
3. ğŸ“Š ë‹¤ì‹œ ëŒì•„ì™€ì„œ ë°ì´í„° ë¶„ì„ ìš”ì²­

**í˜„ì¬ ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ì…‹**: ì—†ìŒ
"""
        else:
            # ì²« ë²ˆì§¸ ë°ì´í„°í”„ë ˆì„ ì‚¬ìš©
            df_id = available_dfs[0]
            df = data_manager.get_dataframe(df_id)
            
            if df is None:
                analysis_result = f"âŒ ë°ì´í„°ì…‹ '{df_id}'ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            else:
                # ì‹¤ì œ ë¶„ì„ ìˆ˜í–‰
                analysis_result = perform_analysis(df, df_id, user_text)
        
        # A2A ì‘ë‹µ ìƒì„±
        response = A2AResponse(
            id=request.id,
            result=A2AResult(
                messageId=f"response-{request.id}",
                role="assistant",
                parts=[MessagePart(text=analysis_result, kind="text")]
            )
        )
        
        logger.info("âœ… Analysis completed and response generated")
        return response
        
    except Exception as e:
        logger.error(f"ğŸ’¥ Analysis failed: {e}", exc_info=True)
        
        error_response = A2AResponse(
            id=request.id,
            result=A2AResult(
                messageId=f"error-{request.id}",
                role="assistant", 
                parts=[MessagePart(text=f"âŒ ë¶„ì„ ì‹¤íŒ¨: {str(e)}", kind="text")]
            )
        )
        return error_response

if __name__ == "__main__":
    logger.info("ğŸš€ Starting Mock Pandas A2A Server...")
    logger.info("ğŸ¯ ì´ ì„œë²„ëŠ” UI í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ Mock êµ¬í˜„ì…ë‹ˆë‹¤")
    logger.info("ğŸ“Š ì‹¤ì œ ë°ì´í„° ë¶„ì„ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤")
    
    uvicorn.run(app, host="0.0.0.0", port=10001) 