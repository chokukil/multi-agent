# File: .env.example
# Location: ./.env.example

# LLM Provider Settings
LLM_PROVIDER=OPENAI  # Options: OPENAI, OLLAMA

# OpenAI Settings
OPENAI_API_KEY=your-api-key-here
OPENAI_API_BASE=https://api.openai.com/v1
OPENAI_MODEL=gpt-4o-mini
OPENAI_TEMPERATURE=0.7

# Ollama Settings (if using local models)
OLLAMA_BASE_URL=http://192.168.0.19:9002
OLLAMA_MODEL=qwen3:8b

# System Settings
RECURSION_LIMIT=30
TIMEOUT_SECONDS=180
MAX_RETRIES=3
DEBUG_MODE=false

# Logging
LOG_LEVEL=INFO
LOG_FILE=debug.log
MAX_LOGS=1000

# Data Settings
MAX_FILE_SIZE_MB=100

# UI Settings
UI_THEME=light
MAX_CHAT_HISTORY=50
SHOW_ADVANCED=false

# User Settings
EMP_NO=2012345

# Optional: Langfuse Settings (for advanced tracing)
LANGFUSE_PUBLIC_KEY=
LANGFUSE_SECRET_KEY=
LANGFUSE_HOST=https://cloud.langfuse.com

# Optional: LangSmith Settings
LANGCHAIN_TRACING_V2=false
LANGCHAIN_PROJECT=data-science-multi-agent
LANGCHAIN_API_KEY=your_langsmith_api_key_here