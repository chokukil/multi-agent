#!/usr/bin/env python3
"""
ğŸš€ Large Dataset Performance Test
ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹(10K+ ë ˆì½”ë“œ)ì— ëŒ€í•œ Phase 1-4 ì‹œìŠ¤í…œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
"""

import pandas as pd
import numpy as np
import sys
import os
import time
import psutil
import gc
from datetime import datetime
from typing import Dict, Any, Tuple
import random

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
project_root = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, project_root)

class PerformanceMonitor:
    """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.start_time = None
        self.start_memory = None
        self.metrics = {}
    
    def start_monitoring(self, test_name: str):
        """ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        self.start_time = time.time()
        self.start_memory = psutil.Process().memory_info().rss / 1024 / 1024  # MB
        print(f"ğŸ”„ {test_name} ì‹œì‘ - ë©”ëª¨ë¦¬: {self.start_memory:.1f}MB")
    
    def end_monitoring(self, test_name: str) -> Dict[str, float]:
        """ëª¨ë‹ˆí„°ë§ ì¢…ë£Œ ë° ê²°ê³¼ ë°˜í™˜"""
        end_time = time.time()
        end_memory = psutil.Process().memory_info().rss / 1024 / 1024  # MB
        
        execution_time = end_time - self.start_time
        memory_usage = end_memory - self.start_memory
        peak_memory = end_memory
        
        result = {
            "execution_time": execution_time,
            "memory_usage": memory_usage,
            "peak_memory": peak_memory,
            "start_memory": self.start_memory
        }
        
        print(f"âœ… {test_name} ì™„ë£Œ")
        print(f"   - ì‹¤í–‰ ì‹œê°„: {execution_time:.2f}ì´ˆ")
        print(f"   - ë©”ëª¨ë¦¬ ì‚¬ìš©: {memory_usage:+.1f}MB")
        print(f"   - ìµœëŒ€ ë©”ëª¨ë¦¬: {peak_memory:.1f}MB")
        
        return result

def generate_large_dataset(size: int = 10000) -> pd.DataFrame:
    """ëŒ€ìš©ëŸ‰ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ìƒì„±"""
    print(f"ğŸ“Š {size:,}ê°œ ë ˆì½”ë“œ ë°ì´í„°ì…‹ ìƒì„± ì¤‘...")
    
    # ë‹¤ì–‘í•œ ë°ì´í„° íƒ€ì…ì„ í¬í•¨í•œ í˜„ì‹¤ì ì¸ ë°ì´í„°ì…‹ ìƒì„±
    np.random.seed(42)  # ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼ë¥¼ ìœ„í•œ ì‹œë“œ ì„¤ì •
    
    data = {
        'id': range(1, size + 1),
        'name': [f'User_{i:06d}' for i in range(1, size + 1)],
        'age': np.random.randint(18, 80, size),
        'salary': np.random.normal(75000, 25000, size).astype(int),
        'department': np.random.choice(['Engineering', 'Sales', 'Marketing', 'HR', 'Finance'], size),
        'experience_years': np.random.randint(0, 25, size),
        'performance_score': np.random.uniform(0.5, 1.0, size),
        'is_remote': np.random.choice([True, False], size),
        'join_date': pd.date_range(start='2020-01-01', end='2024-12-31', periods=size),
        'projects_completed': np.random.poisson(8, size),
        'latitude': np.random.uniform(25.0, 49.0, size),  # ë¯¸êµ­ ìœ„ë„ ë²”ìœ„
        'longitude': np.random.uniform(-125.0, -66.0, size),  # ë¯¸êµ­ ê²½ë„ ë²”ìœ„
        'education_level': np.random.choice(['Bachelor', 'Master', 'PhD', 'High School'], size, 
                                         p=[0.4, 0.35, 0.15, 0.1]),
        'city': np.random.choice(['New York', 'San Francisco', 'Chicago', 'Austin', 'Seattle'], size),
        'bonus': np.random.exponential(5000, size).astype(int)
    }
    
    df = pd.DataFrame(data)
    
    # ì¼ë¶€ ê²°ì¸¡ê°’ ì¶”ê°€ (í˜„ì‹¤ì ì¸ ë°ì´í„°) - DataFrame ìƒì„± í›„ ì²˜ë¦¬
    missing_indices = np.random.choice(size, size=int(size * 0.05), replace=False)
    df.loc[missing_indices, 'bonus'] = np.nan
    
    print(f"âœ… ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ: {df.shape}")
    print(f"   - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {df.memory_usage(deep=True).sum() / 1024 / 1024:.1f}MB")
    print(f"   - ê²°ì¸¡ê°’: {df.isnull().sum().sum()}ê°œ")
    
    return df

def test_phase1_user_file_tracker_performance(df: pd.DataFrame, monitor: PerformanceMonitor) -> Dict[str, Any]:
    """Phase 1: UserFileTracker ëŒ€ìš©ëŸ‰ ë°ì´í„° ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
    monitor.start_monitoring("Phase 1 - UserFileTracker ëŒ€ìš©ëŸ‰ ì²˜ë¦¬")
    
    try:
        from core.user_file_tracker import get_user_file_tracker
        
        tracker = get_user_file_tracker()
        session_id = f"perf_test_{int(time.time())}"
        
        # ëŒ€ìš©ëŸ‰ ë°ì´í„° ë“±ë¡
        success = tracker.register_uploaded_file(
            file_id=f"large_dataset_{len(df)}.csv",
            original_name=f"performance_test_{len(df)}_records.csv",
            session_id=session_id,
            data=df,
            user_context=f"ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ìš© {len(df):,}ê°œ ë ˆì½”ë“œ ë°ì´í„°"
        )
        
        if success:
            # íŒŒì¼ ì„ íƒ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
            selected_file, reason = tracker.get_file_for_a2a_request(
                user_request="ëŒ€ìš©ëŸ‰ ë°ì´í„° ë¶„ì„",
                session_id=session_id,
                agent_name="eda_tools_agent"
            )
            
            result = monitor.end_monitoring("Phase 1 - UserFileTracker")
            result.update({
                "success": success and selected_file is not None,
                "records_processed": len(df),
                "file_selected": selected_file is not None,
                "selection_reason": reason
            })
            
            return result
        else:
            result = monitor.end_monitoring("Phase 1 - UserFileTracker")
            result.update({"success": False, "records_processed": 0})
            return result
            
    except Exception as e:
        result = monitor.end_monitoring("Phase 1 - UserFileTracker")
        result.update({"success": False, "error": str(e), "records_processed": 0})
        return result

def test_phase4_auto_data_profiler_performance(df: pd.DataFrame, monitor: PerformanceMonitor) -> Dict[str, Any]:
    """Phase 4: Auto Data Profiler ëŒ€ìš©ëŸ‰ ë°ì´í„° ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
    monitor.start_monitoring("Phase 4 - Auto Data Profiler ëŒ€ìš©ëŸ‰ ì²˜ë¦¬")
    
    try:
        from core.auto_data_profiler import get_auto_data_profiler
        
        profiler = get_auto_data_profiler()
        
        # ëŒ€ìš©ëŸ‰ ë°ì´í„° í”„ë¡œíŒŒì¼ë§
        profile_result = profiler.profile_data(
            data=df,
            dataset_name=f"large_dataset_{len(df)}",
            session_id=f"perf_test_{int(time.time())}"
        )
        
        result = monitor.end_monitoring("Phase 4 - Auto Data Profiler")
        
        if profile_result:
            result.update({
                "success": True,
                "records_processed": len(df),
                "quality_score": profile_result.quality_score,
                "insights_generated": len(profile_result.key_insights),
                "recommendations_count": len(profile_result.recommendations),
                "columns_analyzed": len(df.columns)
            })
        else:
            result.update({
                "success": False,
                "records_processed": len(df)
            })
        
        return result
        
    except Exception as e:
        result = monitor.end_monitoring("Phase 4 - Auto Data Profiler")
        result.update({"success": False, "error": str(e), "records_processed": len(df)})
        return result

def test_phase4_advanced_code_tracker_performance(df: pd.DataFrame, monitor: PerformanceMonitor) -> Dict[str, Any]:
    """Phase 4: Advanced Code Tracker ëŒ€ìš©ëŸ‰ ë°ì´í„° ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
    monitor.start_monitoring("Phase 4 - Advanced Code Tracker ëŒ€ìš©ëŸ‰ ì²˜ë¦¬")
    
    try:
        from core.advanced_code_tracker import get_advanced_code_tracker
        
        tracker = get_advanced_code_tracker()
        
        # ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì½”ë“œ ì‹¤í–‰
        test_code = f"""
import pandas as pd
import numpy as np

# ê¸°ë³¸ í†µê³„ ê³„ì‚°
basic_stats = df.describe()
print(f"ë°ì´í„° í˜•íƒœ: {{df.shape}}")
print(f"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {{df.memory_usage(deep=True).sum() / 1024 / 1024:.1f}}MB")

# ê°„ë‹¨í•œ ì§‘ê³„ ì—°ì‚°
avg_salary = df['salary'].mean()
dept_counts = df['department'].value_counts()
age_distribution = df['age'].describe()

result = {{
    'avg_salary': avg_salary,
    'dept_counts': dept_counts.to_dict(),
    'total_records': len(df)
}}
"""
        
        execution_result = tracker.track_and_execute_code(
            code=test_code,
            context={"df": df},
            safe_execution=True
        )
        
        result = monitor.end_monitoring("Phase 4 - Advanced Code Tracker")
        
        if execution_result.success:
            result.update({
                "success": True,
                "records_processed": len(df),
                "code_execution_time": execution_result.execution_time,
                "code_memory_usage": execution_result.memory_usage,
                "result_generated": execution_result.result is not None
            })
        else:
            result.update({
                "success": False,
                "records_processed": len(df),
                "error": execution_result.error
            })
        
        return result
        
    except Exception as e:
        result = monitor.end_monitoring("Phase 4 - Advanced Code Tracker")
        result.update({"success": False, "error": str(e), "records_processed": len(df)})
        return result

def test_memory_efficiency(df: pd.DataFrame, monitor: PerformanceMonitor) -> Dict[str, Any]:
    """ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í…ŒìŠ¤íŠ¸"""
    monitor.start_monitoring("ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ë¶„ì„")
    
    try:
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¶„ì„
        initial_memory = psutil.Process().memory_info().rss / 1024 / 1024
        
        # ë°ì´í„° ë³µì‚¬ ë° ì²˜ë¦¬
        df_copy = df.copy()
        after_copy_memory = psutil.Process().memory_info().rss / 1024 / 1024
        
        # ê¸°ë³¸ ì—°ì‚° ìˆ˜í–‰
        stats = df_copy.describe()
        after_stats_memory = psutil.Process().memory_info().rss / 1024 / 1024
        
        # ì§‘ê³„ ì—°ì‚°
        aggregations = df_copy.groupby('department').agg({
            'salary': ['mean', 'std'],
            'age': ['mean', 'min', 'max'],
            'performance_score': 'mean'
        })
        after_agg_memory = psutil.Process().memory_info().rss / 1024 / 1024
        
        # ë©”ëª¨ë¦¬ ì •ë¦¬
        del df_copy, stats, aggregations
        gc.collect()
        final_memory = psutil.Process().memory_info().rss / 1024 / 1024
        
        result = monitor.end_monitoring("ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ë¶„ì„")
        result.update({
            "success": True,
            "records_processed": len(df),
            "initial_memory": initial_memory,
            "after_copy_memory": after_copy_memory,
            "after_stats_memory": after_stats_memory,
            "after_agg_memory": after_agg_memory,
            "final_memory": final_memory,
            "memory_recovered": after_agg_memory - final_memory,
            "peak_additional_memory": after_agg_memory - initial_memory
        })
        
        return result
        
    except Exception as e:
        result = monitor.end_monitoring("ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ë¶„ì„")
        result.update({"success": False, "error": str(e), "records_processed": len(df)})
        return result

def main():
    """ë©”ì¸ ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print("ğŸš€ Large Dataset Performance Test")
    print(f"â° ì‹œì‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)
    
    # ì‹œìŠ¤í…œ ì •ë³´
    print("ğŸ’» ì‹œìŠ¤í…œ ì •ë³´:")
    print(f"   - CPU ì½”ì–´: {psutil.cpu_count()}ê°œ")
    print(f"   - ì´ ë©”ëª¨ë¦¬: {psutil.virtual_memory().total / 1024 / 1024 / 1024:.1f}GB")
    print(f"   - ì‚¬ìš© ê°€ëŠ¥ ë©”ëª¨ë¦¬: {psutil.virtual_memory().available / 1024 / 1024 / 1024:.1f}GB")
    print()
    
    monitor = PerformanceMonitor()
    results = {}
    
    # ë‹¤ì–‘í•œ í¬ê¸°ì˜ ë°ì´í„°ì…‹ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
    dataset_sizes = [1000, 5000, 10000, 25000]  # ì ì§„ì ìœ¼ë¡œ í¬ê¸° ì¦ê°€
    
    for size in dataset_sizes:
        print(f"ğŸ“Š {size:,}ê°œ ë ˆì½”ë“œ ë°ì´í„°ì…‹ í…ŒìŠ¤íŠ¸")
        print("-" * 40)
        
        # ë°ì´í„°ì…‹ ìƒì„±
        df = generate_large_dataset(size)
        results[size] = {"dataset_info": {"records": len(df), "columns": len(df.columns)}}
        
        # Phase 1 í…ŒìŠ¤íŠ¸
        try:
            phase1_result = test_phase1_user_file_tracker_performance(df, monitor)
            results[size]["phase1_userfiletracker"] = phase1_result
        except Exception as e:
            print(f"âŒ Phase 1 í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            results[size]["phase1_userfiletracker"] = {"success": False, "error": str(e)}
        
        # Phase 4 Auto Data Profiler í…ŒìŠ¤íŠ¸
        try:
            phase4_profiler_result = test_phase4_auto_data_profiler_performance(df, monitor)
            results[size]["phase4_auto_profiler"] = phase4_profiler_result
        except Exception as e:
            print(f"âŒ Phase 4 Profiler í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            results[size]["phase4_auto_profiler"] = {"success": False, "error": str(e)}
        
        # Phase 4 Code Tracker í…ŒìŠ¤íŠ¸ (í° ë°ì´í„°ì…‹ì—ì„œë§Œ)
        if size <= 10000:  # ë©”ëª¨ë¦¬ ì œí•œìœ¼ë¡œ 10K ì´í•˜ì—ì„œë§Œ ì‹¤í–‰
            try:
                phase4_tracker_result = test_phase4_advanced_code_tracker_performance(df, monitor)
                results[size]["phase4_code_tracker"] = phase4_tracker_result
            except Exception as e:
                print(f"âŒ Phase 4 Code Tracker í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
                results[size]["phase4_code_tracker"] = {"success": False, "error": str(e)}
        
        # ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í…ŒìŠ¤íŠ¸
        try:
            memory_result = test_memory_efficiency(df, monitor)
            results[size]["memory_efficiency"] = memory_result
        except Exception as e:
            print(f"âŒ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            results[size]["memory_efficiency"] = {"success": False, "error": str(e)}
        
        # ë©”ëª¨ë¦¬ ì •ë¦¬
        del df
        gc.collect()
        
        print(f"âœ… {size:,}ê°œ ë ˆì½”ë“œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ\n")
    
    # ê²°ê³¼ ìš”ì•½
    print("=" * 60)
    print("ğŸ“Š ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    print("=" * 60)
    
    for size, size_results in results.items():
        print(f"\nğŸ“ˆ {size:,}ê°œ ë ˆì½”ë“œ ê²°ê³¼:")
        
        for test_name, test_result in size_results.items():
            if test_name == "dataset_info":
                continue
                
            if test_result.get("success", False):
                exec_time = test_result.get("execution_time", 0)
                memory_usage = test_result.get("memory_usage", 0)
                print(f"  âœ… {test_name}: {exec_time:.2f}ì´ˆ, {memory_usage:+.1f}MB")
            else:
                print(f"  âŒ {test_name}: ì‹¤íŒ¨")
    
    # ì„±ëŠ¥ íŠ¸ë Œë“œ ë¶„ì„
    print(f"\nğŸ“ˆ ì„±ëŠ¥ íŠ¸ë Œë“œ ë¶„ì„:")
    
    for test_type in ["phase1_userfiletracker", "phase4_auto_profiler", "memory_efficiency"]:
        execution_times = []
        sizes = []
        
        for size, size_results in results.items():
            if test_type in size_results and size_results[test_type].get("success"):
                execution_times.append(size_results[test_type].get("execution_time", 0))
                sizes.append(size)
        
        if len(execution_times) >= 2:
            # ê°„ë‹¨í•œ ì„ í˜• ì„±ëŠ¥ ë¶„ì„
            time_per_1k_records = [(t / (s / 1000)) for t, s in zip(execution_times, sizes)]
            avg_time_per_1k = sum(time_per_1k_records) / len(time_per_1k_records)
            print(f"  ğŸ“Š {test_type}: í‰ê·  {avg_time_per_1k:.3f}ì´ˆ/1K ë ˆì½”ë“œ")
    
    print(f"\nâ° ì™„ë£Œ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # ì „ì²´ ì„±ê³µë¥  ê³„ì‚°
    total_tests = 0
    successful_tests = 0
    
    for size_results in results.values():
        for test_name, test_result in size_results.items():
            if test_name != "dataset_info":
                total_tests += 1
                if test_result.get("success", False):
                    successful_tests += 1
    
    success_rate = (successful_tests / total_tests * 100) if total_tests > 0 else 0
    
    print(f"\nğŸ¯ ì „ì²´ ì„±ê³µë¥ : {successful_tests}/{total_tests} ({success_rate:.1f}%)")
    
    if success_rate >= 80:
        print("ğŸ‰ ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì„±ëŠ¥ì´ ìš°ìˆ˜í•©ë‹ˆë‹¤!")
        return True
    elif success_rate >= 60:
        print("âš ï¸ ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì„±ëŠ¥ì´ ì–‘í˜¸í•©ë‹ˆë‹¤.")
        return True
    else:
        print("âŒ ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì„±ëŠ¥ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1) 