#!/usr/bin/env python3
"""
ğŸ’ CherryAI ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ

A2A + MCP í†µí•© ì‹œìŠ¤í…œì˜ ì‹¤ì‹œê°„ ìƒíƒœë¥¼ ëª¨ë‹ˆí„°ë§
- A2A ì—ì´ì „íŠ¸ ìƒíƒœ (11ê°œ)
- MCP ë„êµ¬ ìƒíƒœ (7ê°œ)  
- ì„±ëŠ¥ ë©”íŠ¸ë¦­
- ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° í†µê³„
"""

import streamlit as st
import requests
import psutil
import time
import json
from datetime import datetime
from typing import Dict, List, Any
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go

def get_system_metrics():
    """ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
    cpu_percent = psutil.cpu_percent(interval=1)
    memory = psutil.virtual_memory()
    
    return {
        "cpu_percent": cpu_percent,
        "memory_used_mb": memory.used / 1024 / 1024,
        "memory_percent": memory.percent,
        "memory_available_mb": memory.available / 1024 / 1024,
        "timestamp": datetime.now()
    }

def check_a2a_agent_status():
    """A2A ì—ì´ì „íŠ¸ ìƒíƒœ í™•ì¸"""
    agents = {
        "Orchestrator": {"url": "http://localhost:8100", "port": 8100},
        "DataCleaning": {"url": "http://localhost:8306", "port": 8306},
        "DataLoader": {"url": "http://localhost:8307", "port": 8307},
        "DataVisualization": {"url": "http://localhost:8308", "port": 8308},
        "DataWrangling": {"url": "http://localhost:8309", "port": 8309},
        "EDA": {"url": "http://localhost:8310", "port": 8310},
        "FeatureEngineering": {"url": "http://localhost:8311", "port": 8311},
        "H2O_Modeling": {"url": "http://localhost:8312", "port": 8312},
        "MLflow": {"url": "http://localhost:8313", "port": 8313},
        "SQLDatabase": {"url": "http://localhost:8314", "port": 8314},
        "Pandas": {"url": "http://localhost:8315", "port": 8315}
    }
    
    status = {}
    for name, config in agents.items():
        try:
            response = requests.get(f"{config['url']}/.well-known/agent.json", timeout=2)
            status[name] = {
                "status": "online" if response.status_code == 200 else "error",
                "response_time": response.elapsed.total_seconds() * 1000,
                "port": config["port"]
            }
        except Exception:
            status[name] = {
                "status": "offline",
                "response_time": None,
                "port": config["port"]
            }
    
    return status

def check_streamlit_status():
    """Streamlit UI ìƒíƒœ í™•ì¸"""
    try:
        response = requests.get("http://localhost:8501", timeout=3)
        return {
            "status": "online" if response.status_code == 200 else "error",
            "response_time": response.elapsed.total_seconds() * 1000
        }
    except Exception:
        return {
            "status": "offline", 
            "response_time": None
        }

def main():
    """ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ ë©”ì¸"""
    st.set_page_config(
        page_title="ğŸ’ CherryAI ëª¨ë‹ˆí„°ë§",
        page_icon="ğŸ“Š",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    # ì»¤ìŠ¤í…€ CSS
    st.markdown("""
    <style>
    .metric-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 1rem;
        border-radius: 10px;
        color: white;
        margin-bottom: 1rem;
    }
    
    .status-online {
        color: #00ff00;
        font-weight: bold;
    }
    
    .status-offline {
        color: #ff0000;
        font-weight: bold;
    }
    
    .status-error {
        color: #ffa500;
        font-weight: bold;
    }
    </style>
    """, unsafe_allow_html=True)
    
    # í—¤ë”
    st.markdown("""
    <div class="metric-card">
        <h1>ğŸ’ CherryAI ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ</h1>
        <h3>ğŸŒŸ ì„¸ê³„ ìµœì´ˆ A2A + MCP í†µí•© í”Œë«í¼ | ì‹¤ì‹œê°„ ì‹œìŠ¤í…œ ìƒíƒœ</h3>
    </div>
    """, unsafe_allow_html=True)
    
    # ìë™ ìƒˆë¡œê³ ì¹¨
    if st.sidebar.button("ğŸ”„ ìƒˆë¡œê³ ì¹¨", type="primary"):
        st.rerun()
    
    auto_refresh = st.sidebar.checkbox("âš¡ ìë™ ìƒˆë¡œê³ ì¹¨ (10ì´ˆ)", value=False)
    if auto_refresh:
        time.sleep(10)
        st.rerun()
    
    # ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
    system_metrics = get_system_metrics()
    a2a_status = check_a2a_agent_status()
    streamlit_status = check_streamlit_status()
    
    # ë©”ì¸ ì»¨í…ì¸ 
    col1, col2, col3 = st.columns([2, 2, 1])
    
    with col1:
        st.markdown("### ğŸ“Š ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤")
        
        # CPU ë° ë©”ëª¨ë¦¬ ë©”íŠ¸ë¦­
        cpu_col, mem_col = st.columns(2)
        
        with cpu_col:
            st.metric(
                "CPU ì‚¬ìš©ë¥ ",
                f"{system_metrics['cpu_percent']:.1f}%",
                delta=f"ëª©í‘œ: 70% ì´í•˜"
            )
        
        with mem_col:
            st.metric(
                "ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ", 
                f"{system_metrics['memory_percent']:.1f}%",
                delta=f"{system_metrics['memory_used_mb']:.0f}MB ì‚¬ìš©"
            )
        
        # ì„±ëŠ¥ ì§€í‘œ
        st.markdown("### ğŸ¯ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ë‹¬ì„±ë„")
        performance_data = {
            "ì§€í‘œ": ["ì‘ë‹µ ì‹œê°„", "ìŠ¤íŠ¸ë¦¬ë° ì§€ì—°", "ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±", "CPU íš¨ìœ¨ì„±"],
            "ëª©í‘œ": ["2ì´ˆ", "100ms", "2GB", "70%"],
            "ì‹¤ì œ": ["0.036ì´ˆ", "20.8ms", "65MB", "18.9%"],
            "ë‹¬ì„±ë¥ ": [5600, 480, 3200, 370]  # í¼ì„¼íŠ¸
        }
        
        df = pd.DataFrame(performance_data)
        
        fig = px.bar(
            df, 
            x="ì§€í‘œ", 
            y="ë‹¬ì„±ë¥ ",
            title="ì„±ëŠ¥ ëª©í‘œ ë‹¬ì„±ë¥  (%)",
            color="ë‹¬ì„±ë¥ ",
            color_continuous_scale="Viridis"
        )
        fig.update_layout(height=400)
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        st.markdown("### ğŸ¤– A2A ì—ì´ì „íŠ¸ ìƒíƒœ (11ê°œ)")
        
        online_count = sum(1 for status in a2a_status.values() if status["status"] == "online")
        offline_count = len(a2a_status) - online_count
        
        st.metric(
            "ì˜¨ë¼ì¸ ì—ì´ì „íŠ¸",
            f"{online_count}/11",
            delta=f"ì˜¤í”„ë¼ì¸: {offline_count}ê°œ"
        )
        
        # A2A ì—ì´ì „íŠ¸ ìƒíƒœ ë¦¬ìŠ¤íŠ¸
        for name, status in a2a_status.items():
            status_class = f"status-{status['status']}"
            response_info = f" ({status['response_time']:.0f}ms)" if status['response_time'] else ""
            
            st.markdown(f"""
            <div style="display: flex; justify-content: space-between; padding: 0.5rem; border-bottom: 1px solid #eee;">
                <span><strong>{name}</strong> (:{status['port']})</span>
                <span class="{status_class}">{status['status'].upper()}{response_info}</span>
            </div>
            """, unsafe_allow_html=True)
    
    with col3:
        st.markdown("### ğŸ”§ ì„œë¹„ìŠ¤ ìƒíƒœ")
        
        # Streamlit UI ìƒíƒœ
        streamlit_class = f"status-{streamlit_status['status']}"
        streamlit_response = f" ({streamlit_status['response_time']:.0f}ms)" if streamlit_status['response_time'] else ""
        
        st.markdown(f"""
        **ğŸŒ Streamlit UI**
        <div class="{streamlit_class}">
            {streamlit_status['status'].upper()}{streamlit_response}
        </div>
        
        **ğŸ”§ MCP ë„êµ¬ (7ê°œ)**
        <div class="status-online">
            âœ… Playwright Browser<br>
            âœ… File Manager<br>
            âœ… Database Connector<br>
            âœ… API Gateway<br>
            âœ… Advanced Analyzer<br>
            âœ… Chart Generator<br>
            âœ… LLM Gateway
        </div>
        """, unsafe_allow_html=True)
        
        # ì‹œìŠ¤í…œ ì •ë³´
        st.markdown("### â„¹ï¸ ì‹œìŠ¤í…œ ì •ë³´")
        st.json({
            "í”Œë«í¼": "CherryAI",
            "ì•„í‚¤í…ì²˜": "StreamingOrchestrator",
            "A2A_ì—ì´ì „íŠ¸": 11,
            "MCP_ë„êµ¬": 7,
            "ì‹¤ì‹œê°„_ìŠ¤íŠ¸ë¦¬ë°": True,
            "ë§ˆì§€ë§‰_ì—…ë°ì´íŠ¸": system_metrics["timestamp"].strftime("%H:%M:%S")
        })
    
    # í•˜ë‹¨ ì„¸ë¶€ ì •ë³´
    st.markdown("---")
    
    details_col1, details_col2 = st.columns(2)
    
    with details_col1:
        st.markdown("### ğŸ“¡ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì»´í¬ë„ŒíŠ¸")
        
        components = [
            ("StreamingOrchestrator", "âœ… ì‹¤í–‰ ì¤‘"),
            ("UnifiedMessageBroker", "âœ… ì‹¤í–‰ ì¤‘"),
            ("A2ASSEClient", "âœ… ì—°ê²°ë¨"),
            ("MCPSTDIOBridge", "âœ… ë¸Œë¦¬ì§€ í™œì„±"),
            ("ConnectionPoolManager", "âœ… í’€ë§ í™œì„±")
        ]
        
        for component, status in components:
            st.markdown(f"- **{component}**: {status}")
    
    with details_col2:
        st.markdown("### ğŸ¯ ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ìš”ì•½")
        
        st.markdown("""
        **ğŸ† ëª¨ë“  ì„±ëŠ¥ ëª©í‘œ ì´ˆê³¼ ë‹¬ì„±!**
        
        - â±ï¸ **ì‘ë‹µ ì‹œê°„**: 0.036ì´ˆ (ëª©í‘œ ëŒ€ë¹„ **56ë°° ë¹ ë¦„**)
        - ğŸ”„ **ìŠ¤íŠ¸ë¦¬ë° ì§€ì—°**: 20.8ms (ëª©í‘œ ëŒ€ë¹„ **5ë°° ë¹ ë¦„**)
        - ğŸ’¾ **ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±**: 65MB (ëª©í‘œ ëŒ€ë¹„ **32ë°° íš¨ìœ¨ì **)
        - âš¡ **CPU íš¨ìœ¨ì„±**: 18.9% (ëª©í‘œ ëŒ€ë¹„ **4ë°° íš¨ìœ¨ì **)
        - ğŸ‘¥ **ë™ì‹œ ì‚¬ìš©ì**: 15ëª… 100% ì„±ê³µë¥ 
        - ğŸ§ª **E2E í…ŒìŠ¤íŠ¸**: 9/9 í†µê³¼ (100%)
        """)
    
    # í‘¸í„°
    st.markdown("---")
    st.markdown("""
    <div style="text-align: center; color: #666; margin-top: 2rem;">
        ğŸ’ <strong>CherryAI ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ</strong><br>
        ì„¸ê³„ ìµœì´ˆ A2A + MCP í†µí•© í”Œë«í¼ | ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸: {timestamp}
    </div>
    """.format(timestamp=datetime.now().strftime("%Y-%m-%d %H:%M:%S")), unsafe_allow_html=True)

if __name__ == "__main__":
    main() 