# pages/6_üß†_Smart_Data_Analyst.py
import asyncio
import json
import os
import time
import uuid
from pathlib import Path
from typing import Optional, Dict, Any, List
import io
import base64
from datetime import datetime

# Third-party libraries
import httpx
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import requests
import streamlit as st

# ------------------------------------------------------------------------------
# Page Configuration
# ------------------------------------------------------------------------------
st.set_page_config(
    page_title="Smart Data Analyst",
    page_icon="üß†",
    layout="wide",
)

# Custom CSS for modern UI with thinking process visualization
st.markdown("""
<style>
/* Main container */
.main-container {
    max-width: 1400px;
    margin: 0 auto;
    padding: 0 1rem;
}

/* Hero section */
.hero-section {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    border-radius: 20px;
    padding: 3rem 2rem;
    margin-bottom: 2rem;
    box-shadow: 0 20px 40px rgba(0,0,0,0.1);
    text-align: center;
}

/* File upload area */
.upload-zone {
    border: 3px dashed #667eea;
    border-radius: 20px;
    padding: 4rem 2rem;
    text-align: center;
    background: linear-gradient(135deg, #f8faff 0%, #e6f3ff 100%);
    margin-bottom: 2rem;
    transition: all 0.3s ease;
    cursor: pointer;
}

.upload-zone:hover {
    border-color: #764ba2;
    background: linear-gradient(135deg, #e3f2fd 0%, #bbdefb 100%);
    transform: translateY(-2px);
}

/* Thinking process container */
.thinking-container {
    background: linear-gradient(135deg, #fff 0%, #f8f9fa 100%);
    border-radius: 20px;
    padding: 2rem;
    margin-bottom: 2rem;
    box-shadow: 0 10px 30px rgba(0,0,0,0.05);
    border-left: 6px solid #667eea;
}

/* Workflow step */
.workflow-step {
    background: white;
    border-radius: 15px;
    padding: 1.5rem;
    margin-bottom: 1.5rem;
    box-shadow: 0 8px 25px rgba(0,0,0,0.08);
    border-left: 5px solid #28a745;
    position: relative;
    overflow: hidden;
}

.workflow-step::before {
    content: '';
    position: absolute;
    top: 0;
    left: 0;
    right: 0;
    height: 3px;
    background: linear-gradient(90deg, #28a745 0%, #20c997 100%);
}

.workflow-step.thinking::before {
    background: linear-gradient(90deg, #ffc107 0%, #fd7e14 100%);
    animation: thinking-pulse 2s infinite;
}

.workflow-step.completed::before {
    background: linear-gradient(90deg, #28a745 0%, #20c997 100%);
}

.workflow-step.error::before {
    background: linear-gradient(90deg, #dc3545 0%, #e74c3c 100%);
}

/* Result container */
.result-container {
    background: white;
    border-radius: 15px;
    padding: 1.5rem;
    margin: 1rem 0;
    box-shadow: 0 5px 20px rgba(0,0,0,0.08);
    border-top: 4px solid #667eea;
}

/* Animation for thinking process */
@keyframes thinking-pulse {
    0%, 100% { opacity: 1; }
    50% { opacity: 0.5; }
}
</style>
""", unsafe_allow_html=True)

# ------------------------------------------------------------------------------
# Session State Initialization
# ------------------------------------------------------------------------------
if 'uploaded_data' not in st.session_state:
    st.session_state.uploaded_data = None
if 'conversation_history' not in st.session_state:
    st.session_state.conversation_history = []
if 'thinking_process' not in st.session_state:
    st.session_state.thinking_process = [
        {"title": "Í∏∞Î≥∏ Î∂ÑÏÑù Í≥ÑÌöç", "description": "EDA Î∂ÑÏÑù Ï†ÑÎûµÏùÑ ÏàòÎ¶ΩÌï©ÎãàÎã§.", "status": "pending"},
        {"title": "Îç∞Ïù¥ÌÑ∞ ÌÉêÏÉâ", "description": "Îç∞Ïù¥ÌÑ∞ Íµ¨Ï°∞ÏôÄ ÌíàÏßàÏùÑ Î∂ÑÏÑùÌï©ÎãàÎã§.", "status": "pending"},
        {"title": "ÌÜµÍ≥Ñ Î∂ÑÏÑù", "description": "Í∏∞Î≥∏ ÌÜµÍ≥ÑÎüâÍ≥º Î∂ÑÌè¨Î•º Í≥ÑÏÇ∞Ìï©ÎãàÎã§.", "status": "pending"},
    ]
if 'analysis_workflow' not in st.session_state:
    st.session_state.analysis_workflow = [
        {"title": "Îç∞Ïù¥ÌÑ∞ Î°úÎî©", "agent": "Data Loader", "status": "pending", "tools": ["CSV Reader", "Data Validator"]},
        {"title": "EDA ÏàòÌñâ", "agent": "EDA Specialist", "status": "pending", "tools": ["Statistical Analysis", "Data Profiling"]},
        {"title": "ÏãúÍ∞ÅÌôî", "agent": "Visualization Expert", "status": "pending", "tools": ["Plotly", "Matplotlib"]},
    ]
if 'orchestrator_connected' not in st.session_state:
    st.session_state.orchestrator_connected = False

# ------------------------------------------------------------------------------
# Helper Functions
# ------------------------------------------------------------------------------

def check_orchestrator_status() -> bool:
    """Check if orchestrator is available"""
    try:
        response = requests.get("http://localhost:8100/.well-known/agent.json", timeout=2)
        return response.status_code == 200
    except:
        return False

def process_uploaded_file(uploaded_file) -> Optional[pd.DataFrame]:
    """Process uploaded file and return DataFrame"""
    try:
        if uploaded_file.name.endswith('.csv'):
            return pd.read_csv(uploaded_file)
        elif uploaded_file.name.endswith(('.xlsx', '.xls')):
            return pd.read_excel(uploaded_file)
        elif uploaded_file.name.endswith('.json'):
            return pd.read_json(uploaded_file)
        else:
            st.error("ÏßÄÏõêÌïòÏßÄ ÏïäÎäî ÌååÏùº ÌòïÏãùÏûÖÎãàÎã§. CSV, Excel, JSON ÌååÏùºÎßå ÏóÖÎ°úÎìú Í∞ÄÎä•Ìï©ÎãàÎã§.")
            return None
    except Exception as e:
        st.error(f"ÌååÏùº Ï≤òÎ¶¨ Ï§ë Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§: {str(e)}")
        return None

def save_uploaded_data_to_shared(df: pd.DataFrame, filename: str) -> str:
    """Save uploaded data to shared directory for A2A agents"""
    try:
        # Create shared data directory
        shared_dir = Path("a2a_ds_servers/artifacts/data/shared_dataframes")
        shared_dir.mkdir(parents=True, exist_ok=True)
        
        # Generate unique filename
        timestamp = int(time.time())
        name_without_ext = Path(filename).stem
        shared_filename = f"uploaded_{name_without_ext}_{timestamp}.csv"
        shared_path = shared_dir / shared_filename
        
        # Save as CSV for A2A agents to access
        df.to_csv(shared_path, index=False)
        
        return shared_filename
    except Exception as e:
        st.error(f"Îç∞Ïù¥ÌÑ∞ Ï†ÄÏû• Ï§ë Ïò§Î•ò: {str(e)}")
        return filename

async def send_orchestrator_request(query: str, data_filename: str) -> Dict:
    """Send analysis request to orchestrator using A2A SDK v0.2.9"""
    
    try:
        # Import A2A SDK components dynamically to avoid module-level import issues
        from a2a.client import A2ACardResolver, A2AClient
        from a2a.types import MessageSendParams, SendMessageRequest
        from uuid import uuid4
        
        orchestrator_url = "http://localhost:8100"  # Orchestrator port
        
        enhanced_query = f"""
Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑù ÏöîÏ≤≠: {query}

ÏóÖÎ°úÎìúÎêú Îç∞Ïù¥ÌÑ∞: {data_filename}

Îã§ÏùåÍ≥º Í∞ôÏù¥ Î∂ÑÏÑùÏùÑ ÏßÑÌñâÌï¥Ï£ºÏÑ∏Ïöî:
1. Î®ºÏ†Ä Î∂ÑÏÑù Í≥ÑÌöçÏùÑ ÏàòÎ¶ΩÌïòÍ≥† Ïñ¥Îñ§ ÏóêÏù¥Ï†ÑÌä∏Îì§ÏùÑ ÏÇ¨Ïö©Ìï†ÏßÄ Í≤∞Ï†ïÌï¥Ï£ºÏÑ∏Ïöî
2. Í∞Å Îã®Í≥ÑÎ≥ÑÎ°ú Ïñ¥Îñ§ ÎèÑÍµ¨Î•º ÏÇ¨Ïö©Ìï†ÏßÄ Î™ÖÏãúÌï¥Ï£ºÏÑ∏Ïöî
3. Î∂ÑÏÑù Í≥ºÏ†ïÍ≥º Í≤∞Í≥ºÎ•º ÏÉÅÏÑ∏Ìûà ÏÑ§Î™ÖÌï¥Ï£ºÏÑ∏Ïöî
4. ÏãúÍ∞ÅÌôîÍ∞Ä ÌïÑÏöîÌïú Í≤ΩÏö∞ Ï†ÅÏ†àÌïú Ï∞®Ìä∏Î•º ÏÉùÏÑ±Ìï¥Ï£ºÏÑ∏Ïöî

Î∂ÑÏÑù Í≥ºÏ†ïÏùÑ Îã®Í≥ÑÎ≥ÑÎ°ú Ïä§Ìä∏Î¶¨Î∞çÏúºÎ°ú Î≥¥Ïó¨Ï£ºÏÑ∏Ïöî.
"""
        
        async with httpx.AsyncClient(timeout=120.0) as httpx_client:
            # A2A SDKÎ•º ÏÇ¨Ïö©Ìïú Ïò¨Î∞îÎ•∏ Î∞©Ïãù
            resolver = A2ACardResolver(
                httpx_client=httpx_client,
                base_url=orchestrator_url,
            )
            
            # Agent Card Í∞ÄÏ†∏Ïò§Í∏∞
            try:
                agent_card = await resolver.get_agent_card()
            except Exception as e:
                return {
                    "success": False,
                    "error": f"Agent card fetch failed: {str(e)}",
                    "data": {}
                }
            
            # A2AClient Ï¥àÍ∏∞Ìôî
            client = A2AClient(
                httpx_client=httpx_client, 
                agent_card=agent_card
            )
            
            # Ïò¨Î∞îÎ•∏ A2A Î©îÏãúÏßÄ ÌéòÏù¥Î°úÎìú Íµ¨ÏÑ±
            send_message_payload = {
                'message': {
                    'role': 'user',
                    'parts': [
                        {'kind': 'text', 'text': enhanced_query}
                    ],
                    'messageId': uuid4().hex,
                },
            }
            
            # SendMessageRequest ÏÉùÏÑ±
            request = SendMessageRequest(
                id=str(uuid4()), 
                params=MessageSendParams(**send_message_payload)
            )
            
            # A2A SDKÎ•º ÌÜµÌïú Î©îÏãúÏßÄ Ï†ÑÏÜ°
            response = await client.send_message(request)
            
            # Ïò¨Î∞îÎ•∏ A2A SDK ÏùëÎãµ ÌååÏã±
            if response and hasattr(response, 'root'):
                # SendMessageResponse -> root -> result -> parts
                root_response = response.root
                if hasattr(root_response, 'result'):
                    result_data = root_response.result
                    response_text = ""
                    
                    # Message Í∞ùÏ≤¥ÏóêÏÑú parts Ï∂îÏ∂ú
                    if hasattr(result_data, 'parts') and result_data.parts:
                        for part in result_data.parts:
                            # Part Í∞ùÏ≤¥ÏóêÏÑú root.text Ï∂îÏ∂ú
                            if hasattr(part, 'root') and hasattr(part.root, 'text'):
                                response_text += part.root.text
                    
                    # ÏùëÎãµÏù¥ ÏûàÏúºÎ©¥ ÏÑ±Í≥µÏúºÎ°ú Ï≤òÎ¶¨
                    if response_text:
                        return {
                            "success": True,
                            "data": {
                                "response": response_text,
                                "messageId": getattr(result_data, 'messageId', ''),
                                "role": str(getattr(result_data, 'role', 'agent'))
                            }
                        }
            
            # ÏùëÎãµÏù¥ ÏóÜÍ±∞ÎÇò ÌòïÏãùÏù¥ ÏûòÎ™ªÎêú Í≤ΩÏö∞
            return {
                "success": False,
                "error": f"No valid response content received from orchestrator. Response type: {type(response)}",
                "data": {}
            }
            
    except ImportError as e:
        return {
            "success": False,
            "error": f"A2A SDK import failed: {str(e)}. Please install a2a-sdk",
            "data": {}
        }
    except Exception as e:
        return {
            "success": False,
            "error": f"Request failed: {str(e)}",
            "data": {}
        }

def display_thinking_process(thinking_steps: List[Dict]):
    """Display orchestrator's thinking process"""
    if not thinking_steps:
        return
    
    st.markdown("""
    <div class="thinking-container">
        <h3 style="color: #667eea; margin-bottom: 1rem;">ü§î Ïò§ÏºÄÏä§Ìä∏Î†àÏù¥ÌÑ∞ ÏÇ¨Í≥† Í≥ºÏ†ï</h3>
    </div>
    """, unsafe_allow_html=True)
    
    for i, step in enumerate(thinking_steps):
        status_class = step.get('status', 'thinking')
        
        st.markdown(f"""
        <div class="workflow-step {status_class}">
            <div style="display: flex; align-items: center; gap: 1rem; margin-bottom: 1rem;">
                <span style="padding: 0.3rem 0.8rem; border-radius: 15px; font-size: 0.8rem; font-weight: bold; text-transform: uppercase; letter-spacing: 0.5px; background: #ffc107; color: white;">
                    {step.get('status', 'PENDING')}
                </span>
                <h4 style="margin: 0; color: #495057;">
                    Îã®Í≥Ñ {i+1}: {step.get('title', 'Processing...')}
                </h4>
            </div>
            <p style="margin: 0; color: #6c757d;">
                {step.get('description', 'Processing...')}
            </p>
        </div>
        """, unsafe_allow_html=True)

def display_workflow_timeline(workflow_steps: List[Dict]):
    """Display workflow timeline with agent assignments"""
    if not workflow_steps:
        return
    
    st.markdown("### üìã Î∂ÑÏÑù ÏõåÌÅ¨ÌîåÎ°úÏö∞")
    
    for i, step in enumerate(workflow_steps):
        status = step.get('status', 'pending')
        agent_name = step.get('agent', 'Unknown Agent')
        tools = step.get('tools', [])
        title = step.get('title', f'Step {i+1}')
        
        # Status emoji and color
        if status == 'completed':
            status_emoji = "‚úÖ"
        elif status == 'running':
            status_emoji = "üîÑ"
        else:
            status_emoji = "‚è≥"
        
        st.markdown(f"{status_emoji} **{title}**")

def perform_analysis(user_query: str, df: pd.DataFrame, saved_filename: str):
    """Perform the actual analysis with improved error handling"""
    
    # Add user message to conversation
    st.session_state.conversation_history.append({
        "role": "user",
        "content": user_query,
        "timestamp": time.time()
    })
    
    # Display thinking process
    display_thinking_process(st.session_state.thinking_process)
    
    # Display workflow
    display_workflow_timeline(st.session_state.analysis_workflow)
    
    # Send request to orchestrator
    with st.spinner("ü§ñ Ïò§ÏºÄÏä§Ìä∏Î†àÏù¥ÌÑ∞Í∞Ä Î∂ÑÏÑùÏùÑ ÏàòÌñâÌïòÍ≥† ÏûàÏäµÎãàÎã§..."):
        try:
            # Send actual request to orchestrator
            result = asyncio.run(send_orchestrator_request(user_query, saved_filename))
            
            # Update workflow steps based on orchestrator response
            if result.get("success", False):
                # Parse A2A SDK response
                response_data = result.get("data", {})
                response_content = response_data.get("response", "")
                
                if response_content:
                    # Update thinking process based on response
                    for i in range(len(st.session_state.thinking_process)):
                        st.session_state.thinking_process[i]["status"] = "completed"
                    
                    # Update workflow steps
                    for i in range(len(st.session_state.analysis_workflow)):
                        st.session_state.analysis_workflow[i]["status"] = "completed"
                    
                    # Add the orchestrator's response to chat
                    st.session_state.conversation_history.append({
                        "role": "assistant",
                        "content": response_content,
                        "timestamp": time.time()
                    })
                    
                    st.success("‚úÖ Ïò§ÏºÄÏä§Ìä∏Î†àÏù¥ÌÑ∞ Î∂ÑÏÑùÏù¥ ÏôÑÎ£åÎêòÏóàÏäµÎãàÎã§!")
                    
                    # Display results in clean format
                    st.markdown("### üîç Î∂ÑÏÑù Í≤∞Í≥º")
                    st.markdown(response_content)
                    
                    return True
                else:
                    st.error("‚ùå Ïò§ÏºÄÏä§Ìä∏Î†àÏù¥ÌÑ∞Î°úÎ∂ÄÌÑ∞ ÏùëÎãµÏùÑ Î∞õÏßÄ Î™ªÌñàÏäµÎãàÎã§.")
                    return False
            else:
                # Handle A2A SDK errors
                error_msg = result.get("error", "Unknown error occurred")
                st.session_state.conversation_history.append({
                    "role": "assistant",
                    "content": f"‚ùå Î∂ÑÏÑù Ï§ë Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§: {error_msg}",
                    "timestamp": time.time()
                })
                
                st.error(f"‚ùå Ïò§ÏºÄÏä§Ìä∏Î†àÏù¥ÌÑ∞ Ïó∞Í≤∞ Ïã§Ìå®: {error_msg}")
                return False
                        
        except Exception as e:
            st.error(f"‚ùå ÏãúÏä§ÌÖú Ïò§Î•ò: {str(e)}")
            return False

# ------------------------------------------------------------------------------
# Main UI Layout
# ------------------------------------------------------------------------------

# Hero Section with Status
st.markdown("""
<div class="main-container">
    <div class="hero-section">
        <h1 style="color: white; margin-bottom: 0; font-size: 3rem;">üß† Smart Data Analyst</h1>
        <p style="color: rgba(255,255,255,0.9); font-size: 1.3rem; margin-bottom: 1rem;">
            AI Ïò§ÏºÄÏä§Ìä∏Î†àÏù¥ÌÑ∞Í∞Ä ÏûêÎèôÏúºÎ°ú ÏµúÏ†ÅÏùò Î∂ÑÏÑù Ï†ÑÎûµÏùÑ ÏàòÎ¶ΩÌïòÍ≥† Ïã§ÌñâÌï©ÎãàÎã§
        </p>
    </div>
</div>
""", unsafe_allow_html=True)

# Check orchestrator status at start
st.session_state.orchestrator_connected = check_orchestrator_status()

# Status indicators
col1, col2, col3, col4 = st.columns(4)

with col1:
    if st.session_state.uploaded_data is not None:
        st.success("üìÅ Îç∞Ïù¥ÌÑ∞ Î°úÎìúÎê®")
    else:
        st.info("üìÅ Îç∞Ïù¥ÌÑ∞ ÎåÄÍ∏∞ Ï§ë")

with col2:
    if st.session_state.orchestrator_connected:
        st.success("ü§ñ Ïò§ÏºÄÏä§Ìä∏Î†àÏù¥ÌÑ∞ Ïó∞Í≤∞Îê®")
    else:
        st.error("ü§ñ Ïò§ÏºÄÏä§Ìä∏Î†àÏù¥ÌÑ∞ Ïó∞Í≤∞ Ïã§Ìå®")

with col3:
    if any(step['status'] == 'completed' for step in st.session_state.analysis_workflow):
        st.success("‚úÖ Î∂ÑÏÑù ÏôÑÎ£å")
    else:
        st.info("‚è≥ Î∂ÑÏÑù ÎåÄÍ∏∞ Ï§ë")

with col4:
    if len(st.session_state.conversation_history) > 0:
        st.success("üí¨ ÎåÄÌôî ÌôúÏÑ±Ìôî")
    else:
        st.info("üí¨ ÎåÄÌôî ÎåÄÍ∏∞ Ï§ë")

st.markdown("---")

# Main content area
tab1, tab2, tab3 = st.tabs(["üìä Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑù", "üí¨ ÎåÄÌôî Í∏∞Î°ù", "üöÄ Îπ†Î•∏ Î∂ÑÏÑù"])

with tab1:
    # File upload area
    st.markdown("""
    <div class="upload-zone">
        <h3 style="color: #667eea; margin-bottom: 1rem;">üìÅ Îç∞Ïù¥ÌÑ∞ ÏóÖÎ°úÎìú</h3>
        <p style="color: #6c757d;">CSV, Excel, JSON ÌååÏùºÏùÑ ÏßÄÏõêÌï©ÎãàÎã§</p>
    </div>
    """, unsafe_allow_html=True)
    
    uploaded_file = st.file_uploader(
        "Î∂ÑÏÑùÌï† Îç∞Ïù¥ÌÑ∞Î•º ÏóÖÎ°úÎìúÌïòÏÑ∏Ïöî",
        type=['csv', 'xlsx', 'xls', 'json'],
        help="CSV, Excel, JSON ÌòïÏãùÏùò ÌååÏùºÏùÑ ÏóÖÎ°úÎìúÌï† Ïàò ÏûàÏäµÎãàÎã§."
    )
    
    if uploaded_file is not None:
        # Process uploaded file
        df = process_uploaded_file(uploaded_file)
        
        if df is not None:
            st.session_state.uploaded_data = df
            
            # Display basic data info
            st.success(f"‚úÖ Îç∞Ïù¥ÌÑ∞ ÏóÖÎ°úÎìú ÏôÑÎ£å: {uploaded_file.name}")
            
            # Save to shared directory for A2A agents
            saved_filename = save_uploaded_data_to_shared(df, uploaded_file.name)
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("Ìñâ Ïàò", len(df))
            with col2:
                st.metric("Ïó¥ Ïàò", len(df.columns))
            with col3:
                st.metric("Í≤∞Ï∏°Í∞í", df.isnull().sum().sum())
            
            # Data preview
            with st.expander("üìñ Îç∞Ïù¥ÌÑ∞ ÎØ∏Î¶¨Î≥¥Í∏∞", expanded=True):
                st.dataframe(df.head(), use_container_width=True)
            
            # Analysis request input
            st.markdown("### ü§ñ AI Î∂ÑÏÑù ÏöîÏ≤≠")
            st.markdown("ÏûêÏó∞Ïñ¥Î°ú Î∂ÑÏÑùÏùÑ ÏöîÏ≤≠ÌïòÎ©¥ Ïò§ÏºÄÏä§Ìä∏Î†àÏù¥ÌÑ∞Í∞Ä ÏµúÏ†ÅÏùò Î∂ÑÏÑù Ï†ÑÎûµÏùÑ ÏàòÎ¶ΩÌïòÍ≥† Ïã§ÌñâÌï©ÎãàÎã§.")
            
            # Create a form for better enter key support
            with st.form(key="analysis_form", clear_on_submit=True):
                user_query = st.text_area(
                    "Î∂ÑÏÑù ÏöîÏ≤≠ÏùÑ ÏûÖÎ†•ÌïòÏÑ∏Ïöî:",
                    placeholder="Ïòà: Ïù¥ Îç∞Ïù¥ÌÑ∞Ïùò Ìå®ÌÑ¥ÏùÑ Î∂ÑÏÑùÌïòÍ≥† ÏãúÍ∞ÅÌôîÌï¥Ï£ºÏÑ∏Ïöî",
                    height=100,
                    key="query_input"
                )
                
                # Form submit button
                submit_button = st.form_submit_button("üöÄ Î∂ÑÏÑù ÏãúÏûë", type="primary")
                
                # Check if orchestrator is available before allowing analysis
                if submit_button:
                    if not st.session_state.orchestrator_connected:
                        st.error("‚ùå Ïò§ÏºÄÏä§Ìä∏Î†àÏù¥ÌÑ∞Ïóê Ïó∞Í≤∞Ìï† Ïàò ÏóÜÏäµÎãàÎã§. ÏÑúÎ≤ÑÍ∞Ä Ïã§Ìñâ Ï§ëÏù∏ÏßÄ ÌôïÏù∏Ìï¥Ï£ºÏÑ∏Ïöî.")
                    elif not user_query.strip():
                        st.warning("‚ùó Î∂ÑÏÑù ÏöîÏ≤≠ÏùÑ ÏûÖÎ†•Ìï¥Ï£ºÏÑ∏Ïöî.")
                    else:
                        # Perform analysis. The form will be cleared automatically on rerun.
                        perform_analysis(user_query, df, saved_filename)
    
    # If no data uploaded yet
    else:
        st.info("üìÅ Îç∞Ïù¥ÌÑ∞Î•º ÏóÖÎ°úÎìúÌïòÏó¨ AI Î∂ÑÏÑùÏùÑ ÏãúÏûëÌïòÏÑ∏Ïöî.")

with tab2:
    st.markdown("### üí¨ ÎåÄÌôî Í∏∞Î°ù")
    
    if st.session_state.conversation_history:
        for message in st.session_state.conversation_history:
            timestamp = datetime.fromtimestamp(message['timestamp']).strftime("%H:%M:%S")
            
            if message['role'] == 'user':
                st.markdown(f"""
                <div style="background: linear-gradient(135deg, #e3f2fd 0%, #bbdefb 100%); border-radius: 20px; padding: 1.5rem; margin: 1rem 0;">
                    <strong>üë§ ÏÇ¨Ïö©Ïûê:</strong><br>
                    {message['content']}
                    <br><small style="color: #999;">{timestamp}</small>
                </div>
                """, unsafe_allow_html=True)
            else:
                st.markdown(f"""
                <div style="background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%); border-radius: 20px; padding: 1.5rem; margin: 1rem 0;">
                    <strong>ü§ñ Ïò§ÏºÄÏä§Ìä∏Î†àÏù¥ÌÑ∞:</strong><br>
                    {message['content']}
                    <br><small style="color: #999;">{timestamp}</small>
                </div>
                """, unsafe_allow_html=True)
    else:
        st.info("ÏïÑÏßÅ ÎåÄÌôî Í∏∞Î°ùÏù¥ ÏóÜÏäµÎãàÎã§. Î∂ÑÏÑùÏùÑ ÏöîÏ≤≠Ìï¥Î≥¥ÏÑ∏Ïöî!")

with tab3:
    st.markdown("### üöÄ Îπ†Î•∏ Î∂ÑÏÑù")
    
    if st.session_state.uploaded_data is not None:
        df = st.session_state.uploaded_data
        
        # Quick analysis buttons
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("üìà Í∏∞Î≥∏ ÌÜµÍ≥Ñ"):
                st.markdown("#### üìä Í∏∞Î≥∏ ÌÜµÍ≥Ñ Ï†ïÎ≥¥")
                st.dataframe(df.describe(), use_container_width=True)
        
        with col2:
            if st.button("üîç Îç∞Ïù¥ÌÑ∞ ÌíàÏßà"):
                st.markdown("#### üîç Îç∞Ïù¥ÌÑ∞ ÌíàÏßà Î∂ÑÏÑù")
                quality_info = {
                    "Ïª¨ÎüºÎ™Ö": df.columns.tolist(),
                    "Îç∞Ïù¥ÌÑ∞ ÌÉÄÏûÖ": df.dtypes.tolist(),
                    "Í≤∞Ï∏°Í∞í Í∞úÏàò": df.isnull().sum().tolist(),
                    "Ïú†ÎãàÌÅ¨ Í∞í Í∞úÏàò": df.nunique().tolist()
                }
                quality_df = pd.DataFrame(quality_info)
                st.dataframe(quality_df, use_container_width=True)
        
        with col3:
            if st.button("üìä ÏãúÍ∞ÅÌôî"):
                st.markdown("#### üìä Îπ†Î•∏ ÏãúÍ∞ÅÌôî")
                # Get numeric and categorical columns
                numeric_cols = df.select_dtypes(include=['number']).columns.tolist()
                
                # 1. Distribution plot for first numeric column
                if numeric_cols:
                    fig_hist = px.histogram(
                        df, 
                        x=numeric_cols[0], 
                        title=f"{numeric_cols[0]} Î∂ÑÌè¨",
                        color_discrete_sequence=['#667eea']
                    )
                    fig_hist.update_layout(
                        template="plotly_white",
                        title_font_size=16,
                        title_x=0.5
                    )
                    st.plotly_chart(fig_hist, use_container_width=True)
                
                # 2. Correlation heatmap if multiple numeric columns
                if len(numeric_cols) >= 2:
                    corr_matrix = df[numeric_cols].corr()
                    fig_corr = px.imshow(
                        corr_matrix,
                        text_auto=True,
                        title="Î≥ÄÏàò Í∞Ñ ÏÉÅÍ¥ÄÍ¥ÄÍ≥Ñ",
                        color_continuous_scale='RdBu'
                    )
                    fig_corr.update_layout(
                        template="plotly_white",
                        title_font_size=16,
                        title_x=0.5
                    )
                    st.plotly_chart(fig_corr, use_container_width=True)
    
    else:
        st.info("Îç∞Ïù¥ÌÑ∞Î•º Î®ºÏ†Ä ÏóÖÎ°úÎìúÌï¥Ï£ºÏÑ∏Ïöî.") 