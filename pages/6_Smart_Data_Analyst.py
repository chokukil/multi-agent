# pages/6_ğŸ§ _Smart_Data_Analyst.py
import asyncio
import json
import os
import time
import uuid
from pathlib import Path
from typing import Optional, Dict, Any, List
import io
import base64
from datetime import datetime

# Third-party libraries
import httpx
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import requests
import streamlit as st

# ------------------------------------------------------------------------------
# Page Configuration
# ------------------------------------------------------------------------------
st.set_page_config(
    page_title="Smart Data Analyst",
    page_icon="ğŸ§ ",
    layout="wide",
)

# Custom CSS for modern UI with thinking process visualization
st.markdown("""
<style>
/* Main container */
.main-container {
    max-width: 1400px;
    margin: 0 auto;
    padding: 0 1rem;
}

/* Hero section */
.hero-section {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    border-radius: 20px;
    padding: 3rem 2rem;
    margin-bottom: 2rem;
    box-shadow: 0 20px 40px rgba(0,0,0,0.1);
    text-align: center;
}

/* File upload area */
.upload-zone {
    border: 3px dashed #667eea;
    border-radius: 20px;
    padding: 4rem 2rem;
    text-align: center;
    background: linear-gradient(135deg, #f8faff 0%, #e6f3ff 100%);
    margin-bottom: 2rem;
    transition: all 0.3s ease;
    cursor: pointer;
}

.upload-zone:hover {
    border-color: #764ba2;
    background: linear-gradient(135deg, #e3f2fd 0%, #bbdefb 100%);
    transform: translateY(-2px);
}

/* Thinking process container */
.thinking-container {
    background: linear-gradient(135deg, #fff 0%, #f8f9fa 100%);
    border-radius: 20px;
    padding: 2rem;
    margin-bottom: 2rem;
    box-shadow: 0 10px 30px rgba(0,0,0,0.05);
    border-left: 6px solid #667eea;
}

/* Workflow step */
.workflow-step {
    background: white;
    border-radius: 15px;
    padding: 1.5rem;
    margin-bottom: 1.5rem;
    box-shadow: 0 8px 25px rgba(0,0,0,0.08);
    border-left: 5px solid #28a745;
    position: relative;
    overflow: hidden;
}

.workflow-step::before {
    content: '';
    position: absolute;
    top: 0;
    left: 0;
    right: 0;
    height: 3px;
    background: linear-gradient(90deg, #28a745 0%, #20c997 100%);
}

.workflow-step.thinking::before {
    background: linear-gradient(90deg, #ffc107 0%, #fd7e14 100%);
    animation: thinking-pulse 2s infinite;
}

.workflow-step.completed::before {
    background: linear-gradient(90deg, #28a745 0%, #20c997 100%);
}

.workflow-step.error::before {
    background: linear-gradient(90deg, #dc3545 0%, #e74c3c 100%);
}

/* Result container */
.result-container {
    background: white;
    border-radius: 15px;
    padding: 1.5rem;
    margin: 1rem 0;
    box-shadow: 0 5px 20px rgba(0,0,0,0.08);
    border-top: 4px solid #667eea;
}

/* Animation for thinking process */
@keyframes thinking-pulse {
    0%, 100% { opacity: 1; }
    50% { opacity: 0.5; }
}
</style>
""", unsafe_allow_html=True)

# ------------------------------------------------------------------------------
# Session State Initialization
# ------------------------------------------------------------------------------
if 'uploaded_data' not in st.session_state:
    st.session_state.uploaded_data = None
if 'conversation_history' not in st.session_state:
    st.session_state.conversation_history = []
if 'thinking_process' not in st.session_state:
    st.session_state.thinking_process = [
        {"title": "ê¸°ë³¸ ë¶„ì„ ê³„íš", "description": "EDA ë¶„ì„ ì „ëµì„ ìˆ˜ë¦½í•©ë‹ˆë‹¤.", "status": "pending"},
        {"title": "ë°ì´í„° íƒìƒ‰", "description": "ë°ì´í„° êµ¬ì¡°ì™€ í’ˆì§ˆì„ ë¶„ì„í•©ë‹ˆë‹¤.", "status": "pending"},
        {"title": "í†µê³„ ë¶„ì„", "description": "ê¸°ë³¸ í†µê³„ëŸ‰ê³¼ ë¶„í¬ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.", "status": "pending"},
    ]
if 'analysis_workflow' not in st.session_state:
    st.session_state.analysis_workflow = [
        {"title": "ë°ì´í„° ë¡œë”©", "agent": "Data Loader", "status": "pending", "tools": ["CSV Reader", "Data Validator"]},
        {"title": "EDA ìˆ˜í–‰", "agent": "EDA Specialist", "status": "pending", "tools": ["Statistical Analysis", "Data Profiling"]},
        {"title": "ì‹œê°í™”", "agent": "Visualization Expert", "status": "pending", "tools": ["Plotly", "Matplotlib"]},
    ]
if 'orchestrator_connected' not in st.session_state:
    st.session_state.orchestrator_connected = False

# ------------------------------------------------------------------------------
# Helper Functions
# ------------------------------------------------------------------------------

def check_orchestrator_status() -> bool:
    """Check if orchestrator is available"""
    try:
        response = requests.get("http://localhost:8100/.well-known/agent.json", timeout=2)
        return response.status_code == 200
    except:
        return False

def process_uploaded_file(uploaded_file) -> Optional[pd.DataFrame]:
    """Process uploaded file and return DataFrame"""
    try:
        if uploaded_file.name.endswith('.csv'):
            return pd.read_csv(uploaded_file)
        elif uploaded_file.name.endswith(('.xlsx', '.xls')):
            return pd.read_excel(uploaded_file)
        elif uploaded_file.name.endswith('.json'):
            return pd.read_json(uploaded_file)
        else:
            st.error("ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. CSV, Excel, JSON íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
            return None
    except Exception as e:
        st.error(f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        return None

def save_uploaded_data_to_shared(df: pd.DataFrame, filename: str) -> str:
    """Save uploaded data to shared directory for A2A agents"""
    try:
        # Create shared data directory
        shared_dir = Path("a2a_ds_servers/artifacts/data/shared_dataframes")
        shared_dir.mkdir(parents=True, exist_ok=True)
        
        # Generate unique filename
        timestamp = int(time.time())
        name_without_ext = Path(filename).stem
        shared_filename = f"uploaded_{name_without_ext}_{timestamp}.csv"
        shared_path = shared_dir / shared_filename
        
        # Save as CSV for A2A agents to access
        df.to_csv(shared_path, index=False)
        
        return shared_filename
    except Exception as e:
        st.error(f"ë°ì´í„° ì €ì¥ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return filename

async def send_orchestrator_request(query: str, data_filename: str) -> Dict:
    """Send analysis request to orchestrator using A2A SDK v0.2.9"""
    
    try:
        # Import A2A SDK components dynamically to avoid module-level import issues
        from a2a.client import A2ACardResolver, A2AClient
        from a2a.types import MessageSendParams, SendMessageRequest
        from uuid import uuid4
        
        orchestrator_url = "http://localhost:8100"  # Orchestrator port
        
        enhanced_query = f"""
ë°ì´í„° ë¶„ì„ ìš”ì²­: {query}

ì—…ë¡œë“œëœ ë°ì´í„°: {data_filename}

ë‹¤ìŒê³¼ ê°™ì´ ë¶„ì„ì„ ì§„í–‰í•´ì£¼ì„¸ìš”:
1. ë¨¼ì € ë¶„ì„ ê³„íšì„ ìˆ˜ë¦½í•˜ê³  ì–´ë–¤ ì—ì´ì „íŠ¸ë“¤ì„ ì‚¬ìš©í• ì§€ ê²°ì •í•´ì£¼ì„¸ìš”
2. ê° ë‹¨ê³„ë³„ë¡œ ì–´ë–¤ ë„êµ¬ë¥¼ ì‚¬ìš©í• ì§€ ëª…ì‹œí•´ì£¼ì„¸ìš”
3. ë¶„ì„ ê³¼ì •ê³¼ ê²°ê³¼ë¥¼ ìƒì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”
4. ì‹œê°í™”ê°€ í•„ìš”í•œ ê²½ìš° ì ì ˆí•œ ì°¨íŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”

ë¶„ì„ ê³¼ì •ì„ ë‹¨ê³„ë³„ë¡œ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ë³´ì—¬ì£¼ì„¸ìš”.
"""
        
        async with httpx.AsyncClient(timeout=120.0) as httpx_client:
            # A2A SDKë¥¼ ì‚¬ìš©í•œ ì˜¬ë°”ë¥¸ ë°©ì‹
            resolver = A2ACardResolver(
                httpx_client=httpx_client,
                base_url=orchestrator_url,
            )
            
            # Agent Card ê°€ì ¸ì˜¤ê¸°
            try:
                agent_card = await resolver.get_agent_card()
            except Exception as e:
                return {
                    "success": False,
                    "error": f"Agent card fetch failed: {str(e)}",
                    "data": {}
                }
            
            # A2AClient ì´ˆê¸°í™”
            client = A2AClient(
                httpx_client=httpx_client, 
                agent_card=agent_card
            )
            
            # ì˜¬ë°”ë¥¸ A2A ë©”ì‹œì§€ í˜ì´ë¡œë“œ êµ¬ì„±
            send_message_payload = {
                'message': {
                    'role': 'user',
                    'parts': [
                        {'kind': 'text', 'text': enhanced_query}
                    ],
                    'messageId': uuid4().hex,
                },
            }
            
            # SendMessageRequest ìƒì„±
            request = SendMessageRequest(
                id=str(uuid4()), 
                params=MessageSendParams(**send_message_payload)
            )
            
            # A2A SDKë¥¼ í†µí•œ ë©”ì‹œì§€ ì „ì†¡
            response = await client.send_message(request)
            
            # ì˜¬ë°”ë¥¸ A2A SDK ì‘ë‹µ íŒŒì‹±
            if response and hasattr(response, 'root'):
                # SendMessageResponse -> root -> result -> parts
                root_response = response.root
                if hasattr(root_response, 'result'):
                    result_data = root_response.result
                    response_text = ""
                    
                    # Message ê°ì²´ì—ì„œ parts ì¶”ì¶œ
                    if hasattr(result_data, 'parts') and result_data.parts:
                        for part in result_data.parts:
                            # Part ê°ì²´ì—ì„œ root.text ì¶”ì¶œ
                            if hasattr(part, 'root') and hasattr(part.root, 'text'):
                                response_text += part.root.text
                    
                    # ì‘ë‹µì´ ìˆìœ¼ë©´ ì„±ê³µìœ¼ë¡œ ì²˜ë¦¬
                    if response_text:
                        return {
                            "success": True,
                            "data": {
                                "response": response_text,
                                "messageId": getattr(result_data, 'messageId', ''),
                                "role": str(getattr(result_data, 'role', 'agent'))
                            }
                        }
            
            # ì‘ë‹µì´ ì—†ê±°ë‚˜ í˜•ì‹ì´ ì˜ëª»ëœ ê²½ìš°
            return {
                "success": False,
                "error": f"No valid response content received from orchestrator. Response type: {type(response)}",
                "data": {}
            }
            
    except ImportError as e:
        return {
            "success": False,
            "error": f"A2A SDK import failed: {str(e)}. Please install a2a-sdk",
            "data": {}
        }
    except Exception as e:
        return {
            "success": False,
            "error": f"Request failed: {str(e)}",
            "data": {}
        }

def display_thinking_process(thinking_steps: List[Dict]):
    """Display orchestrator's thinking process"""
    if not thinking_steps:
        return
    
    st.markdown("""
    <div class="thinking-container">
        <h3 style="color: #667eea; margin-bottom: 1rem;">ğŸ¤” ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì‚¬ê³  ê³¼ì •</h3>
    </div>
    """, unsafe_allow_html=True)
    
    for i, step in enumerate(thinking_steps):
        status_class = step.get('status', 'thinking')
        
        st.markdown(f"""
        <div class="workflow-step {status_class}">
            <div style="display: flex; align-items: center; gap: 1rem; margin-bottom: 1rem;">
                <span style="padding: 0.3rem 0.8rem; border-radius: 15px; font-size: 0.8rem; font-weight: bold; text-transform: uppercase; letter-spacing: 0.5px; background: #ffc107; color: white;">
                    {step.get('status', 'PENDING')}
                </span>
                <h4 style="margin: 0; color: #495057;">
                    ë‹¨ê³„ {i+1}: {step.get('title', 'Processing...')}
                </h4>
            </div>
            <p style="margin: 0; color: #6c757d;">
                {step.get('description', 'Processing...')}
            </p>
        </div>
        """, unsafe_allow_html=True)

def display_workflow_timeline(workflow_steps: List[Dict]):
    """Display workflow timeline with agent assignments"""
    if not workflow_steps:
        return
    
    st.markdown("### ğŸ“‹ ë¶„ì„ ì›Œí¬í”Œë¡œìš°")
    
    for i, step in enumerate(workflow_steps):
        status = step.get('status', 'pending')
        agent_name = step.get('agent', 'Unknown Agent')
        tools = step.get('tools', [])
        title = step.get('title', f'Step {i+1}')
        
        # Status emoji and color
        if status == 'completed':
            status_emoji = "âœ…"
        elif status == 'running':
            status_emoji = "ğŸ”„"
        else:
            status_emoji = "â³"
        
        st.markdown(f"{status_emoji} **{title}**")

def perform_analysis(user_query: str, df: pd.DataFrame, saved_filename: str):
    """Perform the actual analysis with improved error handling"""
    
    # Add user message to conversation
    st.session_state.conversation_history.append({
        "role": "user",
        "content": user_query,
        "timestamp": time.time()
    })
    
    # Display thinking process
    display_thinking_process(st.session_state.thinking_process)
    
    # Display workflow
    display_workflow_timeline(st.session_state.analysis_workflow)
    
    # Send request to orchestrator
    with st.spinner("ğŸ¤– ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°ê°€ ë¶„ì„ì„ ìˆ˜í–‰í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
        try:
            # Send actual request to orchestrator
            result = asyncio.run(send_orchestrator_request(user_query, saved_filename))
            
            # Update workflow steps based on orchestrator response
            if result.get("success", False):
                # Parse A2A SDK response
                response_data = result.get("data", {})
                response_content = response_data.get("response", "")
                
                if response_content:
                    # Update thinking process based on response
                    for i in range(len(st.session_state.thinking_process)):
                        st.session_state.thinking_process[i]["status"] = "completed"
                    
                    # Update workflow steps
                    for i in range(len(st.session_state.analysis_workflow)):
                        st.session_state.analysis_workflow[i]["status"] = "completed"
                    
                    # Add the orchestrator's response to chat
                    st.session_state.conversation_history.append({
                        "role": "assistant",
                        "content": response_content,
                        "timestamp": time.time()
                    })
                    
                    st.success("âœ… ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
                    
                    # Display results in clean format
                    st.markdown("### ğŸ” ë¶„ì„ ê²°ê³¼")
                    st.markdown(response_content)
                    
                    return True
                else:
                    st.error("âŒ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°ë¡œë¶€í„° ì‘ë‹µì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                    return False
            else:
                # Handle A2A SDK errors
                error_msg = result.get("error", "Unknown error occurred")
                st.session_state.conversation_history.append({
                    "role": "assistant",
                    "content": f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {error_msg}",
                    "timestamp": time.time()
                })
                
                st.error(f"âŒ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì—°ê²° ì‹¤íŒ¨: {error_msg}")
                return False
                        
        except Exception as e:
            st.error(f"âŒ ì‹œìŠ¤í…œ ì˜¤ë¥˜: {str(e)}")
            return False

# ------------------------------------------------------------------------------
# Main UI Layout
# ------------------------------------------------------------------------------

# Hero Section with Status
st.markdown("""
<div class="main-container">
    <div class="hero-section">
        <h1 style="color: white; margin-bottom: 0; font-size: 3rem;">ğŸ§  Smart Data Analyst</h1>
        <p style="color: rgba(255,255,255,0.9); font-size: 1.3rem; margin-bottom: 1rem;">
            AI ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°ê°€ ìë™ìœ¼ë¡œ ìµœì ì˜ ë¶„ì„ ì „ëµì„ ìˆ˜ë¦½í•˜ê³  ì‹¤í–‰í•©ë‹ˆë‹¤
        </p>
    </div>
</div>
""", unsafe_allow_html=True)

# Check orchestrator status at start
st.session_state.orchestrator_connected = check_orchestrator_status()

# Status indicators
col1, col2, col3, col4 = st.columns(4)

with col1:
    if st.session_state.uploaded_data is not None:
        st.success("ğŸ“ ë°ì´í„° ë¡œë“œë¨")
    else:
        st.info("ğŸ“ ë°ì´í„° ëŒ€ê¸° ì¤‘")

with col2:
    if st.session_state.orchestrator_connected:
        st.success("ğŸ¤– ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì—°ê²°ë¨")
    else:
        st.error("ğŸ¤– ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì—°ê²° ì‹¤íŒ¨")

with col3:
    if any(step['status'] == 'completed' for step in st.session_state.analysis_workflow):
        st.success("âœ… ë¶„ì„ ì™„ë£Œ")
    else:
        st.info("â³ ë¶„ì„ ëŒ€ê¸° ì¤‘")

with col4:
    if len(st.session_state.conversation_history) > 0:
        st.success("ğŸ’¬ ëŒ€í™” í™œì„±í™”")
    else:
        st.info("ğŸ’¬ ëŒ€í™” ëŒ€ê¸° ì¤‘")

st.markdown("---")

# Main content area
tab1, tab2, tab3 = st.tabs(["ğŸ“Š ë°ì´í„° ë¶„ì„", "ğŸ’¬ ëŒ€í™” ê¸°ë¡", "ğŸš€ ë¹ ë¥¸ ë¶„ì„"])

with tab1:
    # File upload area
    st.markdown("""
    <div class="upload-zone">
        <h3 style="color: #667eea; margin-bottom: 1rem;">ğŸ“ ë°ì´í„° ì—…ë¡œë“œ</h3>
        <p style="color: #6c757d;">CSV, Excel, JSON íŒŒì¼ì„ ì§€ì›í•©ë‹ˆë‹¤</p>
    </div>
    """, unsafe_allow_html=True)
    
    uploaded_file = st.file_uploader(
        "ë¶„ì„í•  ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”",
        type=['csv', 'xlsx', 'xls', 'json'],
        help="CSV, Excel, JSON í˜•ì‹ì˜ íŒŒì¼ì„ ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    )
    
    if uploaded_file is not None:
        # Process uploaded file
        df = process_uploaded_file(uploaded_file)
        
        if df is not None:
            st.session_state.uploaded_data = df
            
            # Display basic data info
            st.success(f"âœ… ë°ì´í„° ì—…ë¡œë“œ ì™„ë£Œ: {uploaded_file.name}")
            
            # Save to shared directory for A2A agents
            saved_filename = save_uploaded_data_to_shared(df, uploaded_file.name)
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("í–‰ ìˆ˜", len(df))
            with col2:
                st.metric("ì—´ ìˆ˜", len(df.columns))
            with col3:
                st.metric("ê²°ì¸¡ê°’", df.isnull().sum().sum())
            
            # Data preview
            with st.expander("ğŸ“– ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°", expanded=True):
                st.dataframe(df.head(), use_container_width=True)
            
            # Analysis request input
            st.markdown("### ğŸ¤– AI ë¶„ì„ ìš”ì²­")
            st.markdown("ìì—°ì–´ë¡œ ë¶„ì„ì„ ìš”ì²­í•˜ë©´ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°ê°€ ìµœì ì˜ ë¶„ì„ ì „ëµì„ ìˆ˜ë¦½í•˜ê³  ì‹¤í–‰í•©ë‹ˆë‹¤.")
            
            # Create a form for better enter key support
            with st.form(key="analysis_form", clear_on_submit=True):
                user_query = st.text_area(
                    "ë¶„ì„ ìš”ì²­ì„ ì…ë ¥í•˜ì„¸ìš”:",
                    placeholder="ì˜ˆ: ì´ ë°ì´í„°ì˜ íŒ¨í„´ì„ ë¶„ì„í•˜ê³  ì‹œê°í™”í•´ì£¼ì„¸ìš”",
                    height=100,
                    key="query_input"
                )
                
                # Form submit button
                submit_button = st.form_submit_button("ğŸš€ ë¶„ì„ ì‹œì‘", type="primary")
                
                # Check if orchestrator is available before allowing analysis
                if submit_button:
                    if not st.session_state.orchestrator_connected:
                        st.error("âŒ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
                    elif not user_query.strip():
                        st.warning("â— ë¶„ì„ ìš”ì²­ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                    else:
                        # Perform analysis. The form will be cleared automatically on rerun.
                        perform_analysis(user_query, df, saved_filename)
    
    # If no data uploaded yet
    else:
        st.info("ğŸ“ ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ì—¬ AI ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”.")

with tab2:
    st.markdown("### ğŸ’¬ ëŒ€í™” ê¸°ë¡")
    
    if st.session_state.conversation_history:
        for message in st.session_state.conversation_history:
            timestamp = datetime.fromtimestamp(message['timestamp']).strftime("%H:%M:%S")
            
            if message['role'] == 'user':
                st.markdown(f"""
                <div style="background: linear-gradient(135deg, #e3f2fd 0%, #bbdefb 100%); border-radius: 20px; padding: 1.5rem; margin: 1rem 0;">
                    <strong>ğŸ‘¤ ì‚¬ìš©ì:</strong><br>
                    {message['content']}
                    <br><small style="color: #999;">{timestamp}</small>
                </div>
                """, unsafe_allow_html=True)
            else:
                st.markdown(f"""
                <div style="background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%); border-radius: 20px; padding: 1.5rem; margin: 1rem 0;">
                    <strong>ğŸ¤– ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°:</strong><br>
                    {message['content']}
                    <br><small style="color: #999;">{timestamp}</small>
                </div>
                """, unsafe_allow_html=True)
    else:
        st.info("ì•„ì§ ëŒ€í™” ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤. ë¶„ì„ì„ ìš”ì²­í•´ë³´ì„¸ìš”!")

with tab3:
    st.markdown("### ğŸš€ ë¹ ë¥¸ ë¶„ì„")
    
    if st.session_state.uploaded_data is not None:
        df = st.session_state.uploaded_data
        
        # Quick analysis buttons
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("ğŸ“ˆ ê¸°ë³¸ í†µê³„"):
                st.markdown("#### ğŸ“Š ê¸°ë³¸ í†µê³„ ì •ë³´")
                st.dataframe(df.describe(), use_container_width=True)
        
        with col2:
            if st.button("ğŸ” ë°ì´í„° í’ˆì§ˆ"):
                st.markdown("#### ğŸ” ë°ì´í„° í’ˆì§ˆ ë¶„ì„")
                quality_info = {
                    "ì»¬ëŸ¼ëª…": df.columns.tolist(),
                    "ë°ì´í„° íƒ€ì…": df.dtypes.tolist(),
                    "ê²°ì¸¡ê°’ ê°œìˆ˜": df.isnull().sum().tolist(),
                    "ìœ ë‹ˆí¬ ê°’ ê°œìˆ˜": df.nunique().tolist()
                }
                quality_df = pd.DataFrame(quality_info)
                st.dataframe(quality_df, use_container_width=True)
        
        with col3:
            if st.button("ğŸ“Š ì‹œê°í™”"):
                st.markdown("#### ğŸ“Š ë¹ ë¥¸ ì‹œê°í™”")
                # Get numeric and categorical columns
                numeric_cols = df.select_dtypes(include=['number']).columns.tolist()
                
                # 1. Distribution plot for first numeric column
                if numeric_cols:
                    fig_hist = px.histogram(
                        df, 
                        x=numeric_cols[0], 
                        title=f"{numeric_cols[0]} ë¶„í¬",
                        color_discrete_sequence=['#667eea']
                    )
                    fig_hist.update_layout(
                        template="plotly_white",
                        title_font_size=16,
                        title_x=0.5
                    )
                    st.plotly_chart(fig_hist, use_container_width=True)
                
                # 2. Correlation heatmap if multiple numeric columns
                if len(numeric_cols) >= 2:
                    corr_matrix = df[numeric_cols].corr()
                    fig_corr = px.imshow(
                        corr_matrix,
                        text_auto=True,
                        title="ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„",
                        color_continuous_scale='RdBu'
                    )
                    fig_corr.update_layout(
                        template="plotly_white",
                        title_font_size=16,
                        title_x=0.5
                    )
                    st.plotly_chart(fig_corr, use_container_width=True)
    
    else:
        st.info("ë°ì´í„°ë¥¼ ë¨¼ì € ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.") 