#!/usr/bin/env python3
"""
ν™κ²½ λ³€μ λ° LLM ν…μ¤νΈ
"""

import os
import sys
from pathlib import Path

# ν”„λ΅μ νΈ λ£¨νΈ κ²½λ΅ μ„¤μ •
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / "ai_ds_team"))
os.environ['PYTHONPATH'] = f"{project_root / 'ai_ds_team'}:{os.environ.get('PYTHONPATH', '')}"

print("π”§ ν™κ²½ λ³€μ λ° LLM ν…μ¤νΈ")
print("=" * 50)

# 1. .env νμΌ κ°•μ  λ΅λ“
print("π“‚ .env νμΌ λ΅λ“ μ¤‘...")
try:
    from dotenv import load_dotenv
    env_path = project_root / '.env'
    if env_path.exists():
        load_dotenv(env_path)
        print(f"β… .env νμΌ λ΅λ“: {env_path}")
    else:
        print(f"β .env νμΌ μ—†μ: {env_path}")
except ImportError:
    print("β οΈ python-dotenv ν¨ν‚¤μ§€ μ—†μ")

# 2. ν™κ²½ λ³€μ ν™•μΈ
print("\nπ” ν™κ²½ λ³€μ ν™•μΈ:")
env_vars = ['LLM_PROVIDER', 'OLLAMA_MODEL', 'OLLAMA_BASE_URL', 'OLLAMA_TOOL_CALLING_SUPPORTED']
for var in env_vars:
    value = os.getenv(var)
    print(f"   {var}: {value}")

# 3. LLMFactory ν…μ¤νΈ
print("\nπ€ LLMFactory ν…μ¤νΈ:")
try:
    from core.universal_engine.llm_factory import LLMFactory
    
    # κΈ°λ³Έ μ„¤μ • ν™•μΈ
    configs = LLMFactory.get_default_configs()
    print(f"   κΈ°λ³Έ μ„¤μ •: {list(configs.keys())}")
    
    if 'ollama' in configs:
        ollama_config = configs['ollama']
        print(f"   Ollama μ„¤μ •: {ollama_config}")
    
    print("   LLM ν΄λΌμ΄μ–ΈνΈ μƒμ„± μ‹λ„...")
    llm = LLMFactory.create_llm_client()
    print(f"β… LLM ν΄λΌμ΄μ–ΈνΈ μƒμ„± μ„±κ³µ: {type(llm)}")
    
    success = True
    
except Exception as e:
    print(f"β LLMFactory μ‹¤ν¨: {e}")
    import traceback
    traceback.print_exc()
    success = False

print(f"\nπ” ν…μ¤νΈ {'μ„±κ³µ' if success else 'μ‹¤ν¨'}")