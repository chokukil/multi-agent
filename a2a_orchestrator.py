#!/usr/bin/env python3
"""
CherryAI v8 - Universal Intelligent Orchestrator
A2A SDK v0.2.9 í‘œì¤€ ì¤€ìˆ˜ + ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° + ì§€ëŠ¥í˜• ì—ì´ì „íŠ¸ ë°œê²¬
Enhanced with pandas_agent pattern for LLM First orchestration
"""

import asyncio
import json
import logging
import os
import time
from datetime import datetime
from typing import Any, Dict, List, Optional

import httpx
import uvicorn
from openai import AsyncOpenAI

# A2A SDK 0.2.9 í‘œì¤€ ì„í¬íŠ¸
from a2a.server.apps import A2AStarletteApplication
from a2a.server.request_handlers import DefaultRequestHandler
from a2a.server.tasks import InMemoryTaskStore, TaskUpdater
from a2a.server.agent_execution import AgentExecutor, RequestContext
from a2a.server.events import EventQueue
from a2a.types import (
    AgentCard,
    AgentSkill,
    AgentCapabilities,
    TaskState,
    TextPart,
    Part
)
from a2a.client import A2ACardResolver, A2AClient
from a2a.utils import new_agent_text_message, new_task

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ğŸ”¥ ì™„ì „í•œ 12ê°œ A2A ì—ì´ì „íŠ¸ í¬íŠ¸ ë§¤í•‘ (pandas_agent íŒ¨í„´ ê¸°ì¤€)
AGENT_PORTS = {
    "data_cleaning": 8306,
    "data_loader": 8307,
    "data_visualization": 8308,
    "data_wrangling": 8309,
    "feature_engineering": 8310,
    "sql_database": 8311,
    "eda_tools": 8312,
    "h2o_ml": 8313,
    "mlflow_tools": 8314,
    "pandas_agent": 8210,  # ğŸ¯ ê¸°ì¤€ ëª¨ë¸
    "report_generator": 8316  # ğŸ“‹ ì¢…í•© ë³´ê³ ì„œ
}

# pandas_agent íŒ¨í„´ ê¸°ë°˜ Agent ì¹´í…Œê³ ë¦¬
AGENT_CATEGORIES = {
    "coordination": ["orchestrator"],
    "data_loading": ["data_loader", "pandas_agent"],
    "data_processing": ["data_cleaning", "data_wrangling", "feature_engineering"],
    "analysis": ["eda_tools", "sql_database"],
    "visualization": ["data_visualization"],
    "modeling": ["h2o_ml", "mlflow_tools"],
    "reporting": ["report_generator"]
}


class LLMIntentAnalyzer:
    """pandas_agent íŒ¨í„´: LLM ê¸°ë°˜ ì˜ë„ ë¶„ì„ê¸°"""
    
    def __init__(self, openai_client):
        self.client = openai_client
    
    async def analyze_orchestration_intent(self, user_query: str) -> Dict[str, Any]:
        """ì‚¬ìš©ì ìš”ì²­ì˜ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ì˜ë„ ë¶„ì„"""
        if not self.client:
            return {
                "complexity": "medium",
                "required_agents": ["data_loader", "eda_tools"],
                "workflow_type": "sequential",
                "confidence": 0.7
            }
        
        try:
            response = await self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {
                        "role": "system",
                        "content": """ë‹¹ì‹ ì€ ë°ì´í„° ê³¼í•™ ì›Œí¬í”Œë¡œìš° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
                        ì‚¬ìš©ì ìš”ì²­ì„ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ì—ì´ì „íŠ¸ë“¤ê³¼ ì‹¤í–‰ ìˆœì„œë¥¼ ê²°ì •í•´ì£¼ì„¸ìš”.
                        
                        Available agents: data_cleaning, data_loader, data_visualization, 
                        data_wrangling, feature_engineering, sql_database, eda_tools, 
                        h2o_ml, mlflow_tools, pandas_agent, report_generator
                        """
                    },
                    {
                        "role": "user", 
                        "content": f"ë‹¤ìŒ ìš”ì²­ì„ ë¶„ì„í•´ì£¼ì„¸ìš”: {user_query}"
                    }
                ],
                response_format={"type": "json_object"}
            )
            
            return json.loads(response.choices[0].message.content)
            
        except Exception as e:
            logger.error(f"âŒ LLM ì˜ë„ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                "complexity": "medium",
                "required_agents": ["data_loader", "eda_tools"],
                "workflow_type": "sequential",
                "confidence": 0.5
            }


class LLMAgentSelector:
    """pandas_agent íŒ¨í„´: LLM ê¸°ë°˜ ìµœì  ì—ì´ì „íŠ¸ ì„ íƒê¸°"""
    
    def __init__(self, openai_client):
        self.client = openai_client
    
    async def select_optimal_agents(self, intent_analysis: Dict) -> List[str]:
        """ì˜ë„ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì  ì—ì´ì „íŠ¸ë“¤ ì„ íƒ"""
        required_agents = intent_analysis.get("required_agents", [])
        
        # pandas_agentë¥¼ í•­ìƒ ìš°ì„  ê³ ë ¤ (ê¸°ì¤€ ëª¨ë¸)
        if "data_analysis" in str(intent_analysis) and "pandas_agent" not in required_agents:
            required_agents.insert(0, "pandas_agent")
        
        return required_agents


class LLMWorkflowPlanner:
    """pandas_agent íŒ¨í„´: LLM ê¸°ë°˜ ì›Œí¬í”Œë¡œìš° ê³„íš ìˆ˜ë¦½ê¸°"""
    
    def __init__(self, openai_client):
        self.client = openai_client
    
    async def create_execution_plan(self, intent_analysis: Dict, available_agents: List[str]) -> List[Dict]:
        """ì‹¤í–‰ ê³„íš ìˆ˜ë¦½"""
        required_agents = intent_analysis.get("required_agents", [])
        workflow_type = intent_analysis.get("workflow_type", "sequential")
        
        # ê¸°ë³¸ ì‹¤í–‰ ê³„íš
        execution_plan = []
        
        for i, agent_name in enumerate(required_agents):
            if agent_name in AGENT_PORTS:
                execution_plan.append({
                    "step": i + 1,
                    "agent": agent_name,
                    "port": AGENT_PORTS[agent_name],
                    "description": f"{agent_name} ì—ì´ì „íŠ¸ ì‹¤í–‰",
                    "dependencies": [] if i == 0 else [execution_plan[i-1]["step"]],
                    "parallel": workflow_type == "parallel"
                })
        
        return execution_plan


class CherryAI_v8_UniversalIntelligentOrchestrator(AgentExecutor):
    """
    CherryAI v8 - Universal Intelligent Orchestrator
    Enhanced with pandas_agent pattern for LLM First orchestration
    """
    
    def __init__(self):
        super().__init__()
        self.openai_client = self._initialize_openai_client()
        self.discovered_agents = {}
        
        # pandas_agent íŒ¨í„´: LLM First ì˜ë„ ë¶„ì„ê¸°
        self.intent_analyzer = LLMIntentAnalyzer(self.openai_client)
        self.agent_selector = LLMAgentSelector(self.openai_client)
        self.workflow_planner = LLMWorkflowPlanner(self.openai_client)
        
        logger.info("ğŸš€ CherryAI v8 Universal Intelligent Orchestrator ì´ˆê¸°í™” ì™„ë£Œ")
        logger.info(f"ğŸ¯ ê´€ë¦¬ ëŒ€ìƒ: {len(AGENT_PORTS)}ê°œ A2A ì—ì´ì „íŠ¸")
    
    def _initialize_openai_client(self) -> Optional[AsyncOpenAI]:
        """OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (pandas_agent íŒ¨í„´)"""
        try:
            api_key = os.getenv("OPENAI_API_KEY")
            if not api_key:
                logger.warning("âš ï¸ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
                return None
            return AsyncOpenAI(api_key=api_key)
        except Exception as e:
            logger.error(f"âŒ OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return None

    async def execute(self, context: RequestContext, event_queue: EventQueue) -> None:
        """
        pandas_agent íŒ¨í„´ ê¸°ë°˜ A2A í‘œì¤€ ì‹¤í–‰ ë©”ì„œë“œ
        """
        # A2A í‘œì¤€ TaskUpdater ì´ˆê¸°í™”
        updater = TaskUpdater(event_queue, context.task_id, context.context_id)
        
        try:
            # ì²« ë²ˆì§¸ íƒœìŠ¤í¬ì¸ ê²½ìš° submit í˜¸ì¶œ
            if not context.current_task:
                await updater.submit()
            
            # ì‘ì—… ì‹œì‘ ì•Œë¦¼
            await updater.start_work()
            
            # ì‚¬ìš©ì ì…ë ¥ ì¶”ì¶œ
            user_input = self._extract_user_input(context)
            logger.info(f"ğŸ§‘ğŸ» ì‚¬ìš©ì ìš”ì²­: {user_input[:100]}...")
            
            # ğŸ¯ pandas_agent íŒ¨í„´: LLM First ì˜ë„ ë¶„ì„
            await updater.update_status(
                TaskState.working, 
                message=new_agent_text_message("ğŸ’ LLM ê¸°ë°˜ ìš”ì²­ ì˜ë„ë¥¼ ì •ë°€ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
            )
            
            intent_analysis = await self.intent_analyzer.analyze_orchestration_intent(user_input)
            
            await updater.update_status(
                TaskState.working, 
                message=new_agent_text_message(f"ğŸ’ ì˜ë„ ë¶„ì„ ì™„ë£Œ - ë³µì¡ë„: {intent_analysis.get('complexity', 'medium')}")
            )
            
            # ğŸ” Agent ë°œê²¬ ë° ê°€ìš©ì„± í™•ì¸
            await updater.update_status(
                TaskState.working, 
                message=new_agent_text_message("ğŸ’ A2A ì—ì´ì „íŠ¸ë“¤ì„ ë°œê²¬í•˜ê³  ê°€ìš©ì„±ì„ í™•ì¸í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
            )
            
            available_agents = await self._discover_agent_capabilities()
            
            await updater.update_status(
                TaskState.working, 
                message=new_agent_text_message(f"ğŸ’ {len(available_agents)}ê°œ ì—ì´ì „íŠ¸ ë°œê²¬ ì™„ë£Œ")
            )
            
            # ğŸ¯ ìµœì  ì—ì´ì „íŠ¸ ì„ íƒ
            optimal_agents = await self.agent_selector.select_optimal_agents(intent_analysis)
            
            # ğŸ“‹ ì‹¤í–‰ ê³„íš ìˆ˜ë¦½
            await updater.update_status(
                TaskState.working, 
                message=new_agent_text_message("ğŸ’ LLM ê¸°ë°˜ ìµœì  ì‹¤í–‰ ê³„íšì„ ìˆ˜ë¦½í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
            )
            
            execution_plan = await self.workflow_planner.create_execution_plan(intent_analysis, available_agents)
            
            await updater.update_status(
                TaskState.working, 
                message=new_agent_text_message(f"ğŸ’ ì‹¤í–‰ ê³„íš ì™„ë£Œ - {len(execution_plan)}ë‹¨ê³„ ì›Œí¬í”Œë¡œìš°")
            )
            
            # âš¡ ê³„íš ë‹¨ê³„ë³„ ì‹¤í–‰
            final_results = []
            
            for i, step in enumerate(execution_plan):
                await updater.update_status(
                    TaskState.working, 
                    message=new_agent_text_message(f"ğŸ’ ë‹¨ê³„ {i+1}/{len(execution_plan)} ì‹¤í–‰ ì¤‘: {step.get('description', 'ì²˜ë¦¬ ì¤‘...')}")
                )
                
                try:
                    step_result = await self._execute_plan_step(step, context.context_id)
                    validated_result = await self._validate_agent_response(step_result, step)
                    final_results.append(validated_result)
                    
                except Exception as e:
                    logger.error(f"âŒ ë‹¨ê³„ {i+1} ì‹¤í–‰ ì‹¤íŒ¨: {e}")
                    await updater.update_status(
                        TaskState.working, 
                        message=new_agent_text_message(f"âš ï¸ ë‹¨ê³„ {i+1} ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ, ë‹¤ìŒ ë‹¨ê³„ ì§„í–‰...")
                    )
            
            # ğŸ“ ìµœì¢… ê²°ê³¼ ì¢…í•©
            await updater.update_status(
                TaskState.working, 
                message=new_agent_text_message("ğŸ’ ëª¨ë“  ì—ì´ì „íŠ¸ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
            )
            
            comprehensive_result = await self._synthesize_results(final_results, user_input)
            
            # âœ… ê²°ê³¼ ë°˜í™˜
            await updater.add_artifact(
                [TextPart(text=comprehensive_result)],
                name="orchestration_result",
                metadata={"execution_plan": execution_plan, "agent_count": len(execution_plan)}
            )
            
            await updater.update_status(
                TaskState.completed,
                message=new_agent_text_message("âœ… ë©€í‹° ì—ì´ì „íŠ¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            )
            
        except Exception as e:
            logger.error(f"âŒ Orchestrator ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            await updater.update_status(
                TaskState.failed,
                message=new_agent_text_message(f"âŒ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            )
    
    def _extract_user_input(self, context: RequestContext) -> str:
        """ì‚¬ìš©ì ì…ë ¥ ì¶”ì¶œ"""
        try:
            if context.message and context.message.parts:
                for part in context.message.parts:
                    if hasattr(part.root, 'kind') and part.root.kind == 'text':
                        return part.root.text
                    elif hasattr(part.root, 'type') and part.root.type == 'text':
                        return part.root.text
            return ""
        except Exception as e:
            logger.error(f"ì‚¬ìš©ì ì…ë ¥ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return ""

    async def cancel(self, context: RequestContext, event_queue: EventQueue) -> None:
        """ì‘ì—… ì·¨ì†Œ"""
        logger.info("âŒ CherryAI v8 ì‘ì—…ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤")
        raise Exception('cancel not supported')

    async def _assess_request_complexity(self, user_input: str) -> str:
        """ìš”ì²­ ë³µì¡ë„ í‰ê°€"""
        try:
            # ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜ ë³µì¡ë„ í‰ê°€
            word_count = len(user_input.split())
            question_marks = user_input.count('?')
            
            # ë‹¨ìˆœ ì§ˆë¬¸ íŒ¨í„´
            simple_patterns = ['ì•ˆë…•', 'í…ŒìŠ¤íŠ¸', '?', 'ê°„ë‹¨í•œ']
            if any(pattern in user_input for pattern in simple_patterns) and word_count < 10:
                return "Simple"
            
            # ë‹¨ì¼ ì—ì´ì „íŠ¸ íŒ¨í„´
            single_agent_patterns = ['EDA', 'ì‹œê°í™”', 'ë°ì´í„° ë¡œë“œ', 'ëª¨ë¸ë§']
            if any(pattern in user_input for pattern in single_agent_patterns):
                return "Single Agent"
            
            return "Complex"
            
        except Exception as e:
            logger.error(f"ë³µì¡ë„ í‰ê°€ ì‹¤íŒ¨: {e}")
            return "Complex"
    
    async def _generate_simple_response(self, user_input: str) -> str:
        """ê°„ë‹¨í•œ ì‘ë‹µ ìƒì„±"""
        try:
            if not self.openai_client:
                return f"ì•ˆë…•í•˜ì„¸ìš”! '{user_input}'ì— ëŒ€í•œ ì‘ë‹µì…ë‹ˆë‹¤. OpenAI APIê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ê¸°ë³¸ ì‘ë‹µì„ ì œê³µí•©ë‹ˆë‹¤."
            
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì¹œê·¼í•˜ê³  ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": user_input}
                ],
                temperature=0.7,
                max_tokens=500
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            logger.error(f"ê°„ë‹¨í•œ ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
            return f"ì£„ì†¡í•©ë‹ˆë‹¤. '{user_input}'ì— ëŒ€í•œ ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    async def _select_best_agent(self, user_input: str) -> dict:
        """ìµœì  ì—ì´ì „íŠ¸ ì„ íƒ"""
        # ê¸°ë³¸ ì—ì´ì „íŠ¸ ë§¤í•‘
        agent_mapping = {
            "EDA": {"name": "EDA Tools Agent", "port": 8312},
            "ì‹œê°í™”": {"name": "Data Visualization Agent", "port": 8308},
            "ë°ì´í„° ë¡œë“œ": {"name": "Data Loader Agent", "port": 8307}
        }
        
        for keyword, agent_info in agent_mapping.items():
            if keyword in user_input:
                return agent_info
        
        return None
    
    async def _execute_single_agent(self, agent_info: dict, user_input: str, context_id: str) -> str:
        """ë‹¨ì¼ ì—ì´ì „íŠ¸ ì‹¤í–‰"""
        try:
            # ì‹¤ì œ ì—ì´ì „íŠ¸ í˜¸ì¶œ êµ¬í˜„ (í–¥í›„ í™•ì¥)
            return f"{agent_info['name']}ì—ì„œ '{user_input}' ì²˜ë¦¬ ì™„ë£Œ (ì‹œë®¬ë ˆì´ì…˜)"
        except Exception as e:
            logger.error(f"ë‹¨ì¼ ì—ì´ì „íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return f"ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
    
    async def _extract_user_intent_precisely(self, user_input: str) -> dict:
        """ì‚¬ìš©ì ì˜ë„ ì •ë°€ ë¶„ì„"""
        return {
            "intent": "analysis",
            "action_type": "analyze",
            "domain": "general",
            "complexity": "medium"
        }
    
    async def _discover_agent_capabilities(self) -> list:
        """ì—ì´ì „íŠ¸ ëŠ¥ë ¥ ë™ì  ë°œê²¬"""
        available_agents = []
        
        async with httpx.AsyncClient(timeout=5.0) as client:
            for agent_name, port in AGENT_PORTS.items():
                try:
                    response = await client.get(f"http://localhost:{port}/.well-known/agent.json")
                    if response.status_code == 200:
                        agent_card = response.json()
                        available_agents.append({
                            "name": agent_card.get("name", agent_name),
                            "port": port,
                            "capabilities": ["data_analysis", "statistics"],
                            "description": agent_card.get("description", "")
                        })
                        logger.info(f"âœ… {agent_name} ì—ì´ì „íŠ¸ ë°œê²¬ (í¬íŠ¸: {port})")
                except Exception as e:
                    logger.warning(f"âš ï¸ {agent_name} ì—ì´ì „íŠ¸ í™•ì¸ ì‹¤íŒ¨ (í¬íŠ¸: {port}): {e}")
        
        return available_agents
    
    async def _create_execution_plan(self, intent_analysis: dict, available_agents: list) -> list:
        """ì‹¤í–‰ ê³„íš ìƒì„±"""
        plan = []
        
        # ê¸°ë³¸ ê³„íš: ë°ì´í„° ë¡œë”© -> EDA -> ì‹œê°í™”
        if available_agents:
            plan.append({"agent": "Data Loader Agent", "description": "ë°ì´í„° ë¡œë”©"})
            plan.append({"agent": "EDA Tools Agent", "description": "íƒìƒ‰ì  ë°ì´í„° ë¶„ì„"})
            plan.append({"agent": "Data Visualization Agent", "description": "ë°ì´í„° ì‹œê°í™”"})
        
        return plan
    
    async def _execute_plan_step(self, step: dict, context_id: str) -> dict:
        """ê³„íš ë‹¨ê³„ ì‹¤í–‰"""
        try:
            # ì‹¤ì œ ì—ì´ì „íŠ¸ í˜¸ì¶œ ë¡œì§ êµ¬í˜„
            agent_name = step.get("agent", "Unknown")
            description = step.get("description", "ì²˜ë¦¬ ì¤‘...")
            
            # ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ ë°˜í™˜
            return {
                "status": "success",
                "result": f"{agent_name} ì‹¤í–‰ ì™„ë£Œ: {description}",
                "agent": agent_name,
                "execution_time": 2.5
            }
            
        except Exception as e:
            logger.error(f"ê³„íš ë‹¨ê³„ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return {
                "status": "failed",
                "result": f"ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}",
                "agent": step.get("agent", "Unknown")
            }
    
    async def _validate_agent_response(self, result: dict, step: dict) -> dict:
        """ì—ì´ì „íŠ¸ ì‘ë‹µ ê²€ì¦"""
        if result.get("status") == "success":
            return result
        else:
            # ì‹¤íŒ¨í•œ ê²½ìš° ê¸°ë³¸ ê²°ê³¼ ë°˜í™˜
            return {
                "status": "completed_with_fallback",
                "result": f"{step.get('agent', 'Unknown')} ì²˜ë¦¬ ì™„ë£Œ (ê¸°ë³¸ ê²°ê³¼)",
                "agent": step.get("agent", "Unknown")
            }
    
    async def _create_evidence_based_response(self, user_input: str, intent_analysis: dict, results: list) -> str:
        """ì¦ê±° ê¸°ë°˜ ìµœì¢… ì‘ë‹µ ìƒì„±"""
        try:
            if not self.openai_client:
                return self._generate_fallback_response(user_input, results)
            
            # OpenAIë¥¼ ì‚¬ìš©í•œ ì¢…í•© ì‘ë‹µ ìƒì„±
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {
                        "role": "system", 
                        "content": """ë‹¹ì‹ ì€ CherryAI ì‹œìŠ¤í…œì˜ ì „ë¬¸ ë°ì´í„° ë¶„ì„ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
                        
ì‚¬ìš©ìì˜ ìš”ì²­ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒê³¼ ê°™ì€ í˜•íƒœë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:

# ì¢…í•© ë¶„ì„ ê²°ê³¼

## ğŸ“Š ìš”ì²­ ë‚´ìš© ë¶„ì„
- ì‚¬ìš©ìê°€ ìš”ì²­í•œ ë‚´ìš©ì„ ëª…í™•íˆ íŒŒì•…í•˜ê³  ì„¤ëª…

## ğŸ” ë¶„ì„ ì ‘ê·¼ë²•
- í•´ë‹¹ ìš”ì²­ì„ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ ì ì ˆí•œ ë¶„ì„ ë°©ë²•ë¡  ì œì‹œ

## ğŸ“ˆ ë¶„ì„ ê²°ê³¼
- ìˆ˜í–‰ëœ ë¶„ì„ì˜ ì£¼ìš” ê²°ê³¼ì™€ ë°œê²¬ì‚¬í•­

## ğŸ’¡ í•µì‹¬ ì¸ì‚¬ì´íŠ¸
- ë¶„ì„ì„ í†µí•´ ì–»ì€ ì£¼ìš” ì¸ì‚¬ì´íŠ¸ì™€ ê°€ì¹˜

## ğŸš€ ê¶Œì¥ì‚¬í•­
- ì‹¤ë¬´ì— ì ìš© ê°€ëŠ¥í•œ êµ¬ì²´ì ì¸ ê¶Œì¥ì‚¬í•­

í•­ìƒ ì „ë¬¸ì ì´ê³  ì‹¤ìš©ì ì¸ ì¡°ì–¸ì„ ì œê³µí•´ì£¼ì„¸ìš”."""
                    },
                    {"role": "user", "content": f"ì‚¬ìš©ì ìš”ì²­: {user_input}\n\në¶„ì„ ê²°ê³¼: {results}"}
                ],
                temperature=0.7,
                max_tokens=2000
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            logger.error(f"OpenAI ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
            return self._generate_fallback_response(user_input, results)
    
    def _generate_fallback_response(self, user_input: str, results: list = None) -> str:
        """ê¸°ë³¸ ì‘ë‹µ ìƒì„± (OpenAI ì—†ì„ ë•Œ)"""
        response = f"# {user_input}ì— ëŒ€í•œ ì¢…í•© ë¶„ì„ ê²°ê³¼\n\n"
        
        response += "## ğŸ“Š ìš”ì²­ ë‚´ìš© ë¶„ì„\n"
        response += f"ì‚¬ìš©ìê»˜ì„œ '{user_input}'ì— ëŒ€í•œ ë¶„ì„ì„ ìš”ì²­í•˜ì…¨ìŠµë‹ˆë‹¤.\n\n"
        
        response += "## ğŸ” ë¶„ì„ ì ‘ê·¼ë²•\n"
        response += "CherryAI ì‹œìŠ¤í…œì—ì„œëŠ” ë‹¤ìŒê³¼ ê°™ì€ ë‹¨ê³„ë¡œ ë¶„ì„ì„ ì§„í–‰í•©ë‹ˆë‹¤:\n\n"
        
        response += "## ğŸ“ˆ ë¶„ì„ ê²°ê³¼\n"
        if results and len(results) > 0:
            for i, result in enumerate(results):
                response += f"### ë‹¨ê³„ {i+1}: {result.get('result', 'ê²°ê³¼ ì—†ìŒ')}\n"
        else:
            response += "1. **ë°ì´í„° ìˆ˜ì§‘ ë° ë¡œë”©**: í•„ìš”í•œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³  ì‹œìŠ¤í…œì— ë¡œë“œ\n"
            response += "2. **íƒìƒ‰ì  ë°ì´í„° ë¶„ì„ (EDA)**: ë°ì´í„°ì˜ êµ¬ì¡°ì™€ íŠ¹ì„±ì„ íŒŒì•…\n"
            response += "3. **ë°ì´í„° ì „ì²˜ë¦¬**: ë¶„ì„ì— ì í•©í•˜ë„ë¡ ë°ì´í„° ì •ë¦¬ ë° ë³€í™˜\n"
            response += "4. **ë¶„ì„ ì‹¤í–‰**: ìš”ì²­ëœ ë¶„ì„ ìˆ˜í–‰\n"
            response += "5. **ê²°ê³¼ í•´ì„ ë° ì‹œê°í™”**: ë¶„ì„ ê²°ê³¼ë¥¼ ì´í•´í•˜ê¸° ì‰½ê²Œ ì •ë¦¬\n\n"
        
        response += "## ğŸ’¡ í•µì‹¬ ì¸ì‚¬ì´íŠ¸\n"
        response += "- ë°ì´í„° ê¸°ë°˜ì˜ ê°ê´€ì ì¸ ì¸ì‚¬ì´íŠ¸ ì œê³µ\n"
        response += "- ì‹œê°í™”ë¥¼ í†µí•œ ì§ê´€ì ì¸ ê²°ê³¼ í‘œí˜„\n"
        response += "- ì‹¤ë¬´ì— ì ìš© ê°€ëŠ¥í•œ êµ¬ì²´ì ì¸ ê¶Œì¥ì‚¬í•­\n\n"
        
        response += "## ğŸš€ ê¶Œì¥ì‚¬í•­\n"
        response += "êµ¬ì²´ì ì¸ ë¶„ì„ì„ ìœ„í•´ ë‹¤ìŒ ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤:\n"
        response += "- ë¶„ì„í•˜ê³ ì í•˜ëŠ” ë°ì´í„°ì…‹\n"
        response += "- êµ¬ì²´ì ì¸ ë¶„ì„ ëª©í‘œ\n"
        response += "- ì›í•˜ëŠ” ê²°ê³¼ í˜•íƒœ\n\n"
        
        response += "CherryAI ì‹œìŠ¤í…œì´ ë„ì›€ì„ ë“œë¦´ ì¤€ë¹„ê°€ ë˜ì–´ìˆìŠµë‹ˆë‹¤!"
        
        return response


def create_agent_card() -> AgentCard:
    """CherryAI v8 ì—ì´ì „íŠ¸ ì¹´ë“œ ìƒì„±"""
    return AgentCard(
        name="Universal Intelligent Orchestrator v8.0",
        description="A2A SDK v0.2.9 í‘œì¤€ ì¤€ìˆ˜ + ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° + ì§€ëŠ¥í˜• ì—ì´ì „íŠ¸ ë°œê²¬ì„ í†µí•©í•œ ë²”ìš© ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°",
        url="http://localhost:8100",
        version="8.0.0",
        provider={
            "organization": "CherryAI Team",
            "url": "https://github.com/CherryAI"
        },
        capabilities=AgentCapabilities(
            streaming=True,
            pushNotifications=False,
            stateTransitionHistory=True
        ),
        defaultInputModes=["text/plain"],
        defaultOutputModes=["text/plain"],
        skills=[
            AgentSkill(
                id="universal_analysis",
                name="Universal Data Analysis",
                description="A2A í”„ë¡œí† ì½œì„ í™œìš©í•œ ë²”ìš© ë°ì´í„° ë¶„ì„ ë° AI ì—ì´ì „íŠ¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜",
                tags=["analysis", "orchestration", "a2a", "streaming"],
                examples=[
                    "ë°ì´í„°ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”",
                    "ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”", 
                    "ë°ì´í„° ì‹œê°í™”ë¥¼ í•´ì£¼ì„¸ìš”",
                    "EDAë¥¼ ìˆ˜í–‰í•´ì£¼ì„¸ìš”"
                ],
                inputModes=["text/plain"],
                outputModes=["text/plain"]
            )
        ],
        supportsAuthenticatedExtendedCard=False
    )


async def main():
    """CherryAI v8 ì„œë²„ ì‹œì‘"""
    try:
        # ì—ì´ì „íŠ¸ ì¹´ë“œ ìƒì„±
        agent_card = create_agent_card()
        
        # íƒœìŠ¤í¬ ìŠ¤í† ì–´ ë° ì‹¤í–‰ì ì´ˆê¸°í™”
        task_store = InMemoryTaskStore()
        agent_executor = CherryAI_v8_UniversalIntelligentOrchestrator()
        
        # ìš”ì²­ í•¸ë“¤ëŸ¬ ìƒì„±
        request_handler = DefaultRequestHandler(
            agent_executor=agent_executor,
            task_store=task_store,
        )
        
        # A2A ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒì„±
        app_builder = A2AStarletteApplication(
            agent_card=agent_card,
            http_handler=request_handler
        )
        app = app_builder.build()
        
        # ì„œë²„ ì‹œì‘
        print("ğŸš€ CherryAI v8 Universal Intelligent Orchestrator ì‹œì‘")
        print(f"ğŸ“ Agent Card: http://localhost:8100/.well-known/agent.json")
        print("ğŸ›‘ ì¢…ë£Œí•˜ë ¤ë©´ Ctrl+Cë¥¼ ëˆ„ë¥´ì„¸ìš”")
        
        config = uvicorn.Config(
            app=app,
            host="0.0.0.0",
            port=8100,
            log_level="info"
        )
        server = uvicorn.Server(config)
        await server.serve()
        
    except Exception as e:
        logger.error(f"âŒ ì„œë²„ ì‹œì‘ ì‹¤íŒ¨: {e}")
        raise


if __name__ == "__main__":
    asyncio.run(main()) 