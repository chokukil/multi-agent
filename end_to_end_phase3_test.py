#!/usr/bin/env python3
"""
End-to-End Phase 3 Integration Test
ì‹¤ì œ ì‚¬ìš©ì ì¿¼ë¦¬ë¡œ ì „ì²´ Phase 3 íŒŒì´í”„ë¼ì¸ ê²€ì¦
"""

import asyncio
import json
import time
from typing import Dict, Any

from core.phase3_integration_layer import Phase3IntegrationLayer
from ui.expert_answer_renderer import ExpertAnswerRenderer


async def test_real_user_query():
    """ì‹¤ì œ ì‚¬ìš©ì ì¿¼ë¦¬ë¡œ End-to-End í…ŒìŠ¤íŠ¸"""
    
    print("ğŸ§ª Phase 3 End-to-End Test ì‹œì‘")
    print("=" * 60)
    
    # Phase 3 Integration Layer ì´ˆê¸°í™”
    integration_layer = Phase3IntegrationLayer()
    expert_renderer = ExpertAnswerRenderer()
    
    # ì‹¤ì œ ì‚¬ìš©ì ì¿¼ë¦¬
    user_query = "ì œì¡°ì—… ë°ì´í„°ì˜ í’ˆì§ˆ ì´ìŠˆë¥¼ ë¶„ì„í•˜ê³  ê°œì„  ë°©ì•ˆì„ ì œì‹œí•´ì£¼ì„¸ìš”"
    
    # Mock A2A ì—ì´ì „íŠ¸ ê²°ê³¼ ìƒì„± (ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” A2A ì‹œìŠ¤í…œì—ì„œ ì œê³µ)
    mock_a2a_results = [
        {
            "agent_name": "DataQualityAnalyzer", 
            "success": True,
            "confidence": 0.85,
            "artifacts": [
                {"type": "analysis", "data": "ë°ì´í„° í’ˆì§ˆ ë¶„ì„ ì™„ë£Œ: 85% ì‹ ë¢°ë„"},
                {"type": "report", "data": "ì£¼ìš” í’ˆì§ˆ ì´ìŠˆ 3ê°œ ë°œê²¬"}
            ],
            "execution_time": 12.5,
            "metadata": {"agent_type": "data_analysis", "version": "1.0"}
        },
        {
            "agent_name": "ManufacturingInsights",
            "success": True, 
            "confidence": 0.78,
            "artifacts": [
                {"type": "insight", "data": "ì œì¡° ê³µì • ê°œì„  ê¶Œê³ ì‚¬í•­"},
                {"type": "visualization", "data": "í’ˆì§ˆ íŠ¸ë Œë“œ ì°¨íŠ¸"}
            ],
            "execution_time": 8.3,
            "metadata": {"agent_type": "domain_expert", "version": "2.1"}
        },
        {
            "agent_name": "RecommendationEngine",
            "success": True,
            "confidence": 0.91,
            "artifacts": [
                {"type": "recommendation", "data": "ë°ì´í„° ê²€ì¦ í”„ë¡œì„¸ìŠ¤ ìë™í™”"},
                {"type": "action_plan", "data": "3ë‹¨ê³„ ê°œì„  ë¡œë“œë§µ"}
            ],
            "execution_time": 15.7,
            "metadata": {"agent_type": "recommendation", "version": "1.5"}
        }
    ]
    
    # ì‚¬ìš©ì ë° ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸
    user_context = {
        "user_id": "test_user_001",
        "role": "analyst",  # ìœ íš¨í•œ UserRole ê°’ ì‚¬ìš©
        "domain_expertise": {"manufacturing": 0.8, "data_quality": 0.7},
        "preferences": {"detail_level": "comprehensive", "visualization": True}
    }
    
    session_context = {
        "session_id": "test_session_001",
        "timestamp": time.time(),
        "context": "manufacturing_analysis"
    }
    
    print(f"ğŸ“ ì‚¬ìš©ì ì¿¼ë¦¬: {user_query}")
    print(f"ğŸ¤– A2A ì—ì´ì „íŠ¸ ê²°ê³¼: {len(mock_a2a_results)}ê°œ ì—ì´ì „íŠ¸")
    print(f"ğŸ‘¤ ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸: {user_context['role']} - {user_context['user_id']}")
    print()
    
    # Phase 3 ì „ë¬¸ê°€ê¸‰ ë‹µë³€ ìƒì„±
    start_time = time.time()
    
    try:
        expert_answer = await integration_layer.process_user_query_to_expert_answer(
            user_query=user_query,
            a2a_agent_results=mock_a2a_results,
            user_context=user_context,
            session_context=session_context
        )
        
        processing_time = time.time() - start_time
        
        print("âœ… Phase 3 Expert Answer ìƒì„± ì„±ê³µ!")
        print(f"â±ï¸  ì²˜ë¦¬ ì‹œê°„: {processing_time:.2f}ì´ˆ")
        print()
        
        # ê²°ê³¼ ë¶„ì„
        if expert_answer.get("success", False):
            print("ğŸ“Š Expert Answer ë¶„ì„:")
            print(f"   - ì‹ ë¢°ë„ ì ìˆ˜: {expert_answer.get('confidence_score', 0):.1%}")
            print(f"   - ì‚¬ìš©ëœ ì—ì´ì „íŠ¸: {expert_answer.get('metadata', {}).get('total_agents_used', 0)}ê°œ")
            print(f"   - Phase 1 ì ìˆ˜: {expert_answer.get('metadata', {}).get('phase1_score', 0):.2f}")
            print(f"   - Phase 2 í†µí•© ì ìˆ˜: {expert_answer.get('metadata', {}).get('phase2_integration_score', 0):.2f}")
            print(f"   - Phase 3 í’ˆì§ˆ ì ìˆ˜: {expert_answer.get('metadata', {}).get('phase3_quality_score', 0):.2f}")
            print()
            
            # Expert Answer Rendererë¡œ ì „ë¬¸ê°€ê¸‰ UI ìƒì„±
            print("ğŸ¨ ì „ë¬¸ê°€ê¸‰ UI ë Œë”ë§...")
            
            expert_ui = expert_renderer.render_expert_answer(expert_answer)
            
            print("âœ… Expert UI ë Œë”ë§ ì™„ë£Œ!")
            print(f"ğŸ“„ UI ì»´í¬ë„ŒíŠ¸ ì‹¤í–‰ ì„±ê³µ")
            
            # ê²°ê³¼ ì €ì¥
            result_file = f"end_to_end_test_result_{int(time.time())}.json"
            
            test_result = {
                "test_metadata": {
                    "timestamp": time.time(),
                    "user_query": user_query,
                    "processing_time": processing_time,
                    "success": True
                },
                "expert_answer": expert_answer,
                "ui_component_rendered": expert_ui is not None,
                "a2a_agents_count": len(mock_a2a_results)
            }
            
            with open(result_file, 'w', encoding='utf-8') as f:
                json.dump(test_result, f, ensure_ascii=False, indent=2, default=str)
            
            print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥: {result_file}")
            
        else:
            print("âŒ Expert Answer ìƒì„± ì‹¤íŒ¨")
            print(f"ì˜¤ë¥˜: {expert_answer.get('error', 'Unknown error')}")
            return False
            
    except Exception as e:
        print(f"âŒ End-to-End í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    print()
    print("ğŸ‰ End-to-End Phase 3 í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("=" * 60)
    
    return True


async def test_multiple_scenarios():
    """ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤ë¡œ í…ŒìŠ¤íŠ¸"""
    
    scenarios = [
        {
            "name": "ì œì¡°ì—… í’ˆì§ˆ ë¶„ì„",
            "query": "ì œì¡°ì—… ë°ì´í„°ì˜ í’ˆì§ˆ ì´ìŠˆë¥¼ ë¶„ì„í•˜ê³  ê°œì„  ë°©ì•ˆì„ ì œì‹œí•´ì£¼ì„¸ìš”",
            "role": "analyst"
        },
        {
            "name": "ê¸ˆìœµ ë¦¬ìŠ¤í¬ í‰ê°€", 
            "query": "í¬íŠ¸í´ë¦¬ì˜¤ì˜ ë¦¬ìŠ¤í¬ë¥¼ í‰ê°€í•˜ê³  ìµœì í™” ì „ëµì„ ì¶”ì²œí•´ì£¼ì„¸ìš”",
            "role": "manager"
        },
        {
            "name": "ë§ˆì¼€íŒ… ì„±ê³¼ ë¶„ì„",
            "query": "ë””ì§€í„¸ ë§ˆì¼€íŒ… ìº í˜ì¸ì˜ íš¨ê³¼ë¥¼ ë¶„ì„í•˜ê³  ROIë¥¼ ê°œì„ í•  ë°©ë²•ì„ ì°¾ì•„ì£¼ì„¸ìš”",
            "role": "executive"
        }
    ]
    
    print("ğŸ”„ ë‹¤ì¤‘ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 60)
    
    integration_layer = Phase3IntegrationLayer()
    
    for i, scenario in enumerate(scenarios, 1):
        print(f"\nğŸ“‹ ì‹œë‚˜ë¦¬ì˜¤ {i}: {scenario['name']}")
        print(f"ì¿¼ë¦¬: {scenario['query'][:50]}...")
        print(f"ì—­í• : {scenario['role']}")
        
        mock_results = [
            {
                "agent_name": f"Agent_{j}",
                "success": True,
                "confidence": 0.8 + (j * 0.05),
                "artifacts": [{"type": "analysis", "data": f"Analysis from Agent {j}"}],
                "execution_time": 5.0 + j,
                "metadata": {"agent_type": "analysis"}
            } for j in range(1, 4)
        ]
        
        user_context = {
            "user_id": f"test_user_{i:03d}",
            "role": scenario['role'],
            "domain_expertise": {"general": 0.7},
            "preferences": {}
        }
        
        try:
            result = await integration_layer.process_user_query_to_expert_answer(
                user_query=scenario['query'],
                a2a_agent_results=mock_results,
                user_context=user_context
            )
            
            if result.get("success", False):
                confidence = result.get('confidence_score', 0)
                print(f"âœ… ì„±ê³µ - ì‹ ë¢°ë„: {confidence:.1%}")
            else:
                print(f"âŒ ì‹¤íŒ¨ - {result.get('error', 'Unknown error')}")
                
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜ - {e}")
    
    print("\nğŸ¯ ë‹¤ì¤‘ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")


if __name__ == "__main__":
    print("ğŸš€ CherryAI Phase 3 End-to-End ê²€ì¦ ì‹œì‘")
    print()
    
    # ë‹¨ì¼ ìƒì„¸ í…ŒìŠ¤íŠ¸
    success = asyncio.run(test_real_user_query())
    
    if success:
        print("\n" + "="*60)
        # ë‹¤ì¤‘ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸
        asyncio.run(test_multiple_scenarios())
        
        print("\nğŸ† ëª¨ë“  End-to-End í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        print("Phase 3 Integrationì´ ì‹¤ì œ í™˜ê²½ì—ì„œ ì •ìƒ ì‘ë™í•¨ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤.")
    else:
        print("\nâš ï¸ End-to-End í…ŒìŠ¤íŠ¸ì—ì„œ ë¬¸ì œê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
        print("ë¬¸ì œë¥¼ í•´ê²°í•œ í›„ ë‹¤ì‹œ í…ŒìŠ¤íŠ¸í•´ì£¼ì„¸ìš”.") 