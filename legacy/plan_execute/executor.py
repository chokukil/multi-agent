# File: core/plan_execute/executor.py
# Location: ./core/plan_execute/executor.py

import logging
import time
import traceback
import re
import json
from typing import Dict, Any, Callable, List
from datetime import datetime
from langchain_core.messages import AIMessage, HumanMessage, ToolMessage
from ..data_manager import data_manager
from ..data_lineage import data_lineage_tracker
from ..llm_factory import get_llm_capabilities

MAX_RETRIES = 3

def should_use_tools_for_task(task_type: str, task_description: str) -> bool:
    """ì‘ì—… ìœ í˜•ê³¼ ì„¤ëª…ì„ ê¸°ë°˜ìœ¼ë¡œ ë„êµ¬ ì‚¬ìš©ì´ í•„ìš”í•œì§€ íŒë‹¨"""
    
    # ë„êµ¬ ì‚¬ìš©ì´ í•„ìˆ˜ì¸ ì‘ì—… ìœ í˜•ë“¤
    tool_required_tasks = {
        "eda", "analysis", "preprocessing", "visualization", 
        "stats", "ml", "data_check", "exploration"
    }
    
    # ë„êµ¬ ì‚¬ìš©ì´ í•„ìš”í•œ í‚¤ì›Œë“œë“¤
    tool_keywords = [
        "ë°ì´í„°", "ë¶„ì„", "ì‹œê°í™”", "í†µê³„", "ê·¸ë˜í”„", "ì°¨íŠ¸", "plot",
        "describe", "head", "info", "shape", "correlation", "ì½”ë“œ",
        "python", "pandas", "matplotlib", "seaborn", "ê³„ì‚°"
    ]
    
    # ì‘ì—… ìœ í˜• í™•ì¸
    if task_type.lower() in tool_required_tasks:
        return True
    
    # í‚¤ì›Œë“œ í™•ì¸
    task_lower = task_description.lower()
    for keyword in tool_keywords:
        if keyword in task_lower:
            return True
    
    return False

def create_enhanced_prompt_for_limited_models(task_prompt: str, tools_available: list) -> str:
    """ë„êµ¬ í˜¸ì¶œ ëŠ¥ë ¥ì´ ì œí•œì ì¸ ëª¨ë¸ì„ ìœ„í•œ ê°•í™”ëœ í”„ë¡¬í”„íŠ¸ (Few-shot ì˜ˆì œ ì¶”ê°€)"""
    
    tool_names = [tool.name if hasattr(tool, 'name') else str(tool) for tool in tools_available]
    
    # â— í•µì‹¬ ê°œì„ : ëª¨ë¸ì´ ë”°ë¼ í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì¸ ì½”ë“œ ìƒì„± ì˜ˆì œ(Few-shot) ì¶”ê°€
    enhanced_prompt = f"""
{task_prompt}

ğŸš¨ **CRITICAL INSTRUCTION: YOU MUST USE TOOLS TO COMPLETE THE TASK.**

You are required to use the available tools to answer the user's request.
Your task is to generate **only the executable Python code** for the `python_repl_ast` tool.
Do not add any explanations, markdown, or any text other than the Python code.

**AVAILABLE TOOLS:**
- `python_repl_ast`: A Python interpreter to execute code.

**EXAMPLE OF HOW TO USE THE TOOL:**

**User's Goal:** "Show me the first 5 rows of the dataset."
**Your 'python_repl_ast' input (This is what you should generate):**
```python
df = get_current_data()
df.head()
```

**User's Goal:** "Calculate the correlation matrix."
**Your 'python_repl_ast' input (This is what you should generate):**
```python
df = get_current_data()
df.corr()
```

**FORBIDDEN ACTIONS:**
- âŒ Do NOT write plain text answers.
- âŒ Do NOT explain the code.
- âŒ Do NOT write markdown like `python` at the start of your code.
- âŒ Do NOT use "TASK COMPLETED" before you have successfully executed the code.

Now, based on the user's goal, generate the Python code to be executed in the `python_repl_ast` tool.
"""
    
    return enhanced_prompt.strip()

def detect_premature_completion(response_content: str, tools_used: bool, task_needs_tools: bool) -> bool:
    """ì¡°ê¸° ì™„ë£Œ ê°ì§€ - ë„êµ¬ ì‚¬ìš© ì—†ì´ íƒœìŠ¤í¬ ì™„ë£Œë¥¼ ì‹œë„í•˜ëŠ”ì§€ í™•ì¸"""
    
    # "TASK COMPLETED"ê°€ ìˆê³  ë„êµ¬ê°€ í•„ìš”í•œë° ì‚¬ìš©ë˜ì§€ ì•Šì•˜ë‹¤ë©´ ì¡°ê¸° ì™„ë£Œ
    has_completion_marker = "TASK COMPLETED:" in response_content
    
    if has_completion_marker and task_needs_tools and not tools_used:
        return True
    
    # ê°€ì„¤ì  ë˜ëŠ” ì˜ˆì‹œ ê²°ê³¼ë¥¼ ì œê³µí•˜ëŠ” íŒ¨í„´ ê°ì§€
    premature_patterns = [
        "would show", "would reveal", "might include", "could be",
        "ì˜ˆë¥¼ ë“¤ì–´", "ê°€ì •í•˜ë©´", "ì¼ë°˜ì ìœ¼ë¡œ", "ë³´í†µ", "ëŒ€ëµ",
        "sample output", "example result", "hypothetical"
    ]
    
    response_lower = response_content.lower()
    for pattern in premature_patterns:
        if pattern in response_lower and has_completion_marker:
            return True
    
    return False

def _parse_ollama_tool_calls(response_content: str) -> List[Dict[str, Any]]:
    """Ollamaì˜ ë¹„í‘œì¤€ ë„êµ¬ í˜¸ì¶œ ë¬¸ìì—´ì—ì„œ JSON ê°ì²´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    # ì˜ˆì‹œ: {"name": "tool1", "arguments": {..}}{"name": "tool2", "arguments": {..}}
    # ìœ„ì™€ ê°™ì€ í˜•ì‹ì„ íŒŒì‹±í•˜ê¸° ìœ„í•´ ì •ê·œí‘œí˜„ì‹ ì‚¬ìš©
    try:
        # JSON ê°ì²´ë¥¼ ì°¾ëŠ” ì •ê·œí‘œí˜„ì‹
        json_pattern = re.compile(r'(\{.*?\})', re.DOTALL)
        matches = json_pattern.findall(response_content)
        
        tool_calls = []
        for match in matches:
            try:
                # ì°¾ì€ ë¬¸ìì—´ì´ ìœ íš¨í•œ JSONì¸ì§€ í™•ì¸
                tool_call = json.loads(match)
                # í•„ìš”í•œ í•„ë“œ(name, arguments)ê°€ ìˆëŠ”ì§€ í™•ì¸
                if 'name' in tool_call and 'arguments' in tool_call:
                    tool_calls.append(tool_call)
            except json.JSONDecodeError:
                # ìœ íš¨í•˜ì§€ ì•Šì€ JSONì€ ë¬´ì‹œ
                continue
        return tool_calls
    except Exception as e:
        logging.error(f"Error parsing Ollama tool calls: {e}")
        return []

def create_executor_node(agent: Any, name: str):
    """ë°ì´í„° ì¶”ì  ê¸°ëŠ¥ì´ í¬í•¨ëœ Executor ë…¸ë“œ ìƒì„±"""
    
    def executor_node(state: Dict) -> Dict:
        logging.info(f"ğŸš€ Executing {name}...")
        
        # ğŸ†• ë¬´í•œ ë£¨í”„ ë°©ì§€: ë™ì¼ ì—ì´ì „íŠ¸ì˜ ì—°ì† ì‹¤í–‰ íšŸìˆ˜ ì²´í¬
        execution_history = state.get("execution_history", [])
        recent_executions = [exec_record for exec_record in execution_history[-10:] if exec_record.get("agent") == name]
        
        if len(recent_executions) >= 3:
            logging.warning(f"âš ï¸ Agent {name} has executed {len(recent_executions)} times recently. Skipping to prevent loop.")
            return {
                "messages": state["messages"] + [
                    AIMessage(content=f"TASK COMPLETED: {name} execution limit reached to prevent infinite loop.", name=name)
                ],
                "execution_history": execution_history + [{
                    "agent": name,
                    "timestamp": time.time(),
                    "status": "skipped_limit_reached"
                }]
            }
        
        start_time = time.time()
        
        # í˜„ì¬ ë‹¨ê³„ ì •ë³´
        current_step = state.get("current_step", 0)
        plan = state.get("plan", [])
        
        # ğŸ†• LLM ëŠ¥ë ¥ ë¶„ì„
        llm = getattr(agent, 'llm', None) or getattr(agent, 'runnable', {}).get('model', None)
        llm_capabilities = {}
        if llm:
            llm_capabilities = get_llm_capabilities(llm)
            logging.info(f"ğŸ” LLM Capabilities: {llm_capabilities}")
        
        # ğŸ†• í˜„ì¬ ì‘ì—…ì´ ë„êµ¬ ì‚¬ìš©ì„ í•„ìš”ë¡œ í•˜ëŠ”ì§€ í™•ì¸
        current_task_info = plan[current_step] if current_step < len(plan) else {}
        task_type = current_task_info.get("type", "eda")
        task_description = current_task_info.get("task", "")
        task_needs_tools = should_use_tools_for_task(task_type, task_description)
        
        logging.info(f"ğŸ” Task analysis - Type: {task_type}, Needs tools: {task_needs_tools}")
        
        # ë°ì´í„° ì¶”ì  - ì‹¤í–‰ ì „
        data_before = None
        data_hash_before = None
        if data_manager.is_data_loaded():
            data_before = data_manager.get_data()
            data_hash_before = data_lineage_tracker._compute_hash(data_before)
            logging.info(f"Data hash before execution: {data_hash_before}")
        
        # Agent ì‹¤í–‰
        try:
            # ğŸ’¡ ìˆ˜ì •: ë¼ìš°í„°ì˜ êµ¬ì²´ì ì¸ ì§€ì‹œì‚¬í•­ì„ í¬í•¨í•˜ì—¬ ì—ì´ì „íŠ¸ í˜¸ì¶œ
            messages_for_agent = list(state["messages"])
            task_prompt = state.get("current_task_prompt")
            
            # ğŸ’¡ [í•µì‹¬ ê°œì„ ] ì—ì´ì „íŠ¸ê°€ ì‹¤ì œë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡ì„ í”„ë¡¬í”„íŠ¸ì— ëª…ì‹œì ìœ¼ë¡œ ì£¼ì…
            available_tools = getattr(agent, 'tools', [])
            tool_names = [tool.name for tool in available_tools]
            
            if task_prompt:
                # ë„êµ¬ ëª©ë¡ ì •ë³´ë¥¼ ê¸°ì¡´ í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€
                tool_list_prompt = f"\n\n**AVAILABLE TOOLS:**\nYou have access to the following tools: {', '.join(tool_names)}\nUse them to complete your task."
                enhanced_task_prompt = task_prompt + tool_list_prompt
                
                # Ollama ëª¨ë¸ì˜ ë„êµ¬ í˜¸ì¶œ ëŠ¥ë ¥ì´ ì œí•œì ì¸ ê²½ìš° í”„ë¡¬í”„íŠ¸ ê°•í™”
                if (llm_capabilities.get("provider") == "OLLAMA" and 
                    not llm_capabilities.get("tool_calling_capable", True) and
                    task_needs_tools):
                    
                    logging.warning(f"ğŸ”§ Enhanced prompting for limited Ollama model: {llm_capabilities.get('model_name', 'unknown')}")
                    # create_enhanced_prompt_for_limited_modelsëŠ” ì´ì œ ì‚¬ìš©ë˜ì§€ ì•Šì„ ê°€ëŠ¥ì„±ì´ ë†’ì§€ë§Œ, í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€
                    final_prompt = create_enhanced_prompt_for_limited_models(enhanced_task_prompt, available_tools)
                else:
                    final_prompt = enhanced_task_prompt

                messages_for_agent.append(HumanMessage(content=final_prompt, name="Router_Instruction"))
            
            result = agent.invoke({"messages": messages_for_agent})
            
            # --- ğŸ’¡ Ollama ì‘ë‹µ í›„ì²˜ë¦¬ ë¡œì§ ---
            if (llm_capabilities.get("provider") == "OLLAMA" and 
                result.get("messages") and 
                isinstance(result["messages"][-1], AIMessage)):
                
                last_message = result["messages"][-1]
                # tool_callsê°€ ë¹„ì–´ìˆê³ , contentì— JSONê°™ì€ ë¬¸ìì—´ì´ ìˆë‹¤ë©´ íŒŒì‹± ì‹œë„
                if not last_message.tool_calls and isinstance(last_message.content, str) and '{' in last_message.content:
                    logging.info("Ollama response has no tool_calls, attempting to parse from content.")
                    parsed_tool_calls = _parse_ollama_tool_calls(last_message.content)
                    
                    if parsed_tool_calls:
                        logging.info(f"Successfully parsed {len(parsed_tool_calls)} tool calls from content.")
                        # LangChainì´ ê¸°ëŒ€í•˜ëŠ” í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                        last_message.tool_calls = [
                            {
                                "name": tc["name"],
                                "args": tc["arguments"],
                                "id": f"call_{i}" # ì„ì˜ì˜ ID ìƒì„±
                            }
                            for i, tc in enumerate(parsed_tool_calls)
                        ]
                        # ì›ë³¸ contentëŠ” ì •ë¦¬
                        last_message.content = ""

            execution_time = time.time() - start_time
            
            # ğŸ†• ì‹¤í–‰ ê¸°ë¡ ì¶”ê°€
            execution_record = {
                "agent": name,
                "timestamp": time.time(),
                "execution_time": execution_time,
                "status": "completed"
            }
            
            # ğŸ†• ë„êµ¬ ì‚¬ìš© ì—¬ë¶€ í™•ì¸
            tools_used = False
            if result.get("messages"):
                for msg in result["messages"]:
                    if hasattr(msg, 'tool_calls') and msg.tool_calls:
                        tools_used = True
                        break
                    # ë©”ì‹œì§€ ë‚´ìš©ì—ì„œ ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ í™•ì¸
                    if hasattr(msg, 'content') and any(indicator in msg.content for indicator in [
                        "python_repl_ast", "Tool executed", "Analysis result", "```python", "df.head()", "df.describe()"
                    ]):
                        tools_used = True
                        break
            
            logging.info(f"ğŸ” Tools used in this execution: {tools_used}")
            
            # --- ğŸ›¡ï¸ ê°€ë“œë ˆì¼: LLM ì¶œë ¥ ê²€ì¦ ë° êµì • ---
            if result.get("messages"):
                last_message = result["messages"][-1]
                response_content = last_message.content
                
                # ğŸ†• ì¡°ê¸° ì™„ë£Œ ê°ì§€
                premature_completion = detect_premature_completion(response_content, tools_used, task_needs_tools)
                
                if premature_completion:
                    logging.warning(f"ğŸš¨ Premature completion detected! Task needs tools but none were used.")
                    
                    # ë„êµ¬ ì‚¬ìš©ì„ ê°•ì œí•˜ëŠ” ì¬ì§€ì‹œ ë©”ì‹œì§€ ìƒì„±
                    retry_message = f"""
âš ï¸ **Task Incomplete - Tool Usage Required**

Your previous response attempted to complete the task without using available tools. This is not acceptable.

**Required Action:** You MUST use the available tools to actually perform the analysis.

**Available Tools:** {', '.join([tool.name if hasattr(tool, 'name') else str(tool) for tool in getattr(agent, 'tools', [])])}

**Original Task:** {task_description}

Please start over and use tools to complete this task properly. Do not provide hypothetical results.
"""
                    
                    # ì¬ì‹œë„ ìƒíƒœë¡œ ì„¤ì •
                    state["last_error"] = "Agent attempted to complete task without using required tools."
                    state["next_action"] = "replan"
                    
                    return {
                        "messages": state["messages"] + [
                            AIMessage(content=retry_message, name=name)
                        ],
                        "execution_history": execution_history + [{
                            "agent": name,
                            "timestamp": time.time(),
                            "status": "retry_required",
                            "reason": "premature_completion"
                        }]
                    }
                
                # ì •ìƒì ì¸ ì™„ë£Œ ì²˜ë¦¬
                if isinstance(last_message, AIMessage) and "TASK COMPLETED:" in response_content:
                    logging.info("ğŸ›¡ï¸ Guardrail: 'TASK COMPLETED' detected. Sanitizing final message...")
                    # tool_callsê°€ ìˆë”ë¼ë„ ê°•ì œë¡œ ì œê±°í•˜ê³  ìˆœìˆ˜ contentë§Œ ë‚¨ê¹ë‹ˆë‹¤.
                    clean_message = AIMessage(content=response_content, tool_calls=[])
                    result["messages"][-1] = clean_message
                    logging.info("âœ… Final message sanitized. Removed any lingering tool_calls.")

            # ì„±ê³µ ì‹œ, ì˜¤ë¥˜ ìƒíƒœ ì´ˆê¸°í™”
            state["last_error"] = None
            if "step_retries" not in state:
                state["step_retries"] = {}
            state["step_retries"][current_step] = 0

            # ê²°ê³¼ ì¶”ì¶œ
            if result.get("messages"):
                response_content = result["messages"][-1].content
                
                # ë°ì´í„° ì¶”ì  - ì‹¤í–‰ í›„
                if data_manager.is_data_loaded():
                    data_after = data_manager.get_data()
                    data_hash_after = data_lineage_tracker._compute_hash(data_after)
                    
                    # ë°ì´í„° ë³€ê²½ì´ ìˆì—ˆë‹¤ë©´ ì¶”ì 
                    if data_hash_before != data_hash_after:
                        transformation = data_lineage_tracker.track_transformation(
                            executor_name=name,
                            operation=plan[current_step]["type"] if current_step < len(plan) else "unknown",
                            current_data=data_after,
                            description=f"Task: {plan[current_step]['task'] if current_step < len(plan) else 'Unknown task'}"
                        )
                        
                        logging.info(f"Data transformation tracked: {transformation['changes']}")
                        
                        # ìƒíƒœì— ì¶”ê°€
                        if "data_lineage" not in state:
                            state["data_lineage"] = []
                        state["data_lineage"].append(transformation)
                
                # ì‘ì—… ì™„ë£Œ í™•ì¸
                task_completed = "TASK COMPLETED:" in response_content
                
                # ğŸ”¥ ë””ë²„ê¹… ê°•í™”: ì‘ì—… ì™„ë£Œ ê°ì§€ ë¡œê¹…
                logging.info(f"ğŸ” Response content preview: {response_content[:200]}...")
                logging.info(f"ğŸ” Task completed detected: {task_completed}")
                logging.info(f"ğŸ” Tools used: {tools_used}")
                logging.info(f"ğŸ” Task needs tools: {task_needs_tools}")
                
                # ê²°ê³¼ ì €ì¥
                if "step_results" not in state:
                    state["step_results"] = {}
                
                state["step_results"][current_step] = {
                    "executor": name,
                    "task": plan[current_step]["task"] if current_step < len(plan) else "Unknown",
                    "completed": task_completed,
                    "tools_used": tools_used,
                    "task_needs_tools": task_needs_tools,
                    "execution_time": execution_time,
                    "timestamp": datetime.now().isoformat(),
                    "summary": response_content.split("TASK COMPLETED:")[-1].strip() if task_completed else "In progress",
                    "llm_capabilities": llm_capabilities
                }
                
                # ğŸ”¥ ë””ë²„ê¹… ê°•í™”: ìƒíƒœ ì •ë³´ ë¡œê¹…
                logging.info(f"ğŸ” Current step: {current_step}, Plan length: {len(plan)}")
                logging.info(f"ğŸ” Step result saved: {state['step_results'][current_step]}")
                
                # ì‘ë‹µ ë©”ì‹œì§€ ì¶”ê°€
                state["messages"].append(
                    AIMessage(content=response_content, name=name)
                )
                
                # ğŸ”¥ í•µì‹¬ ìˆ˜ì •: ì‘ì—… ì™„ë£Œ ì‹œ ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰
                if task_completed:
                    # ë‹¤ìŒ ë‹¨ê³„ë¡œ ì´ë™
                    old_step = current_step
                    state["current_step"] = current_step + 1
                    
                    # ğŸ”¥ ë””ë²„ê¹… ê°•í™”: ë‹¨ê³„ ì§„í–‰ ë¡œê¹…
                    logging.info(f"ğŸ”„ Step progression: {old_step} â†’ {state['current_step']}")
                    
                    # ëª¨ë“  ë‹¨ê³„ê°€ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸
                    if state["current_step"] >= len(plan):
                        logging.info(f"ğŸ¯ All steps completed! Current step: {state['current_step']}, Plan length: {len(plan)}")
                        logging.info(f"ğŸ¯ Setting next_action to final_responder")
                        state["next_action"] = "final_responder"
                    else:
                        logging.info(f"ğŸ”„ Step {old_step + 1} completed. Moving to step {state['current_step'] + 1}")
                        logging.info(f"ğŸ“Š Progress: {state['current_step']}/{len(plan)} steps completed")
                        state["next_action"] = "replan"
                else:
                    # ì‘ì—…ì´ ì™„ë£Œë˜ì§€ ì•Šì€ ê²½ìš° ì¬ê³„íš
                    logging.warning(f"âš ï¸ Task not completed. Response: {response_content[:200]}...")
                    logging.warning(f"âš ï¸ Replanning step {current_step + 1}")
                    state["next_action"] = "replan"
                
                # ğŸ”¥ ë””ë²„ê¹… ê°•í™”: ìµœì¢… ìƒíƒœ ë¡œê¹…
                logging.info(f"ğŸ” Final executor state - next_action: {state.get('next_action')}")
                logging.info(f"ğŸ” Final executor state - current_step: {state.get('current_step')}")
                
                logging.info(f"âœ… {name} completed in {execution_time:.2f}s")
                
                return {
                    "messages": state["messages"] + [result["messages"][-1]],
                    "execution_history": execution_history + [execution_record]
                }
                
            else:
                logging.error(f"No messages in agent result")
                state["last_error"] = "Agent did not return any messages."
                state["next_action"] = "replan"
                
        except Exception as e:
            error_trace = traceback.format_exc()
            logging.error(f"Error in executor {name}: {e}\n{error_trace}")

            # ì¬ì‹œë„ íšŸìˆ˜ ê´€ë¦¬
            if "step_retries" not in state:
                state["step_retries"] = {}
            
            retry_count = state["step_retries"].get(current_step, 0) + 1
            state["step_retries"][current_step] = retry_count
            
            # ë§ˆì§€ë§‰ ì˜¤ë¥˜ ìƒíƒœ ì—…ë°ì´íŠ¸
            state["last_error"] = f"Executor {name} failed on step {current_step} with error: {e}\n\nTraceback:\n{error_trace}"

            # ì—ëŸ¬ ê²°ê³¼ ì €ì¥
            if "step_results" not in state:
                state["step_results"] = {}
                
            state["step_results"][current_step] = {
                "executor": name,
                "task": plan[current_step]["task"] if current_step < len(plan) else "Unknown",
                "completed": False,
                "error": str(e),
                "traceback": error_trace,
                "retries": retry_count,
                "timestamp": datetime.now().isoformat()
            }
            
            # ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ í™•ì¸
            if retry_count >= MAX_RETRIES:
                logging.error(f"Executor {name} failed after {MAX_RETRIES} retries. Finalizing.")
                state["next_action"] = "final_responder"
                error_message = f"""âŒ Task failed after multiple retries.
Error: {str(e)}
Full Traceback:
{error_trace}

The system will now move to final response with current progress."""
            else:
                state["next_action"] = "replan"
                error_message = f"""âŒ An error occurred during task execution. Please analyze the error and modify your approach.
Retry attempt {retry_count}/{MAX_RETRIES}.

Error: {str(e)}

Full Traceback:
{error_trace}
"""

            # ì—ëŸ¬ ë©”ì‹œì§€ ì¶”ê°€ (Agentì—ê²Œ context ì œê³µ)
            state["messages"].append(
                AIMessage(
                    content=error_message,
                    name=name
                )
            )
            
            return {
                "messages": state["messages"] + [
                    AIMessage(content=error_message, name=name)
                ],
                "execution_history": execution_history + [{
                    "agent": name,
                    "timestamp": time.time(),
                    "status": "failed",
                    "error": str(e),
                    "traceback": error_trace
                }]
            }
        
        return executor_node
    
    return executor_node