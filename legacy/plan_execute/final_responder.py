# File: core/plan_execute/final_responder.py
# Location: ./core/plan_execute/final_responder.py

import logging
from typing import Dict, List
from langchain_core.messages import AIMessage, SystemMessage, HumanMessage
from langchain_core.prompts import ChatPromptTemplate
from ..llm_factory import create_llm_instance
from ..data_lineage import data_lineage_tracker
from datetime import datetime
import json
import traceback
import streamlit as st

def create_final_response_prompt():
    """ìµœì¢… ì‘ë‹µ ìƒì„±ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ (ê°•í™” ë²„ì „)"""
    return ChatPromptTemplate.from_template("""You are a senior data analyst creating a final summary report for a user.
Your main goal is to synthesize all the work done and present it clearly and concisely.

**User's Initial Request**:
---
{user_request}
---

**Data Validation Summary**:
---
{data_validation}
---

**Summary of All Completed Steps & Key Findings**:
---
{task_results}
---

**Critically Important Instructions**:
1.  **Synthesize, Don't Just List**: Do not just list the steps. Integrate the findings into a coherent narrative that directly answers the user's request.
2.  **Focus on the Goal**: Always keep the user's initial request in mind and structure the report to answer it.
3.  **Acknowledge Artifacts**: Mention that detailed results, visualizations, and data are available as 'Artifacts' that the user can review.
4.  **Be Honest About Failures**: If any steps failed, briefly mention them and their potential impact.
5.  **Clarity is Key**: Use markdown for clear formatting (headings, lists, bold text).
6.  **MANDATORY**: Even if the detailed results are sparse or incomplete, you MUST provide a summary based on the user's request and what was successfully completed. NEVER return an empty or incomplete response.

Now, generate a comprehensive, well-structured final report in Korean.
""").with_fallbacks([
        ChatPromptTemplate.from_template("""Generate a brief summary in Korean stating that the analysis for the request "{user_request}" is complete. Mention that the results can be found in the artifact panel.""")
    ])

def format_task_results(step_results: Dict, max_len: int = 4000) -> str:
    """ì‘ì—… ê²°ê³¼ë¥¼ í¬ë§·íŒ…í•˜ê³  ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤."""
    formatted_str = ""
    
    # Sort by step number
    sorted_steps = sorted(step_results.items())

    for step, result in sorted_steps:
        task_summary = f"\n**Step {step + 1}: {result.get('task', 'Unknown Task')}**\n"
        task_summary += f"- Executor: {result.get('executor', 'Unknown')}\n"
        
        if result.get('completed'):
            task_summary += f"- Status: âœ… Completed\n"
            summary = result.get('summary', 'No summary available.')
            # Truncate long summaries
            if len(summary) > 300:
                summary = summary[:150] + "..." + summary[-150:]
            task_summary += f"- Summary: {summary}\n"
        else:
            task_summary += f"- Status: âŒ Failed\n"
            error = result.get('error', 'An unknown error occurred.')
            task_summary += f"- Error: {error}\n"

        # Prevent exceeding max length
        if len(formatted_str) + len(task_summary) > max_len:
            formatted_str += "\n... (some steps were omitted to fit context length) ..."
            break
        
        formatted_str += task_summary
            
    return formatted_str if formatted_str else "No task results were recorded."

def format_data_validation(state: Dict) -> str:
    """ë°ì´í„° ê²€ì¦ ê²°ê³¼ í¬ë§·íŒ…"""
    lineage_summary = data_lineage_tracker.get_lineage_summary()
    
    validation_text = "## ğŸ” Data Integrity Check\n\n"
    
    # ì›ë³¸ ë°ì´í„° ì‚¬ìš© í™•ì¸
    if lineage_summary.get("original_data"):
        validation_text += "âœ… **SSOT Original Data Used**: Confirmed\n"
        validation_text += f"- Original Shape: {lineage_summary['original_data']['shape']}\n"
        validation_text += f"- Final Shape: {lineage_summary['final_data']['shape']}\n"
    else:
        validation_text += "âš ï¸ **Warning**: No data lineage tracked\n"
    
    # ë³€í™˜ ì´ë ¥
    if lineage_summary.get("total_transformations", 0) > 0:
        validation_text += f"\n**Data Transformations**: {lineage_summary['total_transformations']} operations\n"
        validation_text += f"**Executors Involved**: {', '.join(lineage_summary['executors_involved'])}\n"
    
    # ì˜ì‹¬ìŠ¤ëŸ¬ìš´ íŒ¨í„´
    suspicious = lineage_summary.get("suspicious_patterns", [])
    if suspicious:
        validation_text += "\nâš ï¸ **Suspicious Patterns Detected**:\n"
        for pattern in suspicious:
            validation_text += f"- {pattern['description']} (by {pattern['executor']})\n"
    else:
        validation_text += "\nâœ… **Data Consistency**: No suspicious patterns detected\n"
    
    # ë°ì´í„° ê³„ë³´ ìƒì„¸
    if "data_lineage" in state and state["data_lineage"]:
        validation_text += "\n**Data Lineage**:\n"
        for transform in state["data_lineage"]:
            validation_text += f"- {transform['executor']}: {transform['description']}\n"
            changes = transform.get('changes', {})
            if changes.get('rows_changed', 0) != 0:
                validation_text += f"  - Rows: {changes['rows_changed']:+d}\n"
            if changes.get('cols_changed', 0) != 0:
                validation_text += f"  - Columns: {changes['cols_changed']:+d}\n"
    
    return validation_text

def final_responder_node(state: Dict) -> Dict:
    """ëª¨ë“  ì‘ì—…ì„ ì¢…í•©í•˜ì—¬ ìµœì¢… ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ë…¸ë“œ"""
    logging.info("ğŸ¯ Final Responder: Starting comprehensive response generation")
    
    try:
        plan = state.get("plan", [])
        step_results = state.get("step_results", {})
        user_request = ""
        
        # ì‚¬ìš©ì ìš”ì²­ ì¶”ì¶œ
        messages = state.get("messages", [])
        for msg in messages:
            if hasattr(msg, "type") and msg.type == "human":
                user_request = msg.content
                break
        
        logging.info(f"ğŸ“‹ Generating final response for {len(plan)} planned steps")
        logging.info(f"ğŸ“Š Step results available: {list(step_results.keys())}")
        
        # ì™„ë£Œëœ ë‹¨ê³„ë“¤ ì •ë¦¬
        completed_steps = []
        for step_num, result in step_results.items():
            if result.get("completed", False):
                completed_steps.append({
                    "step": step_num + 1,
                    "task": result.get("task", "Unknown task"),
                    "executor": result.get("executor", "Unknown"),
                    "summary": result.get("summary", "No summary available"),
                    "execution_time": result.get("execution_time", 0)
                })
        
        logging.info(f"âœ… {len(completed_steps)} steps completed successfully")
        
        # ë°ì´í„° ì •ë³´ ìˆ˜ì§‘
        data_info = ""
        try:
            from core.data_manager import data_manager
            if data_manager.is_data_loaded():
                try:
                    df = data_manager.get_data()
                    data_info = f"Dataset: {df.shape[0]} rows Ã— {df.shape[1]} columns"
                    logging.info(f"ğŸ“Š Data info: {data_info}")
                except Exception as e:
                    logging.warning(f"Could not get data info: {e}")
                    data_info = "Dataset information unavailable"
            else:
                data_info = "No dataset currently loaded"
        except ImportError:
            logging.warning("data_manager not available")
            data_info = "Dataset information unavailable"
        
        # ì•„í‹°íŒ©íŠ¸ ì •ë³´ ìˆ˜ì§‘
        artifacts_info = []
        try:
            from core.artifact_system import artifact_manager
            if hasattr(artifact_manager, 'list_artifacts'):
                try:
                    artifacts = artifact_manager.list_artifacts(session_id=state.get("session_id"))
                    for artifact in artifacts:
                        artifacts_info.append({
                            "id": artifact.get("id", "unknown"),
                            "type": artifact.get("type", "unknown"),
                            "title": artifact.get("title", "Untitled")
                        })
                    logging.info(f"ğŸ¨ Found {len(artifacts_info)} artifacts")
                except Exception as e:
                    logging.warning(f"Could not get artifacts: {e}")
        except ImportError:
            logging.warning("artifact_manager not available")
        
        # ì¢…í•© ì‘ë‹µ ìƒì„±
        llm = create_llm_instance(temperature=0.3)
        
        # ê°•í™”ëœ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        system_prompt = f"""You are tasked with creating a comprehensive final response that synthesizes all the work completed.

**User's Original Request:** {user_request}

**Completed Analysis Steps:**
{chr(10).join([f"{i+1}. {step['task']} (by {step['executor']}) - {step['summary']}" for i, step in enumerate(completed_steps)])}

**Data Information:** {data_info}

**Available Artifacts:** {len(artifacts_info)} artifacts created during analysis

**Instructions:**
1. Provide a clear, comprehensive summary that directly addresses the user's request
2. Highlight key findings and insights from each completed step
3. Reference any visualizations, data tables, or analysis artifacts that were created
4. Ensure your response is actionable and informative
5. Structure your response with clear headings and bullet points for readability

**Response Format:**
- Start with an executive summary
- Include key findings from the analysis
- Reference specific artifacts and results
- Conclude with actionable insights or recommendations

Generate a professional, comprehensive response that fully addresses the user's request."""

        logging.info("ğŸ¤– Generating final response with LLM")
        
        messages_for_llm = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=f"Please provide a comprehensive final response for the completed analysis.")
        ]
        
        response = llm.invoke(messages_for_llm)
        final_response = response.content if hasattr(response, 'content') else str(response)
        
        logging.info(f"âœ… Generated final response ({len(final_response)} characters)")
        
        # ì‘ë‹µì´ ë„ˆë¬´ ì§§ì€ ê²½ìš° fallback ì‘ë‹µ ìƒì„±
        if len(final_response.strip()) < 100:
            logging.warning("Generated response too short, creating fallback response")
            final_response = create_fallback_response(user_request, completed_steps, data_info, artifacts_info)
        
        # ìƒíƒœì— ìµœì¢… ì‘ë‹µ ì €ì¥
        state["final_response"] = final_response
        
        # ë©”ì‹œì§€ì— ìµœì¢… ì‘ë‹µ ì¶”ê°€
        logging.info("ğŸ“ Adding final response to messages")
        state["messages"].append(AIMessage(content=final_response, name="Final_Responder"))
        
        # ì•„í‹°íŒ©íŠ¸ë¡œ ìµœì¢… ë³´ê³ ì„œ ì €ì¥
        try:
            from core.artifact_system import artifact_manager
            
            # ì„¸ì…˜ ID ê°€ì ¸ì˜¤ê¸° (ì—¬ëŸ¬ ì†ŒìŠ¤ì—ì„œ ì‹œë„)
            session_id = (
                state.get("session_id") or 
                getattr(st.session_state, 'session_id', None) or
                getattr(st.session_state, 'thread_id', None) or
                "default-session"
            )
            
            # ìµœì¢… ë³´ê³ ì„œë¥¼ ë§ˆí¬ë‹¤ìš´ ì•„í‹°íŒ©íŠ¸ë¡œ ì €ì¥
            artifact_id = artifact_manager.create_artifact(
                content=final_response,
                artifact_type="markdown",
                title="Final Analysis Report",
                agent_name="Final_Responder",
                session_id=session_id,
                metadata={
                    "is_final_report": True,
                    "analysis_steps": len(state.get("plan", [])),
                    "completion_time": datetime.now().isoformat()
                }
            )
            logging.info(f"ğŸ’¾ Saved final report as artifact: {artifact_id} for session: {session_id}")

        except ImportError:
            logging.warning("artifact_manager not available for saving final report")
        except Exception as e:
            logging.error(f"Could not save final report as artifact: {e}\n{traceback.format_exc()}")
        
        logging.info("ğŸ‰ Final Responder completed successfully")
        return state
        
    except Exception as e:
        error_trace = traceback.format_exc()
        logging.error(f"Final Responder error: {e}\n{error_trace}")
        
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ ì‘ë‹µ ìƒì„±
        fallback_response = f"""# Analysis Summary

I encountered an error while generating the comprehensive final response: {str(e)}

However, based on the completed analysis steps, here's what was accomplished:

## Completed Tasks
{chr(10).join([f"- {result.get('task', 'Unknown task')}: {result.get('summary', 'Completed')}" for result in state.get('step_results', {}).values() if result.get('completed')])}

## Data Information
{data_info if 'data_info' in locals() else 'Dataset processed successfully'}

The analysis has been completed with the available results. Please check the artifacts panel for detailed outputs including visualizations and data tables.
"""
        
        state["final_response"] = fallback_response
        state["messages"].append(AIMessage(content=fallback_response, name="Final_Responder"))
        
        logging.info("ğŸ”„ Fallback response generated due to error")
        return state

def create_fallback_response(user_request: str, completed_steps: List[Dict], data_info: str, artifacts_info: List[Dict]) -> str:
    """ê¸°ë³¸ ì‘ë‹µ ìƒì„± (LLM ì—†ì´)"""
    response_parts = []
    
    # í—¤ë”
    response_parts.append("# ğŸ“Š ë¶„ì„ ê²°ê³¼ ì¢…í•© ë³´ê³ ì„œ")
    response_parts.append(f"**ìš”ì²­ì‚¬í•­**: {user_request}")
    response_parts.append("")
    
    # ë°ì´í„° ì •ë³´
    if data_info:
        response_parts.append("## ğŸ“‹ ë°ì´í„° ì •ë³´")
        response_parts.append(data_info)
        response_parts.append("")
    
    # ì™„ë£Œëœ ë‹¨ê³„ë“¤
    if completed_steps:
        response_parts.append("## âœ… ì™„ë£Œëœ ë¶„ì„ ë‹¨ê³„")
        for step in completed_steps:
            response_parts.append(f"### {step['step']}. {step['task']}")
            response_parts.append(f"**ë‹´ë‹¹**: {step['executor']}")
            response_parts.append(f"**ìš”ì•½**: {step['summary']}")
            if step.get('execution_time', 0) > 0:
                response_parts.append(f"**ì‹¤í–‰ ì‹œê°„**: {step['execution_time']:.2f}ì´ˆ")
            response_parts.append("")
    
    # ìƒì„±ëœ ì•„í‹°íŒ©íŠ¸
    if artifacts_info:
        response_parts.append("## ğŸ¨ ìƒì„±ëœ ì•„í‹°íŒ©íŠ¸")
        for artifact in artifacts_info:
            response_parts.append(f"- **{artifact['title']}** ({artifact['type']})")
        response_parts.append("")
        response_parts.append("ìƒì„¸ ê²°ê³¼ëŠ” ìš°ì¸¡ 'ì•„í‹°íŒ©íŠ¸' íŒ¨ë„ì—ì„œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    else:
        response_parts.append("## ğŸ¨ ê²°ê³¼ í™•ì¸")
        response_parts.append("ë¶„ì„ ê²°ê³¼ì™€ ì‹œê°í™” ìë£ŒëŠ” ìš°ì¸¡ 'ì•„í‹°íŒ©íŠ¸' íŒ¨ë„ì—ì„œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        response_parts.append("")
    
    # ë§ˆë¬´ë¦¬
    response_parts.append("## ğŸ“ ê²°ë¡ ")
    response_parts.append("ëª¨ë“  ê³„íšëœ ë¶„ì„ ë‹¨ê³„ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    # ìš”ì²­ì— ë”°ë¥¸ ë§ì¶¤í˜• ê²°ë¡  ì¶”ê°€
    if "í†µê³„" in user_request or "ê¸°ì´ˆ" in user_request:
        response_parts.append("ê¸°ì´ˆ í†µê³„ ë¶„ì„ì´ ì™„ë£Œë˜ì–´ ë°ì´í„°ì˜ ì „ë°˜ì ì¸ íŠ¹ì„±ì„ íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    elif "ì‹œê°í™”" in user_request or "ê·¸ë˜í”„" in user_request:
        response_parts.append("ë°ì´í„° ì‹œê°í™”ê°€ ì™„ë£Œë˜ì–´ íŒ¨í„´ê³¼ ì¸ì‚¬ì´íŠ¸ë¥¼ ì‹œê°ì ìœ¼ë¡œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    elif "ë¶„ì„" in user_request:
        response_parts.append("ìš”ì²­í•˜ì‹  ë¶„ì„ì´ ì™„ë£Œë˜ì–´ ë°ì´í„°ì—ì„œ ìœ ì˜ë¯¸í•œ ì¸ì‚¬ì´íŠ¸ë¥¼ ë„ì¶œí–ˆìŠµë‹ˆë‹¤.")
    
    response_parts.append("ê° ë‹¨ê³„ì˜ ìƒì„¸ ê²°ê³¼ì™€ ìƒì„±ëœ ì‹œê°í™” ìë£ŒëŠ” ì•„í‹°íŒ©íŠ¸ íŒ¨ë„ì—ì„œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    
    return "\n".join(response_parts)

def create_emergency_response(user_request: str, step_results: Dict) -> str:
    """ìµœí›„ì˜ ë¹„ìƒìš© ì‘ë‹µ ìƒì„± (ê³ ì • ë©”ì‹œì§€)"""
    completed_steps = len([r for r in step_results.values() if r.get('completed')])
    total_steps = len(step_results)

    return f"""# âœ… ë¶„ì„ ì²˜ë¦¬ ì™„ë£Œ

**ìš”ì²­ì‚¬í•­**: {user_request}

**ì²˜ë¦¬ í˜„í™©**: ì´ {total_steps}ê°œì˜ ê³„íšëœ ë‹¨ê³„ ì¤‘ {completed_steps}ê°œê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.

ë¶„ì„ ê³¼ì •ì—ì„œ ìµœì¢… ë³´ê³ ì„œë¥¼ ìƒì„±í•˜ëŠ” ë° ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ëª¨ë“  ì‘ì—…ì€ ê³„íšëŒ€ë¡œ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.

ìƒì„¸ ê²°ê³¼ëŠ” ìš°ì¸¡ì˜ **ì•„í‹°íŒ©íŠ¸ íŒ¨ë„**ì—ì„œ ì§ì ‘ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---
*ì²˜ë¦¬ ì™„ë£Œ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
"""
