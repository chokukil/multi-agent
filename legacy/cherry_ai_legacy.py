"""
ğŸ’ Cherry AI - Advanced Multi-Agent Data Analysis Platform
ChatGPT Data Analystì™€ ìœ ì‚¬í•œ ì‚¬ìš©ì ê²½í—˜ì„ ì œê³µí•˜ëŠ” A2A ê¸°ë°˜ ë©€í‹° ì—ì´ì „íŠ¸ ë°ì´í„° ë¶„ì„ í”Œë«í¼

Features:
- ChatGPT ìŠ¤íƒ€ì¼ ëŒ€í™”í˜• ì¸í„°í˜ì´ìŠ¤
- A2A í”„ë¡œí† ì½œ ê¸°ë°˜ 12ê°œ ì „ë¬¸ ì—ì´ì „íŠ¸ í˜‘ì—…
- ì‹¤ì‹œê°„ ì—ì´ì „íŠ¸ ì‘ì—… íˆ¬ëª…ì„± ì œê³µ
- ì§€ëŠ¥ì  ë¶„ì„ ì¶”ì²œ ì‹œìŠ¤í…œ
- LLM First ì›ì¹™ ê¸°ë°˜ ì„¤ê³„
"""

import streamlit as st
import asyncio
import logging
import os
import sys
from datetime import datetime
from pathlib import Path
import uuid
import traceback
import json
from typing import Dict, Any, List, Optional
import pandas as pd
import plotly.graph_objects as go

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì„¤ì •
project_root = Path(__file__).parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Cherry AI í•µì‹¬ ì»´í¬ë„ŒíŠ¸ ì„í¬íŠ¸
try:
    from core.orchestrator.a2a_orchestrator import A2AOrchestrator
    from core.orchestrator.planning_engine import PlanningEngine
    from config.agents_config import AgentConfigLoader, AgentConfig
    CORE_AVAILABLE = True
    logger.info("âœ… Cherry AI í•µì‹¬ ì»´í¬ë„ŒíŠ¸ ë¡œë“œ ì„±ê³µ")
except ImportError as e:
    CORE_AVAILABLE = False
    logger.error(f"âŒ Cherry AI í•µì‹¬ ì»´í¬ë„ŒíŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")

# Universal Engine í†µí•© ì„í¬íŠ¸
try:
    from core.universal_engine.universal_query_processor import UniversalQueryProcessor
    from core.universal_engine.dynamic_context_discovery import DynamicContextDiscovery
    UNIVERSAL_ENGINE_AVAILABLE = True
    logger.info("âœ… Universal Engine ë¡œë“œ ì„±ê³µ")
except ImportError as e:
    UNIVERSAL_ENGINE_AVAILABLE = False
    logger.warning(f"âš ï¸ Universal Engine ë¡œë“œ ì‹¤íŒ¨: {e}")

# ë ˆê±°ì‹œ ë°˜ë„ì²´ ì—”ì§„ (íê¸° ì˜ˆì •)
try:
    from services.semiconductor_domain_engine import analyze_semiconductor_data
    LEGACY_SEMICONDUCTOR_ENGINE_AVAILABLE = True
    logger.info("âœ… ë ˆê±°ì‹œ ë°˜ë„ì²´ ë„ë©”ì¸ ì—”ì§„ ë¡œë“œ ì„±ê³µ (íê¸° ì˜ˆì •)")
except ImportError as e:
    LEGACY_SEMICONDUCTOR_ENGINE_AVAILABLE = False
    logger.warning(f"âš ï¸ ë ˆê±°ì‹œ ë°˜ë„ì²´ ë„ë©”ì¸ ì—”ì§„ ë¡œë“œ ì‹¤íŒ¨: {e}")

# ê¸°ì¡´ UI ì»´í¬ë„ŒíŠ¸ ì¬í™œìš©
try:
    from ui.components.chat_interface import ChatInterface
    from ui.components.file_upload import FileUploadComponent
    from ui.thinking_stream import ThinkingStream
    from ui.advanced_artifact_renderer import AdvancedArtifactRenderer
    UI_COMPONENTS_AVAILABLE = True
    logger.info("âœ… UI ì»´í¬ë„ŒíŠ¸ ë¡œë“œ ì„±ê³µ")
except ImportError as e:
    UI_COMPONENTS_AVAILABLE = False
    logger.warning(f"âš ï¸ UI ì»´í¬ë„ŒíŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")

# ì¶”ì²œ ì‹œìŠ¤í…œ ì»´í¬ë„ŒíŠ¸
class AnalysisRecommender:
    """ì§€ëŠ¥ì  ë¶„ì„ ì¶”ì²œ ì—”ì§„"""
    
    def __init__(self):
        self.recommendation_templates = {
            'csv': [
                "ğŸ“Š ë°ì´í„° ê¸°ë³¸ ì •ë³´ ë° í†µê³„ ìš”ì•½ ë¶„ì„",
                "ğŸ“ˆ ì£¼ìš” ë³€ìˆ˜ë“¤ ê°„ì˜ ìƒê´€ê´€ê³„ ë¶„ì„",
                "ğŸ¯ ë°ì´í„° ì‹œê°í™” ë° íŒ¨í„´ íƒì§€"
            ],
            'excel': [
                "ğŸ“‹ ì—‘ì…€ ì‹œíŠ¸ë³„ ë°ì´í„° êµ¬ì¡° ë¶„ì„",
                "ğŸ“Š ë‹¤ì°¨ì› ë°ì´í„° êµì°¨ ë¶„ì„",
                "ğŸ“ˆ ì‹œíŠ¸ ê°„ ê´€ê³„ì„± ë¶„ì„"
            ],
            'timeseries': [
                "ğŸ“ˆ ì‹œê³„ì—´ íŠ¸ë Œë“œ ë° ê³„ì ˆì„± ë¶„ì„",
                "ğŸ”® ë¯¸ë˜ ê°’ ì˜ˆì¸¡ ë° ì˜ˆì¸¡ ëª¨ë¸ êµ¬ì¶•",
                "ğŸ“Š ì´ìƒì¹˜ ë° ë³€í™”ì  ê°ì§€"
            ]
        }
    
    def generate_initial_recommendations(self, data_info: Dict[str, Any]) -> List[Dict[str, str]]:
        """ë°ì´í„° ì—…ë¡œë“œ í›„ ì´ˆê¸° ì¶”ì²œ ìƒì„±"""
        recommendations = []
        
        # íŒŒì¼ ìœ í˜•ë³„ ì¶”ì²œ
        file_type = data_info.get('file_type', 'csv')
        templates = self.recommendation_templates.get(file_type, self.recommendation_templates['csv'])
        
        for i, template in enumerate(templates):
            recommendations.append({
                'id': f"rec_{i}",
                'title': template,
                'query': template.replace('ğŸ“Š', '').replace('ğŸ“ˆ', '').replace('ğŸ¯', '').replace('ğŸ“‹', '').replace('ğŸ”®', '').strip()
            })
        
        return recommendations
    
    def generate_followup_recommendations(self, analysis_result: Dict[str, Any]) -> List[Dict[str, str]]:
        """ë¶„ì„ ì™„ë£Œ í›„ í›„ì† ì¶”ì²œ ìƒì„±"""
        recommendations = [
            {
                'id': 'followup_1',
                'title': 'ğŸ” ë” ìì„¸í•œ í†µê³„ì  ë¶„ì„ ìˆ˜í–‰',
                'query': 'ì´ ë°ì´í„°ì— ëŒ€í•´ ë” ìì„¸í•œ í†µê³„ì  ë¶„ì„ì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”'
            },
            {
                'id': 'followup_2', 
                'title': 'ğŸ¤– ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ êµ¬ì¶• ì‹œë„',
                'query': 'ì´ ë°ì´í„°ë¡œ ì˜ˆì¸¡ ëª¨ë¸ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”'
            },
            {
                'id': 'followup_3',
                'title': 'ğŸ“Š ë‹¤ë¥¸ ê´€ì ì˜ ì‹œê°í™” ìƒì„±',
                'query': 'ë‹¤ë¥¸ ê´€ì ì—ì„œ ì´ ë°ì´í„°ë¥¼ ì‹œê°í™”í•´ì£¼ì„¸ìš”'
            }
        ]
        
        return recommendations

class AgentDashboard:
    """ì—ì´ì „íŠ¸ ìƒíƒœ ëŒ€ì‹œë³´ë“œ"""
    
    @staticmethod
    def render_agent_status_grid(agents_status: Dict[str, Any]):
        """ì—ì´ì „íŠ¸ ìƒíƒœ ê·¸ë¦¬ë“œ ë Œë”ë§"""
        if not agents_status:
            st.info("ğŸ” ì—ì´ì „íŠ¸ ìƒíƒœë¥¼ í™•ì¸í•˜ëŠ” ì¤‘...")
            return
        
        # ìƒíƒœë³„ ìƒ‰ìƒ ë§¤í•‘
        status_colors = {
            'online': 'ğŸŸ¢',
            'offline': 'ğŸ”´', 
            'error': 'ğŸŸ¡',
            'unknown': 'âšª'
        }
        
        cols = st.columns(4)
        for i, (agent_id, status) in enumerate(agents_status.items()):
            with cols[i % 4]:
                status_icon = status_colors.get(status.get('status', 'unknown'), 'âšª')
                st.metric(
                    label=f"{status_icon} {status.get('name', agent_id)}",
                    value=status.get('status', 'unknown').upper(),
                    help=status.get('description', '')
                )

class CherryAI:
    """Cherry AI ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.orchestrator = None
        self.planning_engine = None
        self.agent_loader = None
        self.recommender = AnalysisRecommender()
        self.session_id = None
        
        # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
        if 'cherry_ai_initialized' not in st.session_state:
            st.session_state.cherry_ai_initialized = False
            st.session_state.messages = []
            st.session_state.current_data = None
            st.session_state.analysis_history = []
            st.session_state.recommendations = []
            st.session_state.show_agent_details = False
            st.session_state.current_execution = None
    
    async def initialize(self):
        """Cherry AI ì´ˆê¸°í™”"""
        try:
            if not CORE_AVAILABLE:
                st.error("âŒ Cherry AI í•µì‹¬ ì»´í¬ë„ŒíŠ¸ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return False
            
            # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
            self.orchestrator = A2AOrchestrator()
            self.planning_engine = PlanningEngine()
            self.agent_loader = AgentConfigLoader()
            
            # ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì´ˆê¸°í™”
            await self.orchestrator.initialize()
            
            # ì„¸ì…˜ ID ìƒì„±
            self.session_id = f"cherry_ai_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{str(uuid.uuid4())[:8]}"
            
            st.session_state.cherry_ai_initialized = True
            logger.info(f"Cherry AI ì´ˆê¸°í™” ì™„ë£Œ - Session: {self.session_id}")
            
            return True
            
        except Exception as e:
            logger.error(f"Cherry AI ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            st.error(f"âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
            return False
    
    def render_header(self):
        """í—¤ë” ë Œë”ë§"""
        st.set_page_config(
            page_title="Cherry AI - Multi-Agent Data Analysis",
            page_icon="ğŸ’",
            layout="wide",
            initial_sidebar_state="expanded"
        )
        
        # ì»¤ìŠ¤í…€ CSS
        st.markdown("""
        <style>
        .main-header {
            background: linear-gradient(90deg, #FF6B6B, #4ECDC4);
            padding: 1rem;
            border-radius: 10px;
            margin-bottom: 2rem;
            text-align: center;
            color: white;
        }
        .agent-card {
            background: #f8f9fa;
            padding: 1rem;
            border-radius: 8px;
            margin: 0.5rem 0;
            border-left: 4px solid #4ECDC4;
        }
        .recommendation-button {
            background: #e3f2fd;
            border: 1px solid #2196f3;
            border-radius: 20px;
            padding: 0.5rem 1rem;
            margin: 0.25rem;
            cursor: pointer;
            transition: all 0.3s;
        }
        .chat-message {
            padding: 1rem;
            margin: 0.5rem 0;
            border-radius: 10px;
        }
        .user-message {
            background: #e3f2fd;
            margin-left: 20%;
        }
        .assistant-message {
            background: #f1f8e9;
            margin-right: 20%;
        }
        </style>
        """, unsafe_allow_html=True)
        
        # ë©”ì¸ í—¤ë”
        st.markdown("""
        <div class="main-header">
            <h1>ğŸ’ Cherry AI</h1>
            <p>Advanced Multi-Agent Data Analysis Platform</p>
        </div>
        """, unsafe_allow_html=True)
    
    def render_sidebar(self):
        """ì‚¬ì´ë“œë°” ë Œë”ë§"""
        with st.sidebar:
            st.header("ğŸ”§ ì‹œìŠ¤í…œ ìƒíƒœ")
            
            # ì—ì´ì „íŠ¸ ìƒíƒœ ìš”ì•½
            if self.orchestrator:
                with st.expander("ğŸ¤– ì—ì´ì „íŠ¸ ìƒíƒœ", expanded=True):
                    # ì—ì´ì „íŠ¸ ìƒíƒœ í™•ì¸ ë²„íŠ¼
                    if st.button("ğŸ”„ ìƒíƒœ ìƒˆë¡œê³ ì¹¨"):
                        st.rerun()
                    
                    # ê°„ë‹¨í•œ ìƒíƒœ í‘œì‹œ
                    agents_config = self.agent_loader.get_all_agents()
                    for agent_id, config in agents_config.items():
                        status = "ğŸŸ¢ ì˜¨ë¼ì¸" if config.enabled else "ğŸ”´ ì˜¤í”„ë¼ì¸"
                        st.text(f"{config.name}: {status}")
            
            st.divider()
            
            # ì„¤ì • ì„¹ì…˜
            st.header("âš™ï¸ ì„¤ì •")
            
            show_details = st.checkbox("ğŸ” ì—ì´ì „íŠ¸ ì‘ì—… ìƒì„¸ ë³´ê¸°", value=st.session_state.show_agent_details)
            st.session_state.show_agent_details = show_details
            
            # ì„¸ì…˜ ì •ë³´
            st.header("ğŸ“Š ì„¸ì…˜ ì •ë³´")
            if self.session_id:
                st.text(f"ì„¸ì…˜ ID: {self.session_id[-8:]}")
            st.text(f"ë©”ì‹œì§€ ìˆ˜: {len(st.session_state.messages)}")
            
            # ì´ˆê¸°í™” ë²„íŠ¼
            if st.button("ğŸ—‘ï¸ ì„¸ì…˜ ì´ˆê¸°í™”"):
                for key in list(st.session_state.keys()):
                    if key.startswith('cherry_ai') or key in ['messages', 'current_data', 'analysis_history', 'recommendations']:
                        del st.session_state[key]
                st.rerun()
    
    def render_file_upload(self):
        """íŒŒì¼ ì—…ë¡œë“œ ì„¹ì…˜"""
        st.header("ğŸ“ ë°ì´í„° ì—…ë¡œë“œ")
        
        uploaded_file = st.file_uploader(
            "ë°ì´í„° íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”",
            type=['csv', 'xlsx', 'xls', 'json'],
            help="CSV, Excel, JSON íŒŒì¼ì„ ì§€ì›í•©ë‹ˆë‹¤"
        )
        
        if uploaded_file is not None:
            try:
                # íŒŒì¼ ì •ë³´ ë¶„ì„
                file_info = {
                    'name': uploaded_file.name,
                    'size': uploaded_file.size,
                    'type': uploaded_file.type,
                    'file_type': uploaded_file.name.split('.')[-1].lower()
                }
                
                # ë°ì´í„° ë¡œë“œ
                if file_info['file_type'] == 'csv':
                    data = pd.read_csv(uploaded_file)
                elif file_info['file_type'] in ['xlsx', 'xls']:
                    data = pd.read_excel(uploaded_file)
                elif file_info['file_type'] == 'json':
                    data = pd.read_json(uploaded_file)
                else:
                    st.error("ì§€ì›ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤.")
                    return
                
                # ë°ì´í„° ì €ì¥
                st.session_state.current_data = data
                
                # ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
                st.success(f"âœ… íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ: {file_info['name']}")
                
                with st.expander("ğŸ“Š ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°", expanded=True):
                    st.write(f"**í–‰ ìˆ˜:** {len(data)}, **ì—´ ìˆ˜:** {len(data.columns)}")
                    st.dataframe(data.head(10), use_container_width=True)
                
                # ì¶”ì²œ ìƒì„±
                file_info['rows'] = len(data)
                file_info['columns'] = len(data.columns)
                recommendations = self.recommender.generate_initial_recommendations(file_info)
                st.session_state.recommendations = recommendations
                
                # ì¶”ì²œ ë²„íŠ¼ í‘œì‹œ
                st.subheader("ğŸ’¡ ì¶”ì²œ ë¶„ì„")
                for rec in recommendations:
                    if st.button(rec['title'], key=f"rec_{rec['id']}"):
                        # ì¶”ì²œ í´ë¦­ ì‹œ ìë™ ì‹¤í–‰
                        st.session_state.messages.append({
                            'role': 'user',
                            'content': rec['query'],
                            'timestamp': datetime.now()
                        })
                        st.rerun()
                
            except Exception as e:
                st.error(f"âŒ íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    
    def render_chat_interface(self):
        """ChatGPT ìŠ¤íƒ€ì¼ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤"""
        st.header("ğŸ’¬ ë¶„ì„ ëŒ€í™”")
        
        # ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ í‘œì‹œ
        chat_container = st.container()
        
        with chat_container:
            for message in st.session_state.messages:
                with st.chat_message(message['role']):
                    st.write(message['content'])
                    
                    # ë¶„ì„ ê²°ê³¼ê°€ ìˆëŠ” ê²½ìš° í‘œì‹œ
                    if 'analysis_result' in message:
                        self.render_analysis_result(message['analysis_result'])
        
        # ì‚¬ìš©ì ì…ë ¥
        if prompt := st.chat_input("ë¶„ì„í•˜ê³  ì‹¶ì€ ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”..."):
            # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
            st.session_state.messages.append({
                'role': 'user',
                'content': prompt,
                'timestamp': datetime.now()
            })
            
            # ë¶„ì„ ì‹¤í–‰
            if st.session_state.current_data is not None:
                with st.chat_message("assistant"):
                    with st.spinner("ğŸ¤– ì—ì´ì „íŠ¸ë“¤ì´ ë¶„ì„í•˜ëŠ” ì¤‘..."):
                        analysis_result = asyncio.run(self.execute_analysis(prompt))
                        
                        # ê²°ê³¼ ë©”ì‹œì§€ ì¶”ê°€
                        assistant_message = {
                            'role': 'assistant',
                            'content': analysis_result.get('summary', 'ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.'),
                            'analysis_result': analysis_result,
                            'timestamp': datetime.now()
                        }
                        st.session_state.messages.append(assistant_message)
                        
                        # ê²°ê³¼ í‘œì‹œ
                        st.write(analysis_result.get('summary', 'ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.'))
                        self.render_analysis_result(analysis_result)
                        
                        # í›„ì† ì¶”ì²œ ìƒì„±
                        followup_recs = self.recommender.generate_followup_recommendations(analysis_result)
                        if followup_recs:
                            st.subheader("ğŸ” ë‹¤ìŒ ë‹¨ê³„ ì¶”ì²œ")
                            cols = st.columns(len(followup_recs))
                            for i, rec in enumerate(followup_recs):
                                with cols[i]:
                                    if st.button(rec['title'], key=f"followup_{rec['id']}_{len(st.session_state.messages)}"):
                                        st.session_state.messages.append({
                                            'role': 'user',
                                            'content': rec['query'],
                                            'timestamp': datetime.now()
                                        })
                                        st.rerun()
            else:
                with st.chat_message("assistant"):
                    st.warning("ğŸ“ ë¨¼ì € ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
    
    async def execute_analysis(self, user_query: str) -> Dict[str, Any]:
        """ë¶„ì„ ì‹¤í–‰ - ë°˜ë„ì²´ ë„ë©”ì¸ ì—”ì§„ ìš°ì„  ì‹œë„"""
        try:
            # 1. ğŸ”¬ ë°˜ë„ì²´ ë„ë©”ì¸ ì—”ì§„ ìš°ì„  ì‹œë„
            if SEMICONDUCTOR_ENGINE_AVAILABLE:
                try:
                    semiconductor_result = await analyze_semiconductor_data(
                        data=st.session_state.current_data,
                        user_query=user_query
                    )
                    
                    # ë°˜ë„ì²´ ë„ë©”ì¸ìœ¼ë¡œ ë†’ì€ ì‹ ë¢°ë„ë¡œ íŒì •ëœ ê²½ìš°
                    confidence = semiconductor_result.get('context', {}).get('confidence_score', 0)
                    
                    if confidence > 0.7:  # 70% ì´ìƒ ì‹ ë¢°ë„
                        return self._format_semiconductor_analysis(semiconductor_result)
                        
                except Exception as e:
                    logger.warning(f"ë°˜ë„ì²´ ë¶„ì„ ì‹œë„ ì¤‘ ì˜¤ë¥˜: {e}")
                    # ì˜¤ë¥˜ ì‹œ ì¼ë°˜ ë¶„ì„ìœ¼ë¡œ fallback
            
            # 2. ì¼ë°˜ A2A ì—ì´ì „íŠ¸ ë¶„ì„ìœ¼ë¡œ fallback
            return await self._general_agent_analysis(user_query)
            
        except Exception as e:
            logger.error(f"ë¶„ì„ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
            return self._error_response(str(e))
    
    async def _general_agent_analysis(self, user_query: str) -> Dict[str, Any]:
        """ì¼ë°˜ A2A ì—ì´ì „íŠ¸ ê¸°ë°˜ ë¶„ì„"""
        # ë°ì´í„° ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„
        data_context = {
            'data': st.session_state.current_data,
            'data_shape': st.session_state.current_data.shape,
            'columns': list(st.session_state.current_data.columns),
            'dtypes': st.session_state.current_data.dtypes.to_dict()
        }
        
        # ë¶„ì„ ê³„íš ìˆ˜ë¦½
        intent = await self.planning_engine.analyze_user_intent(user_query, data_context)
        available_agents = list(self.agent_loader.get_enabled_agents().values())
        
        # ì—ì´ì „íŠ¸ ì„ íƒ
        selected_agents = await self.planning_engine.select_optimal_agents(intent, available_agents)
        
        # ë¶„ì„ ê³„íš ìƒì„±
        plan = await self.orchestrator.create_analysis_plan(user_query, data_context)
        
        # ì‹¤ì‹œê°„ ì§„í–‰ ìƒí™© í‘œì‹œ
        if st.session_state.show_agent_details:
            progress_container = st.container()
            with progress_container:
                st.subheader("ğŸ”„ ì—ì´ì „íŠ¸ ì‘ì—… ì§„í–‰ ìƒí™©")
                
                for i, agent_selection in enumerate(selected_agents):
                    st.write(f"**{i+1}. {agent_selection.agent_id}**: {agent_selection.expected_contribution}")
                    st.caption(f"ì‹ ë¢°ë„: {agent_selection.confidence:.2f} | {agent_selection.reasoning}")
                
                progress_bar = st.progress(0)
                status_text = st.empty()
        
        # ê³„íš ì‹¤í–‰
        result = await self.orchestrator.execute_plan(plan)
        
        # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
        if st.session_state.show_agent_details:
            progress_bar.progress(100)
            status_text.success("âœ… ë¶„ì„ ì™„ë£Œ!")
        
        # ê²°ê³¼ ì²˜ë¦¬
        analysis_result = {
            'status': result.status,
            'summary': self._generate_summary(result, user_query),
            'artifacts': result.artifacts,
            'code': result.generated_code,
            'agent_contributions': result.agent_contributions,
            'execution_time': str(result.execution_time),
            'selected_agents': [agent.agent_id for agent in selected_agents],
            'domain_specific': False
        }
        
        return analysis_result
    
    def _format_semiconductor_analysis(self, result: Dict[str, Any]) -> Dict[str, Any]:
        """ë°˜ë„ì²´ ì „ë¬¸ ë¶„ì„ ê²°ê³¼ë¥¼ Cherry AI í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        
        context = result.get('context', {})
        analysis = result.get('analysis', {})
        recommendations = result.get('recommendations', [])
        
        # Cherry AI í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        formatted_result = {
            'status': 'success',
            'summary': self._create_expert_summary(analysis),
            'artifacts': self._create_semiconductor_artifacts(analysis),
            'code': [],  # ë°˜ë„ì²´ ë¶„ì„ì€ ì£¼ë¡œ í•´ì„ ì¤‘ì‹¬
            'agent_contributions': {
                'semiconductor_expert': {
                    'summary': 'ë°˜ë„ì²´ ì œì¡° ì „ë¬¸ê°€ ë¶„ì„ ì™„ë£Œ',
                    'confidence': context.get('confidence_score', 0.9),
                    'process_type': context.get('process_type', 'unknown'),
                    'analysis_category': context.get('analysis_category', 'unknown')
                }
            },
            'execution_time': 'ì‹¤ì‹œê°„ ë¶„ì„',
            'selected_agents': ['semiconductor_domain_engine'],
            'domain_specific': True,
            'expert_recommendations': recommendations
        }
        
        return formatted_result
    
    def _create_expert_summary(self, analysis: Dict[str, Any]) -> str:
        """ì „ë¬¸ê°€ ë¶„ì„ì„ ì‚¬ìš©ì ì¹œí™”ì  ìš”ì•½ìœ¼ë¡œ ë³€í™˜"""
        
        process_interpretation = analysis.get('process_interpretation', '')
        technical_findings = analysis.get('technical_findings', [])
        quality_assessment = analysis.get('quality_assessment', {})
        
        summary = f"""ğŸ”¬ **ë°˜ë„ì²´ ì „ë¬¸ê°€ ë¶„ì„ ì™„ë£Œ**

**ê³µì • í•´ì„:** {process_interpretation}

**ì£¼ìš” ë°œê²¬ì‚¬í•­:**
"""
        
        for i, finding in enumerate(technical_findings[:3], 1):
            summary += f"\n{i}. {finding}"
        
        if quality_assessment:
            summary += f"""

**í’ˆì§ˆ í‰ê°€:**
- ê³µì • ëŠ¥ë ¥: {quality_assessment.get('process_capability', 'N/A')}
- ìˆ˜ìœ¨ ì˜í–¥: {quality_assessment.get('yield_impact', 'N/A')}
- ìŠ¤í™ ì¤€ìˆ˜: {quality_assessment.get('specification_compliance', 'N/A')}"""
        
        return summary
    
    def _create_semiconductor_artifacts(self, analysis: Dict[str, Any]) -> List[Dict]:
        """ë°˜ë„ì²´ ë¶„ì„ ê²°ê³¼ë¥¼ ì‹œê°í™” ì•„í‹°íŒ©íŠ¸ë¡œ ë³€í™˜"""
        
        artifacts = []
        
        # 1. í’ˆì§ˆ í‰ê°€ í…Œì´ë¸”
        quality_assessment = analysis.get('quality_assessment', {})
        if quality_assessment:
            artifacts.append({
                'type': 'dataframe',
                'title': 'í’ˆì§ˆ í‰ê°€ ìš”ì•½',
                'data': pd.DataFrame([quality_assessment]).T.reset_index(),
                'description': 'ê³µì • ëŠ¥ë ¥ ë° í’ˆì§ˆ ì§€í‘œ í‰ê°€'
            })
        
        # 2. ê°œì„  ê¸°íšŒ ë¦¬ìŠ¤íŠ¸
        opportunities = analysis.get('optimization_opportunities', [])
        if opportunities:
            artifacts.append({
                'type': 'text',
                'title': 'ìµœì í™” ê¸°íšŒ',
                'data': '\n'.join([f"â€¢ {opp}" for opp in opportunities]),
                'description': 'í™•ì¸ëœ ê³µì • ê°œì„  ê¸°íšŒë“¤'
            })
        
        # 3. ë¦¬ìŠ¤í¬ ì§€í‘œ
        risks = analysis.get('risk_indicators', [])
        if risks:
            artifacts.append({
                'type': 'text', 
                'title': 'ë¦¬ìŠ¤í¬ ì§€í‘œ',
                'data': '\n'.join([f"âš ï¸ {risk}" for risk in risks]),
                'description': 'ì£¼ì˜ ê¹Šê²Œ ëª¨ë‹ˆí„°ë§í•´ì•¼ í•  ë¦¬ìŠ¤í¬ ìš”ì†Œë“¤'
            })
        
        # 4. ì‹¤í–‰ ê°€ëŠ¥í•œ ì¡°ì¹˜ ë°©ì•ˆ
        actions = analysis.get('actionable_recommendations', [])
        if actions:
            artifacts.append({
                'type': 'text',
                'title': 'ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ ì¡°ì¹˜',
                'data': '\n'.join([f"ğŸ”§ {action}" for action in actions]),
                'description': 'í˜„ì¥ì—ì„œ ë°”ë¡œ ì ìš©í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì  ì¡°ì¹˜ ë°©ì•ˆ'
            })
        
        return artifacts
    
    def _error_response(self, error_message: str) -> Dict[str, Any]:
        """ì—ëŸ¬ ì‘ë‹µ ìƒì„±"""
        return {
            'status': 'error',
            'summary': f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {error_message}",
            'artifacts': [],
            'code': [],
            'agent_contributions': {},
            'error': error_message
        }
    
    def render_analysis_result(self, result: Dict[str, Any]):
        """ë¶„ì„ ê²°ê³¼ ë Œë”ë§"""
        if result['status'] == 'error':
            st.error(f"âŒ {result.get('summary', 'ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.')}")
            return
        
        # ì•„í‹°íŒ©íŠ¸ í‘œì‹œ
        if result.get('artifacts'):
            for artifact in result['artifacts']:
                if artifact.get('type') == 'plot':
                    # Plotly ì°¨íŠ¸ í‘œì‹œ
                    if 'data' in artifact:
                        st.plotly_chart(artifact['data'], use_container_width=True)
                elif artifact.get('type') == 'dataframe':
                    # ë°ì´í„°í”„ë ˆì„ í‘œì‹œ
                    st.dataframe(artifact['data'], use_container_width=True)
                elif artifact.get('type') == 'text':
                    # í…ìŠ¤íŠ¸ ê²°ê³¼ í‘œì‹œ
                    st.write(artifact['data'])
        
        # ìƒì„±ëœ ì½”ë“œ í‘œì‹œ (ì˜µì…˜)
        if st.session_state.show_agent_details and result.get('code'):
            with st.expander("ğŸ’» ìƒì„±ëœ ì½”ë“œ"):
                for code_block in result['code']:
                    st.code(code_block.get('code', ''), language=code_block.get('language', 'python'))
        
        # ì—ì´ì „íŠ¸ ê¸°ì—¬ë„ í‘œì‹œ (ì˜µì…˜)
        if st.session_state.show_agent_details and result.get('agent_contributions'):
            with st.expander("ğŸ¤– ì—ì´ì „íŠ¸ ê¸°ì—¬ë„"):
                for agent_id, contribution in result['agent_contributions'].items():
                    st.write(f"**{agent_id}**: {contribution.get('summary', 'ì‘ì—… ì™„ë£Œ')}")
    
    def _generate_summary(self, result, user_query: str) -> str:
        """ë¶„ì„ ê²°ê³¼ ìš”ì•½ ìƒì„±"""
        if result.status == 'success':
            agent_count = len(result.agent_contributions)
            return f"âœ… {agent_count}ê°œ ì—ì´ì „íŠ¸ê°€ í˜‘ì—…í•˜ì—¬ '{user_query}'ì— ëŒ€í•œ ë¶„ì„ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤. ì‹¤í–‰ ì‹œê°„: {result.execution_time}"
        else:
            return f"âŒ ë¶„ì„ ì‹¤í–‰ ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ìƒíƒœ: {result.status}"
    
    def run(self):
        """Cherry AI ì‹¤í–‰"""
        # í—¤ë” ë Œë”ë§
        self.render_header()
        
        # ì´ˆê¸°í™” í™•ì¸
        if not st.session_state.cherry_ai_initialized:
            with st.spinner("ğŸ’ Cherry AI ì´ˆê¸°í™” ì¤‘..."):
                success = asyncio.run(self.initialize())
                if not success:
                    st.stop()
        
        # ì‚¬ì´ë“œë°” ë Œë”ë§
        self.render_sidebar()
        
        # ë©”ì¸ ì»¨í…ì¸ 
        tab1, tab2 = st.tabs(["ğŸ’¬ ë¶„ì„ ëŒ€í™”", "ğŸ“Š ì—ì´ì „íŠ¸ ëŒ€ì‹œë³´ë“œ"])
        
        with tab1:
            # íŒŒì¼ ì—…ë¡œë“œ
            if st.session_state.current_data is None:
                self.render_file_upload()
            else:
                # í˜„ì¬ ë°ì´í„° ì •ë³´ í‘œì‹œ
                with st.expander("ğŸ“Š í˜„ì¬ ë°ì´í„°", expanded=False):
                    st.write(f"**íŒŒì¼**: ì—…ë¡œë“œëœ ë°ì´í„° ({st.session_state.current_data.shape[0]}í–‰ Ã— {st.session_state.current_data.shape[1]}ì—´)")
                    if st.button("ğŸ—‘ï¸ ë°ì´í„° ì œê±°"):
                        st.session_state.current_data = None
                        st.session_state.recommendations = []
                        st.rerun()
            
            # ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
            self.render_chat_interface()
        
        with tab2:
            # ì—ì´ì „íŠ¸ ëŒ€ì‹œë³´ë“œ
            st.header("ğŸ¤– ì—ì´ì „íŠ¸ ìƒíƒœ ëŒ€ì‹œë³´ë“œ")
            
            if self.orchestrator:
                # ì—ì´ì „íŠ¸ ìƒíƒœ í‘œì‹œ
                agents_status = {}
                for agent_id, config in self.agent_loader.get_all_agents().items():
                    agents_status[agent_id] = {
                        'name': config.name,
                        'status': 'online' if config.enabled else 'offline',
                        'description': config.description
                    }
                
                AgentDashboard.render_agent_status_grid(agents_status)
                
                # ì—ì´ì „íŠ¸ ì„¤ì • í‘œì‹œ
                with st.expander("âš™ï¸ ì—ì´ì „íŠ¸ ì„¤ì •", expanded=False):
                    for agent_id, config in self.agent_loader.get_all_agents().items():
                        col1, col2, col3 = st.columns([2, 1, 1])
                        with col1:
                            st.write(f"**{config.name}** ({config.category})")
                            st.caption(config.description)
                        with col2:
                            st.write(f"í¬íŠ¸: {config.port}")
                        with col3:
                            status = "ğŸŸ¢ í™œì„±í™”" if config.enabled else "ğŸ”´ ë¹„í™œì„±í™”"
                            st.write(status)
            else:
                st.warning("ğŸ”§ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    try:
        cherry_ai = CherryAI()
        cherry_ai.run()
    except Exception as e:
        logger.error(f"Cherry AI ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        st.error(f"âŒ ì• í”Œë¦¬ì¼€ì´ì…˜ ì˜¤ë¥˜: {str(e)}")
        st.error("ìì„¸í•œ ë‚´ìš©ì€ ë¡œê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        
        # ë””ë²„ê·¸ ì •ë³´ í‘œì‹œ
        if st.checkbox("ğŸ› ë””ë²„ê·¸ ì •ë³´ í‘œì‹œ"):
            st.code(traceback.format_exc())

if __name__ == "__main__":
    main()