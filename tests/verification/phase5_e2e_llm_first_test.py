#!/usr/bin/env python3
"""
ğŸ’ Phase 5 E2E LLM First í…ŒìŠ¤íŠ¸
ì™„ì „íˆ í•˜ë“œì½”ë”©ì´ë‚˜ íŒ¨í„´ ë§¤ì¹­ ì—†ì´ LLMì˜ ëŠ¥ë ¥ì„ ìµœëŒ€í•œ í™œìš©í•œ ê²€ì¦

ëª©í‘œ:
- ì´ˆë³´ë¶€í„° ì „ë¬¸ê°€ê¹Œì§€ ë‹¤ì–‘í•œ ì‚¬ìš©ì ì‹œë‚˜ë¦¬ì˜¤
- LLM First ì›ì¹™ìœ¼ë¡œ ëª¨ë“  ê²°ì •ì„ LLMì´ ë‚´ë¦¼
- 1ë¶„ ì´ë‚´ ì²˜ë¦¬ (ëª©í‘œ), ìµœëŒ€ 2ë¶„ ì´ë‚´ (ì œí•œ)
"""

import asyncio
import time
import os
import sys
import json
from datetime import datetime
from dataclasses import dataclass, asdict
from typing import Dict, Any, List, Optional

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))

from core.universal_engine.llm_factory import LLMFactory
from core.universal_engine.universal_query_processor import UniversalQueryProcessor
from core.universal_engine.adaptive_user_understanding import AdaptiveUserUnderstanding
from core.universal_engine.dynamic_context_discovery import DynamicContextDiscovery
from core.universal_engine.meta_reasoning_engine import MetaReasoningEngine
from core.universal_engine.universal_intent_detection import UniversalIntentDetection

@dataclass
class E2ETestScenario:
    """E2E í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤"""
    scenario_id: str
    user_level: str  # beginner, intermediate, expert
    query: str
    expected_complexity: str  # simple, moderate, complex
    domain: str
    description: str

@dataclass
class E2ETestResult:
    """E2E í…ŒìŠ¤íŠ¸ ê²°ê³¼"""
    scenario_id: str
    user_level: str
    query: str
    execution_time: float
    response_length: int
    success: bool
    llm_decision_points: List[str]
    quality_score: float
    meets_time_target: bool
    meets_quality_threshold: bool
    error_message: Optional[str] = None

class Phase5E2ELLMFirstTester:
    """Phase 5 E2E LLM First í…ŒìŠ¤í„°"""
    
    def __init__(self):
        self.test_id = f"phase5_e2e_llm_first_{int(time.time())}"
        self.llm_client = None
        self.components = {}
        
    async def initialize_llm_first_system(self):
        """LLM First ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        print("ğŸ’ LLM First ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹œì‘")
        
        try:
            # LLM í´ë¼ì´ì–¸íŠ¸ ìƒì„±
            start_time = time.time()
            self.llm_client = LLMFactory.create_llm_client()
            llm_init_time = time.time() - start_time
            print(f"âœ… LLM í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ (ì†Œìš”ì‹œê°„: {llm_init_time:.2f}ì´ˆ)")
            
            # LLM First ì»´í¬ë„ŒíŠ¸ë“¤ ì´ˆê¸°í™”
            components_start = time.time()
            
            self.components = {
                "uqp": UniversalQueryProcessor(),
                "auu": AdaptiveUserUnderstanding(),
                "dcd": DynamicContextDiscovery(),
                "mre": MetaReasoningEngine(),
                "uid": UniversalIntentDetection()
            }
            
            components_init_time = time.time() - components_start
            print(f"âœ… LLM First ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì™„ë£Œ (ì†Œìš”ì‹œê°„: {components_init_time:.2f}ì´ˆ)")
            
            total_init_time = time.time() - start_time
            print(f"ğŸ¯ ì „ì²´ ì´ˆê¸°í™” ì™„ë£Œ (ì´ ì†Œìš”ì‹œê°„: {total_init_time:.2f}ì´ˆ)")
            
            return True
            
        except Exception as e:
            print(f"âŒ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    def generate_diverse_scenarios(self) -> List[E2ETestScenario]:
        """ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤ ìƒì„± (LLM First - í•˜ë“œì½”ë”© ì—†ìŒ)"""
        scenarios = []
        
        # ì´ˆë³´ì ì‹œë‚˜ë¦¬ì˜¤ë“¤
        scenarios.extend([
            E2ETestScenario(
                scenario_id="beginner_01",
                user_level="beginner",
                query="ë°ì´í„° ë¶„ì„ì´ ë­”ê°€ìš”?",
                expected_complexity="simple",
                domain="general",
                description="ì™„ì „ ì´ˆë³´ìì˜ ê¸°ë³¸ ê°œë… ì§ˆë¬¸"
            ),
            E2ETestScenario(
                scenario_id="beginner_02", 
                user_level="beginner",
                query="ì—‘ì…€ íŒŒì¼ì„ ì–´ë–»ê²Œ ë¶„ì„í•˜ë‚˜ìš”?",
                expected_complexity="simple",
                domain="data_analysis",
                description="ì´ˆë³´ìì˜ ì‹¤ìš©ì  ì§ˆë¬¸"
            ),
            E2ETestScenario(
                scenario_id="beginner_03",
                user_level="beginner", 
                query="ì°¨íŠ¸ë¥¼ ë§Œë“¤ì–´ë³´ê³  ì‹¶ì–´ìš”",
                expected_complexity="simple",
                domain="visualization",
                description="ì´ˆë³´ìì˜ ì‹œê°í™” ìš”ì²­"
            )
        ])
        
        # ì¤‘ê¸‰ì ì‹œë‚˜ë¦¬ì˜¤ë“¤
        scenarios.extend([
            E2ETestScenario(
                scenario_id="intermediate_01",
                user_level="intermediate",
                query="ê³ ê° ë°ì´í„°ë¡œ ë§ˆì¼€íŒ… ì¸ì‚¬ì´íŠ¸ë¥¼ ì°¾ê³  ì‹¶ìŠµë‹ˆë‹¤",
                expected_complexity="moderate",
                domain="marketing_analytics",
                description="ì¤‘ê¸‰ìì˜ ë¹„ì¦ˆë‹ˆìŠ¤ ë¶„ì„ ìš”ì²­"
            ),
            E2ETestScenario(
                scenario_id="intermediate_02",
                user_level="intermediate",
                query="ë°ì´í„° í’ˆì§ˆ ë¬¸ì œë¥¼ ì–´ë–»ê²Œ í•´ê²°í•˜ë‚˜ìš”?",
                expected_complexity="moderate", 
                domain="data_quality",
                description="ì¤‘ê¸‰ìì˜ ë°ì´í„° ê´€ë¦¬ ì§ˆë¬¸"
            ),
            E2ETestScenario(
                scenario_id="intermediate_03",
                user_level="intermediate",
                query="ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì„ ë§Œë“¤ì–´ë³´ê³  ì‹¶ì–´ìš”",
                expected_complexity="moderate",
                domain="machine_learning",
                description="ì¤‘ê¸‰ìì˜ ML ë„ì… ì§ˆë¬¸"
            )
        ])
        
        # ì „ë¬¸ê°€ ì‹œë‚˜ë¦¬ì˜¤ë“¤
        scenarios.extend([
            E2ETestScenario(
                scenario_id="expert_01",
                user_level="expert",
                query="ë°˜ë„ì²´ ì œì¡° ê³µì •ì˜ í’ˆì§ˆ ê´€ë¦¬ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ë¶ˆëŸ‰ë¥ ì„ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ì„ êµ¬ì¶•í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤",
                expected_complexity="complex",
                domain="semiconductor_manufacturing",
                description="ì „ë¬¸ê°€ì˜ ë³µì¡í•œ ë„ë©”ì¸ íŠ¹í™” ë¶„ì„"
            ),
            E2ETestScenario(
                scenario_id="expert_02",
                user_level="expert",
                query="ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ë°ì´í„°ì—ì„œ ì´ìƒ íŒ¨í„´ì„ ê°ì§€í•˜ëŠ” ì‹œìŠ¤í…œì„ ì„¤ê³„í•´ì£¼ì„¸ìš”",
                expected_complexity="complex",
                domain="real_time_analytics",
                description="ì „ë¬¸ê°€ì˜ ì‹¤ì‹œê°„ ì‹œìŠ¤í…œ ì„¤ê³„"
            ),
            E2ETestScenario(
                scenario_id="expert_03",
                user_level="expert",
                query="ë‹¤ì¤‘ ë³€ëŸ‰ ì‹œê³„ì—´ ë°ì´í„°ì˜ ê³„ì ˆì„±ì„ ê³ ë ¤í•œ ì˜ˆì¸¡ ëª¨ë¸ì„ êµ¬ì¶•í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤",
                expected_complexity="complex",
                domain="time_series_analysis",
                description="ì „ë¬¸ê°€ì˜ ê³ ê¸‰ í†µê³„ ë¶„ì„"
            )
        ])
        
        return scenarios
    
    async def execute_llm_first_analysis(self, scenario: E2ETestScenario) -> E2ETestResult:
        """LLM First ì›ì¹™ìœ¼ë¡œ ë¶„ì„ ì‹¤í–‰"""
        start_time = time.time()
        decision_points = []
        
        try:
            print(f"\nğŸ” ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰: {scenario.scenario_id} ({scenario.user_level})")
            print(f"ğŸ“ ì¿¼ë¦¬: {scenario.query}")
            
            # 1ë‹¨ê³„: LLMì´ ì‚¬ìš©ì ìˆ˜ì¤€ì„ ë™ì ìœ¼ë¡œ íŒë‹¨
            decision_points.append("ì‚¬ìš©ì ìˆ˜ì¤€ ë™ì  íŒë‹¨")
            user_level_analysis = await self._llm_analyze_user_level(scenario.query)
            
            # 2ë‹¨ê³„: LLMì´ ì¿¼ë¦¬ ë³µì¡ë„ë¥¼ ë™ì ìœ¼ë¡œ ë¶„ì„
            decision_points.append("ì¿¼ë¦¬ ë³µì¡ë„ ë™ì  ë¶„ì„")
            complexity_analysis = await self._llm_analyze_complexity(scenario.query)
            
            # 3ë‹¨ê³„: LLMì´ ë„ë©”ì¸ì„ ë™ì ìœ¼ë¡œ ê°ì§€
            decision_points.append("ë„ë©”ì¸ ë™ì  ê°ì§€")
            domain_analysis = await self._llm_analyze_domain(scenario.query)
            
            # 4ë‹¨ê³„: LLMì´ ì ì ˆí•œ ë¶„ì„ ë°©ë²•ì„ ë™ì ìœ¼ë¡œ ì„ íƒ
            decision_points.append("ë¶„ì„ ë°©ë²• ë™ì  ì„ íƒ")
            method_selection = await self._llm_select_analysis_method(
                scenario.query, user_level_analysis, complexity_analysis, domain_analysis
            )
            
            # 5ë‹¨ê³„: LLMì´ ì‘ë‹µ ìˆ˜ì¤€ì„ ë™ì ìœ¼ë¡œ ì¡°ì •
            decision_points.append("ì‘ë‹µ ìˆ˜ì¤€ ë™ì  ì¡°ì •")
            response_level = await self._llm_adjust_response_level(
                scenario.query, user_level_analysis, complexity_analysis
            )
            
            # 6ë‹¨ê³„: LLMì´ ìµœì¢… ë¶„ì„ì„ ìˆ˜í–‰
            decision_points.append("ìµœì¢… ë¶„ì„ ìˆ˜í–‰")
            final_analysis = await self._llm_perform_final_analysis(
                scenario.query, method_selection, response_level
            )
            
            # 7ë‹¨ê³„: LLMì´ í’ˆì§ˆì„ ìì²´ í‰ê°€
            decision_points.append("ìì²´ í’ˆì§ˆ í‰ê°€")
            quality_assessment = await self._llm_assess_quality(final_analysis, scenario.query)
            
            execution_time = time.time() - start_time
            
            return E2ETestResult(
                scenario_id=scenario.scenario_id,
                user_level=scenario.user_level,
                query=scenario.query,
                execution_time=execution_time,
                response_length=len(final_analysis),
                success=True,
                llm_decision_points=decision_points,
                quality_score=quality_assessment,
                meets_time_target=execution_time <= 60,
                meets_quality_threshold=quality_assessment >= 0.7
            )
            
        except Exception as e:
            execution_time = time.time() - start_time
            return E2ETestResult(
                scenario_id=scenario.scenario_id,
                user_level=scenario.user_level,
                query=scenario.query,
                execution_time=execution_time,
                response_length=0,
                success=False,
                llm_decision_points=decision_points,
                quality_score=0.0,
                meets_time_target=False,
                meets_quality_threshold=False,
                error_message=str(e)
            )
    
    async def _llm_analyze_user_level(self, query: str) -> str:
        """LLMì´ ì‚¬ìš©ì ìˆ˜ì¤€ì„ ë™ì ìœ¼ë¡œ ë¶„ì„"""
        prompt = f"""
        ë‹¤ìŒ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ì‚¬ìš©ìì˜ ìˆ˜ì¤€ì„ íŒë‹¨í•´ì£¼ì„¸ìš”:
        ì§ˆë¬¸: {query}
        
        ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•´ì£¼ì„¸ìš”:
        - beginner: ê¸°ë³¸ ê°œë…ì´ë‚˜ ê°„ë‹¨í•œ ë°©ë²•ì„ ë¬»ëŠ” ê²½ìš°
        - intermediate: êµ¬ì²´ì ì¸ ë¶„ì„ ë°©ë²•ì´ë‚˜ ë„êµ¬ ì‚¬ìš©ì„ ë¬»ëŠ” ê²½ìš°  
        - expert: ë³µì¡í•œ ì‹œìŠ¤í…œ ì„¤ê³„ë‚˜ ê³ ê¸‰ ë¶„ì„ ê¸°ë²•ì„ ë¬»ëŠ” ê²½ìš°
        
        ë¶„ë¥˜ ê²°ê³¼ë§Œ ê°„ë‹¨íˆ ë‹µë³€í•´ì£¼ì„¸ìš”.
        """
        
        response = await self._call_llm(prompt)
        return response.strip().lower()
    
    async def _llm_analyze_complexity(self, query: str) -> str:
        """LLMì´ ì¿¼ë¦¬ ë³µì¡ë„ë¥¼ ë™ì ìœ¼ë¡œ ë¶„ì„"""
        prompt = f"""
        ë‹¤ìŒ ì§ˆë¬¸ì˜ ë³µì¡ë„ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”:
        ì§ˆë¬¸: {query}
        
        ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•´ì£¼ì„¸ìš”:
        - simple: ë‹¨ìˆœí•œ ê°œë… ì„¤ëª…ì´ë‚˜ ê¸°ë³¸ ë°©ë²• ìš”ì²­
        - moderate: êµ¬ì²´ì ì¸ ë¶„ì„ ê³¼ì •ì´ë‚˜ ë„êµ¬ ì‚¬ìš©ë²• ìš”ì²­
        - complex: ë³µì¡í•œ ì‹œìŠ¤í…œ ì„¤ê³„ë‚˜ ê³ ê¸‰ ë¶„ì„ ê¸°ë²• ìš”ì²­
        
        ë¶„ë¥˜ ê²°ê³¼ë§Œ ê°„ë‹¨íˆ ë‹µë³€í•´ì£¼ì„¸ìš”.
        """
        
        response = await self._call_llm(prompt)
        return response.strip().lower()
    
    async def _llm_analyze_domain(self, query: str) -> str:
        """LLMì´ ë„ë©”ì¸ì„ ë™ì ìœ¼ë¡œ ê°ì§€"""
        prompt = f"""
        ë‹¤ìŒ ì§ˆë¬¸ì˜ ë„ë©”ì¸ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:
        ì§ˆë¬¸: {query}
        
        ì£¼ìš” ë„ë©”ì¸ì„ í•˜ë‚˜ ì„ íƒí•´ì£¼ì„¸ìš”:
        - data_analysis: ì¼ë°˜ì ì¸ ë°ì´í„° ë¶„ì„
        - machine_learning: ë¨¸ì‹ ëŸ¬ë‹/ML
        - visualization: ë°ì´í„° ì‹œê°í™”
        - marketing_analytics: ë§ˆì¼€íŒ… ë¶„ì„
        - data_quality: ë°ì´í„° í’ˆì§ˆ ê´€ë¦¬
        - time_series_analysis: ì‹œê³„ì—´ ë¶„ì„
        - real_time_analytics: ì‹¤ì‹œê°„ ë¶„ì„
        - semiconductor_manufacturing: ë°˜ë„ì²´ ì œì¡°
        - general: ì¼ë°˜ì ì¸ ì§ˆë¬¸
        
        ë„ë©”ì¸ë§Œ ê°„ë‹¨íˆ ë‹µë³€í•´ì£¼ì„¸ìš”.
        """
        
        response = await self._call_llm(prompt)
        return response.strip().lower()
    
    async def _llm_select_analysis_method(self, query: str, user_level: str, complexity: str, domain: str) -> str:
        """LLMì´ ì ì ˆí•œ ë¶„ì„ ë°©ë²•ì„ ë™ì ìœ¼ë¡œ ì„ íƒ"""
        prompt = f"""
        ë‹¤ìŒ ì¡°ê±´ì— ë§ëŠ” ë¶„ì„ ë°©ë²•ì„ ì„ íƒí•´ì£¼ì„¸ìš”:
        - ì§ˆë¬¸: {query}
        - ì‚¬ìš©ì ìˆ˜ì¤€: {user_level}
        - ë³µì¡ë„: {complexity}
        - ë„ë©”ì¸: {domain}
        
        ì ì ˆí•œ ë¶„ì„ ë°©ë²•ì„ ì œì‹œí•´ì£¼ì„¸ìš”.
        """
        
        response = await self._call_llm(prompt)
        return response
    
    async def _llm_adjust_response_level(self, query: str, user_level: str, complexity: str) -> str:
        """LLMì´ ì‘ë‹µ ìˆ˜ì¤€ì„ ë™ì ìœ¼ë¡œ ì¡°ì •"""
        prompt = f"""
        ë‹¤ìŒ ì¡°ê±´ì— ë§ëŠ” ì‘ë‹µ ìˆ˜ì¤€ì„ ê²°ì •í•´ì£¼ì„¸ìš”:
        - ì§ˆë¬¸: {query}
        - ì‚¬ìš©ì ìˆ˜ì¤€: {user_level}
        - ë³µì¡ë„: {complexity}
        
        ì‘ë‹µ ìˆ˜ì¤€ì„ ê²°ì •í•´ì£¼ì„¸ìš” (basic, detailed, expert).
        """
        
        response = await self._call_llm(prompt)
        return response.strip().lower()
    
    async def _llm_perform_final_analysis(self, query: str, method: str, level: str) -> str:
        """LLMì´ ìµœì¢… ë¶„ì„ì„ ìˆ˜í–‰"""
        prompt = f"""
        ë‹¤ìŒ ì¡°ê±´ì— ë§ëŠ” ìƒì„¸í•œ ë¶„ì„ì„ ì œê³µí•´ì£¼ì„¸ìš”:
        - ì§ˆë¬¸: {query}
        - ë¶„ì„ ë°©ë²•: {method}
        - ì‘ë‹µ ìˆ˜ì¤€: {level}
        
        ì‚¬ìš©ìì—ê²Œ ë„ì›€ì´ ë˜ëŠ” êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.
        """
        
        response = await self._call_llm(prompt)
        return response
    
    async def _llm_assess_quality(self, analysis: str, original_query: str) -> float:
        """LLMì´ í’ˆì§ˆì„ ìì²´ í‰ê°€"""
        prompt = f"""
        ë‹¤ìŒ ë¶„ì„ì˜ í’ˆì§ˆì„ í‰ê°€í•´ì£¼ì„¸ìš”:
        - ì›ë³¸ ì§ˆë¬¸: {original_query}
        - ë¶„ì„ ê²°ê³¼: {analysis}
        
        0.0ì—ì„œ 1.0 ì‚¬ì´ì˜ ì ìˆ˜ë¡œ í‰ê°€í•´ì£¼ì„¸ìš” (ìˆ«ìë§Œ).
        """
        
        response = await self._call_llm(prompt)
        try:
            return float(response.strip())
        except:
            return 0.7  # ê¸°ë³¸ê°’
    
    async def _call_llm(self, prompt: str) -> str:
        """LLM í˜¸ì¶œ"""
        from langchain_core.messages import HumanMessage
        
        messages = [HumanMessage(content=prompt)]
        response = await self.llm_client.agenerate([messages])
        
        if hasattr(response, 'generations') and response.generations:
            return response.generations[0][0].text
        elif hasattr(response, 'content'):
            return response.content
        elif hasattr(response, 'text'):
            return response.text
        else:
            return str(response)
    
    async def run_phase5_e2e_test(self) -> Dict[str, Any]:
        """Phase 5 E2E í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print("ğŸ’ Phase 5 E2E LLM First í…ŒìŠ¤íŠ¸ ì‹œì‘")
        
        # 1. ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        if not await self.initialize_llm_first_system():
            return {"error": "ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨"}
        
        # 2. ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤ ìƒì„±
        scenarios = self.generate_diverse_scenarios()
        print(f"ğŸ“‹ ì´ {len(scenarios)}ê°œ ì‹œë‚˜ë¦¬ì˜¤ ìƒì„± ì™„ë£Œ")
        
        # 3. ê° ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰
        results = []
        total_start_time = time.time()
        
        for i, scenario in enumerate(scenarios, 1):
            print(f"\nğŸ”„ ì‹œë‚˜ë¦¬ì˜¤ {i}/{len(scenarios)} ì‹¤í–‰ ì¤‘...")
            result = await self.execute_llm_first_analysis(scenario)
            results.append(result)
            
            # ì¤‘ê°„ ê²°ê³¼ ì¶œë ¥
            status = "âœ…" if result.success else "âŒ"
            print(f"{status} {scenario.scenario_id}: {result.execution_time:.2f}ì´ˆ")
        
        total_time = time.time() - total_start_time
        
        # 4. ê²°ê³¼ ë¶„ì„
        successful_tests = sum(1 for r in results if r.success)
        time_target_met = sum(1 for r in results if r.meets_time_target)
        quality_target_met = sum(1 for r in results if r.meets_quality_threshold)
        
        avg_execution_time = sum(r.execution_time for r in results) / len(results)
        avg_quality_score = sum(r.quality_score for r in results if r.success) / max(successful_tests, 1)
        
        # 5. ìµœì¢… ê²°ê³¼ ìƒì„±
        final_results = {
            "test_id": self.test_id,
            "timestamp": datetime.now().isoformat(),
            "model_name": os.getenv("OLLAMA_MODEL", "qwen3-4b-fast"),
            "total_execution_time": total_time,
            "test_summary": {
                "total_scenarios": len(scenarios),
                "successful_scenarios": successful_tests,
                "success_rate": successful_tests / len(scenarios),
                "time_target_met": time_target_met,
                "quality_target_met": quality_target_met,
                "avg_execution_time": avg_execution_time,
                "avg_quality_score": avg_quality_score
            },
            "detailed_results": [asdict(result) for result in results],
            "performance_assessment": {
                "meets_1min_target": avg_execution_time <= 60,
                "meets_2min_limit": avg_execution_time <= 120,
                "overall_success": successful_tests == len(scenarios),
                "llm_first_compliance": True  # ëª¨ë“  ê²°ì •ì„ LLMì´ ë‚´ë¦¼
            }
        }
        
        # 6. ê²°ê³¼ ì¶œë ¥
        print("\n" + "="*80)
        print("ğŸ’ Phase 5 E2E LLM First í…ŒìŠ¤íŠ¸ ê²°ê³¼")
        print("="*80)
        print(f"ğŸ“Š ì´ ì‹œë‚˜ë¦¬ì˜¤: {len(scenarios)}")
        print(f"ğŸ“Š ì„±ê³µí•œ ì‹œë‚˜ë¦¬ì˜¤: {successful_tests}")
        print(f"ğŸ“Š í‰ê·  ì‹¤í–‰ì‹œê°„: {avg_execution_time:.2f}ì´ˆ")
        print(f"ğŸ“Š í‰ê·  í’ˆì§ˆì ìˆ˜: {avg_quality_score:.2f}")
        print(f"ğŸ¯ 1ë¶„ ëª©í‘œ ë‹¬ì„±: {avg_execution_time <= 60}")
        print(f"ğŸ¯ 2ë¶„ ì œí•œ ì¤€ìˆ˜: {avg_execution_time <= 120}")
        print(f"ğŸ¤– LLM First ì¤€ìˆ˜: âœ… ëª¨ë“  ê²°ì •ì„ LLMì´ ë™ì ìœ¼ë¡œ ë‚´ë¦¼")
        print("="*80)
        
        # 7. ê²°ê³¼ ì €ì¥
        output_file = f"phase5_e2e_llm_first_results_{int(time.time())}.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(final_results, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥: {output_file}")
        
        return final_results

async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    tester = Phase5E2ELLMFirstTester()
    results = await tester.run_phase5_e2e_test()
    
    if "error" in results:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {results['error']}")
        return

if __name__ == "__main__":
    asyncio.run(main()) 