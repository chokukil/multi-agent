#!/usr/bin/env python3
"""
ğŸ’ Phase 5 E2E ìµœì í™” í…ŒìŠ¤íŠ¸
ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì í™”ëœ LLM First E2E í…ŒìŠ¤íŠ¸

ê°œì„ ì‚¬í•­:
- í”„ë¡¬í”„íŠ¸ ìµœì í™”ë¡œ ì‘ë‹µ ì‹œê°„ ë‹¨ì¶•
- íƒ€ì„ì•„ì›ƒ ì„¤ì •ìœ¼ë¡œ ë¬´í•œ ëŒ€ê¸° ë°©ì§€
- ìƒì„¸í•œ ì§„í–‰ ìƒí™© ë¡œê¹…
- ë‹¨ê³„ë³„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
"""

import asyncio
import time
import os
import sys
import json
from datetime import datetime
from dataclasses import dataclass, asdict
from typing import Dict, Any, List, Optional

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))

from core.universal_engine.llm_factory import LLMFactory

@dataclass
class OptimizedE2EScenario:
    """ìµœì í™”ëœ E2E ì‹œë‚˜ë¦¬ì˜¤"""
    scenario_id: str
    user_level: str
    query: str
    expected_complexity: str
    domain: str
    description: str

@dataclass
class OptimizedE2EResult:
    """ìµœì í™”ëœ E2E ê²°ê³¼"""
    scenario_id: str
    user_level: str
    query: str
    execution_time: float
    response_length: int
    success: bool
    llm_decision_points: List[str]
    step_times: Dict[str, float]
    quality_score: float
    meets_time_target: bool
    meets_quality_threshold: bool
    error_message: Optional[str] = None

class Phase5E2EOptimizedTester:
    """Phase 5 E2E ìµœì í™” í…ŒìŠ¤í„°"""
    
    def __init__(self):
        self.test_id = f"phase5_e2e_optimized_{int(time.time())}"
        self.llm_client = None
        
    async def initialize_optimized_system(self):
        """ìµœì í™”ëœ ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        print("ğŸ’ ìµœì í™”ëœ LLM First ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹œì‘")
        
        try:
            start_time = time.time()
            self.llm_client = LLMFactory.create_llm_client()
            init_time = time.time() - start_time
            print(f"âœ… LLM í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ (ì†Œìš”ì‹œê°„: {init_time:.2f}ì´ˆ)")
            return True
        except Exception as e:
            print(f"âŒ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    def generate_optimized_scenarios(self) -> List[OptimizedE2EScenario]:
        """ìµœì í™”ëœ ì‹œë‚˜ë¦¬ì˜¤ ìƒì„±"""
        scenarios = []
        
        # ì´ˆë³´ì ì‹œë‚˜ë¦¬ì˜¤ (ë¹ ë¥¸ ì‘ë‹µ ì˜ˆìƒ)
        scenarios.extend([
            OptimizedE2EScenario(
                scenario_id="beginner_01",
                user_level="beginner",
                query="ë°ì´í„° ë¶„ì„ì´ ë­”ê°€ìš”?",
                expected_complexity="simple",
                domain="general",
                description="ì´ˆë³´ì ê¸°ë³¸ ê°œë… ì§ˆë¬¸"
            ),
            OptimizedE2EScenario(
                scenario_id="beginner_02",
                user_level="beginner",
                query="ì—‘ì…€ íŒŒì¼ì„ ì–´ë–»ê²Œ ë¶„ì„í•˜ë‚˜ìš”?",
                expected_complexity="simple",
                domain="data_analysis",
                description="ì´ˆë³´ì ì‹¤ìš©ì  ì§ˆë¬¸"
            )
        ])
        
        # ì¤‘ê¸‰ì ì‹œë‚˜ë¦¬ì˜¤ (ì¤‘ê°„ ë³µì¡ë„)
        scenarios.extend([
            OptimizedE2EScenario(
                scenario_id="intermediate_01",
                user_level="intermediate",
                query="ê³ ê° ë°ì´í„°ë¡œ ë§ˆì¼€íŒ… ì¸ì‚¬ì´íŠ¸ë¥¼ ì°¾ê³  ì‹¶ìŠµë‹ˆë‹¤",
                expected_complexity="moderate",
                domain="marketing_analytics",
                description="ì¤‘ê¸‰ì ë¹„ì¦ˆë‹ˆìŠ¤ ë¶„ì„"
            ),
            OptimizedE2EScenario(
                scenario_id="intermediate_02",
                user_level="intermediate",
                query="ë°ì´í„° í’ˆì§ˆ ë¬¸ì œë¥¼ ì–´ë–»ê²Œ í•´ê²°í•˜ë‚˜ìš”?",
                expected_complexity="moderate",
                domain="data_quality",
                description="ì¤‘ê¸‰ì ë°ì´í„° ê´€ë¦¬"
            )
        ])
        
        # ì „ë¬¸ê°€ ì‹œë‚˜ë¦¬ì˜¤ (ë³µì¡í•œ ë¶„ì„)
        scenarios.extend([
            OptimizedE2EScenario(
                scenario_id="expert_01",
                user_level="expert",
                query="ë°˜ë„ì²´ ì œì¡° ê³µì •ì˜ í’ˆì§ˆ ê´€ë¦¬ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ë¶ˆëŸ‰ë¥ ì„ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ì„ êµ¬ì¶•í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤",
                expected_complexity="complex",
                domain="semiconductor_manufacturing",
                description="ì „ë¬¸ê°€ ë³µì¡í•œ ë„ë©”ì¸ ë¶„ì„"
            )
        ])
        
        return scenarios
    
    async def _call_llm_with_timeout(self, prompt: str, timeout: int = 30) -> str:
        """íƒ€ì„ì•„ì›ƒì´ ìˆëŠ” LLM í˜¸ì¶œ"""
        from langchain_core.messages import HumanMessage
        
        try:
            messages = [HumanMessage(content=prompt)]
            response = await asyncio.wait_for(
                self.llm_client.agenerate([messages]), 
                timeout=timeout
            )
            
            if hasattr(response, 'generations') and response.generations:
                return response.generations[0][0].text
            elif hasattr(response, 'content'):
                return response.content
            elif hasattr(response, 'text'):
                return response.text
            else:
                return str(response)
                
        except asyncio.TimeoutError:
            raise Exception(f"LLM í˜¸ì¶œ íƒ€ì„ì•„ì›ƒ ({timeout}ì´ˆ)")
    
    async def execute_optimized_analysis(self, scenario: OptimizedE2EScenario) -> OptimizedE2EResult:
        """ìµœì í™”ëœ ë¶„ì„ ì‹¤í–‰"""
        start_time = time.time()
        decision_points = []
        step_times = {}
        
        try:
            print(f"\nğŸ” ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰: {scenario.scenario_id} ({scenario.user_level})")
            print(f"ğŸ“ ì¿¼ë¦¬: {scenario.query}")
            
            # 1ë‹¨ê³„: ì‚¬ìš©ì ìˆ˜ì¤€ ë¶„ì„ (ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸)
            step_start = time.time()
            decision_points.append("ì‚¬ìš©ì ìˆ˜ì¤€ ë¶„ì„")
            
            user_level_prompt = f"ì§ˆë¬¸: {scenario.query}\në¶„ë¥˜: beginner/intermediate/expert ì¤‘ í•˜ë‚˜ë§Œ ë‹µë³€"
            user_level_analysis = await self._call_llm_with_timeout(user_level_prompt, 15)
            step_times["user_level"] = time.time() - step_start
            print(f"  âœ… ì‚¬ìš©ì ìˆ˜ì¤€: {user_level_analysis.strip()} ({step_times['user_level']:.2f}ì´ˆ)")
            
            # 2ë‹¨ê³„: ë³µì¡ë„ ë¶„ì„ (ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸)
            step_start = time.time()
            decision_points.append("ë³µì¡ë„ ë¶„ì„")
            
            complexity_prompt = f"ì§ˆë¬¸: {scenario.query}\në³µì¡ë„: simple/moderate/complex ì¤‘ í•˜ë‚˜ë§Œ ë‹µë³€"
            complexity_analysis = await self._call_llm_with_timeout(complexity_prompt, 15)
            step_times["complexity"] = time.time() - step_start
            print(f"  âœ… ë³µì¡ë„: {complexity_analysis.strip()} ({step_times['complexity']:.2f}ì´ˆ)")
            
            # 3ë‹¨ê³„: ë„ë©”ì¸ ê°ì§€ (ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸)
            step_start = time.time()
            decision_points.append("ë„ë©”ì¸ ê°ì§€")
            
            domain_prompt = f"ì§ˆë¬¸: {scenario.query}\në„ë©”ì¸: data_analysis/machine_learning/visualization/marketing_analytics/data_quality/time_series_analysis/semiconductor_manufacturing/general ì¤‘ í•˜ë‚˜ë§Œ ë‹µë³€"
            domain_analysis = await self._call_llm_with_timeout(domain_prompt, 15)
            step_times["domain"] = time.time() - step_start
            print(f"  âœ… ë„ë©”ì¸: {domain_analysis.strip()} ({step_times['domain']:.2f}ì´ˆ)")
            
            # 4ë‹¨ê³„: ë¶„ì„ ë°©ë²• ì„ íƒ (ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸)
            step_start = time.time()
            decision_points.append("ë¶„ì„ ë°©ë²• ì„ íƒ")
            
            method_prompt = f"""
            ì¡°ê±´: {scenario.query}
            ì‚¬ìš©ì: {user_level_analysis.strip()}
            ë³µì¡ë„: {complexity_analysis.strip()}
            ë„ë©”ì¸: {domain_analysis.strip()}
            
            ì ì ˆí•œ ë¶„ì„ ë°©ë²•ì„ 3ì¤„ ì´ë‚´ë¡œ ê°„ë‹¨íˆ ì œì‹œí•˜ì„¸ìš”.
            """
            method_selection = await self._call_llm_with_timeout(method_prompt, 45)
            step_times["method_selection"] = time.time() - step_start
            print(f"  âœ… ë¶„ì„ ë°©ë²• ì„ íƒ ì™„ë£Œ ({step_times['method_selection']:.2f}ì´ˆ)")
            
            # 5ë‹¨ê³„: ì‘ë‹µ ìˆ˜ì¤€ ì¡°ì • (ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸)
            step_start = time.time()
            decision_points.append("ì‘ë‹µ ìˆ˜ì¤€ ì¡°ì •")
            
            level_prompt = f"ì§ˆë¬¸: {scenario.query}\nì‚¬ìš©ì: {user_level_analysis.strip()}\në³µì¡ë„: {complexity_analysis.strip()}\nì‘ë‹µìˆ˜ì¤€: basic/detailed/expert ì¤‘ í•˜ë‚˜ë§Œ ë‹µë³€"
            response_level = await self._call_llm_with_timeout(level_prompt, 15)
            step_times["response_level"] = time.time() - step_start
            print(f"  âœ… ì‘ë‹µ ìˆ˜ì¤€: {response_level.strip()} ({step_times['response_level']:.2f}ì´ˆ)")
            
            # 6ë‹¨ê³„: ìµœì¢… ë¶„ì„ (ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸)
            step_start = time.time()
            decision_points.append("ìµœì¢… ë¶„ì„")
            
            analysis_prompt = f"""
            ì§ˆë¬¸: {scenario.query}
            ë°©ë²•: {method_selection}
            ìˆ˜ì¤€: {response_level.strip()}
            
            êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ë‹µë³€ì„ 5ì¤„ ì´ë‚´ë¡œ ì œê³µí•˜ì„¸ìš”.
            """
            final_analysis = await self._call_llm_with_timeout(analysis_prompt, 60)
            step_times["final_analysis"] = time.time() - step_start
            print(f"  âœ… ìµœì¢… ë¶„ì„ ì™„ë£Œ ({step_times['final_analysis']:.2f}ì´ˆ)")
            
            # 7ë‹¨ê³„: í’ˆì§ˆ í‰ê°€ (ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸)
            step_start = time.time()
            decision_points.append("í’ˆì§ˆ í‰ê°€")
            
            quality_prompt = f"ì§ˆë¬¸: {scenario.query}\në‹µë³€: {final_analysis}\nì ìˆ˜: 0.0-1.0 ì‚¬ì´ ìˆ«ìë§Œ"
            quality_assessment = await self._call_llm_with_timeout(quality_prompt, 10)
            step_times["quality_assessment"] = time.time() - step_start
            
            try:
                quality_score = float(quality_assessment.strip())
            except:
                quality_score = 0.7
            
            print(f"  âœ… í’ˆì§ˆ ì ìˆ˜: {quality_score:.2f} ({step_times['quality_assessment']:.2f}ì´ˆ)")
            
            execution_time = time.time() - start_time
            
            return OptimizedE2EResult(
                scenario_id=scenario.scenario_id,
                user_level=scenario.user_level,
                query=scenario.query,
                execution_time=execution_time,
                response_length=len(final_analysis),
                success=True,
                llm_decision_points=decision_points,
                step_times=step_times,
                quality_score=quality_score,
                meets_time_target=execution_time <= 60,
                meets_quality_threshold=quality_score >= 0.7
            )
            
        except Exception as e:
            execution_time = time.time() - start_time
            print(f"  âŒ ì˜¤ë¥˜: {e}")
            
            return OptimizedE2EResult(
                scenario_id=scenario.scenario_id,
                user_level=scenario.user_level,
                query=scenario.query,
                execution_time=execution_time,
                response_length=0,
                success=False,
                llm_decision_points=decision_points,
                step_times=step_times,
                quality_score=0.0,
                meets_time_target=False,
                meets_quality_threshold=False,
                error_message=str(e)
            )
    
    async def run_optimized_e2e_test(self) -> Dict[str, Any]:
        """ìµœì í™”ëœ E2E í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print("ğŸ’ Phase 5 E2E ìµœì í™” í…ŒìŠ¤íŠ¸ ì‹œì‘")
        
        # 1. ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        if not await self.initialize_optimized_system():
            return {"error": "ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨"}
        
        # 2. ì‹œë‚˜ë¦¬ì˜¤ ìƒì„±
        scenarios = self.generate_optimized_scenarios()
        print(f"ğŸ“‹ ì´ {len(scenarios)}ê°œ ì‹œë‚˜ë¦¬ì˜¤ ìƒì„± ì™„ë£Œ")
        
        # 3. ê° ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰
        results = []
        total_start_time = time.time()
        
        for i, scenario in enumerate(scenarios, 1):
            print(f"\nğŸ”„ ì‹œë‚˜ë¦¬ì˜¤ {i}/{len(scenarios)} ì‹¤í–‰ ì¤‘...")
            result = await self.execute_optimized_analysis(scenario)
            results.append(result)
            
            # ì¤‘ê°„ ê²°ê³¼ ì¶œë ¥
            status = "âœ…" if result.success else "âŒ"
            print(f"{status} {scenario.scenario_id}: {result.execution_time:.2f}ì´ˆ")
            
            if result.success:
                print(f"  ğŸ“Š í’ˆì§ˆì ìˆ˜: {result.quality_score:.2f}")
                print(f"  ğŸ¯ 1ë¶„ëª©í‘œ: {'ë‹¬ì„±' if result.meets_time_target else 'ë¯¸ë‹¬ì„±'}")
        
        total_time = time.time() - total_start_time
        
        # 4. ê²°ê³¼ ë¶„ì„
        successful_tests = sum(1 for r in results if r.success)
        time_target_met = sum(1 for r in results if r.meets_time_target)
        quality_target_met = sum(1 for r in results if r.meets_quality_threshold)
        
        avg_execution_time = sum(r.execution_time for r in results) / len(results)
        avg_quality_score = sum(r.quality_score for r in results if r.success) / max(successful_tests, 1)
        
        # 5. ìµœì¢… ê²°ê³¼ ìƒì„±
        final_results = {
            "test_id": self.test_id,
            "timestamp": datetime.now().isoformat(),
            "model_name": os.getenv("OLLAMA_MODEL", "qwen3-4b-fast"),
            "total_execution_time": total_time,
            "test_summary": {
                "total_scenarios": len(scenarios),
                "successful_scenarios": successful_tests,
                "success_rate": successful_tests / len(scenarios),
                "time_target_met": time_target_met,
                "quality_target_met": quality_target_met,
                "avg_execution_time": avg_execution_time,
                "avg_quality_score": avg_quality_score
            },
            "detailed_results": [asdict(result) for result in results],
            "performance_assessment": {
                "meets_1min_target": avg_execution_time <= 60,
                "meets_2min_limit": avg_execution_time <= 120,
                "overall_success": successful_tests == len(scenarios),
                "llm_first_compliance": True,
                "optimization_applied": True
            }
        }
        
        # 6. ê²°ê³¼ ì¶œë ¥
        print("\n" + "="*80)
        print("ğŸ’ Phase 5 E2E ìµœì í™” í…ŒìŠ¤íŠ¸ ê²°ê³¼")
        print("="*80)
        print(f"ğŸ“Š ì´ ì‹œë‚˜ë¦¬ì˜¤: {len(scenarios)}")
        print(f"ğŸ“Š ì„±ê³µí•œ ì‹œë‚˜ë¦¬ì˜¤: {successful_tests}")
        print(f"ğŸ“Š í‰ê·  ì‹¤í–‰ì‹œê°„: {avg_execution_time:.2f}ì´ˆ")
        print(f"ğŸ“Š í‰ê·  í’ˆì§ˆì ìˆ˜: {avg_quality_score:.2f}")
        print(f"ğŸ¯ 1ë¶„ ëª©í‘œ ë‹¬ì„±: {avg_execution_time <= 60}")
        print(f"ğŸ¯ 2ë¶„ ì œí•œ ì¤€ìˆ˜: {avg_execution_time <= 120}")
        print(f"ğŸ¤– LLM First ì¤€ìˆ˜: âœ… ëª¨ë“  ê²°ì •ì„ LLMì´ ë™ì ìœ¼ë¡œ ë‚´ë¦¼")
        print(f"âš¡ ìµœì í™” ì ìš©: âœ… í”„ë¡¬í”„íŠ¸ ìµœì í™”, íƒ€ì„ì•„ì›ƒ ì„¤ì •")
        print("="*80)
        
        # 7. ê²°ê³¼ ì €ì¥
        output_file = f"phase5_e2e_optimized_results_{int(time.time())}.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(final_results, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥: {output_file}")
        
        return final_results

async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    tester = Phase5E2EOptimizedTester()
    results = await tester.run_optimized_e2e_test()
    
    if "error" in results:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {results['error']}")
        return

if __name__ == "__main__":
    asyncio.run(main()) 