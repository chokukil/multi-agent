#!/usr/bin/env python3
"""
ğŸ’ Qwen3-4b-fast ëª¨ë¸ ê¸°ë³¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
ê°„ë‹¨í•œ LLM í˜¸ì¶œì„ í†µí•œ ì„±ëŠ¥ ì¸¡ì •
"""

import asyncio
import time
import os
import sys
from datetime import datetime
import json

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))

from core.universal_engine.llm_factory import LLMFactory

async def test_basic_llm_performance():
    """ê¸°ë³¸ LLM ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print("ğŸ’ Qwen3-4b-fast ëª¨ë¸ ê¸°ë³¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    # í™˜ê²½ë³€ìˆ˜ í™•ì¸
    model_name = os.getenv("OLLAMA_MODEL", "qwen3-4b-fast")
    print(f"ğŸ“‹ ì‚¬ìš© ëª¨ë¸: {model_name}")
    
    try:
        # LLM í´ë¼ì´ì–¸íŠ¸ ìƒì„±
        print("ğŸ”§ LLM í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì¤‘...")
        start_time = time.time()
        llm_client = LLMFactory.create_llm_client()
        init_time = time.time() - start_time
        print(f"âœ… LLM í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ (ì†Œìš”ì‹œê°„: {init_time:.2f}ì´ˆ)")
        
        # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë“¤
        test_queries = [
            "ì•ˆë…•í•˜ì„¸ìš”",
            "ë°ì´í„° ë¶„ì„ì´ë€ ë¬´ì—‡ì¸ê°€ìš”?",
            "ë°˜ë„ì²´ ì œì¡° ê³µì •ì—ì„œ í’ˆì§ˆ ê´€ë¦¬ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ëŠ” ë°©ë²•ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”."
        ]
        
        results = []
        
        for i, query in enumerate(test_queries, 1):
            print(f"\nğŸ” í…ŒìŠ¤íŠ¸ {i}: {query[:50]}...")
            
            try:
                # LLM í˜¸ì¶œ ì‹œê°„ ì¸¡ì •
                start_time = time.time()
                
                # ê°„ë‹¨í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±
                from langchain_core.messages import HumanMessage
                prompt = f"ë‹¤ìŒ ì§ˆë¬¸ì— ê°„ë‹¨í•˜ê³  ëª…í™•í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”: {query}"
                messages = [HumanMessage(content=prompt)]
                
                # LLM í˜¸ì¶œ
                response = await llm_client.agenerate([messages])
                
                end_time = time.time()
                execution_time = end_time - start_time
                
                # ì‘ë‹µ ì²˜ë¦¬
                if hasattr(response, 'generations') and response.generations:
                    response_text = response.generations[0][0].text
                elif hasattr(response, 'content'):
                    response_text = response.content
                elif hasattr(response, 'text'):
                    response_text = response.text
                else:
                    response_text = str(response)
                
                result = {
                    "query": query,
                    "execution_time": execution_time,
                    "response_length": len(response_text),
                    "success": True,
                    "response_preview": response_text[:100] + "..." if len(response_text) > 100 else response_text
                }
                
                print(f"âœ… ì„±ê³µ - ì‹¤í–‰ì‹œê°„: {execution_time:.2f}ì´ˆ, ì‘ë‹µê¸¸ì´: {len(response_text)}ì")
                
            except Exception as e:
                result = {
                    "query": query,
                    "execution_time": time.time() - start_time,
                    "response_length": 0,
                    "success": False,
                    "error": str(e)
                }
                print(f"âŒ ì‹¤íŒ¨ - ì˜¤ë¥˜: {e}")
            
            results.append(result)
        
        # ê²°ê³¼ ë¶„ì„
        successful_tests = sum(1 for r in results if r["success"])
        avg_execution_time = sum(r["execution_time"] for r in results) / len(results)
        avg_response_length = sum(r["response_length"] for r in results if r["success"]) / max(successful_tests, 1)
        
        # ìµœì¢… ê²°ê³¼ ì¶œë ¥
        print("\n" + "="*60)
        print("ğŸ’ Qwen3-4b-fast ëª¨ë¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ê²°ê³¼")
        print("="*60)
        print(f"ğŸ“Š ì´ í…ŒìŠ¤íŠ¸ ìˆ˜: {len(results)}")
        print(f"ğŸ“Š ì„±ê³µí•œ í…ŒìŠ¤íŠ¸: {successful_tests}")
        print(f"ğŸ“Š í‰ê·  ì‹¤í–‰ì‹œê°„: {avg_execution_time:.2f}ì´ˆ")
        print(f"ğŸ“Š í‰ê·  ì‘ë‹µê¸¸ì´: {avg_response_length:.0f}ì")
        print(f"ğŸ¯ 1ë¶„ ëª©í‘œ ë‹¬ì„±: {avg_execution_time <= 60}")
        print(f"ğŸ¯ 2ë¶„ ì œí•œ ì¤€ìˆ˜: {avg_execution_time <= 120}")
        
        if avg_execution_time <= 60:
            print("âœ… ì„±ëŠ¥ í‰ê°€: ìš°ìˆ˜ - 1ë¶„ ëª©í‘œ ë‹¬ì„±")
        elif avg_execution_time <= 120:
            print("âš ï¸ ì„±ëŠ¥ í‰ê°€: ì–‘í˜¸ - 2ë¶„ ì œí•œ ë‚´")
        else:
            print("âŒ ì„±ëŠ¥ í‰ê°€: ê°œì„  í•„ìš” - 2ë¶„ ì´ˆê³¼")
        
        print("="*60)
        
        # ê²°ê³¼ ì €ì¥
        final_results = {
            "test_id": f"qwen3_4b_fast_basic_{int(time.time())}",
            "timestamp": datetime.now().isoformat(),
            "model_name": model_name,
            "initialization_time": init_time,
            "test_summary": {
                "total_tests": len(results),
                "successful_tests": successful_tests,
                "success_rate": successful_tests / len(results),
                "avg_execution_time": avg_execution_time,
                "avg_response_length": avg_response_length
            },
            "detailed_results": results,
            "performance_assessment": {
                "meets_1min_target": avg_execution_time <= 60,
                "meets_2min_limit": avg_execution_time <= 120,
                "overall_success": successful_tests == len(results)
            }
        }
        
        output_file = f"qwen3_4b_fast_basic_results_{int(time.time())}.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(final_results, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥: {output_file}")
        
        return final_results
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return {"error": str(e)}

async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    results = await test_basic_llm_performance()
    
    if "error" in results:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {results['error']}")
        return

if __name__ == "__main__":
    asyncio.run(main()) 