#!/usr/bin/env python3
"""
ðŸ” Zero-Hardcoding ì»´í”Œë¼ì´ì–¸ìŠ¤ ìµœì¢… ê²€ì¦

Phase 5: í’ˆì§ˆ ë³´ì¦ ë° ê²€ì¦
- 31ê°œ í•˜ë“œì½”ë”© ìœ„ë°˜ 100% ì œê±° ê²€ì¦
- 99.9% ì´ìƒ ì»´í”Œë¼ì´ì–¸ìŠ¤ ì ìˆ˜ ë‹¬ì„± ê²€ì¦
- ë ˆê±°ì‹œ íŒ¨í„´ ì™„ì „ ì œê±° í™•ì¸
- LLM ê¸°ë°˜ ë™ì  ë¡œì§ ë™ìž‘ ê²€ì¦
"""

import ast
import os
import sys
import re
import json
import logging
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Set, Tuple
from dataclasses import dataclass

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì„¤ì •
project_root = Path(__file__).parent.parent.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

@dataclass
class HardcodingViolation:
    """í•˜ë“œì½”ë”© ìœ„ë°˜ ì •ë³´"""
    file_path: str
    line_number: int
    line_content: str
    violation_type: str
    severity: str
    description: str
    pattern_matched: str

class ZeroHardcodingComplianceVerifier:
    """Zero-Hardcoding ì»´í”Œë¼ì´ì–¸ìŠ¤ ê²€ì¦ê¸°"""
    
    def __init__(self):
        self.verification_results = {
            "test_id": f"hardcoding_compliance_{int(datetime.now().timestamp())}",
            "timestamp": datetime.now().isoformat(),
            "target_violations": 31,
            "violations_found": [],
            "compliance_score": 0.0,
            "files_scanned": 0,
            "lines_scanned": 0,
            "overall_status": "unknown"
        }
        
        # í•˜ë“œì½”ë”© íŒ¨í„´ ì •ì˜ (ì œê±°ë˜ì–´ì•¼ í•  íŒ¨í„´ë“¤)
        self.forbidden_patterns = {
            # ë„ë©”ì¸ë³„ í‚¤ì›Œë“œ ë§¤ì¹­
            "domain_keyword_matching": [
                r'if\s+["\']ë„ì¦ˆ["\'].*in.*query',
                r'if\s+["\']ê· ì¼ì„±["\'].*in.*query',
                r'if\s+["\']ë°˜ë„ì²´["\'].*in.*query',
                r'if\s+["\']semiconductor["\'].*in.*query',
                r'if\s+.*\.lower\(\).*in.*\[.*["\']semiconductor["\'].*\]'
            ],
            
            # ì‚¬ì „ ì •ì˜ëœ ë„ë©”ì¸ ì¹´í…Œê³ ë¦¬
            "predefined_domain_categories": [
                r'domain_categories\s*=\s*\{',
                r'DOMAIN_CATEGORIES\s*=\s*\{',
                r'domain_patterns\s*=\s*\{.*semiconductor.*\}',
                r'methodology_database\s*=\s*\{.*manufacturing.*\}'
            ],
            
            # í•˜ë“œì½”ë”©ëœ í”„ë¡œì„¸ìŠ¤ íƒ€ìž…
            "hardcoded_process_types": [
                r'process_type\s*=\s*["\']ion_implantation["\']',
                r'process_type\s*=\s*["\']semiconductor["\']',
                r'PROCESS_TYPE\s*=\s*["\'].*["\']'
            ],
            
            # ì‚¬ìš©ìž ìœ í˜•ë³„ í•˜ë“œì½”ë”© ë¶„ê¸°
            "user_type_hardcoding": [
                r'if\s+user_type\s*==\s*["\']expert["\']',
                r'if\s+user_level\s*==\s*["\']beginner["\']',
                r'USER_TYPE\s*=\s*["\'].*["\']'
            ],
            
            # í•˜ë“œì½”ë”©ëœ ì—”ì§„ ìš°ì„ ìˆœìœ„
            "engine_priority_hardcoding": [
                r'SEMICONDUCTOR_ENGINE_AVAILABLE',
                r'if\s+SEMICONDUCTOR_ENGINE_AVAILABLE',
                r'ENGINE_PRIORITY\s*=\s*\{',
                r'engine_priority\s*=\s*\['
            ],
            
            # í•˜ë“œì½”ë”©ëœ ì—ì´ì „íŠ¸ ì„ íƒ
            "agent_selection_hardcoding": [
                r'agent\.id\s*==\s*["\']data_loader["\']',
                r'agent\.id\s*==\s*["\']eda_tools["\']',
                r'agent_id\s*==\s*["\'].*["\'].*if',
                r'next\(\(agent.*agent\.id\s*==.*\), None\)'
            ],
            
            # í•˜ë“œì½”ë”©ëœ ë„ë©”ì¸ ë¶„ê¸°
            "domain_branching_hardcoding": [
                r'if\s+domain\s*==\s*["\']semiconductor["\']',
                r'if\s+domain\s*==\s*["\']finance["\']',
                r'elif\s+domain\s*==\s*["\'].*["\']',
                r'domain\s*in\s*\[.*["\']semiconductor["\'].*\]'
            ]
        }
        
        # ìŠ¤ìº” ëŒ€ìƒ íŒŒì¼ íŒ¨í„´ - coreì™€ servicesë§Œ ìŠ¤ìº”
        self.scan_patterns = [
            "core/**/*.py",
            "services/**/*.py",
            "config/**/*.py"
        ]
        
        # ì œì™¸í•  íŒŒì¼/ë””ë ‰í† ë¦¬
        self.exclude_patterns = [
            "**/__pycache__/**",
            "**/.*/**",
            "**/node_modules/**",
            "**/.venv/**",
            "**/venv/**",
            "**/env/**",
            "**/tests/**",
            "**/legacy/**",  # legacy í´ë”ëŠ” ì œì™¸
            "**/*test*.py",
            "**/*_test.py",
            "**/site-packages/**",
            "**/debug_logs/**",
            "**/a2a_ds_servers/**",
            "**/examples/**",
            "**/docs/**"
        ]
    
    async def run_compliance_verification(self) -> Dict[str, Any]:
        """ì»´í”Œë¼ì´ì–¸ìŠ¤ ê²€ì¦ ì‹¤í–‰"""
        logger.info("ðŸ” Starting Zero-Hardcoding compliance verification...")
        
        try:
            # 1. íŒŒì¼ ìŠ¤ìº”
            files_to_scan = self._get_files_to_scan()
            logger.info(f"ðŸ“ Found {len(files_to_scan)} files to scan")
            
            # 2. í•˜ë“œì½”ë”© íŒ¨í„´ ê²€ìƒ‰
            await self._scan_for_hardcoding_patterns(files_to_scan)
            
            # 3. AST ê¸°ë°˜ ì‹¬í™” ë¶„ì„
            await self._perform_ast_analysis(files_to_scan)
            
            # 4. ì»´í”Œë¼ì´ì–¸ìŠ¤ ì ìˆ˜ ê³„ì‚°
            self._calculate_compliance_score()
            
            # 5. ê²°ê³¼ ì €ìž¥
            await self._save_compliance_results()
            
            logger.info(f"âœ… Compliance verification completed: {self.verification_results['compliance_score']:.1f}%")
            return self.verification_results
            
        except Exception as e:
            logger.error(f"âŒ Compliance verification failed: {e}")
            self.verification_results["error"] = str(e)
            self.verification_results["overall_status"] = "failed"
            return self.verification_results
    
    def _get_files_to_scan(self) -> List[Path]:
        """ìŠ¤ìº”í•  íŒŒì¼ ëª©ë¡ ìƒì„±"""
        files_to_scan = []
        
        for pattern in self.scan_patterns:
            for file_path in project_root.glob(pattern):
                if file_path.is_file():
                    # ì œì™¸ íŒ¨í„´ í™•ì¸
                    should_exclude = False
                    for exclude_pattern in self.exclude_patterns:
                        if file_path.match(exclude_pattern):
                            should_exclude = True
                            break
                    
                    if not should_exclude:
                        files_to_scan.append(file_path)
        
        return files_to_scan
    
    async def _scan_for_hardcoding_patterns(self, files_to_scan: List[Path]):
        """í•˜ë“œì½”ë”© íŒ¨í„´ ê²€ìƒ‰"""
        logger.info("ðŸ” Scanning for hardcoding patterns...")
        
        total_lines = 0
        
        for file_path in files_to_scan:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    lines = f.readlines()
                    total_lines += len(lines)
                    
                    for line_num, line in enumerate(lines, 1):
                        line_content = line.strip()
                        
                        # ê° íŒ¨í„´ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ê²€ì‚¬
                        for violation_type, patterns in self.forbidden_patterns.items():
                            for pattern in patterns:
                                if re.search(pattern, line_content, re.IGNORECASE):
                                    violation = HardcodingViolation(
                                        file_path=str(file_path.relative_to(project_root)),
                                        line_number=line_num,
                                        line_content=line_content,
                                        violation_type=violation_type,
                                        severity=self._get_violation_severity(violation_type),
                                        description=self._get_violation_description(violation_type),
                                        pattern_matched=pattern
                                    )
                                    
                                    self.verification_results["violations_found"].append({
                                        "file_path": violation.file_path,
                                        "line_number": violation.line_number,
                                        "line_content": violation.line_content,
                                        "violation_type": violation.violation_type,
                                        "severity": violation.severity,
                                        "description": violation.description,
                                        "pattern_matched": violation.pattern_matched
                                    })
                                    
                                    logger.warning(f"âš ï¸ Hardcoding found: {violation.file_path}:{violation.line_number}")
                                    
            except Exception as e:
                logger.error(f"âŒ Error scanning {file_path}: {e}")
        
        self.verification_results["files_scanned"] = len(files_to_scan)
        self.verification_results["lines_scanned"] = total_lines
        
        logger.info(f"ðŸ“Š Scanned {len(files_to_scan)} files, {total_lines} lines")
        logger.info(f"ðŸ” Found {len(self.verification_results['violations_found'])} hardcoding violations")
    
    async def _perform_ast_analysis(self, files_to_scan: List[Path]):
        """AST ê¸°ë°˜ ì‹¬í™” ë¶„ì„"""
        logger.info("ðŸ” Performing AST-based analysis...")
        
        ast_violations = []
        
        for file_path in files_to_scan:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    source_code = f.read()
                
                # AST íŒŒì‹±
                tree = ast.parse(source_code)
                
                # AST ë°©ë¬¸ìžë¡œ í•˜ë“œì½”ë”© íŒ¨í„´ ê²€ì‚¬
                visitor = HardcodingASTVisitor(str(file_path.relative_to(project_root)))
                visitor.visit(tree)
                
                ast_violations.extend(visitor.violations)
                
            except SyntaxError:
                logger.warning(f"âš ï¸ Syntax error in {file_path}, skipping AST analysis")
            except Exception as e:
                logger.error(f"âŒ AST analysis error for {file_path}: {e}")
        
        # AST ë¶„ì„ ê²°ê³¼ë¥¼ ë©”ì¸ ê²°ê³¼ì— ì¶”ê°€
        for violation in ast_violations:
            self.verification_results["violations_found"].append(violation)
        
        logger.info(f"ðŸ” AST analysis found {len(ast_violations)} additional violations")
    
    def _calculate_compliance_score(self):
        """ì»´í”Œë¼ì´ì–¸ìŠ¤ ì ìˆ˜ ê³„ì‚°"""
        total_violations = len(self.verification_results["violations_found"])
        target_violations = self.verification_results["target_violations"]
        
        # ì‹¬ê°ë„ë³„ ê°€ì¤‘ì¹˜
        severity_weights = {
            "critical": 1.0,
            "high": 0.8,
            "medium": 0.5,
            "low": 0.2
        }
        
        # ê°€ì¤‘ ìœ„ë°˜ ì ìˆ˜ ê³„ì‚°
        weighted_violations = 0
        for violation in self.verification_results["violations_found"]:
            severity = violation.get("severity", "medium")
            weighted_violations += severity_weights.get(severity, 0.5)
        
        # ì»´í”Œë¼ì´ì–¸ìŠ¤ ì ìˆ˜ ê³„ì‚° (100% - ìœ„ë°˜ ë¹„ìœ¨)
        if target_violations > 0:
            violation_ratio = min(weighted_violations / target_violations, 1.0)
            compliance_score = max(0, (1.0 - violation_ratio) * 100)
        else:
            compliance_score = 100.0 if total_violations == 0 else 0.0
        
        self.verification_results["compliance_score"] = compliance_score
        self.verification_results["total_violations_found"] = total_violations
        self.verification_results["weighted_violations"] = weighted_violations
        
        # ì „ì²´ ìƒíƒœ ê²°ì •
        if compliance_score >= 99.9:
            self.verification_results["overall_status"] = "excellent"
        elif compliance_score >= 95.0:
            self.verification_results["overall_status"] = "good"
        elif compliance_score >= 85.0:
            self.verification_results["overall_status"] = "acceptable"
        else:
            self.verification_results["overall_status"] = "needs_improvement"
        
        logger.info(f"ðŸ“Š Compliance score: {compliance_score:.1f}%")
    
    async def _save_compliance_results(self):
        """ì»´í”Œë¼ì´ì–¸ìŠ¤ ê²°ê³¼ ì €ìž¥"""
        results_file = f"hardcoding_compliance_results_{int(datetime.now().timestamp())}.json"
        results_path = project_root / "tests" / "verification" / results_file
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        results_path.parent.mkdir(parents=True, exist_ok=True)
        
        # ê²°ê³¼ ì €ìž¥
        with open(results_path, 'w', encoding='utf-8') as f:
            json.dump(self.verification_results, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ðŸ“„ Compliance results saved to: {results_path}")
    
    def _get_violation_severity(self, violation_type: str) -> str:
        """ìœ„ë°˜ ì‹¬ê°ë„ ê²°ì •"""
        severity_map = {
            "domain_keyword_matching": "critical",
            "predefined_domain_categories": "critical",
            "hardcoded_process_types": "high",
            "user_type_hardcoding": "high",
            "engine_priority_hardcoding": "critical",
            "agent_selection_hardcoding": "high",
            "domain_branching_hardcoding": "critical"
        }
        return severity_map.get(violation_type, "medium")
    
    def _get_violation_description(self, violation_type: str) -> str:
        """ìœ„ë°˜ ì„¤ëª… ìƒì„±"""
        descriptions = {
            "domain_keyword_matching": "í•˜ë“œì½”ë”©ëœ ë„ë©”ì¸ í‚¤ì›Œë“œ ë§¤ì¹­ ë¡œì§",
            "predefined_domain_categories": "ì‚¬ì „ ì •ì˜ëœ ë„ë©”ì¸ ì¹´í…Œê³ ë¦¬",
            "hardcoded_process_types": "í•˜ë“œì½”ë”©ëœ í”„ë¡œì„¸ìŠ¤ íƒ€ìž…",
            "user_type_hardcoding": "ì‚¬ìš©ìž ìœ í˜•ë³„ í•˜ë“œì½”ë”© ë¶„ê¸°",
            "engine_priority_hardcoding": "í•˜ë“œì½”ë”©ëœ ì—”ì§„ ìš°ì„ ìˆœìœ„",
            "agent_selection_hardcoding": "í•˜ë“œì½”ë”©ëœ ì—ì´ì „íŠ¸ ì„ íƒ ë¡œì§",
            "domain_branching_hardcoding": "í•˜ë“œì½”ë”©ëœ ë„ë©”ì¸ ë¶„ê¸° ë¡œì§"
        }
        return descriptions.get(violation_type, "ì•Œ ìˆ˜ ì—†ëŠ” í•˜ë“œì½”ë”© íŒ¨í„´")


class HardcodingASTVisitor(ast.NodeVisitor):
    """AST ê¸°ë°˜ í•˜ë“œì½”ë”© íŒ¨í„´ ê²€ì¶œê¸°"""
    
    def __init__(self, file_path: str):
        self.file_path = file_path
        self.violations = []
    
    def visit_If(self, node):
        """If ë¬¸ ê²€ì‚¬"""
        # í•˜ë“œì½”ë”©ëœ ì¡°ê±´ë¬¸ ê²€ì‚¬
        if isinstance(node.test, ast.Compare):
            self._check_hardcoded_comparison(node)
        elif isinstance(node.test, ast.BoolOp):
            self._check_hardcoded_boolean_op(node)
        
        self.generic_visit(node)
    
    def visit_Assign(self, node):
        """í• ë‹¹ë¬¸ ê²€ì‚¬"""
        # í•˜ë“œì½”ë”©ëœ ë”•ì…”ë„ˆë¦¬/ë¦¬ìŠ¤íŠ¸ í• ë‹¹ ê²€ì‚¬
        if isinstance(node.value, (ast.Dict, ast.List)):
            self._check_hardcoded_data_structure(node)
        
        self.generic_visit(node)
    
    def _check_hardcoded_comparison(self, node):
        """í•˜ë“œì½”ë”©ëœ ë¹„êµ ì—°ì‚° ê²€ì‚¬"""
        try:
            # ë¬¸ìžì—´ ë¦¬í„°ëŸ´ê³¼ì˜ ë¹„êµ ê²€ì‚¬
            for comparator in node.comparators:
                if isinstance(comparator, ast.Constant) and isinstance(comparator.value, str):
                    if comparator.value in ['semiconductor', 'expert', 'beginner', 'data_loader', 'eda_tools']:
                        self.violations.append({
                            "file_path": self.file_path,
                            "line_number": node.lineno,
                            "line_content": f"Hardcoded comparison with '{comparator.value}'",
                            "violation_type": "ast_hardcoded_comparison",
                            "severity": "high",
                            "description": "ASTì—ì„œ ë°œê²¬ëœ í•˜ë“œì½”ë”©ëœ ë¹„êµ ì—°ì‚°",
                            "pattern_matched": f"comparison with '{comparator.value}'"
                        })
        except Exception:
            pass
    
    def _check_hardcoded_boolean_op(self, node):
        """í•˜ë“œì½”ë”©ëœ ë¶ˆë¦° ì—°ì‚° ê²€ì‚¬"""
        # ë³µìž¡í•œ ë¶ˆë¦° ì—°ì‚°ì—ì„œì˜ í•˜ë“œì½”ë”© íŒ¨í„´ ê²€ì‚¬
        pass
    
    def _check_hardcoded_data_structure(self, node):
        """í•˜ë“œì½”ë”©ëœ ë°ì´í„° êµ¬ì¡° ê²€ì‚¬"""
        try:
            if isinstance(node.value, ast.Dict):
                # ë”•ì…”ë„ˆë¦¬ì˜ í‚¤ì—ì„œ ë„ë©”ì¸ ê´€ë ¨ í•˜ë“œì½”ë”© ê²€ì‚¬
                for key in node.value.keys:
                    if isinstance(key, ast.Constant) and isinstance(key.value, str):
                        if key.value in ['semiconductor', 'manufacturing', 'finance', 'healthcare']:
                            self.violations.append({
                                "file_path": self.file_path,
                                "line_number": node.lineno,
                                "line_content": f"Hardcoded dictionary key '{key.value}'",
                                "violation_type": "ast_hardcoded_dict",
                                "severity": "medium",
                                "description": "ASTì—ì„œ ë°œê²¬ëœ í•˜ë“œì½”ë”©ëœ ë”•ì…”ë„ˆë¦¬ í‚¤",
                                "pattern_matched": f"dict key '{key.value}'"
                            })
        except Exception:
            pass


async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ðŸ” Zero-Hardcoding Compliance Verification")
    print("=" * 50)
    
    verifier = ZeroHardcodingComplianceVerifier()
    results = await verifier.run_compliance_verification()
    
    print("\nðŸ“Š Compliance Results Summary:")
    print(f"Overall Status: {results['overall_status']}")
    print(f"Compliance Score: {results['compliance_score']:.1f}%")
    print(f"Total Violations Found: {results.get('total_violations_found', 0)}")
    print(f"Target Violations: {results['target_violations']}")
    print(f"Files Scanned: {results['files_scanned']}")
    print(f"Lines Scanned: {results['lines_scanned']}")
    
    if results['compliance_score'] >= 99.9:
        print("\nðŸŽ‰ Excellent! Zero-Hardcoding compliance achieved!")
    elif results['compliance_score'] >= 95.0:
        print("\nâœ… Good! Very high compliance score!")
    elif results['compliance_score'] >= 85.0:
        print("\nâš ï¸ Acceptable, but some hardcoding patterns remain.")
    else:
        print("\nâŒ Needs significant improvements to achieve zero-hardcoding.")
    
    # ìœ„ë°˜ ì‚¬í•­ ìƒì„¸ ì¶œë ¥
    if results.get('violations_found'):
        print(f"\nðŸ” Found {len(results['violations_found'])} violations:")
        for i, violation in enumerate(results['violations_found'][:10], 1):  # ìµœëŒ€ 10ê°œë§Œ í‘œì‹œ
            print(f"{i}. {violation['file_path']}:{violation['line_number']} - {violation['violation_type']}")
        
        if len(results['violations_found']) > 10:
            print(f"... and {len(results['violations_found']) - 10} more violations")
    
    return results


if __name__ == "__main__":
    import asyncio
    asyncio.run(main())