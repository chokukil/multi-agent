#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ” E2E í…ŒìŠ¤íŠ¸ ì„±ëŠ¥ ì§„ë‹¨ ë„êµ¬
LLM First E2E í…ŒìŠ¤íŠ¸ì˜ ë³‘ëª© ì§€ì ì„ ì°¾ê³  ê°œì„  ë°©ì•ˆì„ ì œì‹œ

ì§„ë‹¨ ì˜ì—­:
1. ì»´í¬ë„ŒíŠ¸ë³„ ì´ˆê¸°í™” ì‹œê°„
2. LLM í˜¸ì¶œ ì‘ë‹µ ì‹œê°„
3. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
4. ê° ë‹¨ê³„ë³„ ì‹¤í–‰ ì‹œê°„
"""

import asyncio
import time
import logging
from datetime import datetime
from typing import Dict, List, Any
from pathlib import Path

# Universal Engine Components
from core.universal_engine.llm_factory import LLMFactory
from core.universal_engine.universal_query_processor import UniversalQueryProcessor
from core.universal_engine.meta_reasoning_engine import MetaReasoningEngine
from core.universal_engine.adaptive_user_understanding import AdaptiveUserUnderstanding

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class E2EPerformanceDiagnosis:
    """E2E í…ŒìŠ¤íŠ¸ ì„±ëŠ¥ ì§„ë‹¨ê¸°"""
    
    def __init__(self):
        self.diagnosis_results = {
            "diagnosis_id": f"e2e_diagnosis_{int(time.time())}",
            "timestamp": datetime.now().isoformat(),
            "initialization_times": {},
            "llm_response_times": {},
            "component_performance": {},
            "bottlenecks": [],
            "recommendations": []
        }
    
    async def run_complete_diagnosis(self):
        """ì™„ì „í•œ ì„±ëŠ¥ ì§„ë‹¨ ì‹¤í–‰"""
        print("ğŸ” Starting E2E Performance Diagnosis...")
        
        # 1. ì´ˆê¸°í™” ì‹œê°„ ì§„ë‹¨
        await self._diagnose_initialization_times()
        
        # 2. LLM ì‘ë‹µ ì‹œê°„ ì§„ë‹¨
        await self._diagnose_llm_response_times()
        
        # 3. ì»´í¬ë„ŒíŠ¸ë³„ ì„±ëŠ¥ ì§„ë‹¨
        await self._diagnose_component_performance()
        
        # 4. ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰ ì‹œê°„ ì§„ë‹¨
        await self._diagnose_scenario_execution()
        
        # 5. ë³‘ëª© ì§€ì  ë¶„ì„
        self._analyze_bottlenecks()
        
        # 6. ê°œì„  ë°©ì•ˆ ì œì‹œ
        self._generate_recommendations()
        
        # 7. ê²°ê³¼ ì¶œë ¥
        self._print_diagnosis_results()
        
        return self.diagnosis_results
    
    async def _diagnose_initialization_times(self):
        """ì´ˆê¸°í™” ì‹œê°„ ì§„ë‹¨"""
        print("\nğŸ“Š 1. ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì‹œê°„ ì§„ë‹¨...")
        
        # LLMFactory ì´ˆê¸°í™”
        start_time = time.time()
        try:
            llm_client = LLMFactory.create_llm()
            init_time = time.time() - start_time
            self.diagnosis_results["initialization_times"]["llm_factory"] = {
                "time": init_time,
                "status": "success"
            }
            print(f"  âœ… LLMFactory: {init_time:.3f}s")
        except Exception as e:
            init_time = time.time() - start_time
            self.diagnosis_results["initialization_times"]["llm_factory"] = {
                "time": init_time,
                "status": "failed",
                "error": str(e)
            }
            print(f"  âŒ LLMFactory: {init_time:.3f}s (FAILED: {e})")
        
        # UniversalQueryProcessor ì´ˆê¸°í™”
        start_time = time.time()
        try:
            query_processor = UniversalQueryProcessor()
            init_time = time.time() - start_time
            self.diagnosis_results["initialization_times"]["query_processor"] = {
                "time": init_time,
                "status": "success"
            }
            print(f"  âœ… UniversalQueryProcessor: {init_time:.3f}s")
            
            # ì‹¤ì œ initialize ë©”ì„œë“œ í…ŒìŠ¤íŠ¸
            start_time = time.time()
            init_result = await query_processor.initialize()
            full_init_time = time.time() - start_time
            self.diagnosis_results["initialization_times"]["query_processor_full"] = {
                "time": full_init_time,
                "status": init_result.get("overall_status", "unknown")
            }
            print(f"  âœ… UniversalQueryProcessor.initialize(): {full_init_time:.3f}s")
            
        except Exception as e:
            init_time = time.time() - start_time
            self.diagnosis_results["initialization_times"]["query_processor"] = {
                "time": init_time,
                "status": "failed",
                "error": str(e)
            }
            print(f"  âŒ UniversalQueryProcessor: {init_time:.3f}s (FAILED: {e})")
        
        # MetaReasoningEngine ì´ˆê¸°í™”
        start_time = time.time()
        try:
            meta_reasoning = MetaReasoningEngine()
            init_time = time.time() - start_time
            self.diagnosis_results["initialization_times"]["meta_reasoning"] = {
                "time": init_time,
                "status": "success"
            }
            print(f"  âœ… MetaReasoningEngine: {init_time:.3f}s")
        except Exception as e:
            init_time = time.time() - start_time
            self.diagnosis_results["initialization_times"]["meta_reasoning"] = {
                "time": init_time,
                "status": "failed",
                "error": str(e)
            }
            print(f"  âŒ MetaReasoningEngine: {init_time:.3f}s (FAILED: {e})")
        
        # AdaptiveUserUnderstanding ì´ˆê¸°í™”
        start_time = time.time()
        try:
            user_understanding = AdaptiveUserUnderstanding()
            init_time = time.time() - start_time
            self.diagnosis_results["initialization_times"]["user_understanding"] = {
                "time": init_time,
                "status": "success"
            }
            print(f"  âœ… AdaptiveUserUnderstanding: {init_time:.3f}s")
        except Exception as e:
            init_time = time.time() - start_time
            self.diagnosis_results["initialization_times"]["user_understanding"] = {
                "time": init_time,
                "status": "failed",
                "error": str(e)
            }
            print(f"  âŒ AdaptiveUserUnderstanding: {init_time:.3f}s (FAILED: {e})")
    
    async def _diagnose_llm_response_times(self):
        """LLM ì‘ë‹µ ì‹œê°„ ì§„ë‹¨"""
        print("\nğŸ“Š 2. LLM ì‘ë‹µ ì‹œê°„ ì§„ë‹¨...")
        
        try:
            llm_client = LLMFactory.create_llm()
            
            test_queries = [
                "Simple test query",
                "What is the average of these numbers: 1, 2, 3, 4, 5?",
                "Analyze this complex multivariate regression problem with heteroscedasticity"
            ]
            
            for i, query in enumerate(test_queries):
                start_time = time.time()
                try:
                    response = await llm_client.ainvoke(query)
                    response_time = time.time() - start_time
                    
                    self.diagnosis_results["llm_response_times"][f"query_{i+1}"] = {
                        "query_length": len(query),
                        "response_time": response_time,
                        "status": "success",
                        "response_length": len(str(response))
                    }
                    print(f"  âœ… Query {i+1} ({len(query)} chars): {response_time:.3f}s")
                    
                except Exception as e:
                    response_time = time.time() - start_time
                    self.diagnosis_results["llm_response_times"][f"query_{i+1}"] = {
                        "query_length": len(query),
                        "response_time": response_time,
                        "status": "failed",
                        "error": str(e)
                    }
                    print(f"  âŒ Query {i+1}: {response_time:.3f}s (FAILED: {e})")
                
                # ì§§ì€ ëŒ€ê¸° ì‹œê°„ìœ¼ë¡œ ì—°ì† í˜¸ì¶œ ë°©ì§€
                await asyncio.sleep(0.1)
                
        except Exception as e:
            print(f"  âŒ LLM Client creation failed: {e}")
            self.diagnosis_results["llm_response_times"]["creation_error"] = str(e)
    
    async def _diagnose_component_performance(self):
        """ì»´í¬ë„ŒíŠ¸ë³„ ì„±ëŠ¥ ì§„ë‹¨"""
        print("\nğŸ“Š 3. ì»´í¬ë„ŒíŠ¸ë³„ ì„±ëŠ¥ ì§„ë‹¨...")
        
        try:
            # ì‚¬ìš©ì ì´í•´ ë¶„ì„ ì„±ëŠ¥
            user_understanding = AdaptiveUserUnderstanding()
            start_time = time.time()
            try:
                result = await user_understanding.analyze_user_expertise("What is machine learning?", [])
                analysis_time = time.time() - start_time
                self.diagnosis_results["component_performance"]["user_analysis"] = {
                    "time": analysis_time,
                    "status": "success",
                    "result_size": len(str(result))
                }
                print(f"  âœ… User Analysis: {analysis_time:.3f}s")
            except Exception as e:
                analysis_time = time.time() - start_time
                self.diagnosis_results["component_performance"]["user_analysis"] = {
                    "time": analysis_time,
                    "status": "failed",
                    "error": str(e)
                }
                print(f"  âŒ User Analysis: {analysis_time:.3f}s (FAILED: {e})")
            
            # ë©”íƒ€ ì¶”ë¡  ì„±ëŠ¥
            meta_reasoning = MetaReasoningEngine()
            start_time = time.time()
            try:
                result = await meta_reasoning.analyze_request(
                    "What is the average?", 
                    {"test": "data"}, 
                    {"context": "test"}
                )
                meta_time = time.time() - start_time
                self.diagnosis_results["component_performance"]["meta_reasoning"] = {
                    "time": meta_time,
                    "status": "success",
                    "result_size": len(str(result))
                }
                print(f"  âœ… Meta Reasoning: {meta_time:.3f}s")
            except Exception as e:
                meta_time = time.time() - start_time
                self.diagnosis_results["component_performance"]["meta_reasoning"] = {
                    "time": meta_time,
                    "status": "failed",
                    "error": str(e)
                }
                print(f"  âŒ Meta Reasoning: {meta_time:.3f}s (FAILED: {e})")
                
        except Exception as e:
            print(f"  âŒ Component performance diagnosis failed: {e}")
    
    async def _diagnose_scenario_execution(self):
        """ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰ ì‹œê°„ ì§„ë‹¨"""
        print("\nğŸ“Š 4. ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰ ì‹œê°„ ì§„ë‹¨...")
        
        # ê°„ë‹¨í•œ ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰ ì‹œê°„ ì¸¡ì •
        scenarios = [
            {
                "name": "simple_query",
                "query": "What is 2+2?",
                "timeout": 10
            },
            {
                "name": "beginner_query", 
                "query": "I don't understand this data. Can you help?",
                "timeout": 15
            }
        ]
        
        for scenario in scenarios:
            print(f"  ğŸ” Testing scenario: {scenario['name']}")
            start_time = time.time()
            
            try:
                # íƒ€ì„ì•„ì›ƒì„ ì ìš©í•œ ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰
                result = await asyncio.wait_for(
                    self._execute_single_scenario(scenario),
                    timeout=scenario['timeout']
                )
                
                execution_time = time.time() - start_time
                self.diagnosis_results["component_performance"][f"scenario_{scenario['name']}"] = {
                    "time": execution_time,
                    "status": "success",
                    "timeout": scenario['timeout']
                }
                print(f"    âœ… {scenario['name']}: {execution_time:.3f}s")
                
            except asyncio.TimeoutError:
                execution_time = time.time() - start_time
                self.diagnosis_results["component_performance"][f"scenario_{scenario['name']}"] = {
                    "time": execution_time,
                    "status": "timeout",
                    "timeout": scenario['timeout']
                }
                print(f"    â° {scenario['name']}: TIMEOUT after {execution_time:.3f}s")
                
            except Exception as e:
                execution_time = time.time() - start_time
                self.diagnosis_results["component_performance"][f"scenario_{scenario['name']}"] = {
                    "time": execution_time,
                    "status": "failed",
                    "error": str(e)
                }
                print(f"    âŒ {scenario['name']}: {execution_time:.3f}s (FAILED: {e})")
    
    async def _execute_single_scenario(self, scenario):
        """ë‹¨ì¼ ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰"""
        user_understanding = AdaptiveUserUnderstanding()
        meta_reasoning = MetaReasoningEngine()
        
        # 1. ì‚¬ìš©ì ë¶„ì„
        user_analysis = await user_understanding.analyze_user_expertise(scenario["query"], [])
        
        # 2. ë©”íƒ€ ì¶”ë¡ 
        meta_result = await meta_reasoning.analyze_request(
            scenario["query"],
            {"test": "data"},
            {"user_analysis": user_analysis}
        )
        
        return {
            "user_analysis": user_analysis,
            "meta_reasoning": meta_result
        }
    
    def _analyze_bottlenecks(self):
        """ë³‘ëª© ì§€ì  ë¶„ì„"""
        print("\nğŸ“Š 5. ë³‘ëª© ì§€ì  ë¶„ì„...")
        
        bottlenecks = []
        
        # ì´ˆê¸°í™” ì‹œê°„ ë¶„ì„
        init_times = self.diagnosis_results["initialization_times"]
        for component, data in init_times.items():
            if data.get("time", 0) > 2.0:  # 2ì´ˆ ì´ìƒ
                bottlenecks.append({
                    "type": "initialization",
                    "component": component,
                    "time": data["time"],
                    "severity": "high" if data["time"] > 5.0 else "medium"
                })
        
        # LLM ì‘ë‹µ ì‹œê°„ ë¶„ì„
        llm_times = self.diagnosis_results["llm_response_times"]
        for query_id, data in llm_times.items():
            if isinstance(data, dict) and data.get("response_time", 0) > 5.0:  # 5ì´ˆ ì´ìƒ
                bottlenecks.append({
                    "type": "llm_response",
                    "component": query_id,
                    "time": data["response_time"],
                    "severity": "high" if data["response_time"] > 10.0 else "medium"
                })
        
        # ì»´í¬ë„ŒíŠ¸ ì„±ëŠ¥ ë¶„ì„
        comp_perf = self.diagnosis_results["component_performance"]
        for component, data in comp_perf.items():
            if isinstance(data, dict) and data.get("time", 0) > 10.0:  # 10ì´ˆ ì´ìƒ
                bottlenecks.append({
                    "type": "component_performance",
                    "component": component,
                    "time": data["time"],
                    "severity": "high" if data["time"] > 20.0 else "medium"
                })
        
        self.diagnosis_results["bottlenecks"] = bottlenecks
        
        for bottleneck in bottlenecks:
            severity_emoji = "ğŸ”´" if bottleneck["severity"] == "high" else "ğŸŸ¡"
            print(f"  {severity_emoji} {bottleneck['type']}: {bottleneck['component']} ({bottleneck['time']:.3f}s)")
    
    def _generate_recommendations(self):
        """ê°œì„  ë°©ì•ˆ ìƒì„±"""
        print("\nğŸ’¡ 6. ê°œì„  ë°©ì•ˆ ìƒì„±...")
        
        recommendations = []
        
        # ë³‘ëª© ì§€ì  ê¸°ë°˜ ì¶”ì²œ
        for bottleneck in self.diagnosis_results["bottlenecks"]:
            if bottleneck["type"] == "initialization":
                recommendations.append({
                    "category": "initialization",
                    "priority": "high",
                    "suggestion": f"{bottleneck['component']} ì´ˆê¸°í™” ìµœì í™” - ì§€ì—° ë¡œë”© ë˜ëŠ” ìºì‹± ì ìš©"
                })
            elif bottleneck["type"] == "llm_response":
                recommendations.append({
                    "category": "llm_performance",
                    "priority": "high", 
                    "suggestion": "LLM ì‘ë‹µ ì‹œê°„ ìµœì í™” - ì§§ì€ í”„ë¡¬í”„íŠ¸, ë³‘ë ¬ ì²˜ë¦¬, ë˜ëŠ” ìºì‹±"
                })
            elif bottleneck["type"] == "component_performance":
                recommendations.append({
                    "category": "component_optimization",
                    "priority": "medium",
                    "suggestion": f"{bottleneck['component']} ì„±ëŠ¥ ìµœì í™” - ì•Œê³ ë¦¬ì¦˜ ê°œì„  ë˜ëŠ” ë¹„ë™ê¸° ì²˜ë¦¬"
                })
        
        # ì¼ë°˜ì ì¸ ìµœì í™” ì¶”ì²œ
        recommendations.extend([
            {
                "category": "testing_strategy",
                "priority": "high",
                "suggestion": "ì ì§„ì  í…ŒìŠ¤íŠ¸ - ë‹¨ê³„ë³„ ì‹¤í–‰ìœ¼ë¡œ ë¬¸ì œ ì§€ì  ê²©ë¦¬"
            },
            {
                "category": "logging",
                "priority": "medium",
                "suggestion": "ìƒì„¸ ë¡œê¹… ì¶”ê°€ - ê° ë‹¨ê³„ë³„ ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§"
            },
            {
                "category": "timeout_management",
                "priority": "medium",
                "suggestion": "ì ì‘ì  íƒ€ì„ì•„ì›ƒ - ì»´í¬ë„ŒíŠ¸ë³„ ë‹¤ë¥¸ íƒ€ì„ì•„ì›ƒ ì„¤ì •"
            }
        ])
        
        self.diagnosis_results["recommendations"] = recommendations
        
        for i, rec in enumerate(recommendations, 1):
            priority_emoji = "ğŸ”¥" if rec["priority"] == "high" else "âš¡"
            print(f"  {priority_emoji} {i}. [{rec['category']}] {rec['suggestion']}")
    
    def _print_diagnosis_results(self):
        """ì§„ë‹¨ ê²°ê³¼ ì¶œë ¥"""
        print("\n" + "="*60)
        print("ğŸ“‹ E2E ì„±ëŠ¥ ì§„ë‹¨ ìš”ì•½")
        print("="*60)
        
        # ì´ˆê¸°í™” ì‹œê°„ ìš”ì•½
        init_times = [data.get("time", 0) for data in self.diagnosis_results["initialization_times"].values() 
                     if isinstance(data, dict)]
        if init_times:
            print(f"ğŸš€ ì´ ì´ˆê¸°í™” ì‹œê°„: {sum(init_times):.3f}s")
            print(f"ğŸš€ í‰ê·  ì´ˆê¸°í™” ì‹œê°„: {sum(init_times)/len(init_times):.3f}s")
        
        # LLM ì‘ë‹µ ì‹œê°„ ìš”ì•½
        llm_times = [data.get("response_time", 0) for data in self.diagnosis_results["llm_response_times"].values() 
                    if isinstance(data, dict) and "response_time" in data]
        if llm_times:
            print(f"ğŸ¤– í‰ê·  LLM ì‘ë‹µ ì‹œê°„: {sum(llm_times)/len(llm_times):.3f}s")
            print(f"ğŸ¤– ìµœëŒ€ LLM ì‘ë‹µ ì‹œê°„: {max(llm_times):.3f}s")
        
        # ë³‘ëª© ì§€ì  ìš”ì•½
        high_severity = len([b for b in self.diagnosis_results["bottlenecks"] if b["severity"] == "high"])
        medium_severity = len([b for b in self.diagnosis_results["bottlenecks"] if b["severity"] == "medium"])
        print(f"âš ï¸ ì‹¬ê°í•œ ë³‘ëª©: {high_severity}ê°œ")
        print(f"âš ï¸ ì¤‘ê°„ ë³‘ëª©: {medium_severity}ê°œ")
        
        # ì¶”ì²œì‚¬í•­ ìš”ì•½
        high_priority = len([r for r in self.diagnosis_results["recommendations"] if r["priority"] == "high"])
        print(f"ğŸ’¡ ìš°ì„ ìˆœìœ„ ë†’ì€ ê°œì„ ì‚¬í•­: {high_priority}ê°œ")
        
        print("\nğŸ“ ìƒì„¸ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")


async def main():
    """ë©”ì¸ ì‹¤í–‰"""
    diagnosis = E2EPerformanceDiagnosis()
    
    try:
        results = await diagnosis.run_complete_diagnosis()
        
        # ê²°ê³¼ ì €ì¥
        import json
        output_file = Path("tests/verification/e2e_diagnosis_results.json")
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ’¾ ì§„ë‹¨ ê²°ê³¼ ì €ì¥ë¨: {output_file}")
        
    except Exception as e:
        print(f"\nâŒ ì§„ë‹¨ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        logger.error(f"Diagnosis failed: {e}")


if __name__ == "__main__":
    asyncio.run(main())