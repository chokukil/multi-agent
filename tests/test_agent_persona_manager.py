#!/usr/bin/env python3
"""
Agent Persona Manager í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸

Context Engineering INSTRUCTIONS ë ˆì´ì–´ì˜ Agent Persona Manager ê¸°ëŠ¥ì„ ì¢…í•©ì ìœ¼ë¡œ í…ŒìŠ¤íŠ¸

Test Coverage:
- Persona Registry í…ŒìŠ¤íŠ¸
- Dynamic Persona Selector í…ŒìŠ¤íŠ¸
- Context Adaptation Engine í…ŒìŠ¤íŠ¸
- Agent Persona Manager í†µí•© í…ŒìŠ¤íŠ¸
- ì„±ëŠ¥ ì¶”ì  ë° ë¶„ì„ í…ŒìŠ¤íŠ¸
"""

import pytest
import asyncio
import json
import tempfile
from datetime import datetime
from unittest.mock import AsyncMock, MagicMock, patch
from pathlib import Path

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'a2a_ds_servers', 'context_engineering'))

# í…ŒìŠ¤íŠ¸ ëŒ€ìƒ ì„í¬íŠ¸
from agent_persona_manager import (
    AgentPersonaManager,
    PersonaRegistry,
    DynamicPersonaSelector,
    ContextAdaptationEngine,
    AgentPersona,
    PersonaContext,
    PersonaRecommendation,
    PersonaType,
    PersonaScope,
    get_agent_persona_manager,
    initialize_agent_persona_manager
)

class TestPersonaRegistry:
    """Persona Registry í…ŒìŠ¤íŠ¸"""
    
    @pytest.fixture
    def temp_registry_path(self):
        """ì„ì‹œ ë ˆì§€ìŠ¤íŠ¸ë¦¬ íŒŒì¼ ê²½ë¡œ"""
        with tempfile.NamedTemporaryFile(delete=False, suffix='.json') as f:
            yield f.name
        # ì •ë¦¬
        try:
            os.unlink(f.name)
        except FileNotFoundError:
            pass
    
    @pytest.fixture
    def persona_registry(self, temp_registry_path):
        """Persona Registry í”½ìŠ¤ì²˜"""
        return PersonaRegistry(temp_registry_path)
    
    def test_persona_registry_initialization(self, persona_registry):
        """Persona Registry ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸"""
        assert persona_registry.registry_path is not None
        assert isinstance(persona_registry.personas, dict)
        assert isinstance(persona_registry.persona_templates, dict)
        assert len(persona_registry.persona_templates) > 0
        
        # ê¸°ë³¸ í…œí”Œë¦¿ í™•ì¸
        assert "data_scientist_expert" in persona_registry.persona_templates
        assert "collaborative_facilitator" in persona_registry.persona_templates
        assert "analytical_investigator" in persona_registry.persona_templates
    
    @pytest.mark.asyncio
    async def test_load_personas_create_default(self, persona_registry):
        """ê¸°ë³¸ í˜ë¥´ì†Œë‚˜ ìƒì„± í…ŒìŠ¤íŠ¸"""
        personas = await persona_registry.load_personas()
        
        assert len(personas) > 0
        
        # ê° ì—ì´ì „íŠ¸ë³„ í˜ë¥´ì†Œë‚˜ í™•ì¸
        agent_ids = set(persona.agent_id for persona in personas.values())
        expected_agents = [
            "orchestrator", "data_cleaning", "data_loader", 
            "data_visualization", "pandas_collaboration_hub"
        ]
        
        for agent_id in expected_agents:
            assert agent_id in agent_ids
        
        # í˜ë¥´ì†Œë‚˜ êµ¬ì¡° í™•ì¸
        for persona in personas.values():
            assert isinstance(persona, AgentPersona)
            assert persona.persona_id is not None
            assert persona.agent_id is not None
            assert isinstance(persona.persona_type, PersonaType)
            assert isinstance(persona.scope, PersonaScope)
            assert persona.system_prompt != ""
            assert len(persona.behavioral_traits) > 0
            assert len(persona.expertise_areas) > 0
    
    @pytest.mark.asyncio
    async def test_save_and_load_personas(self, persona_registry):
        """í˜ë¥´ì†Œë‚˜ ì €ì¥ ë° ë¡œë“œ í…ŒìŠ¤íŠ¸"""
        # ê¸°ë³¸ í˜ë¥´ì†Œë‚˜ ìƒì„±
        await persona_registry.load_personas()
        original_count = len(persona_registry.personas)
        
        # ì €ì¥
        await persona_registry.save_personas()
        
        # ìƒˆë¡œìš´ ì¸ìŠ¤í„´ìŠ¤ë¡œ ë¡œë“œ
        new_registry = PersonaRegistry(persona_registry.registry_path)
        loaded_personas = await new_registry.load_personas()
        
        assert len(loaded_personas) == original_count
        
        # ë°ì´í„° ì¼ì¹˜ í™•ì¸
        for persona_id, original_persona in persona_registry.personas.items():
            loaded_persona = loaded_personas[persona_id]
            assert loaded_persona.persona_id == original_persona.persona_id
            assert loaded_persona.agent_id == original_persona.agent_id
            assert loaded_persona.persona_type == original_persona.persona_type
            assert loaded_persona.name == original_persona.name
    
    @pytest.mark.asyncio
    async def test_get_personas_by_agent(self, persona_registry):
        """ì—ì´ì „íŠ¸ë³„ í˜ë¥´ì†Œë‚˜ ì¡°íšŒ í…ŒìŠ¤íŠ¸"""
        await persona_registry.load_personas()
        
        # íŠ¹ì • ì—ì´ì „íŠ¸ì˜ í˜ë¥´ì†Œë‚˜ ì¡°íšŒ
        pandas_personas = await persona_registry.get_personas_by_agent("pandas_collaboration_hub")
        
        assert len(pandas_personas) > 0
        for persona in pandas_personas:
            assert persona.agent_id == "pandas_collaboration_hub"
            assert persona.is_active is True
    
    @pytest.mark.asyncio
    async def test_update_persona_performance(self, persona_registry):
        """í˜ë¥´ì†Œë‚˜ ì„±ëŠ¥ ì—…ë°ì´íŠ¸ í…ŒìŠ¤íŠ¸"""
        await persona_registry.load_personas()
        
        # ì²« ë²ˆì§¸ í˜ë¥´ì†Œë‚˜ ì„ íƒ
        persona_id = list(persona_registry.personas.keys())[0]
        original_persona = persona_registry.personas[persona_id]
        original_usage = original_persona.usage_count
        original_success_rate = original_persona.success_rate
        
        # ì„±ê³µì ì¸ ì‚¬ìš© ì—…ë°ì´íŠ¸
        await persona_registry.update_persona_performance(persona_id, success=True, performance_score=0.85)
        
        updated_persona = persona_registry.personas[persona_id]
        assert updated_persona.usage_count == original_usage + 1
        assert updated_persona.success_rate >= original_success_rate
        assert "average_performance" in updated_persona.performance_metrics

class TestPersonaContext:
    """PersonaContext ë°ì´í„° êµ¬ì¡° í…ŒìŠ¤íŠ¸"""
    
    def test_persona_context_creation(self):
        """PersonaContext ìƒì„± í…ŒìŠ¤íŠ¸"""
        context = PersonaContext(
            context_id="test_context",
            user_request="ë°ì´í„°ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”",
            task_type="data_analysis",
            complexity_level="medium",
            collaboration_type="peer",
            required_skills=["statistics", "visualization"],
            session_history=[],
            user_preferences={"detailed": True},
            performance_requirements={"accuracy": 0.9},
            timestamp=datetime.now()
        )
        
        assert context.context_id == "test_context"
        assert context.task_type == "data_analysis"
        assert context.complexity_level == "medium"
        assert "statistics" in context.required_skills
        assert context.user_preferences["detailed"] is True

class TestDynamicPersonaSelector:
    """Dynamic Persona Selector í…ŒìŠ¤íŠ¸"""
    
    @pytest.fixture
    async def setup_persona_selector(self):
        """Persona Selector ì„¤ì •"""
        registry = PersonaRegistry("test_registry.json")
        await registry.load_personas()
        selector = DynamicPersonaSelector(registry)
        return selector, registry
    
    @pytest.mark.asyncio
    async def test_select_persona_basic(self, setup_persona_selector):
        """ê¸°ë³¸ í˜ë¥´ì†Œë‚˜ ì„ íƒ í…ŒìŠ¤íŠ¸"""
        selector, registry = await setup_persona_selector
        
        context = PersonaContext(
            context_id="test",
            user_request="ë°ì´í„°ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”",
            task_type="data_analysis",
            complexity_level="medium",
            collaboration_type="none",
            required_skills=["statistics", "data_analysis"],
            session_history=[],
            user_preferences={},
            performance_requirements={},
            timestamp=datetime.now()
        )
        
        recommendation = await selector.select_persona("pandas_collaboration_hub", context)
        
        assert isinstance(recommendation, PersonaRecommendation)
        assert recommendation.agent_id == "pandas_collaboration_hub"
        assert 0.0 <= recommendation.confidence <= 1.0
        assert recommendation.reasoning != ""
        assert isinstance(recommendation.adaptation_suggestions, list)
    
    def test_calculate_base_fitness_score(self, setup_persona_selector):
        """ê¸°ë³¸ ì í•©ì„± ì ìˆ˜ ê³„ì‚° í…ŒìŠ¤íŠ¸"""
        selector, registry = asyncio.run(setup_persona_selector)
        
        # í…ŒìŠ¤íŠ¸ìš© í˜ë¥´ì†Œë‚˜ ìƒì„±
        persona = AgentPersona(
            persona_id="test_persona",
            agent_id="test_agent",
            persona_type=PersonaType.ANALYTICAL,
            scope=PersonaScope.DOMAIN,
            name="Test Persona",
            description="Test",
            system_prompt="Test prompt",
            behavioral_traits=["analytical", "thorough"],
            expertise_areas=["data_analysis", "statistics"],
            communication_style="professional",
            collaboration_preferences={},
            context_adaptations={},
            performance_metrics={},
            usage_count=10,
            success_rate=0.8,
            created_at=datetime.now(),
            updated_at=datetime.now()
        )
        
        context = PersonaContext(
            context_id="test",
            user_request="ë°ì´í„° ë¶„ì„",
            task_type="data_analysis",
            complexity_level="medium",
            collaboration_type="none",
            required_skills=["data_analysis", "statistics"],
            session_history=[],
            user_preferences={},
            performance_requirements={},
            timestamp=datetime.now()
        )
        
        score = selector._calculate_base_fitness_score(persona, context)
        
        assert 0.0 <= score <= 1.0
        assert score > 0.5  # ì¢‹ì€ ë§¤ì¹˜ì´ë¯€ë¡œ ë†’ì€ ì ìˆ˜ ê¸°ëŒ€
    
    def test_calculate_type_fitness(self, setup_persona_selector):
        """í˜ë¥´ì†Œë‚˜ íƒ€ì… ì í•©ì„± ê³„ì‚° í…ŒìŠ¤íŠ¸"""
        selector, registry = asyncio.run(setup_persona_selector)
        
        context = PersonaContext(
            context_id="test",
            user_request="ë°ì´í„° ë¶„ì„",
            task_type="data_analysis",
            complexity_level="medium",
            collaboration_type="none",
            required_skills=[],
            session_history=[],
            user_preferences={},
            performance_requirements={},
            timestamp=datetime.now()
        )
        
        # ANALYTICAL íƒ€ì…ì€ data_analysisì— ë†’ì€ ì ìˆ˜
        analytical_score = selector._calculate_type_fitness(PersonaType.ANALYTICAL, context)
        assert analytical_score >= 0.8
        
        # COLLABORATIVE íƒ€ì…ì€ data_analysisì— ìƒëŒ€ì ìœ¼ë¡œ ë‚®ì€ ì ìˆ˜
        collaborative_score = selector._calculate_type_fitness(PersonaType.COLLABORATIVE, context)
        assert collaborative_score < analytical_score

class TestContextAdaptationEngine:
    """Context Adaptation Engine í…ŒìŠ¤íŠ¸"""
    
    @pytest.fixture
    def adaptation_engine(self):
        """Context Adaptation Engine í”½ìŠ¤ì²˜"""
        return ContextAdaptationEngine()
    
    @pytest.fixture
    def sample_persona(self):
        """ìƒ˜í”Œ í˜ë¥´ì†Œë‚˜"""
        return AgentPersona(
            persona_id="test_persona",
            agent_id="test_agent",
            persona_type=PersonaType.ANALYTICAL,
            scope=PersonaScope.DOMAIN,
            name="Test Analytical Persona",
            description="í…ŒìŠ¤íŠ¸ìš© ë¶„ì„ í˜ë¥´ì†Œë‚˜",
            system_prompt="ë‹¹ì‹ ì€ ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.",
            behavioral_traits=["analytical", "thorough"],
            expertise_areas=["data_analysis", "statistics"],
            communication_style="professional",
            collaboration_preferences={},
            context_adaptations={},
            performance_metrics={},
            usage_count=0,
            success_rate=0.0,
            created_at=datetime.now(),
            updated_at=datetime.now()
        )
    
    @pytest.fixture
    def sample_context(self):
        """ìƒ˜í”Œ ì»¨í…ìŠ¤íŠ¸"""
        return PersonaContext(
            context_id="test_context",
            user_request="ë³µì¡í•œ ë°ì´í„°ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”",
            task_type="data_analysis",
            complexity_level="high",
            collaboration_type="team",
            required_skills=["statistics", "machine_learning"],
            session_history=[],
            user_preferences={"detailed_explanation": True},
            performance_requirements={"accuracy": 0.95},
            timestamp=datetime.now()
        )
    
    @pytest.mark.asyncio
    async def test_adapt_persona_basic(self, adaptation_engine, sample_persona, sample_context):
        """ê¸°ë³¸ í˜ë¥´ì†Œë‚˜ ì ì‘ í…ŒìŠ¤íŠ¸"""
        suggestions = [
            "ë³µì¡í•œ ì‘ì—…ì„ ìœ„í•´ ë‹¨ê³„ë³„ ì ‘ê·¼",
            "íŒ€ í˜‘ì—…ì„ ìœ„í•œ ì†Œí†µ ìµœì í™”"
        ]
        
        adapted_prompt = await adaptation_engine.adapt_persona(
            sample_persona, sample_context, suggestions
        )
        
        assert adapted_prompt != sample_persona.system_prompt
        assert "ë³µì¡í•œ ë°ì´í„°ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”" in adapted_prompt
        assert "ë³µì¡í•œ ì‘ì—…ì„ ìœ„í•´ ë‹¨ê³„ë³„ ì ‘ê·¼" in adapted_prompt
        assert "íŒ€ í˜‘ì—…ì„ ìœ„í•œ ì†Œí†µ ìµœì í™”" in adapted_prompt
        assert "ì»¨í…ìŠ¤íŠ¸" in adapted_prompt
    
    def test_apply_basic_adaptations(self, adaptation_engine, sample_persona, sample_context):
        """ê¸°ë³¸ ì ì‘ ì ìš© í…ŒìŠ¤íŠ¸"""
        suggestions = ["ë‹¨ê³„ë³„ ì ‘ê·¼", "ìƒì„¸í•œ ì„¤ëª…"]
        
        adapted_prompt = adaptation_engine._apply_basic_adaptations(
            sample_persona, sample_context, suggestions
        )
        
        # ì›ë³¸ í”„ë¡¬í”„íŠ¸ í¬í•¨ í™•ì¸
        assert sample_persona.system_prompt in adapted_prompt
        
        # ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ì¶”ê°€ í™•ì¸
        assert sample_context.user_request in adapted_prompt
        assert sample_context.task_type in adapted_prompt
        assert sample_context.complexity_level in adapted_prompt
        
        # ì ì‘ ì œì•ˆ ì¶”ê°€ í™•ì¸
        for suggestion in suggestions:
            assert suggestion in adapted_prompt

class TestAgentPersonaManager:
    """Agent Persona Manager í†µí•© í…ŒìŠ¤íŠ¸"""
    
    @pytest.fixture
    def temp_registry_path(self):
        """ì„ì‹œ ë ˆì§€ìŠ¤íŠ¸ë¦¬ íŒŒì¼ ê²½ë¡œ"""
        with tempfile.NamedTemporaryFile(delete=False, suffix='.json') as f:
            yield f.name
        # ì •ë¦¬
        try:
            os.unlink(f.name)
        except FileNotFoundError:
            pass
    
    @pytest.fixture
    def persona_manager(self, temp_registry_path):
        """Agent Persona Manager í”½ìŠ¤ì²˜"""
        return AgentPersonaManager(temp_registry_path)
    
    @pytest.mark.asyncio
    async def test_persona_manager_initialization(self, persona_manager):
        """Persona Manager ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸"""
        result = await persona_manager.initialize()
        
        assert "total_personas" in result
        assert "agents_with_personas" in result
        assert "persona_types" in result
        assert result["initialization_status"] == "completed"
        assert result["total_personas"] > 0
        assert len(result["features"]) > 0
    
    @pytest.mark.asyncio
    async def test_get_persona_for_agent(self, persona_manager):
        """ì—ì´ì „íŠ¸ìš© í˜ë¥´ì†Œë‚˜ ì œê³µ í…ŒìŠ¤íŠ¸"""
        # ì´ˆê¸°í™”
        await persona_manager.initialize()
        
        # í˜ë¥´ì†Œë‚˜ ìš”ì²­
        result = await persona_manager.get_persona_for_agent(
            agent_id="pandas_collaboration_hub",
            user_request="ë°ì´í„°ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”",
            task_type="data_analysis",
            complexity_level="high",
            collaboration_type="team",
            required_skills=["statistics", "visualization"],
            session_id="test_session"
        )
        
        assert "error" not in result
        assert result["agent_id"] == "pandas_collaboration_hub"
        assert "persona_id" in result
        assert "persona_name" in result
        assert "system_prompt" in result
        assert "behavioral_traits" in result
        assert "recommendation" in result
        
        # ì¶”ì²œ ì •ë³´ í™•ì¸
        recommendation = result["recommendation"]
        assert "confidence" in recommendation
        assert "reasoning" in recommendation
        assert "adaptation_suggestions" in recommendation
        assert 0.0 <= recommendation["confidence"] <= 1.0
    
    @pytest.mark.asyncio
    async def test_update_persona_performance(self, persona_manager):
        """í˜ë¥´ì†Œë‚˜ ì„±ëŠ¥ ì—…ë°ì´íŠ¸ í…ŒìŠ¤íŠ¸"""
        await persona_manager.initialize()
        
        # í˜ë¥´ì†Œë‚˜ ìš”ì²­
        result = await persona_manager.get_persona_for_agent(
            agent_id="data_visualization",
            session_id="performance_test_session"
        )
        
        persona_id = result["persona_id"]
        
        # ì„±ëŠ¥ ì—…ë°ì´íŠ¸
        await persona_manager.update_persona_performance(
            session_id="performance_test_session",
            success=True,
            performance_score=0.9,
            feedback="ë§¤ìš° ì¢‹ì€ ê²°ê³¼"
        )
        
        # ì„±ëŠ¥ ê¸°ë¡ í™•ì¸
        assert "performance_test_session" in persona_manager.active_personas
        assert persona_id in persona_manager.performance_tracker
        
        performance_records = persona_manager.performance_tracker[persona_id]
        assert len(performance_records) > 0
        
        latest_record = performance_records[-1]
        assert latest_record["success"] is True
        assert latest_record["performance_score"] == 0.9
        assert latest_record["feedback"] == "ë§¤ìš° ì¢‹ì€ ê²°ê³¼"
    
    @pytest.mark.asyncio
    async def test_get_persona_analytics(self, persona_manager):
        """í˜ë¥´ì†Œë‚˜ ë¶„ì„ ì •ë³´ í…ŒìŠ¤íŠ¸"""
        await persona_manager.initialize()
        
        # ì „ì²´ ë¶„ì„
        analytics = await persona_manager.get_persona_analytics()
        
        assert "total_personas" in analytics
        assert "persona_types" in analytics
        assert "performance_summary" in analytics
        assert "usage_statistics" in analytics
        assert analytics["total_personas"] > 0
        
        # íŠ¹ì • ì—ì´ì „íŠ¸ ë¶„ì„
        agent_analytics = await persona_manager.get_persona_analytics(agent_id="pandas_collaboration_hub")
        
        assert agent_analytics["total_personas"] > 0
        assert isinstance(agent_analytics["persona_types"], dict)

class TestGlobalFunctions:
    """ì „ì—­ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸"""
    
    def test_get_agent_persona_manager_singleton(self):
        """Agent Persona Manager ì‹±ê¸€í†¤ íŒ¨í„´ í…ŒìŠ¤íŠ¸"""
        manager1 = get_agent_persona_manager()
        manager2 = get_agent_persona_manager()
        
        # ê°™ì€ ì¸ìŠ¤í„´ìŠ¤ì—¬ì•¼ í•¨
        assert manager1 is manager2
    
    @pytest.mark.asyncio
    async def test_initialize_agent_persona_manager_global(self):
        """ì „ì—­ Agent Persona Manager ì´ˆê¸°í™” í•¨ìˆ˜ í…ŒìŠ¤íŠ¸"""
        result = await initialize_agent_persona_manager()
        
        assert "total_personas" in result
        assert "initialization_status" in result
        assert result["initialization_status"] == "completed"

class TestPersonaEnums:
    """Persona ì—´ê±°í˜• í…ŒìŠ¤íŠ¸"""
    
    def test_persona_type_enum(self):
        """PersonaType ì—´ê±°í˜• í…ŒìŠ¤íŠ¸"""
        assert PersonaType.EXPERT.value == "expert"
        assert PersonaType.COLLABORATIVE.value == "collaborative"
        assert PersonaType.ANALYTICAL.value == "analytical"
        assert PersonaType.CREATIVE.value == "creative"
        assert PersonaType.METHODICAL.value == "methodical"
        assert PersonaType.ADAPTIVE.value == "adaptive"
        assert PersonaType.MENTOR.value == "mentor"
        assert PersonaType.SPECIALIST.value == "specialist"
    
    def test_persona_scope_enum(self):
        """PersonaScope ì—´ê±°í˜• í…ŒìŠ¤íŠ¸"""
        assert PersonaScope.GLOBAL.value == "global"
        assert PersonaScope.DOMAIN.value == "domain"
        assert PersonaScope.TASK.value == "task"
        assert PersonaScope.SESSION.value == "session"
        assert PersonaScope.COLLABORATION.value == "collaboration"

class TestPerformanceTracking:
    """ì„±ëŠ¥ ì¶”ì  í…ŒìŠ¤íŠ¸"""
    
    @pytest.fixture
    async def manager_with_usage(self):
        """ì‚¬ìš© ì´ë ¥ì´ ìˆëŠ” Manager ì„¤ì •"""
        with tempfile.NamedTemporaryFile(delete=False, suffix='.json') as f:
            manager = AgentPersonaManager(f.name)
            await manager.initialize()
            
            # ì—¬ëŸ¬ í˜ë¥´ì†Œë‚˜ ì‚¬ìš© ì‹œë®¬ë ˆì´ì…˜
            for i in range(3):
                session_id = f"test_session_{i}"
                result = await manager.get_persona_for_agent(
                    agent_id="data_visualization",
                    session_id=session_id
                )
                
                # ì„±ëŠ¥ ì—…ë°ì´íŠ¸
                await manager.update_persona_performance(
                    session_id=session_id,
                    success=i % 2 == 0,  # 50% ì„±ê³µë¥ 
                    performance_score=0.7 + i * 0.1
                )
            
            yield manager
            
            # ì •ë¦¬
            try:
                os.unlink(f.name)
            except FileNotFoundError:
                pass
    
    @pytest.mark.asyncio
    async def test_performance_tracking_statistics(self, manager_with_usage):
        """ì„±ëŠ¥ ì¶”ì  í†µê³„ í…ŒìŠ¤íŠ¸"""
        manager = await manager_with_usage
        
        # ì„±ëŠ¥ ê¸°ë¡ í™•ì¸
        assert len(manager.performance_tracker) > 0
        
        for persona_id, records in manager.performance_tracker.items():
            assert len(records) > 0
            for record in records:
                assert "session_id" in record
                assert "persona_id" in record
                assert "timestamp" in record
                assert "success" in record
                assert isinstance(record["success"], bool)
    
    @pytest.mark.asyncio
    async def test_analytics_with_performance_data(self, manager_with_usage):
        """ì„±ëŠ¥ ë°ì´í„°ê°€ ìˆëŠ” ë¶„ì„ í…ŒìŠ¤íŠ¸"""
        manager = await manager_with_usage
        
        analytics = await manager.get_persona_analytics()
        
        # ì„±ëŠ¥ ìš”ì•½ í™•ì¸
        assert len(analytics["performance_summary"]) > 0
        
        for persona_id, summary in analytics["performance_summary"].items():
            assert "usage_count" in summary
            assert "success_rate" in summary
            assert summary["usage_count"] > 0
            assert 0.0 <= summary["success_rate"] <= 1.0

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    import subprocess
    import sys
    
    print("ğŸ­ Agent Persona Manager í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘...")
    
    # pytest ì‹¤í–‰
    result = subprocess.run([
        sys.executable, "-m", "pytest", __file__, "-v", "--tb=short"
    ], capture_output=True, text=True)
    
    print(result.stdout)
    if result.stderr:
        print("STDERR:", result.stderr)
    
    print(f"\nğŸ¯ í…ŒìŠ¤íŠ¸ ê²°ê³¼: {'âœ… ì„±ê³µ' if result.returncode == 0 else 'âŒ ì‹¤íŒ¨'}")
    
    if result.returncode == 0:
        print("ğŸ­ Agent Persona Managerê°€ ëª¨ë“  í…ŒìŠ¤íŠ¸ë¥¼ í†µê³¼í–ˆìŠµë‹ˆë‹¤!")
        print("âœ¨ Context Engineering INSTRUCTIONS ë ˆì´ì–´ê°€ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤.")
    else:
        print("âš ï¸ ì¼ë¶€ í…ŒìŠ¤íŠ¸ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë¡œê·¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.") 