#!/usr/bin/env python3
"""
ğŸ­ ì‹¤ì œ ìš´ì˜ A2A ì—ì´ì „íŠ¸ ê²€ì¦ í…ŒìŠ¤íŠ¸

ì˜¨ë¼ì¸ ìƒíƒœì¸ ì‹¤ì œ A2A ì—ì´ì „íŠ¸ë“¤ê³¼ ì§ì ‘ í†µì‹ í•˜ì—¬:
- ê°œë³„ ì—ì´ì „íŠ¸ ê¸°ëŠ¥ ê²€ì¦
- ì‹¤ì œ ë°ì´í„° ì²˜ë¦¬ ëŠ¥ë ¥ í…ŒìŠ¤íŠ¸
- LLM ê¸°ë°˜ ì‘ë‹µ í’ˆì§ˆ í‰ê°€
- ì¢…í•© ì„±ëŠ¥ ë° ì•ˆì •ì„± ê²€ì¦
"""

import asyncio
import json
import logging
import time
import httpx
import pandas as pd
import numpy as np
from datetime import datetime
from typing import Dict, List, Any, Optional
from pathlib import Path

# í…ŒìŠ¤íŠ¸ í™˜ê²½ ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class ProductionAgentValidator:
    """ì‹¤ì œ ìš´ì˜ A2A ì—ì´ì „íŠ¸ ê²€ì¦ê¸°"""
    
    def __init__(self):
        # ì‹¤ì œ ì˜¨ë¼ì¸ ì—ì´ì „íŠ¸ ëª©ë¡ (í…ŒìŠ¤íŠ¸ì—ì„œ í™•ì¸ëœ ê²ƒë“¤)
        self.online_agents = {
            'data_cleaning': 'http://localhost:8306',
            'data_loader': 'http://localhost:8307', 
            'data_visualization': 'http://localhost:8308',
            'data_wrangling': 'http://localhost:8309',
            'eda': 'http://localhost:8310',
            'feature_engineering': 'http://localhost:8311',
            'h2o_modeling': 'http://localhost:8312',
            'mlflow': 'http://localhost:8313',
            'sql_database': 'http://localhost:8314',
            'pandas': 'http://localhost:8315'
        }
        
        self.test_results = {}
        self.performance_metrics = {}
        
    def generate_test_data(self) -> pd.DataFrame:
        """ì‹¤ì œ ë¶„ì„ì— ì‚¬ìš©í•  í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±"""
        np.random.seed(42)
        
        n_samples = 1000
        data = {
            'customer_id': range(1, n_samples + 1),
            'age': np.random.randint(18, 80, n_samples),
            'income': np.random.normal(65000, 20000, n_samples),
            'purchase_amount': np.random.exponential(150, n_samples),
            'region': np.random.choice(['North', 'South', 'East', 'West'], n_samples),
            'product_category': np.random.choice(['Electronics', 'Clothing', 'Books', 'Home'], n_samples),
            'satisfaction_score': np.random.uniform(1, 10, n_samples),
            'is_premium': np.random.choice([True, False], n_samples, p=[0.3, 0.7]),
            'days_since_last_purchase': np.random.exponential(30, n_samples)
        }
        
        df = pd.DataFrame(data)
        df['income'] = np.clip(df['income'], 20000, 200000)  # í˜„ì‹¤ì ì¸ ë²”ìœ„ë¡œ ì œí•œ
        df['purchase_amount'] = np.clip(df['purchase_amount'], 10, 2000)  # í˜„ì‹¤ì ì¸ ë²”ìœ„ë¡œ ì œí•œ
        
        return df
        
    async def test_agent_health(self, agent_name: str, endpoint: str) -> Dict[str, Any]:
        """ê°œë³„ ì—ì´ì „íŠ¸ ìƒíƒœ ê²€ì‚¬"""
        start_time = time.time()
        
        try:
            async with httpx.AsyncClient(timeout=10.0) as client:
                # ì—ì´ì „íŠ¸ ì¹´ë“œ í™•ì¸
                response = await client.get(f"{endpoint}/.well-known/agent.json")
                
                if response.status_code == 200:
                    agent_info = response.json()
                    response_time = time.time() - start_time
                    
                    return {
                        'status': 'healthy',
                        'response_time': response_time,
                        'agent_info': agent_info,
                        'capabilities': agent_info.get('capabilities', []),
                        'description': agent_info.get('description', ''),
                        'version': agent_info.get('version', 'unknown')
                    }
                else:
                    return {
                        'status': 'unhealthy',
                        'response_time': time.time() - start_time,
                        'error': f"HTTP {response.status_code}"
                    }
                    
        except Exception as e:
            return {
                'status': 'error',
                'response_time': time.time() - start_time,
                'error': str(e)
            }
    
    async def test_agent_functionality(self, agent_name: str, endpoint: str, test_data: pd.DataFrame) -> Dict[str, Any]:
        """ê°œë³„ ì—ì´ì „íŠ¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
        start_time = time.time()
        
        # ì—ì´ì „íŠ¸ë³„ íŠ¹í™” í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
        test_queries = {
            'data_cleaning': "ì´ ë°ì´í„°ì˜ ê²°ì¸¡ê°’ê³¼ ì´ìƒì¹˜ë¥¼ íƒì§€í•˜ê³  ì •ë¦¬í•´ì£¼ì„¸ìš”.",
            'data_loader': "ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  ê¸°ë³¸ ì •ë³´ë¥¼ ìš”ì•½í•´ì£¼ì„¸ìš”.",
            'data_visualization': "ê³ ê° ë°ì´í„°ì˜ ì£¼ìš” ë¶„í¬ë¥¼ ì‹œê°í™”í•´ì£¼ì„¸ìš”.",
            'data_wrangling': "ë°ì´í„°ë¥¼ ë¶„ì„ì— ì í•©í•œ í˜•íƒœë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”.",
            'eda': "ì´ ë°ì´í„°ì— ëŒ€í•œ íƒìƒ‰ì  ë°ì´í„° ë¶„ì„ì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”.",
            'feature_engineering': "ë¨¸ì‹ ëŸ¬ë‹ì„ ìœ„í•œ ìƒˆë¡œìš´ í”¼ì²˜ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.",
            'h2o_modeling': "H2O AutoMLì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ êµ¬ì¶•í•´ì£¼ì„¸ìš”.",
            'mlflow': "ëª¨ë¸ ì‹¤í—˜ì„ ì¶”ì í•˜ê³  ê´€ë¦¬í•´ì£¼ì„¸ìš”.",
            'sql_database': "ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬ë¥¼ ìµœì í™”í•´ì£¼ì„¸ìš”.",
            'pandas': "Pandasë¥¼ ì‚¬ìš©í•œ ìƒì„¸í•œ ë°ì´í„° ë¶„ì„ì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”."
        }
        
        query = test_queries.get(agent_name, "ë°ì´í„°ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”.")
        
        try:
            async with httpx.AsyncClient(timeout=30.0) as client:
                # A2A ë©”ì‹œì§€ í˜•ì‹
                message = {
                    "messageId": f"test_{agent_name}_{int(time.time())}",
                    "role": "user",
                    "parts": [
                        {
                            "kind": "text",
                            "text": json.dumps({
                                "query": query,
                                "data_summary": {
                                    "rows": len(test_data),
                                    "columns": len(test_data.columns),
                                    "column_names": list(test_data.columns),
                                    "data_types": {col: str(dtype) for col, dtype in test_data.dtypes.items()},
                                    "sample_data": test_data.head(3).to_dict('records')
                                }
                            })
                        }
                    ]
                }
                
                # A2A ì—ì´ì „íŠ¸ì— ìš”ì²­ (ìŠ¤íŠ¸ë¦¬ë°ì´ ì•„ë‹Œ ì¼ë°˜ ìš”ì²­)
                try:
                    response = await client.post(f"{endpoint}/a2a/agent", json=message)
                    
                    if response.status_code == 200:
                        result_data = response.json()
                        response_time = time.time() - start_time
                        
                        # ì‘ë‹µì—ì„œ ì‹¤ì œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                        response_text = ""
                        if 'result' in result_data and 'message' in result_data['result']:
                            parts = result_data['result']['message'].get('parts', [])
                            for part in parts:
                                if part.get('kind') == 'text':
                                    response_text += part.get('text', '')
                        
                        return {
                            'status': 'success',
                            'response_time': response_time,
                            'response_length': len(response_text),
                            'response_content': response_text[:500] + "..." if len(response_text) > 500 else response_text,
                            'full_response': result_data,
                            'query_used': query
                        }
                    else:
                        return {
                            'status': 'http_error',
                            'response_time': time.time() - start_time,
                            'error': f"HTTP {response.status_code}: {response.text}"
                        }
                        
                except httpx.ConnectError:
                    # A2A ì—”ë“œí¬ì¸íŠ¸ê°€ ì—†ëŠ” ê²½ìš° ëŒ€ì²´ ì—”ë“œí¬ì¸íŠ¸ ì‹œë„
                    return {
                        'status': 'endpoint_unavailable',
                        'response_time': time.time() - start_time,
                        'error': "A2A endpoint not available"
                    }
                    
        except Exception as e:
            return {
                'status': 'error',
                'response_time': time.time() - start_time,
                'error': str(e)
            }
    
    def evaluate_response_quality(self, agent_name: str, query: str, response: str) -> Dict[str, Any]:
        """LLMì„ ì‚¬ìš©í•˜ì§€ ì•Šê³  ê¸°ë³¸ì ì¸ ì‘ë‹µ í’ˆì§ˆ í‰ê°€"""
        
        quality_score = {
            'completeness': 0,
            'relevance': 0,
            'technical_accuracy': 0,
            'actionability': 0,
            'overall': 0
        }
        
        # ê¸°ë³¸ì ì¸ íœ´ë¦¬ìŠ¤í‹± í‰ê°€
        if response and len(response) > 0:
            # ì™„ì„±ë„ í‰ê°€ (ì‘ë‹µ ê¸¸ì´ ê¸°ë°˜)
            if len(response) > 100:
                quality_score['completeness'] = 8
            elif len(response) > 50:
                quality_score['completeness'] = 6
            else:
                quality_score['completeness'] = 4
            
            # ê´€ë ¨ì„± í‰ê°€ (í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€)
            response_lower = response.lower()
            agent_keywords = {
                'data_cleaning': ['clean', 'missing', 'null', 'outlier', 'duplicate'],
                'data_visualization': ['chart', 'plot', 'graph', 'visual', 'histogram'],
                'eda': ['analysis', 'distribution', 'correlation', 'summary', 'statistics'],
                'pandas': ['dataframe', 'pandas', 'groupby', 'merge', 'aggregate'],
                'feature_engineering': ['feature', 'encoding', 'scaling', 'transform'],
                'h2o_modeling': ['model', 'prediction', 'accuracy', 'h2o', 'automl'],
                'mlflow': ['experiment', 'tracking', 'model', 'logging', 'mlflow']
            }
            
            keywords = agent_keywords.get(agent_name, ['data', 'analysis'])
            keyword_matches = sum(1 for keyword in keywords if keyword in response_lower)
            quality_score['relevance'] = min(10, keyword_matches * 2)
            
            # ê¸°ìˆ ì  ì •í™•ì„± (ì—ëŸ¬ë‚˜ ë¬¸ì œ ì–¸ê¸‰ ì—¬ë¶€)
            if any(word in response_lower for word in ['error', 'failed', 'cannot', 'unable']):
                quality_score['technical_accuracy'] = 5
            else:
                quality_score['technical_accuracy'] = 7
            
            # ì‹¤í–‰ ê°€ëŠ¥ì„± (êµ¬ì²´ì ì¸ ì œì•ˆì´ë‚˜ ê²°ê³¼ í¬í•¨ ì—¬ë¶€)
            if any(word in response_lower for word in ['recommend', 'suggest', 'result', 'found']):
                quality_score['actionability'] = 7
            else:
                quality_score['actionability'] = 5
            
            # ì „ì²´ ì ìˆ˜ ê³„ì‚°
            quality_score['overall'] = round(
                (quality_score['completeness'] + quality_score['relevance'] + 
                 quality_score['technical_accuracy'] + quality_score['actionability']) / 4
            )
        
        return quality_score
    
    async def run_comprehensive_validation(self) -> Dict[str, Any]:
        """ì¢…í•©ì ì¸ ê²€ì¦ ì‹¤í–‰"""
        
        logger.info("ğŸ­ ì‹¤ì œ ìš´ì˜ A2A ì—ì´ì „íŠ¸ ì¢…í•© ê²€ì¦ ì‹œì‘")
        
        validation_start_time = time.time()
        
        # 1. í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
        test_data = self.generate_test_data()
        logger.info(f"ğŸ“Š í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„± ì™„ë£Œ: {len(test_data)}í–‰ x {len(test_data.columns)}ì—´")
        
        # 2. ê° ì—ì´ì „íŠ¸ë³„ ê²€ì¦
        agent_results = {}
        
        for agent_name, endpoint in self.online_agents.items():
            logger.info(f"ğŸ” {agent_name} ì—ì´ì „íŠ¸ ê²€ì¦ ì¤‘...")
            
            # ìƒíƒœ ê²€ì‚¬
            health_result = await self.test_agent_health(agent_name, endpoint)
            
            # ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ (ìƒíƒœê°€ ì •ìƒì¸ ê²½ìš°ë§Œ)
            functionality_result = None
            quality_evaluation = None
            
            if health_result['status'] == 'healthy':
                functionality_result = await self.test_agent_functionality(agent_name, endpoint, test_data)
                
                # ì‘ë‹µ í’ˆì§ˆ í‰ê°€ (ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ê°€ ì„±ê³µí•œ ê²½ìš°ë§Œ)
                if functionality_result['status'] == 'success':
                    quality_evaluation = self.evaluate_response_quality(
                        agent_name,
                        functionality_result['query_used'],
                        functionality_result['response_content']
                    )
            
            agent_results[agent_name] = {
                'health': health_result,
                'functionality': functionality_result,
                'quality': quality_evaluation,
                'endpoint': endpoint
            }
            
            # ì§„í–‰ ìƒí™© ë¡œê·¸
            status = "âœ…" if health_result['status'] == 'healthy' else "âŒ"
            logger.info(f"  {status} {agent_name}: {health_result['status']}")
        
        # 3. ì¢…í•© ê²°ê³¼ ë¶„ì„
        total_agents = len(self.online_agents)
        healthy_agents = sum(1 for r in agent_results.values() if r['health']['status'] == 'healthy')
        functional_agents = sum(1 for r in agent_results.values() 
                              if r['functionality'] and r['functionality']['status'] == 'success')
        
        avg_response_time = np.mean([r['health']['response_time'] for r in agent_results.values()])
        
        # í’ˆì§ˆ ì ìˆ˜ í‰ê·  ê³„ì‚°
        quality_scores = [r['quality'] for r in agent_results.values() if r['quality']]
        avg_quality = None
        if quality_scores:
            avg_quality = {
                'completeness': np.mean([q['completeness'] for q in quality_scores]),
                'relevance': np.mean([q['relevance'] for q in quality_scores]),
                'technical_accuracy': np.mean([q['technical_accuracy'] for q in quality_scores]),
                'actionability': np.mean([q['actionability'] for q in quality_scores]),
                'overall': np.mean([q['overall'] for q in quality_scores])
            }
        
        total_validation_time = time.time() - validation_start_time
        
        comprehensive_result = {
            'validation_summary': {
                'total_agents_tested': total_agents,
                'healthy_agents': healthy_agents,
                'functional_agents': functional_agents,
                'health_rate': (healthy_agents / total_agents) * 100,
                'functionality_rate': (functional_agents / total_agents) * 100,
                'avg_response_time': avg_response_time,
                'total_validation_time': total_validation_time
            },
            'quality_analysis': avg_quality,
            'agent_details': agent_results,
            'test_data_info': {
                'rows': len(test_data),
                'columns': len(test_data.columns),
                'column_names': list(test_data.columns)
            },
            'timestamp': datetime.now().isoformat()
        }
        
        # 4. ê²°ê³¼ ë¡œê¹…
        logger.info("\n" + "="*60)
        logger.info("ğŸ“Š ì¢…í•© ê²€ì¦ ê²°ê³¼")
        logger.info("="*60)
        logger.info(f"ğŸ’Š ì—ì´ì „íŠ¸ ìƒíƒœ: {healthy_agents}/{total_agents} ({healthy_agents/total_agents*100:.1f}%)")
        logger.info(f"âš¡ ê¸°ëŠ¥ ì •ìƒ: {functional_agents}/{total_agents} ({functional_agents/total_agents*100:.1f}%)")
        logger.info(f"â±ï¸ í‰ê·  ì‘ë‹µ ì‹œê°„: {avg_response_time:.3f}ì´ˆ")
        
        if avg_quality:
            logger.info(f"ğŸ¯ í‰ê·  í’ˆì§ˆ ì ìˆ˜: {avg_quality['overall']:.1f}/10")
        
        logger.info(f"â° ì´ ê²€ì¦ ì‹œê°„: {total_validation_time:.2f}ì´ˆ")
        
        return comprehensive_result


async def main():
    """ë©”ì¸ ê²€ì¦ ì‹¤í–‰"""
    
    validator = ProductionAgentValidator()
    result = await validator.run_comprehensive_validation()
    
    # ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥
    timestamp = int(time.time())
    result_file = f"production_agent_validation_{timestamp}.json"
    
    with open(result_file, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2, default=str)
    
    logger.info(f"ğŸ“„ ìƒì„¸ ê²°ê³¼ ì €ì¥: {result_file}")
    
    return result


if __name__ == "__main__":
    asyncio.run(main()) 