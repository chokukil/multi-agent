#!/usr/bin/env python3
"""
ğŸ’ CherryAI ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤íŠ¸
Phase 1.7: pytest ê¸°ë°˜ ì „ì²´ ì‹œìŠ¤í…œ í†µí•© ê²€ì¦

Test Coverage:
- MCP Config Manager + Connection Monitor í†µí•©
- Server Manager + Metrics Collector í†µí•©
- ì „ì²´ ëª¨ë‹ˆí„°ë§ íŒŒì´í”„ë¼ì¸ ê²€ì¦
- ì‹¤ì‹œê°„ ë°ì´í„° íë¦„ í…ŒìŠ¤íŠ¸
- ì¥ì•  ìƒí™© ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸

Author: CherryAI Team
Date: 2025-07-13
"""

import pytest
import asyncio
import tempfile
import json
import os
import time
from pathlib import Path
from unittest.mock import patch, MagicMock, AsyncMock
from datetime import datetime, timedelta

import sys
sys.path.append('.')

from core.monitoring.mcp_config_manager import MCPConfigManager, MCPServerDefinition, MCPServerType
from core.monitoring.mcp_connection_monitor import MCPConnectionMonitor
from core.monitoring.mcp_server_manager import MCPServerManager
from core.monitoring.performance_metrics_collector import PerformanceMetricsCollector

class TestMonitoringSystemIntegration:
    """ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤íŠ¸"""
    
    @pytest.fixture
    def temp_config_file(self):
        """ì„ì‹œ ì„¤ì • íŒŒì¼ í”½ìŠ¤ì²˜"""
        with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as f:
            integration_config = {
                "mcpServers": {
                    "integrationStdioServer": {
                        "type": "stdio",
                        "name": "Integration STDIO Server",
                        "description": "í†µí•© í…ŒìŠ¤íŠ¸ìš© STDIO ì„œë²„",
                        "command": "echo",
                        "args": ["integration_test"],
                        "env": {"TEST_MODE": "integration"},
                        "enabled": True,
                        "timeout": 15.0,
                        "retry_count": 2,
                        "health_check_interval": 30.0
                    },
                    "integrationSseServer": {
                        "type": "sse",
                        "name": "Integration SSE Server",
                        "description": "í†µí•© í…ŒìŠ¤íŠ¸ìš© SSE ì„œë²„",
                        "url": "http://localhost:9999/integration",
                        "enabled": True,
                        "timeout": 10.0,
                        "retry_count": 3
                    },
                    "disabledIntegrationServer": {
                        "type": "stdio",
                        "name": "Disabled Integration Server",
                        "description": "ë¹„í™œì„±í™”ëœ í†µí•© í…ŒìŠ¤íŠ¸ ì„œë²„",
                        "command": "sleep",
                        "args": ["1"],
                        "enabled": False
                    }
                },
                "globalSettings": {
                    "default_timeout": 20.0,
                    "default_retry_count": 3,
                    "default_health_check_interval": 45.0,
                    "environment_variables": {
                        "INTEGRATION_TEST": "true"
                    }
                },
                "metadata": {
                    "version": "1.0.0",
                    "created": "2025-07-13T00:00:00Z",
                    "description": "í†µí•© í…ŒìŠ¤íŠ¸ ì„¤ì •"
                }
            }
            json.dump(integration_config, f, indent=2)
            temp_path = f.name
        
        yield temp_path
        
        if os.path.exists(temp_path):
            os.unlink(temp_path)
    
    @pytest.fixture
    def temp_db_path(self):
        """ì„ì‹œ ë°ì´í„°ë² ì´ìŠ¤ ê²½ë¡œ í”½ìŠ¤ì²˜"""
        with tempfile.NamedTemporaryFile(suffix='.db', delete=False) as f:
            temp_path = f.name
        yield temp_path
        if os.path.exists(temp_path):
            os.unlink(temp_path)
    
    @pytest.fixture
    def integrated_system(self, temp_config_file, temp_db_path):
        """í†µí•© ì‹œìŠ¤í…œ í”½ìŠ¤ì²˜"""
        # Config Manager ì´ˆê¸°í™”
        config_manager = MCPConfigManager(config_path=temp_config_file)
        
        # Connection Monitor ì´ˆê¸°í™”
        connection_monitor = MCPConnectionMonitor(config_manager=config_manager)
        
        # Server Manager ì´ˆê¸°í™”
        with patch('core.monitoring.mcp_server_manager.Path.mkdir'):
            server_manager = MCPServerManager(
                config_manager=config_manager,
                connection_monitor=connection_monitor
            )
        
        # Metrics Collector ì´ˆê¸°í™”
        with patch('core.monitoring.performance_metrics_collector.get_mcp_config_manager', return_value=config_manager), \
             patch('core.monitoring.performance_metrics_collector.get_server_manager', return_value=server_manager):
            metrics_collector = PerformanceMetricsCollector(db_path=temp_db_path)
            metrics_collector.collection_interval = 0.1  # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸
        
        return {
            'config_manager': config_manager,
            'connection_monitor': connection_monitor,
            'server_manager': server_manager,
            'metrics_collector': metrics_collector
        }
    
    def test_system_initialization(self, integrated_system):
        """ì‹œìŠ¤í…œ ì´ˆê¸°í™” í†µí•© í…ŒìŠ¤íŠ¸"""
        config_manager = integrated_system['config_manager']
        connection_monitor = integrated_system['connection_monitor']
        server_manager = integrated_system['server_manager']
        metrics_collector = integrated_system['metrics_collector']
        
        # ëª¨ë“  ì»´í¬ë„ŒíŠ¸ê°€ ì •ìƒ ì´ˆê¸°í™”ë˜ì—ˆëŠ”ì§€ í™•ì¸
        assert config_manager is not None
        assert connection_monitor is not None
        assert server_manager is not None
        assert metrics_collector is not None
        
        # Config Manager ì„¤ì • í™•ì¸
        enabled_servers = config_manager.get_enabled_servers()
        assert len(enabled_servers) == 2  # í™œì„±í™”ëœ ì„œë²„ 2ê°œ
        assert "integrationStdioServer" in enabled_servers
        assert "integrationSseServer" in enabled_servers
        assert "disabledIntegrationServer" not in enabled_servers
        
        # Connection Monitor ì´ˆê¸° ìƒíƒœ í™•ì¸
        assert connection_monitor.connections == {}
        assert connection_monitor.monitoring_active is False
        
        # Server Manager ì´ˆê¸° ìƒíƒœ í™•ì¸
        assert server_manager.server_processes == {}
        assert server_manager.monitoring_active is False
        
        # Metrics Collector ì´ˆê¸° ìƒíƒœ í™•ì¸
        assert metrics_collector.metrics_cache == []
        assert metrics_collector.is_collecting is False
    
    @pytest.mark.asyncio
    async def test_config_to_monitor_integration(self, integrated_system):
        """Config Manager â†’ Connection Monitor í†µí•© í…ŒìŠ¤íŠ¸"""
        config_manager = integrated_system['config_manager']
        connection_monitor = integrated_system['connection_monitor']
        
        with patch.object(connection_monitor.auto_recovery, 'start_server', new_callable=AsyncMock) as mock_start:
            mock_start.return_value = True
            
            # ì„œë²„ ë°œê²¬
            await connection_monitor.discover_servers()
            
            # ì„¤ì •ëœ ì„œë²„ë“¤ì´ ë°œê²¬ë˜ì—ˆëŠ”ì§€ í™•ì¸
            assert len(connection_monitor.connections) == 2
            assert "integrationStdioServer" in connection_monitor.connections
            assert "integrationSseServer" in connection_monitor.connections
            
            # ì„œë²„ íƒ€ì…ì´ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸
            stdio_server = connection_monitor.connections["integrationStdioServer"]
            sse_server = connection_monitor.connections["integrationSseServer"]
            
            assert stdio_server["type"] == "stdio"
            assert sse_server["type"] == "sse"
            
            # Configì—ì„œ ê°€ì ¸ì˜¨ ì •ë³´ê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸
            assert stdio_server["config"]["name"] == "Integration STDIO Server"
            assert sse_server["config"]["name"] == "Integration SSE Server"
    
    @pytest.mark.asyncio
    async def test_server_manager_integration(self, integrated_system):
        """Server Manager í†µí•© í…ŒìŠ¤íŠ¸"""
        config_manager = integrated_system['config_manager']
        server_manager = integrated_system['server_manager']
        
        server_id = "integrationStdioServer"
        
        with patch('asyncio.create_subprocess_exec') as mock_subprocess, \
             patch('builtins.open'), \
             patch('psutil.Process') as mock_process_class:
            
            # í”„ë¡œì„¸ìŠ¤ ì‹œì‘ ì„±ê³µ ëª¨í‚¹
            mock_process = AsyncMock()
            mock_process.pid = 99999
            mock_process.returncode = None
            mock_subprocess.return_value = mock_process
            
            # psutil Process ëª¨í‚¹
            mock_psutil_process = MagicMock()
            mock_psutil_process.is_running.return_value = True
            mock_psutil_process.cpu_percent.return_value = 15.0
            mock_psutil_process.memory_info.return_value = MagicMock(rss=1024*1024*50)
            mock_psutil_process.connections.return_value = ['conn1', 'conn2']
            mock_psutil_process.create_time.return_value = time.time() - 1800
            mock_process_class.return_value = mock_psutil_process
            
            # ì„œë²„ ì‹œì‘
            start_result = await server_manager.start_server(server_id)
            assert start_result is True
            assert server_id in server_manager.server_processes
            
            # ì„¤ì • ê²€ì¦
            validation_result = await server_manager.validate_server_config(server_id)
            assert validation_result.server_id == server_id
            assert validation_result.score > 0
            
            # ì„±ëŠ¥ ì •ë³´ ìˆ˜ì§‘
            performance = await server_manager.get_server_performance(server_id)
            assert performance["status"] == "running"
            assert "metrics" in performance
            assert performance["metrics"]["cpu_percent"] == 15.0
    
    @pytest.mark.asyncio
    async def test_metrics_collector_integration(self, integrated_system):
        """Metrics Collector í†µí•© í…ŒìŠ¤íŠ¸"""
        config_manager = integrated_system['config_manager']
        server_manager = integrated_system['server_manager']
        metrics_collector = integrated_system['metrics_collector']
        
        # Mock ì„±ëŠ¥ ë°ì´í„° ì„¤ì •
        mock_performance = {
            "status": "running",
            "metrics": {
                "cpu_percent": 25.0,
                "memory_mb": 75.0,
                "connections": 3,
                "uptime_seconds": 3600,
                "restart_count": 1
            }
        }
        
        with patch.object(server_manager, 'get_server_performance', new_callable=AsyncMock) as mock_get_perf, \
             patch('requests.get') as mock_requests:
            
            mock_get_perf.return_value = mock_performance
            
            # A2A ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ëª¨í‚¹
            mock_response = MagicMock()
            mock_response.status_code = 200
            mock_response.elapsed.total_seconds.return_value = 0.15
            mock_requests.return_value = mock_response
            
            # MCP ì„œë²„ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
            enabled_servers = config_manager.get_enabled_servers()
            for server_id, server_def in enabled_servers.items():
                await metrics_collector._collect_mcp_metrics(server_id, server_def)
            
            # A2A ë©”íŠ¸ë¦­ ìˆ˜ì§‘
            await metrics_collector._collect_a2a_metrics(8100, "Test Agent")
            
            # ë©”íŠ¸ë¦­ì´ ìˆ˜ì§‘ë˜ì—ˆëŠ”ì§€ í™•ì¸
            assert len(metrics_collector.metrics_cache) > 0
            
            # ì„±ëŠ¥ ìš”ì•½ ì—…ë°ì´íŠ¸
            await metrics_collector._update_performance_summaries()
            
            # ìš”ì•½ì´ ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸
            assert len(metrics_collector.performance_summaries) > 0
    
    @pytest.mark.asyncio
    async def test_full_monitoring_pipeline(self, integrated_system):
        """ì „ì²´ ëª¨ë‹ˆí„°ë§ íŒŒì´í”„ë¼ì¸ í†µí•© í…ŒìŠ¤íŠ¸"""
        config_manager = integrated_system['config_manager']
        connection_monitor = integrated_system['connection_monitor']
        server_manager = integrated_system['server_manager']
        metrics_collector = integrated_system['metrics_collector']
        
        # 1. ì„¤ì • ë¡œë“œ í™•ì¸
        enabled_servers = config_manager.get_enabled_servers()
        assert len(enabled_servers) == 2
        
        # 2. ì„œë²„ ë°œê²¬ ë° ì—°ê²° ëª¨ë‹ˆí„°ë§
        with patch.object(connection_monitor.auto_recovery, 'start_server', new_callable=AsyncMock) as mock_start:
            mock_start.return_value = True
            await connection_monitor.discover_servers()
            assert len(connection_monitor.connections) == 2
        
        # 3. ì„œë²„ ê´€ë¦¬ ë° ì„±ëŠ¥ ìˆ˜ì§‘
        with patch('asyncio.create_subprocess_exec') as mock_subprocess, \
             patch('builtins.open'), \
             patch('psutil.Process') as mock_process_class:
            
            # Mock ì„¤ì •
            mock_process = AsyncMock()
            mock_process.pid = 88888
            mock_process.returncode = None
            mock_subprocess.return_value = mock_process
            
            mock_psutil_process = MagicMock()
            mock_psutil_process.is_running.return_value = True
            mock_psutil_process.cpu_percent.return_value = 20.0
            mock_psutil_process.memory_info.return_value = MagicMock(rss=1024*1024*60)
            mock_psutil_process.connections.return_value = ['conn1']
            mock_psutil_process.create_time.return_value = time.time() - 900
            mock_process_class.return_value = mock_psutil_process
            
            # ì„œë²„ ì‹œì‘
            start_result = await server_manager.start_server("integrationStdioServer")
            assert start_result is True
        
        # 4. ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ë° ë¶„ì„
        with patch.object(server_manager, 'get_server_performance', new_callable=AsyncMock) as mock_perf:
            mock_perf.return_value = {
                "status": "running",
                "metrics": {"cpu_percent": 20.0, "memory_mb": 60.0}
            }
            
            # ë©”íŠ¸ë¦­ ìˆ˜ì§‘
            await metrics_collector._collect_all_metrics()
            await metrics_collector._update_performance_summaries()
            
            # ìˆ˜ì§‘ëœ ë°ì´í„° í™•ì¸
            assert len(metrics_collector.metrics_cache) > 0
            assert len(metrics_collector.performance_summaries) > 0
        
        # 5. ì—°ê²° ìƒíƒœ ìš”ì•½
        with patch.object(connection_monitor.auto_recovery, 'get_summary', return_value={"servers": {}}):
            summary = connection_monitor.get_connection_summary()
            assert summary["total_servers"] >= 0
            assert "servers" in summary
            assert "auto_recovery" in summary
    
    @pytest.mark.asyncio
    async def test_error_propagation_and_recovery(self, integrated_system):
        """ì—ëŸ¬ ì „íŒŒ ë° ë³µêµ¬ í†µí•© í…ŒìŠ¤íŠ¸"""
        connection_monitor = integrated_system['connection_monitor']
        server_manager = integrated_system['server_manager']
        metrics_collector = integrated_system['metrics_collector']
        
        # 1. ì„œë²„ ì‹œì‘ ì‹¤íŒ¨ ì‹œë‚˜ë¦¬ì˜¤
        with patch('asyncio.create_subprocess_exec') as mock_subprocess:
            # í”„ë¡œì„¸ìŠ¤ ì‹œì‘ ì‹¤íŒ¨
            mock_subprocess.side_effect = Exception("Process start failed")
            
            start_result = await server_manager.start_server("integrationStdioServer")
            assert start_result is False
        
        # 2. ì—°ê²° ëª¨ë‹ˆí„°ë§ì—ì„œ ì‹¤íŒ¨ ê°ì§€
        with patch.object(connection_monitor, '_check_single_connection', new_callable=AsyncMock) as mock_check:
            mock_check.return_value = False
            
            await connection_monitor.check_all_connections()
            
            # ì‹¤íŒ¨ê°€ ê¸°ë¡ë˜ì—ˆëŠ”ì§€ í™•ì¸
            assert mock_check.called
        
        # 3. ë©”íŠ¸ë¦­ ìˆ˜ì§‘ì—ì„œ ì—ëŸ¬ ì²˜ë¦¬
        with patch.object(server_manager, 'get_server_performance', new_callable=AsyncMock) as mock_perf:
            mock_perf.return_value = {"error": "Server not found"}
            
            # ì—ëŸ¬ ìƒí™©ì—ì„œë„ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ì´ ì¤‘ë‹¨ë˜ì§€ ì•ŠëŠ”ì§€ í™•ì¸
            await metrics_collector._collect_all_metrics()
            # ì—ëŸ¬ê°€ ë°œìƒí•´ë„ ì‹œìŠ¤í…œì´ ê³„ì† ë™ì‘í•´ì•¼ í•¨
    
    @pytest.mark.asyncio
    async def test_concurrent_operations(self, integrated_system):
        """ë™ì‹œ ì‘ì—… í†µí•© í…ŒìŠ¤íŠ¸"""
        connection_monitor = integrated_system['connection_monitor']
        server_manager = integrated_system['server_manager']
        metrics_collector = integrated_system['metrics_collector']
        
        with patch.object(connection_monitor.auto_recovery, 'start_server', new_callable=AsyncMock) as mock_start, \
             patch.object(server_manager, 'get_server_performance', new_callable=AsyncMock) as mock_perf, \
             patch.object(connection_monitor, '_check_single_connection', new_callable=AsyncMock) as mock_check:
            
            mock_start.return_value = True
            mock_perf.return_value = {"status": "running", "metrics": {"cpu_percent": 10.0}}
            mock_check.return_value = True
            
            # ì—¬ëŸ¬ ì‘ì—…ì„ ë™ì‹œì— ì‹¤í–‰
            tasks = [
                connection_monitor.discover_servers(),
                connection_monitor.check_all_connections(),
                metrics_collector._collect_all_metrics(),
                metrics_collector._update_performance_summaries()
            ]
            
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # ëª¨ë“  ì‘ì—…ì´ ì˜ˆì™¸ ì—†ì´ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸
            for result in results:
                assert not isinstance(result, Exception)
    
    @pytest.mark.asyncio
    async def test_system_summary_integration(self, integrated_system):
        """ì‹œìŠ¤í…œ ìš”ì•½ í†µí•© í…ŒìŠ¤íŠ¸"""
        config_manager = integrated_system['config_manager']
        connection_monitor = integrated_system['connection_monitor']
        server_manager = integrated_system['server_manager']
        metrics_collector = integrated_system['metrics_collector']
        
        # Mock ë°ì´í„° ì„¤ì •
        with patch.object(connection_monitor.auto_recovery, 'get_summary', return_value={"servers": {}}), \
             patch.object(server_manager, 'get_server_performance', new_callable=AsyncMock) as mock_perf:
            
            mock_perf.return_value = {"status": "running", "metrics": {}}
            
            # ê° ì»´í¬ë„ŒíŠ¸ì˜ ìš”ì•½ ì •ë³´ ìˆ˜ì§‘
            connection_summary = connection_monitor.get_connection_summary()
            system_summary = await server_manager.get_system_summary()
            all_summaries = metrics_collector.get_all_summaries()
            
            # ìš”ì•½ ì •ë³´ê°€ ì˜¬ë°”ë¥´ê²Œ ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸
            assert "total_servers" in connection_summary
            assert "servers" in connection_summary
            assert "total_servers" in system_summary
            assert "management_features" in system_summary
            assert isinstance(all_summaries, dict)
    
    def test_configuration_changes_propagation(self, integrated_system):
        """ì„¤ì • ë³€ê²½ ì „íŒŒ í…ŒìŠ¤íŠ¸"""
        config_manager = integrated_system['config_manager']
        connection_monitor = integrated_system['connection_monitor']
        
        # ìƒˆ ì„œë²„ ì¶”ê°€
        new_server = MCPServerDefinition(
            server_id="dynamicTestServer",
            server_type=MCPServerType.STDIO,
            name="Dynamic Test Server",
            description="ë™ì  ì¶”ê°€ í…ŒìŠ¤íŠ¸ ì„œë²„",
            command="echo",
            args=["dynamic"],
            enabled=True
        )
        
        result = config_manager.add_server(new_server)
        assert result is True
        
        # ì„¤ì • ë³€ê²½ì´ ë‹¤ë¥¸ ì»´í¬ë„ŒíŠ¸ì— ë°˜ì˜ë˜ëŠ”ì§€ í™•ì¸
        enabled_servers = config_manager.get_enabled_servers()
        assert "dynamicTestServer" in enabled_servers
        assert len(enabled_servers) == 3  # ê¸°ì¡´ 2ê°œ + ìƒˆë¡œ ì¶”ê°€ 1ê°œ
    
    @pytest.mark.asyncio
    async def test_performance_threshold_integration(self, integrated_system):
        """ì„±ëŠ¥ ì„ê³„ê°’ í†µí•© í…ŒìŠ¤íŠ¸"""
        metrics_collector = integrated_system['metrics_collector']
        
        # ì„ê³„ê°’ì„ ì´ˆê³¼í•˜ëŠ” ì„±ëŠ¥ ìš”ì•½ ì„¤ì •
        from core.monitoring.performance_metrics_collector import ServerPerformanceSummary
        
        high_cpu_summary = ServerPerformanceSummary(
            server_id="highCpuServer",
            server_type="test",
            last_update=datetime.now(),
            avg_cpu_usage=90.0,  # ì„ê³„ê°’ ì´ˆê³¼
            avg_response_time=2000.0  # ì„ê³„ê°’ ì´ˆê³¼
        )
        
        metrics_collector.performance_summaries["highCpuServer"] = high_cpu_summary
        
        # ì•Œë¦¼ í™•ì¸
        await metrics_collector._check_alerts()
        
        active_alerts = metrics_collector.get_active_alerts()
        assert len(active_alerts) > 0
        
        # CPU ì‚¬ìš©ë¥  ì•Œë¦¼ì´ ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸
        cpu_alerts = [a for a in active_alerts if a.metric_type.value == "cpu_usage"]
        assert len(cpu_alerts) > 0

class TestMonitoringSystemResilience:
    """ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ë³µì›ë ¥ í…ŒìŠ¤íŠ¸"""
    
    @pytest.mark.asyncio
    async def test_system_resilience_to_component_failures(self):
        """ì»´í¬ë„ŒíŠ¸ ì¥ì• ì— ëŒ€í•œ ì‹œìŠ¤í…œ ë³µì›ë ¥ í…ŒìŠ¤íŠ¸"""
        with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as f:
            test_config = {"mcpServers": {}, "globalSettings": {}}
            json.dump(test_config, f, indent=2)
            temp_config_path = f.name
        
        try:
            config_manager = MCPConfigManager(config_path=temp_config_path)
            
            # Config Managerê°€ ì‹¤íŒ¨í•´ë„ ë‹¤ë¥¸ ì»´í¬ë„ŒíŠ¸ê°€ ë™ì‘í•˜ëŠ”ì§€ í™•ì¸
            with patch.object(config_manager, 'get_enabled_servers', side_effect=Exception("Config error")):
                
                connection_monitor = MCPConnectionMonitor(config_manager=config_manager)
                
                # ì„¤ì • ì˜¤ë¥˜ê°€ ìˆì–´ë„ ëª¨ë‹ˆí„°ê°€ ì´ˆê¸°í™”ë˜ëŠ”ì§€ í™•ì¸
                assert connection_monitor is not None
                assert connection_monitor.connections == {}
                
                # ì—ëŸ¬ê°€ ë°œìƒí•´ë„ ëª¨ë‹ˆí„°ë§ ì‹œì‘ì´ ì‹¤íŒ¨í•˜ì§€ ì•ŠëŠ”ì§€ í™•ì¸
                try:
                    # ì§§ì€ ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì‹œë„
                    async def quick_monitor():
                        await asyncio.sleep(0.01)
                        connection_monitor.monitoring_active = False
                    
                    monitor_task = asyncio.create_task(connection_monitor.start_monitoring())
                    stop_task = asyncio.create_task(quick_monitor())
                    
                    await asyncio.gather(monitor_task, stop_task, return_exceptions=True)
                    
                except Exception:
                    pass  # ì˜ˆì™¸ê°€ ë°œìƒí•´ë„ ì‹œìŠ¤í…œì´ ì™„ì „íˆ ì¤‘ë‹¨ë˜ì§€ ì•Šì•„ì•¼ í•¨
                
        finally:
            if os.path.exists(temp_config_path):
                os.unlink(temp_config_path)
    
    @pytest.mark.asyncio
    async def test_resource_cleanup_on_shutdown(self):
        """ì‹œìŠ¤í…œ ì¢…ë£Œ ì‹œ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ í…ŒìŠ¤íŠ¸"""
        with tempfile.NamedTemporaryFile(suffix='.db', delete=False) as f:
            temp_db_path = f.name
        
        try:
            with patch('core.monitoring.performance_metrics_collector.get_mcp_config_manager'), \
                 patch('core.monitoring.performance_metrics_collector.get_server_manager'):
                
                metrics_collector = PerformanceMetricsCollector(db_path=temp_db_path)
                
                # ì¼ë¶€ ë©”íŠ¸ë¦­ ì¶”ê°€
                from core.monitoring.performance_metrics_collector import MetricRecord, MetricType
                test_metric = MetricRecord(
                    server_id="testServer",
                    server_type="test",
                    metric_type=MetricType.CPU_USAGE,
                    value=50.0,
                    timestamp=datetime.now()
                )
                metrics_collector._add_metric(test_metric)
                
                # ì •ìƒ ì¢…ë£Œ
                await metrics_collector.stop_collection()
                
                # ë©”íŠ¸ë¦­ì´ ì €ì¥ë˜ì—ˆëŠ”ì§€ í™•ì¸
                assert metrics_collector.is_collecting is False
                assert len(metrics_collector.metrics_cache) == 0  # ì •ë¦¬ë¨
                
        finally:
            if os.path.exists(temp_db_path):
                os.unlink(temp_db_path)

if __name__ == "__main__":
    pytest.main([__file__, "-v"]) 