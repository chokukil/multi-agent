#!/usr/bin/env python3
"""
Real User Scenario Testing
ì‹¤ì œ ì‚¬ìš©ì ì‹œë‚˜ë¦¬ì˜¤ ê¸°ë°˜ ì—”ë“œíˆ¬ì—”ë“œ í…ŒìŠ¤íŠ¸

ë‹¤ì–‘í•œ ë°ì´í„° íƒ€ì…(CSV, Excel, JSON) ë° ë¶„ì„ ìœ í˜• ê²€ì¦

Author: CherryAI Team
"""

import os
import json
import tempfile
import pandas as pd
import requests
import time
from datetime import datetime
from pathlib import Path

class RealUserScenarioTest:
    """ì‹¤ì œ ì‚¬ìš©ì ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸"""
    
    def __init__(self):
        self.results = {
            "test_start": datetime.now().isoformat(),
            "tests": [],
            "overall_success": False,
            "errors": [],
            "scenario_results": []
        }
        self.streamlit_url = "http://localhost:8501"
        self.test_data_dir = None
    
    def run_comprehensive_test(self):
        """ì¢…í•© ì‹¤ì œ ì‚¬ìš©ì ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print("ğŸ§ª Real User Scenario Comprehensive Testing")
        print("=" * 70)
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ë””ë ‰í„°ë¦¬ ìƒì„±
        self.test_data_dir = tempfile.mkdtemp(prefix="cherryai_user_scenarios_")
        
        try:
            # 1. CSV ë°ì´í„° ë¶„ì„ ì‹œë‚˜ë¦¬ì˜¤
            self._test_csv_analysis_scenario()
            
            # 2. Excel ë°ì´í„° ë¶„ì„ ì‹œë‚˜ë¦¬ì˜¤
            self._test_excel_analysis_scenario()
            
            # 3. JSON ë°ì´í„° ë¶„ì„ ì‹œë‚˜ë¦¬ì˜¤
            self._test_json_analysis_scenario()
            
            # 4. ë‹¤ì¤‘ íŒŒì¼ í†µí•© ë¶„ì„ ì‹œë‚˜ë¦¬ì˜¤
            self._test_multi_file_integration_scenario()
            
            # 5. ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì‹œë‚˜ë¦¬ì˜¤
            self._test_large_dataset_scenario()
            
            # ê²°ê³¼ ê³„ì‚°
            success_count = sum(1 for test in self.results["tests"] if test["success"])
            total_count = len(self.results["tests"])
            self.results["overall_success"] = success_count >= total_count * 0.8
            
            print(f"\nğŸ“Š ì‹¤ì œ ì‚¬ìš©ì ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸ ê²°ê³¼: {success_count}/{total_count} ì„±ê³µ")
            
        finally:
            # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì •ë¦¬
            if self.test_data_dir:
                import shutil
                shutil.rmtree(self.test_data_dir, ignore_errors=True)
        
        return self.results
    
    def _test_csv_analysis_scenario(self):
        """CSV ë°ì´í„° ë¶„ì„ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸"""
        print("\n1ï¸âƒ£ CSV ë°ì´í„° ë¶„ì„ ì‹œë‚˜ë¦¬ì˜¤")
        
        # ì‹¤ì œ ë¹„ì¦ˆë‹ˆìŠ¤ ì‹œë‚˜ë¦¬ì˜¤: ê³ ê° êµ¬ë§¤ ë°ì´í„° ë¶„ì„
        csv_data = {
            "customer_id": [f"CUST_{i:03d}" for i in range(1, 101)],
            "age": [20 + (i % 50) for i in range(100)],
            "gender": ["Male" if i % 2 == 0 else "Female" for i in range(100)],
            "city": [["Seoul", "Busan", "Incheon", "Daegu", "Daejeon"][i % 5] for i in range(100)],
            "purchase_amount": [1000 + (i * 150) % 5000 for i in range(100)],
            "category": [["Electronics", "Clothing", "Books", "Food", "Sports"][i % 5] for i in range(100)]
        }
        
        df = pd.DataFrame(csv_data)
        csv_file = os.path.join(self.test_data_dir, "customer_data.csv")
        df.to_csv(csv_file, index=False)
        
        # CSV ë¶„ì„ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
        csv_analysis_results = self._perform_data_analysis_test(
            file_path=csv_file,
            data_type="CSV",
            expected_features=[
                "ê¸°ë³¸ í†µê³„",
                "ë°ì´í„° íƒ€ì… í™•ì¸", 
                "ê²°ì¸¡ê°’ ê²€ì‚¬",
                "ë²”ì£¼í˜• ë°ì´í„° ë¶„ì„",
                "ìˆ˜ì¹˜í˜• ë°ì´í„° ë¶„ì„"
            ]
        )
        
        success = csv_analysis_results["data_loaded"] and csv_analysis_results["features_found"] >= 3
        details = f"ë¡œë“œ: {csv_analysis_results['data_loaded']}, ê¸°ëŠ¥: {csv_analysis_results['features_found']}/5"
        
        self._log_test("CSV ë°ì´í„° ë¶„ì„ ì‹œë‚˜ë¦¬ì˜¤", success, details)
    
    def _test_excel_analysis_scenario(self):
        """Excel ë°ì´í„° ë¶„ì„ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸"""
        print("\n2ï¸âƒ£ Excel ë°ì´í„° ë¶„ì„ ì‹œë‚˜ë¦¬ì˜¤")
        
        # ì‹¤ì œ ë¹„ì¦ˆë‹ˆìŠ¤ ì‹œë‚˜ë¦¬ì˜¤: ë§¤ì¶œ ë³´ê³ ì„œ ë¶„ì„
        excel_data = {
            "month": ["2024-01", "2024-02", "2024-03", "2024-04", "2024-05", "2024-06"],
            "revenue": [1200000, 1350000, 1180000, 1420000, 1550000, 1380000],
            "costs": [800000, 850000, 790000, 920000, 980000, 890000],
            "profit": [400000, 500000, 390000, 500000, 570000, 490000],
            "region": ["Seoul", "Busan", "Seoul", "Incheon", "Seoul", "Daegu"]
        }
        
        df = pd.DataFrame(excel_data)
        excel_file = os.path.join(self.test_data_dir, "sales_report.xlsx")
        df.to_excel(excel_file, index=False)
        
        # Excel ë¶„ì„ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
        excel_analysis_results = self._perform_data_analysis_test(
            file_path=excel_file,
            data_type="Excel",
            expected_features=[
                "ì‹œê³„ì—´ ë¶„ì„",
                "ë§¤ì¶œ íŠ¸ë Œë“œ",
                "ì§€ì—­ë³„ ë¶„ì„", 
                "ìˆ˜ìµì„± ë¶„ì„",
                "ì‹œê°í™”"
            ]
        )
        
        success = excel_analysis_results["data_loaded"] and excel_analysis_results["features_found"] >= 2
        details = f"ë¡œë“œ: {excel_analysis_results['data_loaded']}, ê¸°ëŠ¥: {excel_analysis_results['features_found']}/5"
        
        self._log_test("Excel ë°ì´í„° ë¶„ì„ ì‹œë‚˜ë¦¬ì˜¤", success, details)
    
    def _test_json_analysis_scenario(self):
        """JSON ë°ì´í„° ë¶„ì„ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸"""
        print("\n3ï¸âƒ£ JSON ë°ì´í„° ë¶„ì„ ì‹œë‚˜ë¦¬ì˜¤")
        
        # ì‹¤ì œ ë¹„ì¦ˆë‹ˆìŠ¤ ì‹œë‚˜ë¦¬ì˜¤: API ë¡œê·¸ ë°ì´í„° ë¶„ì„
        json_data = [
            {
                "timestamp": "2024-06-28T10:00:00Z",
                "endpoint": "/api/users",
                "method": "GET", 
                "response_time": 120,
                "status_code": 200,
                "user_agent": "Chrome"
            },
            {
                "timestamp": "2024-06-28T10:01:00Z",
                "endpoint": "/api/orders",
                "method": "POST",
                "response_time": 250,
                "status_code": 201,
                "user_agent": "Firefox"
            },
            {
                "timestamp": "2024-06-28T10:02:00Z", 
                "endpoint": "/api/users",
                "method": "GET",
                "response_time": 95,
                "status_code": 200,
                "user_agent": "Safari"
            }
        ] * 20  # 60ê°œ ë ˆì½”ë“œ ìƒì„±
        
        json_file = os.path.join(self.test_data_dir, "api_logs.json")
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(json_data, f, ensure_ascii=False, indent=2)
        
        # JSON ë¶„ì„ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
        json_analysis_results = self._perform_data_analysis_test(
            file_path=json_file,
            data_type="JSON",
            expected_features=[
                "API ì„±ëŠ¥ ë¶„ì„",
                "ì‘ë‹µ ì‹œê°„ ë¶„ì„",
                "ìƒíƒœ ì½”ë“œ ë¶„í¬",
                "ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš©ëŸ‰",
                "ì‚¬ìš©ì ì—ì´ì „íŠ¸ ë¶„ì„"
            ]
        )
        
        success = json_analysis_results["data_loaded"] and json_analysis_results["features_found"] >= 2
        details = f"ë¡œë“œ: {json_analysis_results['data_loaded']}, ê¸°ëŠ¥: {json_analysis_results['features_found']}/5"
        
        self._log_test("JSON ë°ì´í„° ë¶„ì„ ì‹œë‚˜ë¦¬ì˜¤", success, details)
    
    def _test_multi_file_integration_scenario(self):
        """ë‹¤ì¤‘ íŒŒì¼ í†µí•© ë¶„ì„ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸"""
        print("\n4ï¸âƒ£ ë‹¤ì¤‘ íŒŒì¼ í†µí•© ë¶„ì„ ì‹œë‚˜ë¦¬ì˜¤")
        
        # ê³ ê° ê¸°ë³¸ ì •ë³´ (CSV)
        customers_data = {
            "customer_id": [f"CUST_{i:03d}" for i in range(1, 21)],
            "name": [f"Customer {i}" for i in range(1, 21)],
            "email": [f"customer{i}@example.com" for i in range(1, 21)],
            "signup_date": ["2024-01-01"] * 20
        }
        customers_df = pd.DataFrame(customers_data)
        customers_file = os.path.join(self.test_data_dir, "customers.csv")
        customers_df.to_csv(customers_file, index=False)
        
        # ì£¼ë¬¸ ì •ë³´ (Excel)
        orders_data = {
            "order_id": [f"ORD_{i:03d}" for i in range(1, 51)],
            "customer_id": [f"CUST_{(i % 20) + 1:03d}" for i in range(50)],
            "product": [f"Product {(i % 10) + 1}" for i in range(50)],
            "amount": [100 + (i * 50) for i in range(50)]
        }
        orders_df = pd.DataFrame(orders_data)
        orders_file = os.path.join(self.test_data_dir, "orders.xlsx")
        orders_df.to_excel(orders_file, index=False)
        
        # í†µí•© ë¶„ì„ í…ŒìŠ¤íŠ¸
        integration_features = [
            "ë‹¤ì¤‘ íŒŒì¼ ë¡œë“œ",
            "ë°ì´í„° ì¡°ì¸/ë³‘í•©",
            "ê³ ê°ë³„ ì£¼ë¬¸ ë¶„ì„",
            "ë§¤ì¶œ ì§‘ê³„",
            "í†µí•© ë¦¬í¬íŠ¸"
        ]
        
        # íŒŒì¼ ì¡´ì¬ ë° ë¡œë“œ ê°€ëŠ¥ì„± í™•ì¸
        files_loadable = 0
        for file_path in [customers_file, orders_file]:
            try:
                if file_path.endswith('.csv'):
                    test_df = pd.read_csv(file_path)
                elif file_path.endswith('.xlsx'):
                    test_df = pd.read_excel(file_path)
                
                if len(test_df) > 0:
                    files_loadable += 1
                    print(f"âœ… {os.path.basename(file_path)}: ë¡œë“œ ê°€ëŠ¥ ({len(test_df)}ê°œ ë ˆì½”ë“œ)")
                
            except Exception as e:
                print(f"âŒ {os.path.basename(file_path)}: ë¡œë“œ ì‹¤íŒ¨ - {e}")
        
        # í†µí•© ë¶„ì„ ì‹œë®¬ë ˆì´ì…˜
        integration_possible = files_loadable == 2
        if integration_possible:
            # ì‹¤ì œ ì¡°ì¸ í…ŒìŠ¤íŠ¸
            try:
                customers_df = pd.read_csv(customers_file)
                orders_df = pd.read_excel(orders_file)
                
                # ì¡°ì¸ ìˆ˜í–‰
                merged_df = pd.merge(orders_df, customers_df, on='customer_id', how='left')
                join_successful = len(merged_df) > 0 and 'name' in merged_df.columns
                
                if join_successful:
                    print("âœ… ë°ì´í„° ì¡°ì¸: ì„±ê³µ")
                else:
                    print("âŒ ë°ì´í„° ì¡°ì¸: ì‹¤íŒ¨")
                    
            except Exception as e:
                join_successful = False
                print(f"âŒ ë°ì´í„° ì¡°ì¸: ì˜¤ë¥˜ - {e}")
        else:
            join_successful = False
        
        success = files_loadable >= 2 and join_successful
        details = f"ë¡œë“œê°€ëŠ¥íŒŒì¼: {files_loadable}/2, ì¡°ì¸ì„±ê³µ: {join_successful}"
        
        self._log_test("ë‹¤ì¤‘ íŒŒì¼ í†µí•© ë¶„ì„", success, details)
    
    def _test_large_dataset_scenario(self):
        """ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸"""
        print("\n5ï¸âƒ£ ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì‹œë‚˜ë¦¬ì˜¤")
        
        # ëŒ€ìš©ëŸ‰ ë°ì´í„° ìƒì„± (10,000 ë ˆì½”ë“œ)
        large_data_size = 10000
        
        large_data = {
            "id": range(1, large_data_size + 1),
            "timestamp": [f"2024-06-{(i % 30) + 1:02d}T{(i % 24):02d}:00:00Z" for i in range(large_data_size)],
            "value": [(i * 1.5) % 1000 for i in range(large_data_size)],
            "category": [f"Category_{(i % 50) + 1}" for i in range(large_data_size)],
            "status": ["active" if i % 3 == 0 else "inactive" for i in range(large_data_size)]
        }
        
        large_df = pd.DataFrame(large_data)
        large_file = os.path.join(self.test_data_dir, "large_dataset.csv")
        
        # ëŒ€ìš©ëŸ‰ ë°ì´í„° ì €ì¥ ë° ë¡œë“œ í…ŒìŠ¤íŠ¸
        try:
            start_time = time.time()
            large_df.to_csv(large_file, index=False)
            save_time = time.time() - start_time
            
            file_size_mb = os.path.getsize(large_file) / (1024 * 1024)
            
            start_time = time.time()
            loaded_df = pd.read_csv(large_file)
            load_time = time.time() - start_time
            
            # ê¸°ë³¸ ë¶„ì„ ìˆ˜í–‰
            start_time = time.time()
            basic_stats = loaded_df.describe()
            value_counts = loaded_df['category'].value_counts()
            analysis_time = time.time() - start_time
            
            performance_ok = (
                save_time < 5.0 and  # 5ì´ˆ ì´ë‚´ ì €ì¥
                load_time < 3.0 and  # 3ì´ˆ ì´ë‚´ ë¡œë“œ
                analysis_time < 2.0   # 2ì´ˆ ì´ë‚´ ë¶„ì„
            )
            
            print(f"ğŸ“Š íŒŒì¼ í¬ê¸°: {file_size_mb:.2f}MB")
            print(f"ğŸ“Š ì €ì¥ ì‹œê°„: {save_time:.2f}ì´ˆ")
            print(f"ğŸ“Š ë¡œë“œ ì‹œê°„: {load_time:.2f}ì´ˆ")
            print(f"ğŸ“Š ë¶„ì„ ì‹œê°„: {analysis_time:.2f}ì´ˆ")
            
            if performance_ok:
                print("âœ… ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬: ì„±ëŠ¥ ê¸°ì¤€ ì¶©ì¡±")
            else:
                print("âš ï¸ ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬: ì„±ëŠ¥ ê°œì„  í•„ìš”")
            
            success = len(loaded_df) == large_data_size and performance_ok
            details = f"í¬ê¸°: {file_size_mb:.1f}MB, ì„±ëŠ¥: {performance_ok}, ë ˆì½”ë“œ: {len(loaded_df)}"
            
        except Exception as e:
            success = False
            details = f"ì˜¤ë¥˜: {str(e)}"
            print(f"âŒ ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        
        self._log_test("ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬", success, details)
    
    def _perform_data_analysis_test(self, file_path: str, data_type: str, expected_features: list) -> dict:
        """ë°ì´í„° ë¶„ì„ í…ŒìŠ¤íŠ¸ ìˆ˜í–‰"""
        result = {
            "data_loaded": False,
            "features_found": 0,
            "analysis_time": 0,
            "error": None
        }
        
        try:
            start_time = time.time()
            
            # íŒŒì¼ ë¡œë“œ
            if data_type == "CSV":
                df = pd.read_csv(file_path)
            elif data_type == "Excel":
                df = pd.read_excel(file_path)
            elif data_type == "JSON":
                df = pd.read_json(file_path)
            else:
                raise ValueError(f"ì§€ì›ë˜ì§€ ì•ŠëŠ” ë°ì´í„° íƒ€ì…: {data_type}")
            
            result["data_loaded"] = len(df) > 0
            
            # ê¸°ë³¸ ë¶„ì„ ìˆ˜í–‰
            analysis_features = []
            
            # ê¸°ë³¸ í†µê³„
            if len(df.select_dtypes(include=['number']).columns) > 0:
                basic_stats = df.describe()
                analysis_features.append("ê¸°ë³¸ í†µê³„")
            
            # ë°ì´í„° íƒ€ì… í™•ì¸
            if len(df.dtypes) > 0:
                analysis_features.append("ë°ì´í„° íƒ€ì… í™•ì¸")
            
            # ê²°ì¸¡ê°’ ê²€ì‚¬
            missing_values = df.isnull().sum()
            analysis_features.append("ê²°ì¸¡ê°’ ê²€ì‚¬")
            
            # ë²”ì£¼í˜• ë°ì´í„° ë¶„ì„
            categorical_cols = df.select_dtypes(include=['object']).columns
            if len(categorical_cols) > 0:
                for col in categorical_cols[:2]:  # ìµœëŒ€ 2ê°œ ì»¬ëŸ¼
                    value_counts = df[col].value_counts()
                analysis_features.append("ë²”ì£¼í˜• ë°ì´í„° ë¶„ì„")
            
            # ìˆ˜ì¹˜í˜• ë°ì´í„° ë¶„ì„
            numeric_cols = df.select_dtypes(include=['number']).columns
            if len(numeric_cols) > 0:
                analysis_features.append("ìˆ˜ì¹˜í˜• ë°ì´í„° ë¶„ì„")
            
            result["features_found"] = len(analysis_features)
            result["analysis_time"] = time.time() - start_time
            
            print(f"âœ… {data_type} ë¶„ì„: {len(df)}ê°œ ë ˆì½”ë“œ, {result['features_found']}ê°œ ê¸°ëŠ¥")
            
        except Exception as e:
            result["error"] = str(e)
            print(f"âŒ {data_type} ë¶„ì„ ì‹¤íŒ¨: {e}")
        
        return result
    
    def _log_test(self, test_name: str, success: bool, details: str = ""):
        """í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¡œê¹…"""
        self.results["tests"].append({
            "name": test_name,
            "success": success,
            "details": details,
            "timestamp": datetime.now().isoformat()
        })

def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    tester = RealUserScenarioTest()
    results = tester.run_comprehensive_test()
    
    # ê²°ê³¼ íŒŒì¼ ì €ì¥
    results_file = f"real_user_scenarios_test_results_{int(time.time())}.json"
    with open(results_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ“„ ê²°ê³¼ ì €ì¥: {results_file}")
    
    # ìµœì¢… ìƒíƒœ ì¶œë ¥
    if results["overall_success"]:
        print("ğŸ‰ ì‹¤ì œ ì‚¬ìš©ì ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
        return True
    else:
        print("âš ï¸ ì¼ë¶€ ì‚¬ìš©ì ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤")
        return False

if __name__ == "__main__":
    main() 