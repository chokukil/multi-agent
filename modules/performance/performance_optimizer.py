"""
ì„±ëŠ¥ ìµœì í™” ì‹œìŠ¤í…œ

ì´ ëª¨ë“ˆì€ ëŒ€ìš©ëŸ‰ ì•„í‹°íŒ©íŠ¸ ì§€ì—° ë¡œë”©, ë©”ëª¨ë¦¬ ê´€ë¦¬ ë° ìë™ ì •ë¦¬,
ìºì‹± ì „ëµ ë° ë¬´íš¨í™” ì •ì±…ì„ ì œê³µí•˜ëŠ” ì„±ëŠ¥ ìµœì í™” ì‹œìŠ¤í…œì„ êµ¬í˜„í•©ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
- ëŒ€ìš©ëŸ‰ ì•„í‹°íŒ©íŠ¸ ì§€ì—° ë¡œë”© (Lazy Loading)
- ë©”ëª¨ë¦¬ ê´€ë¦¬ ë° ìë™ ì •ë¦¬
- ìºì‹± ì „ëµ ë° ë¬´íš¨í™”
- ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë° ìµœì í™”
"""

import asyncio
import gc
import json
import logging
import pickle
import time
import threading
import weakref
from collections import defaultdict, OrderedDict
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional, Callable, Union, Tuple
from enum import Enum
import streamlit as st
import psutil
import sys
from concurrent.futures import ThreadPoolExecutor, as_completed
import hashlib

logger = logging.getLogger(__name__)

class CacheType(Enum):
    """ìºì‹œ ìœ í˜•"""
    MEMORY = "memory"           # ë©”ëª¨ë¦¬ ìºì‹œ
    DISK = "disk"              # ë””ìŠ¤í¬ ìºì‹œ
    HYBRID = "hybrid"          # í•˜ì´ë¸Œë¦¬ë“œ ìºì‹œ
    DISTRIBUTED = "distributed" # ë¶„ì‚° ìºì‹œ

class OptimizationLevel(Enum):
    """ìµœì í™” ìˆ˜ì¤€"""
    MINIMAL = "minimal"         # ìµœì†Œ ìµœì í™”
    STANDARD = "standard"       # í‘œì¤€ ìµœì í™”
    AGGRESSIVE = "aggressive"   # ì ê·¹ì  ìµœì í™”
    MAXIMUM = "maximum"         # ìµœëŒ€ ìµœì í™”

class ResourceType(Enum):
    """ë¦¬ì†ŒìŠ¤ ìœ í˜•"""
    MEMORY = "memory"
    CPU = "cpu"
    DISK = "disk"
    NETWORK = "network"

@dataclass
class CacheEntry:
    """ìºì‹œ ì—”íŠ¸ë¦¬"""
    key: str
    data: Any
    size: int  # bytes
    created_at: datetime
    last_accessed: datetime
    access_count: int = 0
    ttl: Optional[int] = None  # seconds
    priority: int = 1  # 1-10 (10ì´ ê°€ì¥ ë†’ìŒ)
    compressed: bool = False

@dataclass
class LazyLoadConfig:
    """ì§€ì—° ë¡œë”© ì„¤ì •"""
    enabled: bool = True
    chunk_size: int = 1000        # ì²­í¬ í¬ê¸°
    preload_chunks: int = 2       # ë¯¸ë¦¬ ë¡œë“œí•  ì²­í¬ ìˆ˜
    memory_threshold: float = 0.8  # ë©”ëª¨ë¦¬ ì„ê³„ì¹˜ (80%)
    max_concurrent_loads: int = 3  # ìµœëŒ€ ë™ì‹œ ë¡œë”©

@dataclass
class MemoryStats:
    """ë©”ëª¨ë¦¬ í†µê³„"""
    total_memory: int
    available_memory: int
    used_memory: int
    memory_percent: float
    cache_memory: int
    app_memory: int

@dataclass
class PerformanceMetrics:
    """ì„±ëŠ¥ ë©”íŠ¸ë¦­"""
    timestamp: datetime
    memory_usage: float
    cpu_usage: float
    cache_hit_rate: float
    avg_response_time: float
    concurrent_users: int
    active_artifacts: int

class LRUCache:
    """LRU ìºì‹œ êµ¬í˜„"""
    
    def __init__(self, max_size: int, max_memory: int):
        self.max_size = max_size
        self.max_memory = max_memory  # bytes
        self.cache: OrderedDict[str, CacheEntry] = OrderedDict()
        self.current_memory = 0
        self.hits = 0
        self.misses = 0
        self.lock = threading.RLock()
    
    def get(self, key: str) -> Optional[Any]:
        """ìºì‹œì—ì„œ ë°ì´í„° ì¡°íšŒ"""
        
        with self.lock:
            if key in self.cache:
                entry = self.cache[key]
                
                # TTL ì²´í¬
                if entry.ttl and (datetime.now() - entry.created_at).total_seconds() > entry.ttl:
                    self._remove_entry(key)
                    self.misses += 1
                    return None
                
                # LRU ì—…ë°ì´íŠ¸
                entry.last_accessed = datetime.now()
                entry.access_count += 1
                self.cache.move_to_end(key)
                
                self.hits += 1
                return entry.data
            
            self.misses += 1
            return None
    
    def put(self, key: str, data: Any, size: int = None, ttl: int = None, priority: int = 1):
        """ìºì‹œì— ë°ì´í„° ì €ì¥"""
        
        if size is None:
            size = sys.getsizeof(data)
        
        with self.lock:
            # ê¸°ì¡´ ì—”íŠ¸ë¦¬ ì œê±°
            if key in self.cache:
                self._remove_entry(key)
            
            # ë©”ëª¨ë¦¬ ì²´í¬
            while (self.current_memory + size > self.max_memory or 
                   len(self.cache) >= self.max_size):
                if not self.cache:
                    break
                self._evict_lru()
            
            # ìƒˆ ì—”íŠ¸ë¦¬ ì¶”ê°€
            entry = CacheEntry(
                key=key,
                data=data,
                size=size,
                created_at=datetime.now(),
                last_accessed=datetime.now(),
                ttl=ttl,
                priority=priority
            )
            
            self.cache[key] = entry
            self.current_memory += size
    
    def _remove_entry(self, key: str):
        """ì—”íŠ¸ë¦¬ ì œê±°"""
        
        if key in self.cache:
            entry = self.cache.pop(key)
            self.current_memory -= entry.size
    
    def _evict_lru(self):
        """ê°€ì¥ ì˜¤ë˜ëœ í•­ëª© ì œê±°"""
        
        if self.cache:
            # ìš°ì„ ìˆœìœ„ê°€ ë‚®ì€ ê²ƒë¶€í„° ì œê±°
            sorted_items = sorted(
                self.cache.items(),
                key=lambda x: (x[1].priority, x[1].last_accessed)
            )
            
            key, _ = sorted_items[0]
            self._remove_entry(key)
    
    def clear(self):
        """ìºì‹œ ì „ì²´ í´ë¦¬ì–´"""
        
        with self.lock:
            self.cache.clear()
            self.current_memory = 0
    
    def get_stats(self) -> Dict[str, Any]:
        """ìºì‹œ í†µê³„"""
        
        total_requests = self.hits + self.misses
        hit_rate = self.hits / total_requests if total_requests > 0 else 0
        
        return {
            'size': len(self.cache),
            'max_size': self.max_size,
            'memory_usage': self.current_memory,
            'max_memory': self.max_memory,
            'hits': self.hits,
            'misses': self.misses,
            'hit_rate': hit_rate
        }

class LazyArtifactLoader:
    """ì§€ì—° ì•„í‹°íŒ©íŠ¸ ë¡œë”"""
    
    def __init__(self, config: LazyLoadConfig):
        self.config = config
        self.loaded_chunks: Dict[str, Dict[int, Any]] = defaultdict(dict)
        self.loading_status: Dict[str, bool] = defaultdict(bool)
        self.executor = ThreadPoolExecutor(max_workers=config.max_concurrent_loads)
        self.lock = threading.RLock()
    
    def register_artifact(self, artifact_id: str, data_source: Any, total_size: int):
        """ì•„í‹°íŒ©íŠ¸ ë“±ë¡"""
        
        self.artifact_registry[artifact_id] = {
            'data_source': data_source,
            'total_size': total_size,
            'chunk_count': (total_size + self.config.chunk_size - 1) // self.config.chunk_size,
            'loaded_chunks': set()
        }
    
    def load_chunk(self, artifact_id: str, chunk_index: int) -> Any:
        """ì²­í¬ ë¡œë”©"""
        
        with self.lock:
            # ì´ë¯¸ ë¡œë“œëœ ì²­í¬ í™•ì¸
            if chunk_index in self.loaded_chunks[artifact_id]:
                return self.loaded_chunks[artifact_id][chunk_index]
            
            # ë©”ëª¨ë¦¬ ì²´í¬
            if not self._check_memory():
                self._free_memory()
            
            # ì²­í¬ ë¡œë”©
            chunk_data = self._load_chunk_data(artifact_id, chunk_index)
            self.loaded_chunks[artifact_id][chunk_index] = chunk_data
            
            # ë¯¸ë¦¬ ë¡œë”© (ë¹„ë™ê¸°)
            self._preload_next_chunks(artifact_id, chunk_index)
            
            return chunk_data
    
    def _load_chunk_data(self, artifact_id: str, chunk_index: int) -> Any:
        """ì‹¤ì œ ì²­í¬ ë°ì´í„° ë¡œë”©"""
        
        start_time = time.time()
        
        try:
            # ë°ì´í„° ì†ŒìŠ¤ì—ì„œ ì²­í¬ ë¡œë”© (êµ¬í˜„ ì˜ˆì‹œ)
            start_idx = chunk_index * self.config.chunk_size
            end_idx = start_idx + self.config.chunk_size
            
            # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë°ì´í„° ì†ŒìŠ¤ì— ë”°ë¼ ë‹¤ë¦„
            chunk_data = f"chunk_{artifact_id}_{chunk_index}"
            
            load_time = time.time() - start_time
            logger.debug(f"ì²­í¬ ë¡œë”© ì™„ë£Œ: {artifact_id}[{chunk_index}] ({load_time:.3f}ì´ˆ)")
            
            return chunk_data
            
        except Exception as e:
            logger.error(f"ì²­í¬ ë¡œë”© ì‹¤íŒ¨: {artifact_id}[{chunk_index}] - {e}")
            return None
    
    def _preload_next_chunks(self, artifact_id: str, current_chunk: int):
        """ë‹¤ìŒ ì²­í¬ë“¤ ë¯¸ë¦¬ ë¡œë”©"""
        
        if not self.config.enabled:
            return
        
        # ë¯¸ë¦¬ ë¡œë”©í•  ì²­í¬ë“¤ ê³„ì‚°
        for i in range(1, self.config.preload_chunks + 1):
            next_chunk = current_chunk + i
            
            if (next_chunk not in self.loaded_chunks[artifact_id] and
                not self.loading_status.get(f"{artifact_id}_{next_chunk}", False)):
                
                # ë¹„ë™ê¸° ë¡œë”©
                self.executor.submit(self._async_load_chunk, artifact_id, next_chunk)
    
    def _async_load_chunk(self, artifact_id: str, chunk_index: int):
        """ë¹„ë™ê¸° ì²­í¬ ë¡œë”©"""
        
        loading_key = f"{artifact_id}_{chunk_index}"
        self.loading_status[loading_key] = True
        
        try:
            chunk_data = self._load_chunk_data(artifact_id, chunk_index)
            
            with self.lock:
                self.loaded_chunks[artifact_id][chunk_index] = chunk_data
        
        finally:
            self.loading_status[loading_key] = False
    
    def _check_memory(self) -> bool:
        """ë©”ëª¨ë¦¬ ì²´í¬"""
        
        memory = psutil.virtual_memory()
        return memory.percent / 100.0 < self.config.memory_threshold
    
    def _free_memory(self):
        """ë©”ëª¨ë¦¬ í•´ì œ"""
        
        # ê°€ì¥ ì˜¤ë˜ëœ ì²­í¬ë“¤ ì œê±°
        all_chunks = []
        
        for artifact_id, chunks in self.loaded_chunks.items():
            for chunk_idx, chunk_data in chunks.items():
                all_chunks.append((artifact_id, chunk_idx, time.time()))
        
        # ì˜¤ë˜ëœ ìˆœìœ¼ë¡œ ì •ë ¬
        all_chunks.sort(key=lambda x: x[2])
        
        # ì¼ë¶€ ì²­í¬ ì œê±°
        chunks_to_remove = len(all_chunks) // 4  # 25% ì œê±°
        
        for i in range(chunks_to_remove):
            artifact_id, chunk_idx, _ = all_chunks[i]
            
            if chunk_idx in self.loaded_chunks[artifact_id]:
                del self.loaded_chunks[artifact_id][chunk_idx]
        
        # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
        gc.collect()

class PerformanceOptimizer:
    """ì„±ëŠ¥ ìµœì í™” ì‹œìŠ¤í…œ"""
    
    def __init__(self, optimization_level: OptimizationLevel = OptimizationLevel.STANDARD):
        self.optimization_level = optimization_level
        
        # ìºì‹œ ì‹œìŠ¤í…œ
        self.memory_cache = LRUCache(
            max_size=self._get_cache_size(),
            max_memory=self._get_cache_memory()
        )
        
        # ì§€ì—° ë¡œë”©
        self.lazy_loader = LazyArtifactLoader(
            LazyLoadConfig(
                chunk_size=self._get_chunk_size(),
                preload_chunks=self._get_preload_chunks(),
                memory_threshold=self._get_memory_threshold()
            )
        )
        
        # ì„±ëŠ¥ ë©”íŠ¸ë¦­
        self.metrics_history: List[PerformanceMetrics] = []
        self.monitoring_active = False
        self.monitoring_thread: Optional[threading.Thread] = None
        
        # ìë™ ì •ë¦¬ ì„¤ì •
        self.auto_cleanup_enabled = True
        self.cleanup_interval = 300  # 5ë¶„
        self.last_cleanup = time.time()
        
        # ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§
        self.resource_monitors: Dict[ResourceType, Callable] = {
            ResourceType.MEMORY: self._monitor_memory,
            ResourceType.CPU: self._monitor_cpu,
            ResourceType.DISK: self._monitor_disk
        }
        
        # ìµœì í™” ì „ëµ
        self.optimization_strategies = {
            OptimizationLevel.MINIMAL: self._minimal_optimization,
            OptimizationLevel.STANDARD: self._standard_optimization,
            OptimizationLevel.AGGRESSIVE: self._aggressive_optimization,
            OptimizationLevel.MAXIMUM: self._maximum_optimization
        }
    
    def _get_cache_size(self) -> int:
        """ìµœì í™” ìˆ˜ì¤€ì— ë”°ë¥¸ ìºì‹œ í¬ê¸°"""
        
        sizes = {
            OptimizationLevel.MINIMAL: 100,
            OptimizationLevel.STANDARD: 500,
            OptimizationLevel.AGGRESSIVE: 1000,
            OptimizationLevel.MAXIMUM: 2000
        }
        return sizes[self.optimization_level]
    
    def _get_cache_memory(self) -> int:
        """ìµœì í™” ìˆ˜ì¤€ì— ë”°ë¥¸ ìºì‹œ ë©”ëª¨ë¦¬"""
        
        # ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ì˜ ì¼ì • ë¹„ìœ¨
        total_memory = psutil.virtual_memory().total
        
        ratios = {
            OptimizationLevel.MINIMAL: 0.05,    # 5%
            OptimizationLevel.STANDARD: 0.10,   # 10%
            OptimizationLevel.AGGRESSIVE: 0.15, # 15%
            OptimizationLevel.MAXIMUM: 0.20     # 20%
        }
        
        return int(total_memory * ratios[self.optimization_level])
    
    def _get_chunk_size(self) -> int:
        """ì²­í¬ í¬ê¸° ê²°ì •"""
        
        sizes = {
            OptimizationLevel.MINIMAL: 2000,
            OptimizationLevel.STANDARD: 1000,
            OptimizationLevel.AGGRESSIVE: 500,
            OptimizationLevel.MAXIMUM: 250
        }
        return sizes[self.optimization_level]
    
    def _get_preload_chunks(self) -> int:
        """ë¯¸ë¦¬ ë¡œë“œí•  ì²­í¬ ìˆ˜"""
        
        counts = {
            OptimizationLevel.MINIMAL: 1,
            OptimizationLevel.STANDARD: 2,
            OptimizationLevel.AGGRESSIVE: 3,
            OptimizationLevel.MAXIMUM: 5
        }
        return counts[self.optimization_level]
    
    def _get_memory_threshold(self) -> float:
        """ë©”ëª¨ë¦¬ ì„ê³„ì¹˜"""
        
        thresholds = {
            OptimizationLevel.MINIMAL: 0.9,
            OptimizationLevel.STANDARD: 0.8,
            OptimizationLevel.AGGRESSIVE: 0.7,
            OptimizationLevel.MAXIMUM: 0.6
        }
        return thresholds[self.optimization_level]
    
    def cache_artifact(self, key: str, data: Any, ttl: int = None, priority: int = 1):
        """ì•„í‹°íŒ©íŠ¸ ìºì‹±"""
        
        # ë°ì´í„° í¬ê¸° ê³„ì‚°
        size = sys.getsizeof(data)
        
        # ëŒ€ìš©ëŸ‰ ë°ì´í„°ëŠ” ì••ì¶•
        if size > 1024 * 1024:  # 1MB ì´ìƒ
            data = self._compress_data(data)
            size = sys.getsizeof(data)
        
        # ìºì‹œì— ì €ì¥
        self.memory_cache.put(key, data, size, ttl, priority)
        
        logger.debug(f"ì•„í‹°íŒ©íŠ¸ ìºì‹œë¨: {key} ({size} bytes)")
    
    def get_cached_artifact(self, key: str) -> Optional[Any]:
        """ìºì‹œëœ ì•„í‹°íŒ©íŠ¸ ì¡°íšŒ"""
        
        data = self.memory_cache.get(key)
        
        if data is not None:
            # ì••ì¶•ëœ ë°ì´í„°ë©´ ì••ì¶• í•´ì œ
            if isinstance(data, bytes):
                data = self._decompress_data(data)
            
            logger.debug(f"ìºì‹œ íˆíŠ¸: {key}")
        
        return data
    
    def load_artifact_lazily(self, artifact_id: str, data_source: Any, total_size: int) -> 'LazyArtifact':
        """ì§€ì—° ë¡œë”© ì•„í‹°íŒ©íŠ¸ ìƒì„±"""
        
        self.lazy_loader.register_artifact(artifact_id, data_source, total_size)
        
        return LazyArtifact(artifact_id, self.lazy_loader)
    
    def start_monitoring(self):
        """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        
        if self.monitoring_active:
            return
        
        self.monitoring_active = True
        self.monitoring_thread = threading.Thread(target=self._monitoring_loop, daemon=True)
        self.monitoring_thread.start()
        
        logger.info("ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œì‘ë¨")
    
    def stop_monitoring(self):
        """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€"""
        
        self.monitoring_active = False
        
        if self.monitoring_thread:
            self.monitoring_thread.join(timeout=5)
        
        logger.info("ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€ë¨")
    
    def _monitoring_loop(self):
        """ëª¨ë‹ˆí„°ë§ ë£¨í”„"""
        
        while self.monitoring_active:
            try:
                # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
                metrics = self._collect_metrics()
                self.metrics_history.append(metrics)
                
                # íˆìŠ¤í† ë¦¬ í¬ê¸° ì œí•œ
                if len(self.metrics_history) > 1000:
                    self.metrics_history = self.metrics_history[-500:]
                
                # ìë™ ìµœì í™” ì‹¤í–‰
                if self._should_optimize(metrics):
                    self._auto_optimize(metrics)
                
                # ìë™ ì •ë¦¬
                if self._should_cleanup():
                    self._auto_cleanup()
                
                time.sleep(30)  # 30ì´ˆ ê°„ê²©
                
            except Exception as e:
                logger.error(f"ëª¨ë‹ˆí„°ë§ ì˜¤ë¥˜: {e}")
                time.sleep(60)  # ì˜¤ë¥˜ ì‹œ 1ë¶„ ëŒ€ê¸°
    
    def _collect_metrics(self) -> PerformanceMetrics:
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        
        memory = psutil.virtual_memory()
        cpu_percent = psutil.cpu_percent(interval=1)
        
        cache_stats = self.memory_cache.get_stats()
        
        return PerformanceMetrics(
            timestamp=datetime.now(),
            memory_usage=memory.percent,
            cpu_usage=cpu_percent,
            cache_hit_rate=cache_stats['hit_rate'],
            avg_response_time=0.0,  # TODO: ì‘ë‹µ ì‹œê°„ ì¸¡ì •
            concurrent_users=1,     # TODO: ì‚¬ìš©ì ìˆ˜ ì¸¡ì •
            active_artifacts=len(self.lazy_loader.loaded_chunks)
        )
    
    def _should_optimize(self, metrics: PerformanceMetrics) -> bool:
        """ìµœì í™” í•„ìš” ì—¬ë¶€ íŒë‹¨"""
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì´ 80% ì´ìƒ
        if metrics.memory_usage > 80:
            return True
        
        # CPU ì‚¬ìš©ë¥ ì´ 90% ì´ìƒ
        if metrics.cpu_usage > 90:
            return True
        
        # ìºì‹œ íˆíŠ¸ìœ¨ì´ 50% ë¯¸ë§Œ
        if metrics.cache_hit_rate < 0.5:
            return True
        
        return False
    
    def _auto_optimize(self, metrics: PerformanceMetrics):
        """ìë™ ìµœì í™” ì‹¤í–‰"""
        
        logger.info(f"ìë™ ìµœì í™” ì‹¤í–‰ - ë©”ëª¨ë¦¬: {metrics.memory_usage:.1f}%, CPU: {metrics.cpu_usage:.1f}%")
        
        # ìµœì í™” ì „ëµ ì‹¤í–‰
        strategy = self.optimization_strategies[self.optimization_level]
        strategy(metrics)
    
    def _should_cleanup(self) -> bool:
        """ì •ë¦¬ í•„ìš” ì—¬ë¶€ íŒë‹¨"""
        
        return (self.auto_cleanup_enabled and 
                time.time() - self.last_cleanup > self.cleanup_interval)
    
    def _auto_cleanup(self):
        """ìë™ ì •ë¦¬ ì‹¤í–‰"""
        
        logger.info("ìë™ ì •ë¦¬ ì‹¤í–‰")
        
        # ìºì‹œ ì •ë¦¬
        self._cleanup_cache()
        
        # ì§€ì—° ë¡œë”© ë°ì´í„° ì •ë¦¬
        self._cleanup_lazy_data()
        
        # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
        gc.collect()
        
        self.last_cleanup = time.time()
    
    def _cleanup_cache(self):
        """ìºì‹œ ì •ë¦¬"""
        
        # ë§Œë£Œëœ ìºì‹œ ì—”íŠ¸ë¦¬ ì œê±°
        expired_keys = []
        
        for key, entry in self.memory_cache.cache.items():
            if (entry.ttl and 
                (datetime.now() - entry.created_at).total_seconds() > entry.ttl):
                expired_keys.append(key)
        
        for key in expired_keys:
            self.memory_cache._remove_entry(key)
        
        logger.debug(f"ë§Œë£Œëœ ìºì‹œ ì—”íŠ¸ë¦¬ {len(expired_keys)}ê°œ ì œê±°")
    
    def _cleanup_lazy_data(self):
        """ì§€ì—° ë¡œë”© ë°ì´í„° ì •ë¦¬"""
        
        # ì˜¤ë˜ëœ ì²­í¬ ì œê±°
        self.lazy_loader._free_memory()
    
    def _minimal_optimization(self, metrics: PerformanceMetrics):
        """ìµœì†Œ ìµœì í™” ì „ëµ"""
        
        if metrics.memory_usage > 90:
            # ê¸´ê¸‰ ë©”ëª¨ë¦¬ ì •ë¦¬
            self._cleanup_cache()
            gc.collect()
    
    def _standard_optimization(self, metrics: PerformanceMetrics):
        """í‘œì¤€ ìµœì í™” ì „ëµ"""
        
        if metrics.memory_usage > 85:
            self._cleanup_cache()
        
        if metrics.cache_hit_rate < 0.3:
            # ìºì‹œ í¬ê¸° ì¦ê°€
            self.memory_cache.max_size = min(self.memory_cache.max_size * 1.2, 1000)
    
    def _aggressive_optimization(self, metrics: PerformanceMetrics):
        """ì ê·¹ì  ìµœì í™” ì „ëµ"""
        
        if metrics.memory_usage > 80:
            self._cleanup_cache()
            self._cleanup_lazy_data()
        
        if metrics.cpu_usage > 85:
            # ë™ì‹œ ë¡œë”© ìˆ˜ ê°ì†Œ
            self.lazy_loader.config.max_concurrent_loads = max(1, 
                self.lazy_loader.config.max_concurrent_loads - 1)
    
    def _maximum_optimization(self, metrics: PerformanceMetrics):
        """ìµœëŒ€ ìµœì í™” ì „ëµ"""
        
        if metrics.memory_usage > 75:
            # ì ê·¹ì  ì •ë¦¬
            self.memory_cache.clear()
            self._cleanup_lazy_data()
            gc.collect()
        
        if metrics.cpu_usage > 80:
            # ì²˜ë¦¬ ì§€ì—°
            time.sleep(0.1)
    
    def _compress_data(self, data: Any) -> bytes:
        """ë°ì´í„° ì••ì¶•"""
        
        import gzip
        
        try:
            serialized = pickle.dumps(data)
            compressed = gzip.compress(serialized)
            
            compression_ratio = len(compressed) / len(serialized)
            
            if compression_ratio < 0.8:  # 20% ì´ìƒ ì••ì¶•ë˜ë©´ ì‚¬ìš©
                logger.debug(f"ë°ì´í„° ì••ì¶•: {len(serialized)} â†’ {len(compressed)} bytes ({compression_ratio:.2%})")
                return compressed
            else:
                return serialized
                
        except Exception as e:
            logger.warning(f"ë°ì´í„° ì••ì¶• ì‹¤íŒ¨: {e}")
            return pickle.dumps(data)
    
    def _decompress_data(self, data: bytes) -> Any:
        """ë°ì´í„° ì••ì¶• í•´ì œ"""
        
        import gzip
        
        try:
            # ì••ì¶• í•´ì œ ì‹œë„
            try:
                decompressed = gzip.decompress(data)
                return pickle.loads(decompressed)
            except:
                # ì••ì¶•ë˜ì§€ ì•Šì€ ë°ì´í„°
                return pickle.loads(data)
                
        except Exception as e:
            logger.error(f"ë°ì´í„° ì••ì¶• í•´ì œ ì‹¤íŒ¨: {e}")
            return None
    
    def _monitor_memory(self) -> Dict[str, float]:
        """ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§"""
        
        memory = psutil.virtual_memory()
        
        return {
            'total': memory.total,
            'available': memory.available,
            'used': memory.used,
            'percent': memory.percent
        }
    
    def _monitor_cpu(self) -> Dict[str, float]:
        """CPU ëª¨ë‹ˆí„°ë§"""
        
        return {
            'percent': psutil.cpu_percent(interval=1),
            'cores': psutil.cpu_count()
        }
    
    def _monitor_disk(self) -> Dict[str, float]:
        """ë””ìŠ¤í¬ ëª¨ë‹ˆí„°ë§"""
        
        disk = psutil.disk_usage('/')
        
        return {
            'total': disk.total,
            'used': disk.used,
            'free': disk.free,
            'percent': (disk.used / disk.total) * 100
        }
    
    def get_performance_summary(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ ìš”ì•½ ì •ë³´"""
        
        if not self.metrics_history:
            return {"error": "No performance data available"}
        
        recent_metrics = self.metrics_history[-10:]  # ìµœê·¼ 10ê°œ
        
        avg_memory = sum(m.memory_usage for m in recent_metrics) / len(recent_metrics)
        avg_cpu = sum(m.cpu_usage for m in recent_metrics) / len(recent_metrics)
        avg_cache_hit = sum(m.cache_hit_rate for m in recent_metrics) / len(recent_metrics)
        
        cache_stats = self.memory_cache.get_stats()
        
        return {
            'optimization_level': self.optimization_level.value,
            'avg_memory_usage': avg_memory,
            'avg_cpu_usage': avg_cpu,
            'avg_cache_hit_rate': avg_cache_hit,
            'cache_stats': cache_stats,
            'monitoring_active': self.monitoring_active,
            'metrics_count': len(self.metrics_history),
            'last_cleanup': datetime.fromtimestamp(self.last_cleanup).isoformat()
        }
    
    def render_performance_dashboard(self, container=None):
        """ì„±ëŠ¥ ëŒ€ì‹œë³´ë“œ ë Œë”ë§"""
        
        if container is None:
            container = st.container()
        
        with container:
            st.markdown("## âš¡ ì„±ëŠ¥ ìµœì í™” ëŒ€ì‹œë³´ë“œ")
            
            # í˜„ì¬ ì„±ëŠ¥ ìƒíƒœ
            col1, col2, col3, col4 = st.columns(4)
            
            memory = psutil.virtual_memory()
            cpu_percent = psutil.cpu_percent()
            cache_stats = self.memory_cache.get_stats()
            
            with col1:
                st.metric(
                    "ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ",
                    f"{memory.percent:.1f}%",
                    f"{memory.used // (1024**3):.1f}GB / {memory.total // (1024**3):.1f}GB"
                )
            
            with col2:
                st.metric(
                    "CPU ì‚¬ìš©ë¥ ",
                    f"{cpu_percent:.1f}%"
                )
            
            with col3:
                st.metric(
                    "ìºì‹œ íˆíŠ¸ìœ¨",
                    f"{cache_stats['hit_rate']:.1%}",
                    f"{cache_stats['hits']} / {cache_stats['hits'] + cache_stats['misses']}"
                )
            
            with col4:
                st.metric(
                    "ìºì‹œ í¬ê¸°",
                    f"{cache_stats['size']}",
                    f"{cache_stats['memory_usage'] // (1024*1024):.1f}MB"
                )
            
            # ì„¤ì • ì œì–´
            st.markdown("### âš™ï¸ ìµœì í™” ì„¤ì •")
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                new_level = st.selectbox(
                    "ìµœì í™” ìˆ˜ì¤€",
                    options=list(OptimizationLevel),
                    index=list(OptimizationLevel).index(self.optimization_level),
                    format_func=lambda x: x.value.title()
                )
                
                if new_level != self.optimization_level:
                    self.optimization_level = new_level
                    st.success("ìµœì í™” ìˆ˜ì¤€ì´ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤!")
            
            with col2:
                auto_cleanup = st.checkbox(
                    "ìë™ ì •ë¦¬ í™œì„±í™”",
                    value=self.auto_cleanup_enabled
                )
                
                if auto_cleanup != self.auto_cleanup_enabled:
                    self.auto_cleanup_enabled = auto_cleanup
            
            with col3:
                monitoring = st.checkbox(
                    "ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§",
                    value=self.monitoring_active
                )
                
                if monitoring != self.monitoring_active:
                    if monitoring:
                        self.start_monitoring()
                    else:
                        self.stop_monitoring()
            
            # ìˆ˜ë™ ì‘ì—…
            st.markdown("### ğŸ› ï¸ ìˆ˜ë™ ì‘ì—…")
            
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                if st.button("ğŸ§¹ ìºì‹œ ì •ë¦¬"):
                    self._cleanup_cache()
                    st.success("ìºì‹œê°€ ì •ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤!")
            
            with col2:
                if st.button("â™»ï¸ ë©”ëª¨ë¦¬ ì •ë¦¬"):
                    self._cleanup_lazy_data()
                    gc.collect()
                    st.success("ë©”ëª¨ë¦¬ê°€ ì •ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤!")
            
            with col3:
                if st.button("ğŸ“Š ì„±ëŠ¥ ë¶„ì„"):
                    metrics = self._collect_metrics()
                    st.json({
                        'memory_usage': f"{metrics.memory_usage:.1f}%",
                        'cpu_usage': f"{metrics.cpu_usage:.1f}%",
                        'cache_hit_rate': f"{metrics.cache_hit_rate:.1%}",
                        'active_artifacts': metrics.active_artifacts
                    })
            
            with col4:
                if st.button("ğŸ”„ ìµœì í™” ì‹¤í–‰"):
                    metrics = self._collect_metrics()
                    self._auto_optimize(metrics)
                    st.success("ìµœì í™”ê°€ ì‹¤í–‰ë˜ì—ˆìŠµë‹ˆë‹¤!")

class LazyArtifact:
    """ì§€ì—° ë¡œë”© ì•„í‹°íŒ©íŠ¸"""
    
    def __init__(self, artifact_id: str, loader: LazyArtifactLoader):
        self.artifact_id = artifact_id
        self.loader = loader
        self._current_chunk = 0
    
    def get_chunk(self, chunk_index: int) -> Any:
        """íŠ¹ì • ì²­í¬ ì¡°íšŒ"""
        
        return self.loader.load_chunk(self.artifact_id, chunk_index)
    
    def __iter__(self):
        """ë°˜ë³µì"""
        
        self._current_chunk = 0
        return self
    
    def __next__(self):
        """ë‹¤ìŒ ì²­í¬"""
        
        chunk_data = self.get_chunk(self._current_chunk)
        
        if chunk_data is None:
            raise StopIteration
        
        self._current_chunk += 1
        return chunk_data