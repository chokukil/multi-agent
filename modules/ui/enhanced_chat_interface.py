import streamlit as st
import time
import asyncio
from typing import Dict, Any, List, Optional
from datetime import datetime
import uuid

from modules.core.universal_orchestrator import UniversalOrchestrator
from modules.core.streaming_controller import StreamingController
from modules.ui.agent_collaboration_visualizer import AgentCollaborationVisualizer
from modules.models import AgentProgressInfo, TaskState

class EnhancedChatInterface:
    def __init__(self):
        try:
            self.orchestrator = UniversalOrchestrator()
            self.streaming_controller = StreamingController()
            self.collaboration_visualizer = AgentCollaborationVisualizer()
            self._initialized = True
        except Exception as e:
            st.error(f"Enhanced chat interface initialization error: {e}")
            self._initialized = False
        
        # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
        if "messages" not in st.session_state:
            st.session_state.messages = []
        if "current_agents" not in st.session_state:
            st.session_state.current_agents = []
        if "is_processing" not in st.session_state:
            st.session_state.is_processing = False

    def _get_data_context(self) -> Dict[str, Any]:
        datasets = st.session_state.get("uploaded_datasets", {})
        selected = st.session_state.get("selected_datasets", list(datasets.keys()))
        return {"datasets": datasets, "selected": selected}

    def render_chat_container(self):
        """
        í–¥ìƒëœ ì±„íŒ… ì»¨í…Œì´ë„ˆ ë Œë”ë§:
        - ì‹¤ì‹œê°„ íƒ€ì´í•‘ íš¨ê³¼
        - ì—ì´ì „íŠ¸ í˜‘ì—… ì‹œê°í™”
        - ì§„í–‰ ìƒí™© í‘œì‹œ
        - ìë™ ìŠ¤í¬ë¡¤
        """
        if not self._initialized:
            st.error("Enhanced chat interface is not properly initialized. Using fallback mode.")
            self._render_fallback_chat()
            return
        
        try:
            st.markdown('<div data-testid="chat-interface"></div>', unsafe_allow_html=True)
            
            # ê¸°ì¡´ ë©”ì‹œì§€ í‘œì‹œ
            for message in st.session_state.messages:
                with st.chat_message(message["role"]):
                    st.markdown(message["content"])
                    
                    # ì—ì´ì „íŠ¸ ì‘ë‹µì— ëŒ€í•œ ì¶”ê°€ ì •ë³´ í‘œì‹œ
                    if message["role"] == "assistant" and message.get("agents_info"):
                        with st.expander("ğŸ¤– Agent Details", expanded=False):
                            agents_info = message["agents_info"]
                            for agent_info in agents_info:
                                st.markdown(f"**{agent_info['name']}** (Port {agent_info['port']}): {agent_info['status']}")
            
            # í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ ê²½ìš° ì—ì´ì „íŠ¸ í˜‘ì—… ì‹œê°í™” í‘œì‹œ
            if st.session_state.is_processing and st.session_state.current_agents:
                st.markdown("---")
                try:
                    self.collaboration_visualizer.render_collaboration_dashboard(
                        agents=st.session_state.current_agents,
                        task_id=st.session_state.get("current_task_id", "current"),
                        show_data_flow=True
                    )
                except Exception as e:
                    st.warning(f"Agent collaboration visualization error: {e}")
            
            # ì±„íŒ… ì…ë ¥
            user_input = st.chat_input("ì—¬ê¸°ì— ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”...", key="enhanced_chat_input")
            
            if user_input:
                self._handle_user_input(user_input)
                
        except Exception as e:
            st.error(f"Enhanced chat container error: {e}")
            self._render_fallback_chat()
    
    def _render_fallback_chat(self):
        """Fallback chat interface"""
        st.markdown('<div data-testid="chat-interface"></div>', unsafe_allow_html=True)
        
        # ê¸°ì¡´ ë©”ì‹œì§€ í‘œì‹œ
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
        
        # ì±„íŒ… ì…ë ¥
        user_input = st.chat_input("ì—¬ê¸°ì— ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”...", key="fallback_chat_input")
        
        if user_input:
            # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
            st.session_state.messages.append({
                "role": "user",
                "content": user_input,
                "timestamp": datetime.now()
            })
            
            # ê¸°ë³¸ ì‘ë‹µ
            st.session_state.messages.append({
                "role": "assistant",
                "content": f"I received your message: '{user_input}'. Enhanced features are not available.",
                "timestamp": datetime.now()
            })
            
            st.rerun()
    
    def _handle_user_input(self, user_input: str):
        """
        ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬:
        - ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
        - ì—ì´ì „íŠ¸ í˜‘ì—… ì‹œê°í™” ì‹œì‘
        - ì‹¤ì‹œê°„ ì‘ë‹µ ìŠ¤íŠ¸ë¦¬ë°
        """
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        st.session_state.messages.append({
            "role": "user",
            "content": user_input,
            "timestamp": datetime.now()
        })
        
        # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
        with st.chat_message("user"):
            st.markdown(user_input)
        
        # ì²˜ë¦¬ ìƒíƒœ ì„¤ì •
        st.session_state.is_processing = True
        task_id = str(uuid.uuid4())
        st.session_state.current_task_id = task_id
        
        # ë°ëª¨ìš© ì—ì´ì „íŠ¸ ìƒì„± (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” orchestratorì—ì„œ ê°€ì ¸ì˜´)
        demo_agents = self._create_demo_agents_for_query(user_input)
        st.session_state.current_agents = demo_agents
        
        # ì—ì´ì „íŠ¸ í˜‘ì—… ì‹œê°í™” í‘œì‹œ
        collaboration_placeholder = st.empty()
        
        with collaboration_placeholder.container():
            self.collaboration_visualizer.render_collaboration_dashboard(
                agents=demo_agents,
                task_id=task_id,
                show_data_flow=True
            )
        
        # ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µ ì²˜ë¦¬
        with st.chat_message("assistant"):
            response_placeholder = st.empty()
            
            # ì‹¤ì‹œê°„ ì‘ë‹µ ì‹œë®¬ë ˆì´ì…˜
            self._simulate_real_time_response(
                user_input, 
                response_placeholder, 
                collaboration_placeholder,
                demo_agents
            )
        
        # ì²˜ë¦¬ ì™„ë£Œ
        st.session_state.is_processing = False
        st.rerun()
    
    def _simulate_real_time_response(self, 
                                   query: str, 
                                   response_placeholder,
                                   collaboration_placeholder,
                                   agents: List[AgentProgressInfo]):
        """
        ì‹¤ì‹œê°„ ì‘ë‹µ ì‹œë®¬ë ˆì´ì…˜:
        - ì—ì´ì „íŠ¸ ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
        - íƒ€ì´í•‘ íš¨ê³¼ë¡œ ì‘ë‹µ í‘œì‹œ
        - í˜‘ì—… ì‹œê°í™” ì—…ë°ì´íŠ¸
        """
        try:
            # ì‹¤ì œ orchestrator í˜¸ì¶œ
            data_ctx = self._get_data_context()
            
            # ì—ì´ì „íŠ¸ ìƒíƒœ ì‹œë®¬ë ˆì´ì…˜
            self._simulate_agent_progress(agents, collaboration_placeholder)
            
            # ì‹¤ì œ ì‘ë‹µ ìƒì„±
            try:
                resp = self.orchestrator.orchestrate_analysis(
                    query=query,
                    data=data_ctx,
                    user_context={"ui": "streamlit", "task_id": st.session_state.current_task_id}
                )
                reply = resp if isinstance(resp, str) else resp.get("text", "ì²˜ë¦¬ ê²°ê³¼ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
            except Exception as e:
                reply = f"ìš”ì²­ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            
            # íƒ€ì´í•‘ íš¨ê³¼ë¡œ ì‘ë‹µ í‘œì‹œ
            self._display_typing_effect(reply, response_placeholder)
            
            # ìµœì¢… ë©”ì‹œì§€ ì €ì¥
            st.session_state.messages.append({
                "role": "assistant",
                "content": reply,
                "timestamp": datetime.now(),
                "agents_info": [
                    {
                        "name": agent.name,
                        "port": agent.port,
                        "status": agent.status.value,
                        "progress": agent.progress_percentage
                    }
                    for agent in agents
                ]
            })
            
        except Exception as e:
            error_message = f"ì‹œìŠ¤í…œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            response_placeholder.error(error_message)
            
            st.session_state.messages.append({
                "role": "assistant",
                "content": error_message,
                "timestamp": datetime.now()
            })
    
    def _simulate_agent_progress(self, 
                               agents: List[AgentProgressInfo], 
                               collaboration_placeholder):
        """ì—ì´ì „íŠ¸ ì§„í–‰ ìƒí™© ì‹œë®¬ë ˆì´ì…˜"""
        import random
        
        # ì—ì´ì „íŠ¸ ìƒíƒœ ì—…ë°ì´íŠ¸ ì‹œë®¬ë ˆì´ì…˜
        for i in range(10):  # 10ë²ˆì˜ ì—…ë°ì´íŠ¸
            for agent in agents:
                if agent.status == TaskState.WORKING:
                    # ì§„í–‰ë¥  ì¦ê°€
                    agent.progress_percentage = min(
                        agent.progress_percentage + random.randint(5, 15), 
                        100
                    )
                    agent.execution_time += 0.5
                    
                    # ì™„ë£Œ ì²´í¬
                    if agent.progress_percentage >= 100:
                        agent.status = TaskState.COMPLETED
                        agent.current_task = "Task completed successfully"
                        agent.artifacts_generated.append(f"result_{agent.port}.json")
                
                elif agent.status == TaskState.PENDING and random.random() > 0.7:
                    # ëŒ€ê¸° ì¤‘ì¸ ì—ì´ì „íŠ¸ ì‹œì‘
                    agent.status = TaskState.WORKING
                    agent.current_task = f"Processing data with {agent.name}..."
                    agent.progress_percentage = random.randint(5, 20)
            
            # í˜‘ì—… ì‹œê°í™” ì—…ë°ì´íŠ¸
            with collaboration_placeholder.container():
                self.collaboration_visualizer.render_collaboration_dashboard(
                    agents=agents,
                    task_id=st.session_state.current_task_id,
                    show_data_flow=True
                )
            
            time.sleep(0.5)  # 0.5ì´ˆ ê°„ê²©ìœ¼ë¡œ ì—…ë°ì´íŠ¸
            
            # ëª¨ë“  ì—ì´ì „íŠ¸ê°€ ì™„ë£Œë˜ë©´ ì¢…ë£Œ
            if all(agent.status == TaskState.COMPLETED for agent in agents):
                break
    
    def _display_typing_effect(self, text: str, placeholder):
        """íƒ€ì´í•‘ íš¨ê³¼ë¡œ í…ìŠ¤íŠ¸ í‘œì‹œ"""
        displayed_text = ""
        words = text.split()
        
        for i, word in enumerate(words):
            displayed_text += word + " "
            placeholder.markdown(displayed_text)
            time.sleep(0.05)  # ë‹¨ì–´ë‹¹ 50ms ì§€ì—°
        
        # ìµœì¢… í…ìŠ¤íŠ¸ í‘œì‹œ
        placeholder.markdown(text)
        placeholder.markdown('<div data-testid="assistant-message"></div>', unsafe_allow_html=True)
    
    def _create_demo_agents_for_query(self, query: str) -> List[AgentProgressInfo]:
        """ì¿¼ë¦¬ì— ë”°ë¥¸ ë°ëª¨ ì—ì´ì „íŠ¸ ìƒì„±"""
        
        # ì¿¼ë¦¬ ë‚´ìš©ì— ë”°ë¼ ê´€ë ¨ ì—ì´ì „íŠ¸ ì„ íƒ
        relevant_agents = []
        
        if any(keyword in query.lower() for keyword in ["ë¶„ì„", "analysis", "eda", "íƒìƒ‰"]):
            relevant_agents.extend([8312, 8315])  # EDA Tools, Pandas Analyst
        
        if any(keyword in query.lower() for keyword in ["ì‹œê°í™”", "chart", "plot", "ê·¸ë˜í”„"]):
            relevant_agents.append(8308)  # Data Visualization
        
        if any(keyword in query.lower() for keyword in ["ì •ë¦¬", "clean", "ì „ì²˜ë¦¬"]):
            relevant_agents.append(8306)  # Data Cleaning
        
        if any(keyword in query.lower() for keyword in ["ë¨¸ì‹ ëŸ¬ë‹", "ml", "ëª¨ë¸", "ì˜ˆì¸¡"]):
            relevant_agents.extend([8313, 8314])  # H2O ML, MLflow
        
        # ê¸°ë³¸ ì—ì´ì „íŠ¸ (í•­ìƒ í¬í•¨)
        if not relevant_agents:
            relevant_agents = [8312, 8315]  # EDA Tools, Pandas Analyst
        
        # ì¤‘ë³µ ì œê±°
        relevant_agents = list(set(relevant_agents))
        
        # AgentProgressInfo ê°ì²´ ìƒì„±
        demo_agents = []
        for i, port in enumerate(relevant_agents):
            agent_info = self.collaboration_visualizer.agent_avatars.get(port, {
                "name": f"Agent {port}",
                "icon": "ğŸ”„"
            })
            
            # ì²« ë²ˆì§¸ ì—ì´ì „íŠ¸ëŠ” ì¦‰ì‹œ ì‹œì‘, ë‚˜ë¨¸ì§€ëŠ” ëŒ€ê¸°
            if i == 0:
                status = TaskState.WORKING
                progress = 10
                task = f"Starting {agent_info['name'].lower()}..."
            else:
                status = TaskState.PENDING
                progress = 0
                task = "Waiting for previous agent to complete..."
            
            agent = AgentProgressInfo(
                port=port,
                name=agent_info["name"],
                status=status,
                progress_percentage=progress,
                current_task=task,
                execution_time=0.0,
                artifacts_generated=[]
            )
            
            demo_agents.append(agent)
        
        return demo_agents