"""
Streaming Controller - ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ë° ì—ì´ì „íŠ¸ í˜‘ì—… ì‹œê°í™”

SSE (Server-Sent Events) ê¸°ë°˜ì˜ ìžì—°ìŠ¤ëŸ¬ìš´ í…ìŠ¤íŠ¸ ìŠ¤íŠ¸ë¦¬ë°ê³¼ 
A2A SDK TaskUpdater íŒ¨í„´ì„ ì‚¬ìš©í•œ ì‹¤ì‹œê°„ ì—ì´ì „íŠ¸ í˜‘ì—… ì‹œê°í™”
"""

import asyncio
import time
import logging
from typing import AsyncGenerator, Dict, List, Any, Optional, Callable
from datetime import datetime
import json
import re
from dataclasses import asdict

from ..models import StreamingResponse, AgentProgressInfo, TaskState, ProgressInfo

logger = logging.getLogger(__name__)


class StreamingController:
    """
    ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì»¨íŠ¸ë¡¤ëŸ¬
    - ìžì—°ìŠ¤ëŸ¬ìš´ íƒ€ì´í•‘ íš¨ê³¼ì™€ ì§€ëŠ¥ì  ì²­í‚¹
    - ì‹¤ì‹œê°„ ì—ì´ì „íŠ¸ í˜‘ì—… ì‹œê°í™”
    - A2A SDK TaskUpdater íŒ¨í„´ ì§€ì›
    """
    
    def __init__(self):
        """Streaming Controller ì´ˆê¸°í™”"""
        self.chunk_delay = 0.001  # ìžì—°ìŠ¤ëŸ¬ìš´ íƒ€ì´í•‘ ì†ë„ (1ms)
        self.sentence_boundaries = ['.', '!', '?', '\n', ':', ';']
        self.chunk_size = 3  # í•œ ë²ˆì— ì „ì†¡í•  ë¬¸ìž ìˆ˜
        self.status_update_interval = 0.5  # ì—ì´ì „íŠ¸ ìƒíƒœ ì—…ë°ì´íŠ¸ ê°„ê²© (0.5ì´ˆ)
        
        # í™œì„± ìŠ¤íŠ¸ë¦¼ ì¶”ì 
        self.active_streams: Dict[str, Dict] = {}
        
        logger.info("Streaming Controller initialized")
    
    async def stream_response(self, 
                            content: str,
                            response_id: str,
                            agent_progress: Optional[List[AgentProgressInfo]] = None,
                            chunk_callback: Optional[Callable] = None) -> AsyncGenerator[StreamingResponse, None]:
        """
        ìžì—°ìŠ¤ëŸ¬ìš´ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ:
        1. ì§€ëŠ¥ì  ì˜ë¯¸ ë‹¨ìœ„ë³„ ì²­í‚¹
        2. êµ¬ë‘ì ì—ì„œ ìžì—°ìŠ¤ëŸ¬ìš´ ë©ˆì¶¤
        3. ì‹¤ì‹œê°„ ì—ì´ì „íŠ¸ ì§„í–‰ ìƒí™© ì‹œê°í™”
        4. ì¤‘ë‹¨ ì‹œ ìš°ì•„í•œ ì„±ëŠ¥ ì €í•˜
        """
        try:
            logger.info(f"Starting stream response for {response_id}")
            
            # ìŠ¤íŠ¸ë¦¼ ìƒíƒœ ì´ˆê¸°í™”
            self.active_streams[response_id] = {
                'start_time': datetime.now(),
                'status': 'streaming',
                'chunks_sent': 0,
                'agent_progress': agent_progress or []
            }
            
            # ì˜ë¯¸ ë‹¨ìœ„ë³„ ì²­í‚¹
            semantic_chunks = self._chunk_by_semantic_units(content)
            
            total_chunks = len(semantic_chunks)
            
            for i, chunk in enumerate(semantic_chunks):
                try:
                    # ìŠ¤íŠ¸ë¦¼ì´ ì¤‘ë‹¨ë˜ì—ˆëŠ”ì§€ í™•ì¸
                    if response_id not in self.active_streams:
                        logger.warning(f"Stream {response_id} was interrupted")
                        break
                    
                    # ì§„í–‰ ìƒí™© ì •ë³´ ìƒì„±
                    progress_info = self._create_progress_info(
                        agent_progress, i + 1, total_chunks
                    ) if agent_progress else None
                    
                    # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„±
                    streaming_response = StreamingResponse(
                        content=chunk,
                        is_complete=(i == total_chunks - 1),
                        chunk_index=i,
                        total_chunks=total_chunks,
                        progress_info=progress_info
                    )
                    
                    yield streaming_response
                    
                    # ì²­í¬ ì½œë°± í˜¸ì¶œ
                    if chunk_callback:
                        chunk_callback(chunk, i + 1, total_chunks)
                    
                    # ìŠ¤íŠ¸ë¦¼ ìƒíƒœ ì—…ë°ì´íŠ¸
                    self.active_streams[response_id]['chunks_sent'] = i + 1
                    
                    # ìžì—°ìŠ¤ëŸ¬ìš´ íƒ€ì´í•‘ ì§€ì—°
                    await self._calculate_natural_delay(chunk)
                    
                except Exception as e:
                    logger.error(f"Error streaming chunk {i}: {str(e)}")
                    # ì˜¤ë¥˜ ë°œìƒ ì‹œì—ë„ ê³„ì† ì§„í–‰
                    continue
            
            # ìŠ¤íŠ¸ë¦¼ ì™„ë£Œ
            self.active_streams[response_id]['status'] = 'completed'
            self.active_streams[response_id]['end_time'] = datetime.now()
            
        except Exception as e:
            logger.error(f"Streaming error for {response_id}: {str(e)}")
            
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ìš°ì•„í•œ ì„±ëŠ¥ ì €í•˜
            yield StreamingResponse(
                content=content,  # ì „ì²´ ë‚´ìš©ì„ í•œ ë²ˆì— ì „ì†¡
                is_complete=True,
                chunk_index=0,
                total_chunks=1
            )
        
        finally:
            # ì •ë¦¬
            if response_id in self.active_streams:
                self.active_streams[response_id]['status'] = 'finished'
    
    def _chunk_by_semantic_units(self, text: str) -> List[str]:
        """
        ì§€ëŠ¥ì  ì˜ë¯¸ ë‹¨ìœ„ë³„ í…ìŠ¤íŠ¸ ì²­í‚¹:
        - ë¬¸ìž¥ ê²½ê³„ì—ì„œ ë¶„í• 
        - ëª©ë¡ ì•„ì´í…œë³„ ë¶„í• 
        - ì½”ë“œ ë¸”ë¡ ë³´ì¡´
        - ë§ˆí¬ë‹¤ìš´ êµ¬ì¡° ìœ ì§€
        """
        chunks = []
        
        # ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì²˜ë¦¬
        code_block_pattern = r'```[\s\S]*?```'
        code_blocks = re.findall(code_block_pattern, text)
        
        # ì½”ë“œ ë¸”ë¡ì„ ìž„ì‹œ í”Œë ˆì´ìŠ¤í™€ë”ë¡œ êµì²´
        temp_text = text
        for i, block in enumerate(code_blocks):
            temp_text = temp_text.replace(block, f'__CODE_BLOCK_{i}__', 1)
        
        # ë¬¸ìž¥ë³„ ë¶„í• 
        sentences = self._split_by_sentences(temp_text)
        
        for sentence in sentences:
            # ì½”ë“œ ë¸”ë¡ ë³µì›
            for i, block in enumerate(code_blocks):
                sentence = sentence.replace(f'__CODE_BLOCK_{i}__', block)
            
            if sentence.strip():
                chunks.append(sentence.strip())
        
        # ë¹ˆ ì²­í¬ ì œê±° ë° ìµœì†Œ ê¸¸ì´ ë³´ìž¥
        filtered_chunks = []
        current_chunk = ""
        
        for chunk in chunks:
            current_chunk += chunk + " "
            
            # ìµœì†Œ ê¸¸ì´ì— ë„ë‹¬í•˜ê±°ë‚˜ ë¬¸ìž¥ì´ ì™„ë£Œë˜ë©´ ì²­í¬ ì¶”ê°€
            if (len(current_chunk) >= 50 or 
                any(boundary in chunk for boundary in self.sentence_boundaries)):
                
                filtered_chunks.append(current_chunk.strip())
                current_chunk = ""
        
        # ë‚¨ì€ ë‚´ìš© ì¶”ê°€
        if current_chunk.strip():
            filtered_chunks.append(current_chunk.strip())
        
        return filtered_chunks
    
    def _split_by_sentences(self, text: str) -> List[str]:
        """ë¬¸ìž¥ë³„ í…ìŠ¤íŠ¸ ë¶„í• """
        
        # ë§ˆí¬ë‹¤ìš´ ëª©ë¡ ì•„ì´í…œ ì²˜ë¦¬
        lines = text.split('\n')
        sentences = []
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
                
            # ëª©ë¡ ì•„ì´í…œì€ ê°œë³„ ì²­í¬ë¡œ ì²˜ë¦¬
            if line.startswith(('- ', '* ', '+ ', '1. ', '2. ', '3. ')):
                sentences.append(line)
                continue
            
            # í—¤ë”ëŠ” ê°œë³„ ì²­í¬ë¡œ ì²˜ë¦¬
            if line.startswith('#'):
                sentences.append(line)
                continue
            
            # ì¼ë°˜ í…ìŠ¤íŠ¸ëŠ” ë¬¸ìž¥ë³„ë¡œ ë¶„í• 
            sentence_parts = re.split(r'([.!?:;]\s+)', line)
            
            current_sentence = ""
            for part in sentence_parts:
                current_sentence += part
                
                if any(boundary in part for boundary in self.sentence_boundaries):
                    if current_sentence.strip():
                        sentences.append(current_sentence.strip())
                    current_sentence = ""
            
            # ë‚¨ì€ ë‚´ìš© ì¶”ê°€
            if current_sentence.strip():
                sentences.append(current_sentence.strip())
        
        return sentences
    
    async def _calculate_natural_delay(self, chunk: str):
        """ìžì—°ìŠ¤ëŸ¬ìš´ íƒ€ì´í•‘ ì§€ì—° ê³„ì‚°"""
        
        # ê¸°ë³¸ ì§€ì—°
        base_delay = self.chunk_delay
        
        # ì²­í¬ ê¸¸ì´ì— ë”°ë¥¸ ì¡°ì •
        length_factor = len(chunk) / 50  # 50ìž ê¸°ì¤€
        adjusted_delay = base_delay * (1 + length_factor * 0.1)
        
        # êµ¬ë‘ì ì—ì„œ ì¶”ê°€ ì§€ì—°
        if any(boundary in chunk for boundary in ['.', '!', '?']):
            adjusted_delay += 0.1  # 100ms ì¶”ê°€ ì§€ì—°
        
        # ëª©ë¡ ì•„ì´í…œ í›„ ì§§ì€ ì§€ì—°
        if chunk.strip().startswith(('- ', '* ', '+ ')):
            adjusted_delay += 0.05  # 50ms ì¶”ê°€ ì§€ì—°
        
        # ìµœëŒ€ ì§€ì—° ì œí•œ
        adjusted_delay = min(adjusted_delay, 0.3)  # ìµœëŒ€ 300ms
        
        if adjusted_delay > 0:
            await asyncio.sleep(adjusted_delay)
    
    def _create_progress_info(self, 
                            agent_progress: List[AgentProgressInfo],
                            current_chunk: int,
                            total_chunks: int) -> ProgressInfo:
        """ì§„í–‰ ìƒí™© ì •ë³´ ìƒì„±"""
        
        # ì—ì´ì „íŠ¸ë³„ ì§„í–‰ë¥  ê³„ì‚°
        for agent in agent_progress:
            if agent.status == TaskState.WORKING:
                # í…ìŠ¤íŠ¸ ì²­í‚¹ ì§„í–‰ë¥ ì„ ì—ì´ì „íŠ¸ ì§„í–‰ë¥ ì— ë°˜ì˜
                chunk_progress = (current_chunk / total_chunks) * 100
                agent.progress_percentage = min(chunk_progress, 90)  # ìµœëŒ€ 90%ê¹Œì§€
            elif agent.status == TaskState.COMPLETED:
                agent.progress_percentage = 100
        
        # ì „ì²´ ì§„í–‰ë¥  ê³„ì‚°
        total_agents = len(agent_progress)
        completed_agents = sum(1 for agent in agent_progress 
                             if agent.status == TaskState.COMPLETED)
        working_agents = sum(1 for agent in agent_progress 
                           if agent.status == TaskState.WORKING)
        
        # ê°€ì¤‘ í‰ê· ìœ¼ë¡œ ì „ì²´ ì§„í–‰ë¥  ê³„ì‚°
        if total_agents > 0:
            completion_percentage = (completed_agents / total_agents) * 100
            
            # ìž‘ì—… ì¤‘ì¸ ì—ì´ì „íŠ¸ì˜ ë¶€ë¶„ ì§„í–‰ë¥  ì¶”ê°€
            if working_agents > 0:
                avg_working_progress = sum(
                    agent.progress_percentage for agent in agent_progress
                    if agent.status == TaskState.WORKING
                ) / working_agents
                
                working_contribution = (working_agents / total_agents) * (avg_working_progress / 100) * 100
                completion_percentage = min(completion_percentage + working_contribution, 95)
        else:
            completion_percentage = 0
        
        return ProgressInfo(
            agents_working=agent_progress,
            current_step=f"ìŠ¤íŠ¸ë¦¬ë° ì§„í–‰ ì¤‘... ({current_chunk}/{total_chunks})",
            total_steps=total_chunks,
            completion_percentage=completion_percentage,
            estimated_remaining_time=self._estimate_remaining_time(
                current_chunk, total_chunks, agent_progress
            )
        )
    
    def _estimate_remaining_time(self, 
                                current_chunk: int,
                                total_chunks: int,
                                agent_progress: List[AgentProgressInfo]) -> Optional[int]:
        """ë‚¨ì€ ì‹œê°„ ì¶”ì •"""
        
        if current_chunk == 0:
            return None
        
        # ì²­í‚¹ ê¸°ë°˜ ì‹œê°„ ì¶”ì •
        avg_chunk_time = 0.05  # í‰ê·  ì²­í¬ë‹¹ 50ms
        remaining_chunks = total_chunks - current_chunk
        chunk_time_estimate = remaining_chunks * avg_chunk_time
        
        # ì—ì´ì „íŠ¸ ìž‘ì—… ì‹œê°„ ì¶”ì •
        working_agents = [agent for agent in agent_progress 
                         if agent.status == TaskState.WORKING]
        
        agent_time_estimate = 0
        if working_agents:
            # ê°€ìž¥ ëŠë¦° ì—ì´ì „íŠ¸ ê¸°ì¤€ìœ¼ë¡œ ì¶”ì •
            max_remaining_work = max(
                (100 - agent.progress_percentage) / 100 
                for agent in working_agents
            )
            
            # ì—ì´ì „íŠ¸ë‹¹ í‰ê·  30ì´ˆ ìž‘ì—… ì‹œê°„ ê°€ì •
            agent_time_estimate = max_remaining_work * 30
        
        total_estimate = max(chunk_time_estimate, agent_time_estimate)
        
        return int(total_estimate) if total_estimate > 1 else None
    
    async def stream_agent_collaboration(self, 
                                       agents: List[AgentProgressInfo],
                                       task_id: str) -> AsyncGenerator[Dict[str, Any], None]:
        """
        ì‹¤ì‹œê°„ ì—ì´ì „íŠ¸ í˜‘ì—… ì‹œê°í™”:
        - ê°œë³„ ì—ì´ì „íŠ¸ ì§„í–‰ë¥  (0-100%)
        - ì—ì´ì „íŠ¸ ì•„ë°”íƒ€ì™€ ìƒíƒœ í‘œì‹œê¸°
        - í˜„ìž¬ ìž‘ì—… ì„¤ëª…
        - ì™„ë£Œ ì²´í¬ë§ˆí¬ì™€ ì‹¤í–‰ ì‹œê°„
        - ì—ì´ì „íŠ¸ ê°„ ë°ì´í„° íë¦„ ì‹œê°í™”
        """
        try:
            start_time = datetime.now()
            
            while any(agent.status == TaskState.WORKING for agent in agents):
                
                # í˜„ìž¬ ìƒíƒœ ìŠ¤ëƒ…ìƒ· ìƒì„±
                collaboration_snapshot = {
                    'task_id': task_id,
                    'timestamp': datetime.now().isoformat(),
                    'agents': [],
                    'overall_progress': 0,
                    'active_agents_count': 0,
                    'completed_agents_count': 0,
                    'elapsed_time': (datetime.now() - start_time).total_seconds()
                }
                
                total_progress = 0
                active_count = 0
                completed_count = 0
                
                for agent in agents:
                    agent_info = {
                        'port': agent.port,
                        'name': agent.name,
                        'status': agent.status.value,
                        'progress_percentage': agent.progress_percentage,
                        'current_task': agent.current_task,
                        'execution_time': agent.execution_time,
                        'artifacts_generated': agent.artifacts_generated,
                        'status_icon': self._get_status_icon(agent.status),
                        'status_color': self._get_status_color(agent.status),
                        'avatar_icon': agent.avatar_icon or self._get_default_avatar(agent.port)
                    }
                    
                    collaboration_snapshot['agents'].append(agent_info)
                    
                    total_progress += agent.progress_percentage
                    
                    if agent.status == TaskState.WORKING:
                        active_count += 1
                    elif agent.status == TaskState.COMPLETED:
                        completed_count += 1
                
                # ì „ì²´ ì§„í–‰ë¥  ê³„ì‚°
                collaboration_snapshot['overall_progress'] = total_progress / len(agents) if agents else 0
                collaboration_snapshot['active_agents_count'] = active_count
                collaboration_snapshot['completed_agents_count'] = completed_count
                
                yield collaboration_snapshot
                
                # 0.5ì´ˆ ê°„ê²©ìœ¼ë¡œ ì—…ë°ì´íŠ¸
                await asyncio.sleep(self.status_update_interval)
            
            # ìµœì¢… ì™„ë£Œ ìƒíƒœ ì „ì†¡
            final_snapshot = collaboration_snapshot.copy()
            final_snapshot['status'] = 'completed'
            final_snapshot['overall_progress'] = 100
            
            yield final_snapshot
            
        except Exception as e:
            logger.error(f"Agent collaboration streaming error: {str(e)}")
            
            # ì˜¤ë¥˜ ìƒíƒœ ì „ì†¡
            yield {
                'task_id': task_id,
                'status': 'error',
                'error_message': str(e),
                'timestamp': datetime.now().isoformat()
            }
    
    def _get_status_icon(self, status: TaskState) -> str:
        """ìƒíƒœë³„ ì•„ì´ì½˜ ë°˜í™˜"""
        status_icons = {
            TaskState.PENDING: "â³",
            TaskState.WORKING: "âš¡",
            TaskState.COMPLETED: "âœ…",
            TaskState.FAILED: "âŒ"
        }
        return status_icons.get(status, "â“")
    
    def _get_status_color(self, status: TaskState) -> str:
        """ìƒíƒœë³„ ìƒ‰ìƒ ë°˜í™˜"""
        status_colors = {
            TaskState.PENDING: "#ffc107",  # ë…¸ëž€ìƒ‰
            TaskState.WORKING: "#007bff",  # íŒŒëž€ìƒ‰
            TaskState.COMPLETED: "#28a745",  # ì´ˆë¡ìƒ‰
            TaskState.FAILED: "#dc3545"  # ë¹¨ê°„ìƒ‰
        }
        return status_colors.get(status, "#6c757d")
    
    def _get_default_avatar(self, port: int) -> str:
        """í¬íŠ¸ë³„ ê¸°ë³¸ ì•„ë°”íƒ€ ì•„ì´ì½˜"""
        avatar_mapping = {
            8306: "ðŸ§¹",  # Data Cleaning
            8307: "ðŸ“",  # Data Loader
            8308: "ðŸ“Š",  # Data Visualization
            8309: "ðŸ”§",  # Data Wrangling
            8310: "âš™ï¸",  # Feature Engineering
            8311: "ðŸ—„ï¸",  # SQL Database
            8312: "ðŸ”",  # EDA Tools
            8313: "ðŸ¤–",  # H2O ML
            8314: "ðŸ“ˆ",  # MLflow Tools
            8315: "ðŸ¼"   # Pandas Analyst
        }
        return avatar_mapping.get(port, "ðŸ”„")
    
    async def handle_stream_interruption(self, 
                                       response_id: str, 
                                       fallback_content: str = None) -> StreamingResponse:
        """
        ìŠ¤íŠ¸ë¦¼ ì¤‘ë‹¨ ì‹œ ìš°ì•„í•œ ì„±ëŠ¥ ì €í•˜:
        - ëª…í™•í•œ ì˜¤ë¥˜ ë©”ì‹œì§€
        - ê¸°ë³¸ ì‘ë‹µìœ¼ë¡œ í´ë°±
        - ì¤‘ë‹¨ ì „ê¹Œì§€ì˜ ì§„í–‰ ìƒí™© ë³´ì¡´
        """
        try:
            if response_id in self.active_streams:
                stream_info = self.active_streams[response_id]
                stream_info['status'] = 'interrupted'
                stream_info['interruption_time'] = datetime.now()
                
                chunks_sent = stream_info.get('chunks_sent', 0)
                
                fallback_message = (
                    f"âš ï¸ ìŠ¤íŠ¸ë¦¬ë°ì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤ (ì²­í¬ {chunks_sent}ê°œ ì „ì†¡ ì™„ë£Œ).\n\n"
                    f"{fallback_content or 'ì „ì²´ ì‘ë‹µì„ í‘œì‹œí•©ë‹ˆë‹¤.'}"
                )
                
                return StreamingResponse(
                    content=fallback_message,
                    is_complete=True,
                    chunk_index=chunks_sent,
                    total_chunks=chunks_sent + 1
                )
            else:
                return StreamingResponse(
                    content=fallback_content or "ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                    is_complete=True,
                    chunk_index=0,
                    total_chunks=1
                )
                
        except Exception as e:
            logger.error(f"Error handling stream interruption: {str(e)}")
            
            return StreamingResponse(
                content="ì‹œìŠ¤í…œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                is_complete=True,
                chunk_index=0,
                total_chunks=1
            )
    
    def get_active_streams(self) -> Dict[str, Dict]:
        """í™œì„± ìŠ¤íŠ¸ë¦¼ ëª©ë¡ ë°˜í™˜"""
        return self.active_streams.copy()
    
    def get_stream_statistics(self) -> Dict[str, Any]:
        """ìŠ¤íŠ¸ë¦¬ë° í†µê³„ ë°˜í™˜"""
        total_streams = len(self.active_streams)
        completed_streams = sum(1 for stream in self.active_streams.values() 
                               if stream['status'] == 'completed')
        
        return {
            'total_streams': total_streams,
            'completed_streams': completed_streams,
            'active_streams': total_streams - completed_streams,
            'average_chunks_per_stream': (
                sum(stream.get('chunks_sent', 0) for stream in self.active_streams.values()) 
                / total_streams if total_streams > 0 else 0
            )
        }
    
    def cleanup_finished_streams(self, max_age_hours: int = 1):
        """ì™„ë£Œëœ ìŠ¤íŠ¸ë¦¼ ì •ë¦¬"""
        current_time = datetime.now()
        to_remove = []
        
        for stream_id, stream_info in self.active_streams.items():
            if stream_info['status'] in ['completed', 'interrupted', 'finished']:
                end_time = stream_info.get('end_time') or stream_info.get('interruption_time')
                if end_time and (current_time - end_time).total_seconds() > max_age_hours * 3600:
                    to_remove.append(stream_id)
        
        for stream_id in to_remove:
            del self.active_streams[stream_id]
        
        logger.info(f"Cleaned up {len(to_remove)} finished streams")