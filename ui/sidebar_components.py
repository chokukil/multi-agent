# File: ui/sidebar_components.py
# Location: ./ui/sidebar_components.py

import streamlit as st
import os
import json
from pathlib import Path
from typing import Dict, List, Tuple
import pandas as pd
import asyncio
import logging
from datetime import datetime

def render_mcp_config_section():
    """MCP Server Configuration ÏÑπÏÖò Î†åÎçîÎßÅ"""
    from core.utils.config import load_mcp_configs, save_mcp_config, delete_mcp_config
    from core.tools.mcp_tools import get_available_mcp_tools_info
    
    with st.expander("üîß MCP Server Configuration", expanded=False):
        st.markdown("### MCP ÎèÑÍµ¨ ÏÑ§Ï†ï Í¥ÄÎ¶¨")
        
        # ÌòÑÏû¨ Ï†ÄÏû•Îêú ÏÑ§Ï†ïÎì§ ÌëúÏãú
        saved_configs = load_mcp_configs()
        
        if saved_configs:
            st.markdown("#### Ï†ÄÏû•Îêú ÏÑ§Ï†ï")
            config_names = [config.get('name', config['config_name']) for config in saved_configs]
            selected_config = st.selectbox(
                "ÏÑ§Ï†ï ÏÑ†ÌÉù",
                ["None"] + config_names,
                help="Ï†ÄÏû•Îêú MCP ÏÑ§Ï†ïÏùÑ ÏÑ†ÌÉùÌïòÏÑ∏Ïöî"
            )
            
            if selected_config != "None":
                config_data = next((c for c in saved_configs if c.get('name', c['config_name']) == selected_config), None)
                if config_data:
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        if st.button("üìä ÏÉÅÌÉú ÌôïÏù∏", key="check_mcp_status"):
                            with st.spinner("MCP ÏÑúÎ≤Ñ ÏÉÅÌÉú ÌôïÏù∏ Ï§ë..."):
                                tools_info = get_available_mcp_tools_info(config_data['config_name'])
                                if tools_info['available']:
                                    st.success(f"‚úÖ {tools_info['available_servers']}/{tools_info['total_servers']} ÏÑúÎ≤Ñ ÏÇ¨Ïö© Í∞ÄÎä•")
                                    for tool in tools_info['tools']:
                                        status_icon = "üü¢" if tool['status'] == "available" else "üî¥"
                                        st.text(f"{status_icon} {tool['server_name']}")
                                else:
                                    st.error("‚ùå ÏÇ¨Ïö© Í∞ÄÎä•Ìïú ÏÑúÎ≤ÑÍ∞Ä ÏóÜÏäµÎãàÎã§")
                    
                    with col2:
                        if st.button("üìù ÏàòÏ†ï", key="edit_mcp_config"):
                            st.session_state.editing_mcp_config = config_data
                    
                    with col3:
                        if st.button("üóëÔ∏è ÏÇ≠Ï†ú", key="delete_mcp_config"):
                            if delete_mcp_config(config_data['config_name']):
                                st.success(f"‚úÖ '{selected_config}' ÏÇ≠Ï†úÎê®")
                                st.rerun()
                            else:
                                st.error("‚ùå ÏÇ≠Ï†ú Ïã§Ìå®")
        
        # ÏÉà ÏÑ§Ï†ï Ï∂îÍ∞Ä ÎòêÎäî ÏàòÏ†ï
        st.markdown("#### ÏÉà ÏÑ§Ï†ï Ï∂îÍ∞Ä")
        
        with st.form("mcp_config_form"):
            config_name = st.text_input(
                "ÏÑ§Ï†ï Ïù¥Î¶Ñ",
                value=st.session_state.get('editing_mcp_config', {}).get('name', ''),
                placeholder="Ïòà: my_data_tools"
            )
            
            config_description = st.text_area(
                "ÏÑ§Î™Ö",
                value=st.session_state.get('editing_mcp_config', {}).get('description', ''),
                placeholder="Ïù¥ ÏÑ§Ï†ïÏóê ÎåÄÌïú Í∞ÑÎã®Ìïú ÏÑ§Î™ÖÏùÑ ÏûÖÎ†•ÌïòÏÑ∏Ïöî"
            )
            
            # JSON ÏÑ§Ï†ï ÏûÖÎ†•
            default_json = json.dumps(
                st.session_state.get('editing_mcp_config', {}).get('mcpServers', {
                    "data_science_tools": {
                        "url": "http://localhost:8007/sse", 
                        "transport": "sse",
                        "description": "Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑù ÎèÑÍµ¨"
                    }
                }),
                indent=2
            )
            
            json_config = st.text_area(
                "MCP ÏÑúÎ≤Ñ ÏÑ§Ï†ï (JSON)",
                value=default_json,
                height=200,
                help="MCP ÏÑúÎ≤Ñ ÏÑ§Ï†ïÏùÑ JSON ÌòïÏãùÏúºÎ°ú ÏûÖÎ†•ÌïòÏÑ∏Ïöî"
            )
            
            col1, col2 = st.columns(2)
            with col1:
                save_button = st.form_submit_button("üíæ Ï†ÄÏû•", type="primary")
            with col2:
                if st.form_submit_button("‚ùå Ï∑®ÏÜå"):
                    if 'editing_mcp_config' in st.session_state:
                        del st.session_state.editing_mcp_config
                    st.rerun()
            
            if save_button:
                if not config_name:
                    st.error("‚ùå ÏÑ§Ï†ï Ïù¥Î¶ÑÏùÑ ÏûÖÎ†•ÌïòÏÑ∏Ïöî")
                else:
                    try:
                        # JSON Ïú†Ìö®ÏÑ± Í≤ÄÏÇ¨
                        servers_config = json.loads(json_config)
                        
                        # ÏÑ§Ï†ï Îç∞Ïù¥ÌÑ∞ Íµ¨ÏÑ±
                        config_data = {
                            "name": config_name,
                            "description": config_description,
                            "mcpServers": servers_config,
                            "created_at": datetime.now().isoformat()
                        }
                        
                        # Ï†ÄÏû•
                        if save_mcp_config(config_name, config_data):
                            st.success(f"‚úÖ '{config_name}' ÏÑ§Ï†ïÏù¥ Ï†ÄÏû•ÎêòÏóàÏäµÎãàÎã§")
                            if 'editing_mcp_config' in st.session_state:
                                del st.session_state.editing_mcp_config
                            st.rerun()
                        else:
                            st.error("‚ùå ÏÑ§Ï†ï Ï†ÄÏû• Ïã§Ìå®")
                    
                    except json.JSONDecodeError as e:
                        st.error(f"‚ùå JSON ÌòïÏãù Ïò§Î•ò: {e}")

def render_data_upload_section():
    """Îç∞Ïù¥ÌÑ∞ ÏóÖÎ°úÎìú ÏÑπÏÖò Î†åÎçîÎßÅ"""
    from core import data_manager, data_lineage_tracker
    
    st.markdown("### Í∞ïÌôîÎêú Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑù")
    
    # SSOT Îç∞Ïù¥ÌÑ∞ ÏÉÅÌÉú ÌëúÏãú
    current_status = data_manager.get_status_message()
    
    if data_manager.is_data_loaded():
        st.success(current_status)
        
        # Îç∞Ïù¥ÌÑ∞ Ï†ïÎ≥¥ ÌëúÏãú
        with st.expander("üìà ÌòÑÏû¨ Îç∞Ïù¥ÌÑ∞ Ï†ïÎ≥¥", expanded=False):
            info = data_manager.get_data_info()
            col1, col2 = st.columns(2)
            
            with col1:
                st.metric("Ìñâ Ïàò", f"{info['row_count']:,}")
                st.metric("Î©îÎ™®Î¶¨", f"{info['memory_mb']:.2f}MB")
            
            with col2:
                st.metric("Ïó¥ Ïàò", f"{info['col_count']:,}")
                st.metric("Ï∂úÏ≤ò", info['source'])
            
            st.write("**Ïª¨Îüº Ï†ïÎ≥¥:**")
            cols_display = ', '.join(info['columns'][:8])
            if len(info['columns']) > 8:
                cols_display += f" ... (+{len(info['columns']) - 8}Í∞ú)"
            st.text(cols_display)
            
            st.write("**ÌÜµÍ≥Ñ:**")
            st.text(f"ÏàòÏπòÌòï: {len(info['numeric_cols'])}Í∞ú, Î≤îÏ£ºÌòï: {len(info['categorical_cols'])}Í∞ú, Í≤∞Ï∏°Í∞í: {info['null_count']:,}Í∞ú")
        
        # Îç∞Ïù¥ÌÑ∞ Í¥ÄÎ¶¨ ÎèÑÍµ¨Îì§
        col1, col2 = st.columns(2)
        with col1:
            if st.button("üîÑ ÏÉàÎ°úÍ≥†Ïπ®", use_container_width=True):
                if hasattr(st.session_state, 'uploaded_data') and st.session_state.uploaded_data is not None:
                    success = data_manager.set_data(st.session_state.uploaded_data, "ÏÑ∏ÏÖò Îç∞Ïù¥ÌÑ∞ ÏÉàÎ°úÍ≥†Ïπ®")
                    if success:
                        st.success("‚úÖ Îç∞Ïù¥ÌÑ∞Í∞Ä ÏÉàÎ°úÍ≥†Ïπ®ÎêòÏóàÏäµÎãàÎã§!")
                        st.rerun()
        
        with col2:
            if st.button("‚úÖ ÏùºÍ¥ÄÏÑ± Í≤ÄÏ¶ù", use_container_width=True):
                is_valid, message = data_manager.validate_data_consistency()
                if is_valid:
                    st.success(f"‚úÖ {message}")
                else:
                    st.error(f"‚ùå {message}")
    else:
        st.warning(current_status)
    
    # sandbox/datasets Ìè¥Îçî ÏÉùÏÑ±
    DATASETS_DIR = "./sandbox/datasets"
    os.makedirs(DATASETS_DIR, exist_ok=True)
    
    uploaded_csv = st.file_uploader("üìÇ CSV ÌååÏùº ÏóÖÎ°úÎìú", type=["csv"], help="Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑùÏùÑ ÏúÑÌïú CSV ÌååÏùºÏùÑ ÏóÖÎ°úÎìúÌïòÏÑ∏Ïöî")
    if uploaded_csv:
        try:
            # ÌååÏùºÏùÑ datasets Ìè¥ÎçîÏóê Ï†ÄÏû•
            file_path = os.path.join(DATASETS_DIR, uploaded_csv.name)
            with open(file_path, "wb") as f:
                f.write(uploaded_csv.getvalue())
                
            # Ï†ÄÏû•Îêú ÌååÏùºÏùÑ DataFrameÏúºÎ°ú Î°úÎìú
            df = pd.read_csv(file_path)
            
            # Í∞ïÌôîÎêú SSOTÏóê Îç∞Ïù¥ÌÑ∞ ÏÑ§Ï†ï
            success = data_manager.set_data(df, f"ÏóÖÎ°úÎìúÎêú ÌååÏùº: {uploaded_csv.name}")
            
            if success:
                # Îç∞Ïù¥ÌÑ∞ Í≥ÑÎ≥¥ Ï∂îÏ†Å ÏãúÏûë
                original_hash = data_lineage_tracker.set_original_data(df)
                
                # ÏÑ∏ÏÖò ÏÉÅÌÉúÏóêÎèÑ Î∞±ÏóÖ Ï†ÄÏû•
                st.session_state.uploaded_data = df
                st.session_state.original_data_hash = original_hash
                
                st.success(f"‚úÖ Í∞ïÌôîÎêú SSOT ÏÑ§Ï†ï ÏôÑÎ£å: {uploaded_csv.name}")
                
                # ÏóÖÎç∞Ïù¥Ìä∏Îêú Îç∞Ïù¥ÌÑ∞ Ï†ïÎ≥¥ ÌëúÏãú
                with st.expander("üìà ÏóÖÎ°úÎìúÎêú Îç∞Ïù¥ÌÑ∞ Ï†ïÎ≥¥", expanded=True):
                    info = data_manager.get_data_info()
                    
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("Ìñâ Ïàò", f"{info['row_count']:,}")
                    with col2:
                        st.metric("Ïó¥ Ïàò", f"{info['col_count']:,}")
                    with col3:
                        st.metric("Î©îÎ™®Î¶¨", f"{info['memory_mb']:.2f}MB")
                    
                    st.write("**ÌååÏùº Í≤ΩÎ°ú**: `" + file_path + "`")
                    st.write("**Ïª¨Îüº Î™©Î°ù**: " + ', '.join(info['columns'][:5]) + ("..." if len(info['columns']) > 5 else ""))
                    
                    # ÏÉòÌîå Îç∞Ïù¥ÌÑ∞ ÎØ∏Î¶¨Î≥¥Í∏∞
                    st.write("**ÎØ∏Î¶¨Î≥¥Í∏∞:**")
                    st.dataframe(df.head(3), use_container_width=True)
                
                # ÏãúÏä§ÌÖú Ï¥àÍ∏∞Ìôî ÏïàÎÇ¥
                if st.session_state.get("graph_initialized", False):
                    st.info("üí° Î™®Îì† ExecutorÍ∞Ä ÎèôÏùºÌïú Îç∞Ïù¥ÌÑ∞Ïóê Ï†ëÍ∑ºÌï† Ïàò ÏûàÏäµÎãàÎã§!")
            else:
                st.error("‚ùå Í∞ïÌôîÎêú SSOT Îç∞Ïù¥ÌÑ∞ ÏÑ§Ï†ï Ïã§Ìå®")
                
        except Exception as e:
            # SSOT Ï¥àÍ∏∞Ìôî
            data_manager.clear_data()
            if hasattr(st.session_state, 'uploaded_data'):
                del st.session_state.uploaded_data
            st.error(f"CSV ÏóÖÎ°úÎìú Ïã§Ìå®: {e}")
    
    # Îç∞Ïù¥ÌÑ∞ ÏÇ≠Ï†ú ÏòµÏÖò
    if data_manager.is_data_loaded():
        if st.button("üóëÔ∏è Îç∞Ïù¥ÌÑ∞ ÏÇ≠Ï†ú", use_container_width=True, type="secondary"):
            data_manager.clear_data()
            if hasattr(st.session_state, 'uploaded_data'):
                del st.session_state.uploaded_data
            st.success("‚úÖ Îç∞Ïù¥ÌÑ∞Í∞Ä ÏÇ≠Ï†úÎêòÏóàÏäµÎãàÎã§.")
            st.rerun()

def render_system_settings():
    """ÏãúÏä§ÌÖú ÏÑ§Ï†ï ÏÑπÏÖò Î†åÎçîÎßÅ"""
    with st.expander("‚öôÔ∏è System Settings", expanded=False):
        col1, col2 = st.columns(2)
        
        with col1:
            new_recursion_limit = st.number_input(
                "Recursion Limit",
                min_value=5,
                max_value=50,
                value=st.session_state.get("recursion_limit", 30),
                step=1,
                help="Maximum number of recursive calls to prevent infinite loops"
            )
        
        with col2:
            new_timeout_seconds = st.number_input(
                "Query Timeout (seconds)",
                min_value=30,
                max_value=600,
                value=st.session_state.get("timeout_seconds", 180),
                step=30,
                help="Maximum time to wait for response (30-600 seconds)"
            )
        
        if st.button("Apply Settings", use_container_width=True):
            st.session_state.recursion_limit = new_recursion_limit
            st.session_state.timeout_seconds = new_timeout_seconds
            st.success(f"‚úÖ Settings updated - Recursion: {new_recursion_limit}, Timeout: {new_timeout_seconds}s")
            st.rerun()

def render_executor_creation_form():
    """Executor ÏÉùÏÑ± Ìèº Î†åÎçîÎßÅ - MCP ÎèÑÍµ¨ ÏÑ†ÌÉù Í∏∞Îä• Ìè¨Ìï®"""
    from core.utils.config import load_mcp_configs
    from core.tools.mcp_tools import get_available_mcp_tools_info
    
    st.subheader("‚ûï Create New Executor")
    
    # Enhanced agent creation with detailed options
    with st.form("create_executor_form"):
        # Executor name
        executor_name = st.text_input(
            "Executor Name", 
            placeholder="e.g., Data Analyst",
            help="Choose a descriptive name for the executor"
        )
        
        # Enhanced role templates
        role_templates = {
            "Custom": "",
            "EDA Specialist": """You are an Exploratory Data Analysis Expert who uncovers hidden patterns and insights in data. 
You focus on understanding data structure, distributions, relationships, and anomalies.

CRITICAL DATA HANDLING RULE: You MUST use the `python_repl_ast` tool for ALL data operations.
1. ALWAYS start by calling `df = get_current_data()` within the Python tool.
2. Perform ALL your analysis on `df` in the SAME Python tool execution.
3. End with 'TASK COMPLETED: [Summary]' when finished.""",
            "Visualization Expert": """You are a Data Visualization Expert who creates compelling and insightful charts, graphs, and dashboards.
You excel at choosing the right visualization for the data and message.

CRITICAL DATA HANDLING RULE: You MUST use the `python_repl_ast` tool for ALL data operations.
1. ALWAYS start by calling `df = get_current_data()` within the Python tool.
2. Create visualizations using matplotlib, seaborn, or plotly.
3. End with 'TASK COMPLETED: [Summary]' when finished.""",
            "ML Engineer": """You are a Machine Learning Engineer who builds, trains, and evaluates predictive models.
You handle the full ML pipeline from data preparation to model deployment.

CRITICAL DATA HANDLING RULE: You MUST use the `python_repl_ast` tool for ALL data operations.
1. ALWAYS start by calling `df = get_current_data()` within the Python tool.
2. Use sklearn or other ML libraries for modeling.
3. End with 'TASK COMPLETED: [Summary]' when finished.""",
            "Data Preprocessor": """You are a Data Preprocessing Expert who cleans, transforms, and prepares data for analysis.
You handle missing values, outliers, encoding, and feature scaling.

CRITICAL DATA HANDLING RULE: You MUST use the `python_repl_ast` tool for ALL data operations.
1. ALWAYS start by calling `df = get_current_data()` within the Python tool.
2. Document all transformations clearly.
3. End with 'TASK COMPLETED: [Summary]' when finished.""",
            "Statistical Analyst": """You are a Statistical Analysis Expert who performs rigorous statistical tests and modeling.
You derive meaningful insights through hypothesis testing and statistical inference.

CRITICAL DATA HANDLING RULE: You MUST use the `python_repl_ast` tool for ALL data operations.
1. ALWAYS start by calling `df = get_current_data()` within the Python tool.
2. Use scipy.stats or statsmodels for analysis.
3. End with 'TASK COMPLETED: [Summary]' when finished.""",
            "Report Writer": """You are a Report Writing Expert who creates comprehensive analysis reports.
You summarize findings and communicate insights to stakeholders.

CRITICAL DATA HANDLING RULE: You MUST use the `python_repl_ast` tool for ALL data operations.
1. ALWAYS start by calling `df = get_current_data()` within the Python tool if data analysis is needed.
2. Focus on clear, actionable insights.
3. End with 'TASK COMPLETED: [Summary]' when finished."""
        }
        
        selected_role = st.selectbox(
            "Select Role Template",
            list(role_templates.keys()),
            help="Choose a predefined role or create custom"
        )
        
        if selected_role == "Custom":
            prompt_text = st.text_area(
                "Role Description",
                height=150,
                placeholder="Describe the executor's role... Include 'TASK COMPLETED:' instruction at the end."
            )
        else:
            prompt_text = st.text_area(
                "Role Description",
                value=role_templates[selected_role],
                height=150
            )
        
        # Tool selection
        st.subheader("üîß Tool Selection")
        
        # Python tool (always included for data science tasks)
        use_python = st.checkbox(
            "Enhanced Python Tool (SSOT)", 
            value=True,
            help="Í∞ïÌôîÎêú SSOT Í∏∞Î∞ò Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑù ÌôòÍ≤Ω"
        )
        
        # MCP Tools Selection
        st.markdown("#### MCP ÎèÑÍµ¨ ÏÑ†ÌÉù")
        saved_configs = load_mcp_configs()
        
        if saved_configs:
            config_names = ["None"] + [config.get('name', config['config_name']) for config in saved_configs]
            selected_mcp_config = st.selectbox(
                "MCP ÏÑ§Ï†ï ÏÑ†ÌÉù",
                config_names,
                help="ÏÇ¨Ïö©Ìï† MCP ÎèÑÍµ¨ ÏÑ§Ï†ïÏùÑ ÏÑ†ÌÉùÌïòÏÑ∏Ïöî"
            )
            
            selected_mcp_tools = []
            if selected_mcp_config != "None":
                config_data = next((c for c in saved_configs if c.get('name', c['config_name']) == selected_mcp_config), None)
                if config_data:
                    # Ïã§ÏãúÍ∞Ñ ÏÑúÎ≤Ñ ÏÉÅÌÉú ÌôïÏù∏
                    tools_info = get_available_mcp_tools_info(config_data['config_name'])
                    
                    if tools_info['available']:
                        st.success(f"‚úÖ {tools_info['available_servers']}/{tools_info['total_servers']} MCP ÏÑúÎ≤Ñ ÏÇ¨Ïö© Í∞ÄÎä•")
                        
                        # ÏÇ¨Ïö© Í∞ÄÎä•Ìïú ÎèÑÍµ¨Îì§ÏùÑ Ï≤¥ÌÅ¨Î∞ïÏä§Î°ú ÌëúÏãú
                        for tool in tools_info['tools']:
                            if tool['status'] == 'available':
                                if st.checkbox(f"üü¢ {tool['server_name']}", value=True, key=f"mcp_tool_{tool['server_name']}"):
                                    selected_mcp_tools.append(tool['server_name'])
                            else:
                                st.checkbox(f"üî¥ {tool['server_name']} (ÏÇ¨Ïö© Î∂àÍ∞Ä)", value=False, disabled=True, key=f"mcp_tool_disabled_{tool['server_name']}")
                    else:
                        st.warning("‚ö†Ô∏è ÏÑ†ÌÉùÌïú ÏÑ§Ï†ïÏùò MCP ÏÑúÎ≤ÑÎì§Ïù¥ Ïã§ÌñâÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§")
        else:
            st.info("üí° MCP ÏÑ§Ï†ïÏùÑ Î®ºÏ†Ä ÏÉùÏÑ±ÌïòÏÑ∏Ïöî")
        
        # Submit button
        submitted = st.form_submit_button("‚ú® Create Executor", type="primary", use_container_width=True)
        
        if submitted:
            if not executor_name:
                st.error("‚ùå Please enter an executor name")
            elif not prompt_text:
                st.error("‚ùå Please enter a role description")
            elif executor_name in st.session_state.get("executors", {}):
                st.error(f"‚ùå Executor '{executor_name}' already exists")
            else:
                # Initialize executors dict if not exists
                if "executors" not in st.session_state:
                    st.session_state.executors = {}
                
                # Í∏∞Î≥∏ ÎèÑÍµ¨ Î™©Î°ù Íµ¨ÏÑ±
                tools = ["python_repl_ast"] if use_python else []
                
                # MCP ÎèÑÍµ¨ ÏÑ§Ï†ï Ï∂îÍ∞Ä
                mcp_config = {}
                if 'selected_mcp_config' in locals() and selected_mcp_config != "None" and selected_mcp_tools:
                    config_data = next((c for c in saved_configs if c.get('name', c['config_name']) == selected_mcp_config), None)
                    if config_data:
                        mcp_config = {
                            "config_name": selected_mcp_config,
                            "selected_tools": selected_mcp_tools,
                            "mcpServers": {tool: config_data['mcpServers'].get(tool, {}) for tool in selected_mcp_tools}
                        }
                        # MCP ÎèÑÍµ¨Îì§ÏùÑ ÎèÑÍµ¨ Î™©Î°ùÏóê Ï∂îÍ∞Ä
                        for tool in selected_mcp_tools:
                            tools.append(f"mcp:{selected_mcp_config}:{tool}")
                
                # Create executor configuration
                executor_config = {
                    "prompt": prompt_text,
                    "tools": tools,
                    "mcp_config": mcp_config,
                    "created_at": datetime.now().isoformat()
                }
                
                st.session_state.executors[executor_name] = executor_config
                st.success(f"‚úÖ Executor '{executor_name}' created successfully!")
                
                logging.info(f"Created executor: {executor_name} with tools: {tools}")
                st.rerun()

def render_saved_systems():
    """Ï†ÄÏû•Îêú ÏãúÏä§ÌÖú Í¥ÄÎ¶¨ ÏÑπÏÖò Î†åÎçîÎßÅ"""
    st.markdown("### üìÇ Saved Multi-Agent Systems")
    
    saved_configs = load_multi_agent_configs()
    
    if saved_configs:
        selected_config = st.selectbox(
            "Load a saved system",
            ["None"] + [f"{config['name']} ({config['executors_count']} executors)" for config in saved_configs],
            help="Select a saved multi-agent system to load"
        )
        
        if selected_config != "None":
            config_name = selected_config.split(" (")[0]
            config_to_load = next((c for c in saved_configs if c['name'] == config_name), None)
            
            if config_to_load:
                col1, col2 = st.columns(2)
                
                with col1:
                    if st.button("üì• Load", use_container_width=True):
                        config_data = load_multi_agent_config(config_to_load['file'])
                        if config_data:
                            st.session_state.executors = config_data.get("executors", {})
                            st.session_state.current_system_name = config_data.get("name", "")
                            st.success(f"‚úÖ Loaded '{config_name}' successfully!")
                            st.rerun()
                
                with col2:
                    if st.button("üóëÔ∏è Delete", use_container_width=True):
                        if delete_multi_agent_config(config_to_load['file']):
                            st.success(f"‚úÖ Deleted '{config_name}'")
                            st.rerun()
    else:
        st.info("No saved systems yet. Create and save your first one!")

def render_quick_templates():
    """Îπ†Î•∏ ÏãúÏûë ÌÖúÌîåÎ¶ø Î†åÎçîÎßÅ - MCP ÎèÑÍµ¨ ÏûêÎèô Ìï†Îãπ Í∞ïÌôî"""
    from core.tools.mcp_tools import test_mcp_server_availability, get_role_mcp_tools
    
    with st.expander("üöÄ Quick Start Templates", expanded=True):
        st.markdown("### Pre-configured Systems")
        
        if st.button("üî¨ Data Science Team", use_container_width=True):
            # MCP ÏÑúÎ≤Ñ Í∞ÄÏö©ÏÑ± ÌôïÏù∏
            with st.spinner("MCP ÏÑúÎ≤Ñ ÏÉÅÌÉú ÌôïÏù∏ Ï§ë..."):
                try:
                    # ÎπÑÎèôÍ∏∞ Ìï®ÏàòÎ•º ÎèôÍ∏∞Ï†ÅÏúºÎ°ú Ïã§Ìñâ
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)
                    available_servers = loop.run_until_complete(test_mcp_server_availability())
                    loop.close()
                except Exception as e:
                    logging.warning(f"MCP server availability check failed: {e}")
                    available_servers = {}
            
            # Í∏∞Î≥∏ Data Science ÌåÄ Íµ¨ÏÑ± with MCP tools
            st.session_state.executors = {}
            
            team_roles = [
                ("Data_Preprocessor", "Data_Preprocessor"),
                ("EDA_Specialist", "EDA_Specialist"), 
                ("Visualization_Expert", "Visualization_Expert"),
                ("ML_Engineer", "ML_Engineer"),
                ("Statistical_Analyst", "Statistical_Analyst"),
                ("Report_Writer", "Report_Writer")
            ]
            
            for executor_name, role_name in team_roles:
                # Ïó≠Ìï†Î≥Ñ MCP ÎèÑÍµ¨ Ìï†Îãπ
                tools, mcp_config = get_role_mcp_tools(role_name, available_servers)
                
                role_prompts = {
                    "Data_Preprocessor": """You are a Data Preprocessing Expert who cleans, transforms, and prepares data for analysis.
You handle missing values, outliers, encoding, and feature scaling.

CRITICAL DATA HANDLING RULE: You MUST use the `python_repl_ast` tool for ALL data operations.
1. ALWAYS start by calling `df = get_current_data()` within the Python tool.
2. Document all transformations clearly.
3. End with 'TASK COMPLETED: [Summary]' when finished.""",
                    "EDA_Specialist": """You are an Exploratory Data Analysis Expert who uncovers hidden patterns and insights in data. 
You focus on understanding data structure, distributions, relationships, and anomalies.

CRITICAL DATA HANDLING RULE: You MUST use the `python_repl_ast` tool for ALL data operations.
1. ALWAYS start by calling `df = get_current_data()` within the Python tool.
2. Perform ALL your analysis on `df` in the SAME Python tool execution.
3. End with 'TASK COMPLETED: [Summary]' when finished.""",
                    "Visualization_Expert": """You are a Data Visualization Expert who creates compelling and insightful charts, graphs, and dashboards.
You excel at choosing the right visualization for the data and message.

CRITICAL DATA HANDLING RULE: You MUST use the `python_repl_ast` tool for ALL data operations.
1. ALWAYS start by calling `df = get_current_data()` within the Python tool.
2. Create visualizations using matplotlib, seaborn, or plotly.
3. End with 'TASK COMPLETED: [Summary]' when finished.""",
                    "ML_Engineer": """You are a Machine Learning Engineer who builds, trains, and evaluates predictive models.
You handle the full ML pipeline from data preparation to model deployment.

CRITICAL DATA HANDLING RULE: You MUST use the `python_repl_ast` tool for ALL data operations.
1. ALWAYS start by calling `df = get_current_data()` within the Python tool.
2. Use sklearn or other ML libraries for modeling.
3. End with 'TASK COMPLETED: [Summary]' when finished.""",
                    "Statistical_Analyst": """You are a Statistical Analysis Expert who performs rigorous statistical tests and modeling.
You derive meaningful insights through hypothesis testing and statistical inference.

CRITICAL DATA HANDLING RULE: You MUST use the `python_repl_ast` tool for ALL data operations.
1. ALWAYS start by calling `df = get_current_data()` within the Python tool.
2. Use scipy.stats or statsmodels for analysis.
3. End with 'TASK COMPLETED: [Summary]' when finished.""",
                    "Report_Writer": """You are a Report Writing Expert who creates comprehensive analysis reports.
You summarize findings and communicate insights to stakeholders.

CRITICAL DATA HANDLING RULE: You MUST use the `python_repl_ast` tool for ALL data operations.
1. ALWAYS start by calling `df = get_current_data()` within the Python tool if data analysis is needed.
2. Focus on clear, actionable insights.
3. End with 'TASK COMPLETED: [Summary]' when finished."""
                }
                
                st.session_state.executors[executor_name] = {
                    "prompt": role_prompts[role_name],
                    "tools": tools,
                    "mcp_config": mcp_config,
                    "created_at": datetime.now().isoformat()
                }
            
            # ÏÇ¨Ïö© Í∞ÄÎä•Ìïú MCP ÏÑúÎ≤Ñ Í∞úÏàò ÌëúÏãú
            available_count = sum(available_servers.values())
            total_count = len(available_servers)
            
            if available_count > 0:
                st.success(f"‚úÖ Data Science Team template loaded! ({available_count}/{total_count} MCP servers available)")
            else:
                st.success("‚úÖ Data Science Team template loaded! (Python tools only)")
                st.info("üí° MCP ÏÑúÎ≤ÑÎ•º Ïã§ÌñâÌïòÎ©¥ Îçî ÎßéÏùÄ ÎèÑÍµ¨Î•º ÏÇ¨Ïö©Ìï† Ïàò ÏûàÏäµÎãàÎã§")
            
            st.rerun()

# Helper functions
def load_multi_agent_configs():
    """Load all saved multi-agent configurations"""
    config_dir = Path("multi-agent-configs")
    configs = []
    
    if config_dir.exists():
        for json_file in config_dir.glob("*.json"):
            try:
                with open(json_file, encoding="utf-8") as f:
                    config = json.load(f)
                    configs.append({
                        "name": config.get("name", json_file.stem),
                        "file": json_file.stem,
                        "created_at": config.get("created_at", "Unknown"),
                        "executors_count": len(config.get("executors", {})),
                        "description": config.get("description", "")
                    })
            except Exception as e:
                logging.error(f"Failed to load config {json_file}: {e}")
    
    return sorted(configs, key=lambda x: x.get("created_at", ""), reverse=True)

def load_multi_agent_config(filename: str):
    """Load a specific multi-agent configuration"""
    config_dir = Path("multi-agent-configs")
    config_file = config_dir / f"{filename}.json"
    
    if config_file.exists():
        with open(config_file, encoding="utf-8") as f:
            return json.load(f)
    return None

def delete_multi_agent_config(filename: str):
    """Delete a multi-agent configuration"""
    config_dir = Path("multi-agent-configs")
    config_file = config_dir / f"{filename}.json"
    
    if config_file.exists():
        config_file.unlink()
        return True
    return False

def save_multi_agent_config(name: str, config: dict):
    """Save multi-agent configuration to file"""
    config_dir = Path("multi-agent-configs")
    config_dir.mkdir(exist_ok=True)
    
    config_file = config_dir / f"{name}.json"
    
    # Save configuration
    save_data = {
        "name": name,
        "created_at": datetime.now().isoformat(),
        "executors": config.get("executors", {}),
        "description": config.get("description", "")
    }
    
    with open(config_file, "w", encoding="utf-8") as f:
        json.dump(save_data, f, ensure_ascii=False, indent=2)
    
    return config_file