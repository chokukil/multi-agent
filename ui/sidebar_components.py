# File: ui/sidebar_components.py
# Location: ./ui/sidebar_components.py

import streamlit as st
import os
import json
from pathlib import Path
from typing import Dict, List, Tuple
import pandas as pd
import asyncio
import logging
from datetime import datetime

# Add log_event import
from core.utils.helpers import log_event

def render_mcp_config_section():
    """MCP Server Configuration ì„¹ì…˜ ë Œë”ë§"""
    from core.utils.config import load_mcp_configs, save_mcp_config, delete_mcp_config
    from core.tools.mcp_tools import get_available_mcp_tools_info
    
    with st.expander("ğŸ”§ MCP Server Configuration", expanded=False):
        st.markdown("### MCP ë„êµ¬ ì„¤ì • ê´€ë¦¬")
        
        # í˜„ì¬ ì €ì¥ëœ ì„¤ì •ë“¤ í‘œì‹œ
        saved_configs = load_mcp_configs()
        
        if saved_configs:
            st.markdown("#### ì €ì¥ëœ ì„¤ì •")
            config_names = [config.get('name', config['config_name']) for config in saved_configs]
            selected_config = st.selectbox(
                "ì„¤ì • ì„ íƒ",
                ["None"] + config_names,
                help="ì €ì¥ëœ MCP ì„¤ì •ì„ ì„ íƒí•˜ì„¸ìš”"
            )
            
            if selected_config != "None":
                config_data = next((c for c in saved_configs if c.get('name', c['config_name']) == selected_config), None)
                if config_data:
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        if st.button("ğŸ“Š ìƒíƒœ í™•ì¸", key="check_mcp_status"):
                            with st.spinner("MCP ì„œë²„ ìƒíƒœ í™•ì¸ ì¤‘..."):
                                tools_info = get_available_mcp_tools_info(config_data['config_name'])
                                if tools_info['available']:
                                    st.success(f"âœ… {tools_info['available_servers']}/{tools_info['total_servers']} ì„œë²„ ì‚¬ìš© ê°€ëŠ¥")
                                    for tool in tools_info['tools']:
                                        status_icon = "ğŸŸ¢" if tool['status'] == "available" else "ğŸ”´"
                                        st.text(f"{status_icon} {tool['server_name']}")
                                else:
                                    st.error("âŒ ì‚¬ìš© ê°€ëŠ¥í•œ ì„œë²„ê°€ ì—†ìŠµë‹ˆë‹¤")
                    
                    with col2:
                        if st.button("ğŸ“ ìˆ˜ì •", key="edit_mcp_config"):
                            st.session_state.editing_mcp_config = config_data
                    
                    with col3:
                        if st.button("ğŸ—‘ï¸ ì‚­ì œ", key="delete_mcp_config"):
                            if delete_mcp_config(config_data['config_name']):
                                st.success(f"âœ… '{selected_config}' ì‚­ì œë¨")
                                st.rerun()
                            else:
                                st.error("âŒ ì‚­ì œ ì‹¤íŒ¨")
        
        # ìƒˆ ì„¤ì • ì¶”ê°€ ë˜ëŠ” ìˆ˜ì •
        st.markdown("#### ìƒˆ ì„¤ì • ì¶”ê°€")
        
        with st.form("mcp_config_form"):
            config_name = st.text_input(
                "ì„¤ì • ì´ë¦„",
                value=st.session_state.get('editing_mcp_config', {}).get('name', ''),
                placeholder="ì˜ˆ: my_data_tools"
            )
            
            config_description = st.text_area(
                "ì„¤ëª…",
                value=st.session_state.get('editing_mcp_config', {}).get('description', ''),
                placeholder="ì´ ì„¤ì •ì— ëŒ€í•œ ê°„ë‹¨í•œ ì„¤ëª…ì„ ì…ë ¥í•˜ì„¸ìš”"
            )
            
            # JSON ì„¤ì • ì…ë ¥
            default_json = json.dumps(
                st.session_state.get('editing_mcp_config', {}).get('mcpServers', {
                    "data_science_tools": {
                        "url": "http://localhost:8007/sse", 
                        "transport": "sse",
                        "description": "ë°ì´í„° ë¶„ì„ ë„êµ¬"
                    }
                }),
                indent=2
            )
            
            json_config = st.text_area(
                "MCP ì„œë²„ ì„¤ì • (JSON)",
                value=default_json,
                height=200,
                help="MCP ì„œë²„ ì„¤ì •ì„ JSON í˜•ì‹ìœ¼ë¡œ ì…ë ¥í•˜ì„¸ìš”"
            )
            
            col1, col2 = st.columns(2)
            with col1:
                save_button = st.form_submit_button("ğŸ’¾ ì €ì¥", type="primary")
            with col2:
                if st.form_submit_button("âŒ ì·¨ì†Œ"):
                    if 'editing_mcp_config' in st.session_state:
                        del st.session_state.editing_mcp_config
                    st.rerun()
            
            if save_button:
                if not config_name:
                    st.error("âŒ ì„¤ì • ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”")
                else:
                    try:
                        # JSON ìœ íš¨ì„± ê²€ì‚¬
                        servers_config = json.loads(json_config)
                        
                        # ì„¤ì • ë°ì´í„° êµ¬ì„±
                        config_data = {
                            "name": config_name,
                            "description": config_description,
                            "mcpServers": servers_config,
                            "created_at": datetime.now().isoformat()
                        }
                        
                        # ì €ì¥
                        if save_mcp_config(config_name, config_data):
                            st.success(f"âœ… '{config_name}' ì„¤ì •ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤")
                            if 'editing_mcp_config' in st.session_state:
                                del st.session_state.editing_mcp_config
                            st.rerun()
                        else:
                            st.error("âŒ ì„¤ì • ì €ì¥ ì‹¤íŒ¨")
                    
                    except json.JSONDecodeError as e:
                        st.error(f"âŒ JSON í˜•ì‹ ì˜¤ë¥˜: {e}")

def render_data_upload_section():
    """ë°ì´í„° ì—…ë¡œë“œ ì„¹ì…˜ ë Œë”ë§"""
    from core import data_manager, data_lineage_tracker
    
    st.markdown("### ê°•í™”ëœ ë°ì´í„° ë¶„ì„")
    
    # SSOT ë°ì´í„° ìƒíƒœ í‘œì‹œ
    current_status = data_manager.get_status_message()
    
    if data_manager.is_data_loaded():
        st.success(current_status)
        
        # ë°ì´í„° ì •ë³´ í‘œì‹œ
        with st.expander("ğŸ“ˆ í˜„ì¬ ë°ì´í„° ì •ë³´", expanded=False):
            info = data_manager.get_data_info()
            col1, col2 = st.columns(2)
            
            with col1:
                st.metric("í–‰ ìˆ˜", f"{info['row_count']:,}")
                st.metric("ë©”ëª¨ë¦¬", f"{info['memory_mb']:.2f}MB")
            
            with col2:
                st.metric("ì—´ ìˆ˜", f"{info['col_count']:,}")
                st.metric("ì¶œì²˜", info['source'])
            
            st.write("**ì»¬ëŸ¼ ì •ë³´:**")
            cols_display = ', '.join(info['columns'][:8])
            if len(info['columns']) > 8:
                cols_display += f" ... (+{len(info['columns']) - 8}ê°œ)"
            st.text(cols_display)
            
            st.write("**í†µê³„:**")
            st.text(f"ìˆ˜ì¹˜í˜•: {len(info['numeric_cols'])}ê°œ, ë²”ì£¼í˜•: {len(info['categorical_cols'])}ê°œ, ê²°ì¸¡ê°’: {info['null_count']:,}ê°œ")
        
        # ë°ì´í„° ê´€ë¦¬ ë„êµ¬ë“¤
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ”„ ìƒˆë¡œê³ ì¹¨", use_container_width=True):
                if hasattr(st.session_state, 'uploaded_data') and st.session_state.uploaded_data is not None:
                    success = data_manager.set_data(st.session_state.uploaded_data, "ì„¸ì…˜ ë°ì´í„° ìƒˆë¡œê³ ì¹¨")
                    if success:
                        st.success("âœ… ë°ì´í„°ê°€ ìƒˆë¡œê³ ì¹¨ë˜ì—ˆìŠµë‹ˆë‹¤!")
                        st.rerun()
        
        with col2:
            if st.button("âœ… ì¼ê´€ì„± ê²€ì¦", use_container_width=True):
                is_valid, message = data_manager.validate_data_consistency()
                if is_valid:
                    st.success(f"âœ… {message}")
                else:
                    st.error(f"âŒ {message}")
    else:
        st.warning(current_status)
    
    # sandbox/datasets í´ë” ìƒì„±
    DATASETS_DIR = "./sandbox/datasets"
    os.makedirs(DATASETS_DIR, exist_ok=True)
    
    uploaded_csv = st.file_uploader("ğŸ“‚ CSV íŒŒì¼ ì—…ë¡œë“œ", type=["csv"], help="ë°ì´í„° ë¶„ì„ì„ ìœ„í•œ CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”")
    if uploaded_csv:
        try:
            # íŒŒì¼ì„ datasets í´ë”ì— ì €ì¥
            file_path = os.path.join(DATASETS_DIR, uploaded_csv.name)
            with open(file_path, "wb") as f:
                f.write(uploaded_csv.getvalue())
                
            # ì €ì¥ëœ íŒŒì¼ì„ DataFrameìœ¼ë¡œ ë¡œë“œ
            df = pd.read_csv(file_path)
            
            # ê°•í™”ëœ SSOTì— ë°ì´í„° ì„¤ì •
            success = data_manager.set_data(df, f"ì—…ë¡œë“œëœ íŒŒì¼: {uploaded_csv.name}")
            
            if success:
                # ë°ì´í„° ê³„ë³´ ì¶”ì  ì‹œì‘
                original_hash = data_lineage_tracker.set_original_data(df)
                
                # ì„¸ì…˜ ìƒíƒœì—ë„ ë°±ì—… ì €ì¥
                st.session_state.uploaded_data = df
                st.session_state.original_data_hash = original_hash
                
                st.success(f"âœ… ê°•í™”ëœ SSOT ì„¤ì • ì™„ë£Œ: {uploaded_csv.name}")
                
                # ì—…ë°ì´íŠ¸ëœ ë°ì´í„° ì •ë³´ í‘œì‹œ
                with st.expander("ğŸ“ˆ ì—…ë¡œë“œëœ ë°ì´í„° ì •ë³´", expanded=True):
                    info = data_manager.get_data_info()
                    
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("í–‰ ìˆ˜", f"{info['row_count']:,}")
                    with col2:
                        st.metric("ì—´ ìˆ˜", f"{info['col_count']:,}")
                    with col3:
                        st.metric("ë©”ëª¨ë¦¬", f"{info['memory_mb']:.2f}MB")
                    
                    st.write("**íŒŒì¼ ê²½ë¡œ**: `" + file_path + "`")
                    st.write("**ì»¬ëŸ¼ ëª©ë¡**: " + ', '.join(info['columns'][:5]) + ("..." if len(info['columns']) > 5 else ""))
                    
                    # ìƒ˜í”Œ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
                    st.write("**ë¯¸ë¦¬ë³´ê¸°:**")
                    st.dataframe(df.head(3), use_container_width=True)
                
                # ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì•ˆë‚´
                if st.session_state.get("graph_initialized", False):
                    st.info("ğŸ’¡ ëª¨ë“  Executorê°€ ë™ì¼í•œ ë°ì´í„°ì— ì ‘ê·¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!")
            else:
                st.error("âŒ ê°•í™”ëœ SSOT ë°ì´í„° ì„¤ì • ì‹¤íŒ¨")
                
        except Exception as e:
            # SSOT ì´ˆê¸°í™”
            data_manager.clear_data()
            if hasattr(st.session_state, 'uploaded_data'):
                del st.session_state.uploaded_data
            st.error(f"CSV ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    # ë°ì´í„° ì‚­ì œ ì˜µì…˜
    if data_manager.is_data_loaded():
        if st.button("ğŸ—‘ï¸ ë°ì´í„° ì‚­ì œ", use_container_width=True, type="secondary"):
            data_manager.clear_data()
            if hasattr(st.session_state, 'uploaded_data'):
                del st.session_state.uploaded_data
            st.success("âœ… ë°ì´í„°ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
            st.rerun()

def render_system_settings():
    """ì‹œìŠ¤í…œ ì„¤ì • ì„¹ì…˜ ë Œë”ë§"""
    with st.expander("âš™ï¸ System Settings", expanded=False):
        col1, col2 = st.columns(2)
        
        with col1:
            new_recursion_limit = st.number_input(
                "Recursion Limit",
                min_value=5,
                max_value=50,
                value=st.session_state.get("recursion_limit", 30),
                step=1,
                help="Maximum number of recursive calls to prevent infinite loops"
            )
        
        with col2:
            new_timeout_seconds = st.number_input(
                "Query Timeout (seconds)",
                min_value=30,
                max_value=600,
                value=st.session_state.get("timeout_seconds", 180),
                step=30,
                help="Maximum time to wait for response (30-600 seconds)"
            )
        
        if st.button("Apply Settings", use_container_width=True):
            st.session_state.recursion_limit = new_recursion_limit
            st.session_state.timeout_seconds = new_timeout_seconds
            st.success(f"âœ… Settings updated - Recursion: {new_recursion_limit}, Timeout: {new_timeout_seconds}s")
            st.rerun()

def render_executor_creation_form():
    """Enhanced Executor ìƒì„± í¼ - íŒŒì¼ ê¸°ë°˜ í…œí”Œë¦¿ ì‹œìŠ¤í…œ í¬í•¨"""
    from core.utils.config import (
        load_executor_templates, get_template_categories, 
        load_mcp_templates, save_executor_template
    )
    from core.tools.mcp_tools import get_available_mcp_tools_info
    
    st.subheader("â• Create New Executor")
    
    # Enhanced agent creation with file-based templates
    with st.form("create_executor_form"):
        # Executor name
        executor_name = st.text_input(
            "Executor Name", 
            placeholder="e.g., Data Analyst",
            help="Choose a descriptive name for the executor"
        )
        
        # Load templates from prompt-configs
        st.subheader("ğŸ“ Role Template")
        
        templates = load_executor_templates()
        categories = get_template_categories()
        
        # Category filter
        col1, col2 = st.columns([2, 1])
        with col1:
            selected_category = st.selectbox(
                "Filter by Category",
                ["All"] + categories,
                help="Filter templates by category"
            )
        
        with col2:
            show_source = st.checkbox("Show Source", help="Show template source (user/system)")
        
        # Filter templates by category
        if selected_category != "All":
            filtered_templates = {k: v for k, v in templates.items() 
                                if v.get("category") == selected_category}
        else:
            filtered_templates = templates
        
        # Template selection with source indication
        if show_source:
            template_options = ["Custom"] + [
                f"{name} ({config.get('source', 'system')})" 
                for name, config in filtered_templates.items()
            ]
            format_func = lambda x: x
        else:
            template_options = ["Custom"] + list(filtered_templates.keys())
            format_func = lambda x: x
        
        selected_template_display = st.selectbox(
            "Select Template",
            template_options,
            format_func=format_func,
            help="Choose from available prompt templates"
        )
        
        # Extract actual template name
        if selected_template_display == "Custom":
            selected_template = "Custom"
        else:
            selected_template = selected_template_display.split(" (")[0] if show_source else selected_template_display
        
        # Show template info and prompt editing
        if selected_template == "Custom":
            prompt_text = st.text_area(
                "Role Description",
                height=150,
                placeholder="Describe the executor's role... Include 'TASK COMPLETED:' instruction at the end.",
                help="Create a custom role description"
            )
        else:
            template_data = filtered_templates.get(selected_template, {})
            
            # Show template metadata
            if template_data:
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.info(f"ğŸ“‚ **Source**: {template_data.get('source', 'system')}")
                with col2:
                    st.info(f"ğŸ·ï¸ **Category**: {template_data.get('category', 'other')}")
                with col3:
                    st.info(f"ğŸ“„ **File**: {template_data.get('file', 'unknown')}")
                
                # Show creation date if available
                if template_data.get('created_at'):
                    st.caption(f"Created: {template_data['created_at']}")
            
            prompt_text = st.text_area(
                "Role Description",
                value=template_data.get("prompt", ""),
                height=150,
                help="You can edit the selected template"
            )
        
        # Tool selection
        st.subheader("ğŸ”§ Tool Selection")
        
        # Python tool (always included for data science tasks)
        use_python = st.checkbox(
            "Enhanced Python Tool (SSOT)", 
            value=True,
            help="ê°•í™”ëœ SSOT ê¸°ë°˜ ë°ì´í„° ë¶„ì„ í™˜ê²½"
        )
        
        # MCP Tools Selection - using new template system
        st.markdown("#### MCP Tools Configuration")
        mcp_templates = load_mcp_templates()
        
        if mcp_templates:
            template_names = ["None"] + list(mcp_templates.keys())
            selected_mcp_template = st.selectbox(
                "MCP Template",
                template_names,
                help="Select MCP tools configuration template"
            )
            
            selected_mcp_servers = []
            if selected_mcp_template != "None":
                mcp_config = mcp_templates[selected_mcp_template]
                
                # Show template info
                st.info(f"ğŸ“¦ **{selected_mcp_template}** - {mcp_config.get('description', 'No description')}")
                
                # Server selection with real-time status
                available_servers = mcp_config.get("servers", [])
                
                if available_servers:
                    st.write("**Available Servers:**")
                    
                    # Check server status
                    try:
                        tools_info = get_available_mcp_tools_info(selected_mcp_template)
                        server_status = {tool['server_name']: tool['status'] for tool in tools_info.get('tools', [])}
                    except:
                        server_status = {}
                    
                    # Server checkboxes
                    for server in available_servers:
                        status = server_status.get(server, 'unknown')
                        status_icon = "ğŸŸ¢" if status == "available" else "ğŸ”´" if status == "unavailable" else "ğŸŸ¡"
                        
                        if status == "available":
                            if st.checkbox(f"{status_icon} {server}", value=True, key=f"mcp_server_{server}"):
                                selected_mcp_servers.append(server)
                        else:
                            status_text = "unavailable" if status == "unavailable" else "unknown"
                            st.checkbox(f"{status_icon} {server} ({status_text})", value=False, disabled=True, key=f"mcp_server_disabled_{server}")
                    
                    # Show selected servers summary
                    if selected_mcp_servers:
                        st.success(f"âœ… Selected: {', '.join(selected_mcp_servers)}")
                    
                    # Configuration preview
                    with st.expander("ğŸ“‹ Configuration Preview", expanded=False):
                        if selected_mcp_servers:
                            preview_config = {
                                server: mcp_config["config"]["mcpServers"].get(server, {})
                                for server in selected_mcp_servers
                            }
                            st.json(preview_config)
                        else:
                            st.info("Select servers to see configuration preview")
                else:
                    st.warning("No servers found in this template")
        else:
            st.info("ğŸ’¡ No MCP templates found. Create templates in mcp-configs/ directory")
        
        # Additional options
        with st.expander("âš™ï¸ Advanced Options", expanded=False):
            save_as_template = st.checkbox(
                "Save as Template", 
                help="Save this configuration as a reusable template"
            )
            
            if save_as_template:
                template_name = st.text_input("Template Name", placeholder="My Custom Template")
                template_category = st.selectbox("Category", ["custom"] + categories)
        
        # Submit button
        submitted = st.form_submit_button("âœ¨ Create Executor", type="primary", use_container_width=True)
        
        if submitted:
            if not executor_name:
                st.error("âŒ Please enter an executor name")
            elif not prompt_text:
                st.error("âŒ Please enter a role description")
            elif executor_name in st.session_state.get("executors", {}):
                st.error(f"âŒ Executor '{executor_name}' already exists")
            else:
                # Initialize executors dict if not exists
                if "executors" not in st.session_state:
                    st.session_state.executors = {}
                
                # Build tools list
                tools = ["python_repl_ast"] if use_python else []
                
                # MCP configuration
                mcp_config = {}
                if 'selected_mcp_template' in locals() and selected_mcp_template != "None" and selected_mcp_servers:
                    mcp_template_data = mcp_templates[selected_mcp_template]
                    mcp_config = {
                        "config_name": selected_mcp_template,
                        "selected_tools": selected_mcp_servers,
                        "mcpServers": {
                            server: mcp_template_data["config"]["mcpServers"].get(server, {})
                            for server in selected_mcp_servers
                        }
                    }
                    
                    # Add MCP tools to tools list
                    for server in selected_mcp_servers:
                        tools.append(f"mcp:{selected_mcp_template}:{server}")
                
                # Create executor configuration
                executor_config = {
                    "prompt": prompt_text,
                    "tools": tools,
                    "mcp_config": mcp_config,
                    "created_at": datetime.now().isoformat(),
                    "template_source": selected_template if selected_template != "Custom" else "custom"
                }
                
                # Save as template if requested
                if save_as_template and 'template_name' in locals() and template_name:
                    template_data = {
                        "prompt": prompt_text,
                        "category": template_category,
                        "created_at": datetime.now().strftime("%Y-%m-%d")
                    }
                    
                    if save_executor_template(template_name, template_data):
                        st.success(f"âœ… Template '{template_name}' saved!")
                    else:
                        st.warning("âš ï¸ Failed to save template")
                
                # Add executor to session
                st.session_state.executors[executor_name] = executor_config
                st.success(f"âœ… Executor '{executor_name}' created successfully!")
                
                # Log creation
                logging.info(f"Created executor: {executor_name} with tools: {tools}")
                if mcp_config:
                    logging.info(f"MCP config: {selected_mcp_template} with servers: {selected_mcp_servers}")
                
                st.rerun()

def render_template_management_section():
    """í…œí”Œë¦¿ ê´€ë¦¬ ì„¹ì…˜ ë Œë”ë§"""
    from core.utils.config import (
        load_executor_templates, delete_executor_template, 
        get_template_categories, load_mcp_templates, delete_mcp_template
    )
    
    with st.expander("ğŸ“š Template Management", expanded=False):
        tab1, tab2 = st.tabs(["ğŸ¤– Executor Templates", "ğŸ”§ MCP Templates"])
        
        with tab1:
            st.markdown("#### Executor Template Management")
            
            templates = load_executor_templates()
            
            if templates:
                # Filter by source
                source_filter = st.radio(
                    "Filter by Source",
                    ["All", "User", "System"],
                    horizontal=True,
                    key="template_source_filter"
                )
                
                filtered_templates = templates
                if source_filter != "All":
                    filtered_templates = {
                        k: v for k, v in templates.items() 
                        if v.get("source", "system").lower() == source_filter.lower()
                    }
                
                if filtered_templates:
                    # Template list
                    for template_name, template_data in filtered_templates.items():
                        with st.container():
                            col1, col2, col3 = st.columns([3, 1, 1])
                            
                            with col1:
                                source_icon = "ğŸ‘¤" if template_data.get("source") == "user" else "ğŸ¢"
                                category = template_data.get("category", "other")
                                st.write(f"{source_icon} **{template_name}** `{category}`")
                                
                                # Preview prompt (first 100 chars)
                                prompt_preview = template_data.get("prompt", "")[:100]
                                if len(prompt_preview) == 100:
                                    prompt_preview += "..."
                                st.caption(prompt_preview)
                            
                            with col2:
                                if st.button("ğŸ‘ï¸", help="Preview", key=f"preview_{template_name}"):
                                    st.session_state[f"preview_template_{template_name}"] = True
                            
                            with col3:
                                # Only allow deletion of user templates
                                if template_data.get("source") == "user":
                                    if st.button("ğŸ—‘ï¸", help="Delete", key=f"delete_{template_name}"):
                                        if delete_executor_template(template_name):
                                            st.success(f"âœ… Template '{template_name}' deleted!")
                                            st.rerun()
                                        else:
                                            st.error("âŒ Failed to delete template")
                                else:
                                    st.write("ğŸ”’")  # System templates are locked
                            
                            # Show preview if requested
                            if st.session_state.get(f"preview_template_{template_name}", False):
                                with st.expander(f"ğŸ“– Preview: {template_name}", expanded=True):
                                    st.text_area(
                                        "Prompt Content",
                                        value=template_data.get("prompt", ""),
                                        height=200,
                                        disabled=True,
                                        key=f"preview_content_{template_name}"
                                    )
                                    
                                    col1, col2 = st.columns(2)
                                    with col1:
                                        st.info(f"**Source**: {template_data.get('source', 'unknown')}")
                                        st.info(f"**Category**: {template_data.get('category', 'other')}")
                                    with col2:
                                        st.info(f"**File**: {template_data.get('file', 'unknown')}")
                                        if template_data.get('created_at'):
                                            st.info(f"**Created**: {template_data['created_at']}")
                                    
                                    if st.button("âŒ Close Preview", key=f"close_preview_{template_name}"):
                                        st.session_state[f"preview_template_{template_name}"] = False
                                        st.rerun()
                            
                            st.markdown("---")
                
                else:
                    st.info(f"No {source_filter.lower()} templates found")
            else:
                st.info("No executor templates found")
        
        with tab2:
            st.markdown("#### MCP Template Management")
            
            mcp_templates = load_mcp_templates()
            
            if mcp_templates:
                for template_name, template_data in mcp_templates.items():
                    with st.container():
                        col1, col2, col3 = st.columns([3, 1, 1])
                        
                        with col1:
                            st.write(f"ğŸ”§ **{template_name}**")
                            st.caption(template_data.get("description", "No description"))
                            
                            # Show server count
                            server_count = len(template_data.get("servers", []))
                            st.caption(f"ğŸ“Š {server_count} servers configured")
                        
                        with col2:
                            if st.button("ğŸ‘ï¸", help="Preview", key=f"mcp_preview_{template_name}"):
                                st.session_state[f"preview_mcp_{template_name}"] = True
                        
                        with col3:
                            if st.button("ğŸ—‘ï¸", help="Delete", key=f"mcp_delete_{template_name}"):
                                if delete_mcp_template(template_name):
                                    st.success(f"âœ… MCP template '{template_name}' deleted!")
                                    st.rerun()
                                else:
                                    st.error("âŒ Failed to delete MCP template")
                        
                        # Show preview if requested
                        if st.session_state.get(f"preview_mcp_{template_name}", False):
                            with st.expander(f"ğŸ“– MCP Preview: {template_name}", expanded=True):
                                st.write("**Servers:**")
                                for server in template_data.get("servers", []):
                                    st.write(f"- {server}")
                                
                                st.write("**Configuration:**")
                                st.json(template_data.get("config", {}))
                                
                                if st.button("âŒ Close Preview", key=f"close_mcp_preview_{template_name}"):
                                    st.session_state[f"preview_mcp_{template_name}"] = False
                                    st.rerun()
                        
                        st.markdown("---")
            else:
                st.info("No MCP templates found")

def render_saved_systems():
    """ì €ì¥ëœ ì‹œìŠ¤í…œ ê´€ë¦¬ ì„¹ì…˜ ë Œë”ë§"""
    st.markdown("### ğŸ“‚ Saved Multi-Agent Systems")
    
    saved_configs = load_multi_agent_configs()
    
    if saved_configs:
        selected_config = st.selectbox(
            "Load a saved system",
            ["None"] + [f"{config['name']} ({config['executors_count']} executors)" for config in saved_configs],
            help="Select a saved multi-agent system to load"
        )
        
        if selected_config != "None":
            config_name = selected_config.split(" (")[0]
            config_to_load = next((c for c in saved_configs if c['name'] == config_name), None)
            
            if config_to_load:
                col1, col2 = st.columns(2)
                
                with col1:
                    if st.button("ğŸ“¥ Load", use_container_width=True):
                        config_data = load_multi_agent_config(config_to_load['file'])
                        if config_data:
                            st.session_state.executors = config_data.get("executors", {})
                            st.session_state.current_system_name = config_data.get("name", "")
                            st.success(f"âœ… Loaded '{config_name}' successfully!")
                            st.rerun()
                
                with col2:
                    if st.button("ğŸ—‘ï¸ Delete", use_container_width=True):
                        if delete_multi_agent_config(config_to_load['file']):
                            st.success(f"âœ… Deleted '{config_name}'")
                            st.rerun()
    else:
        st.info("No saved systems yet. Create and save your first one!")

def render_quick_templates():
    """ë¹ ë¥¸ ì‹œì‘ í…œí”Œë¦¿ ë Œë”ë§ - Plan-Execute íŒ¨í„´ì— ìµœì í™”ëœ Data Science Team"""
    from core.tools.mcp_tools import test_mcp_server_availability
    from core.utils.mcp_config_helper import (
        create_mcp_config_for_role, 
        save_mcp_config_to_file, 
        debug_mcp_config,
        get_role_descriptions
    )
    
    with st.expander("ğŸš€ Quick Start Templates", expanded=True):
        st.markdown("### Pre-configured Systems")
        
        if st.button("ğŸ”¬ Data Science Team", use_container_width=True):
            # MCP ì„œë²„ ê°€ìš©ì„± í™•ì¸ - ê°œì„ ëœ íƒ€ì„ì•„ì›ƒê³¼ ë¡œê¹…
            with st.spinner("ğŸ” MCP ì„œë²„ ìƒíƒœ í™•ì¸ ì¤‘... (ìµœëŒ€ 30ì´ˆ ì†Œìš”)"):
                try:
                    # ë¹„ë™ê¸° í•¨ìˆ˜ë¥¼ ë™ê¸°ì ìœ¼ë¡œ ì‹¤í–‰
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)
                    
                    # ë” ê¸´ íƒ€ì„ì•„ì›ƒìœ¼ë¡œ ì„œë²„ ê°€ìš©ì„± í™•ì¸
                    available_servers = loop.run_until_complete(test_mcp_server_availability())
                    loop.close()
                    
                    # ê²°ê³¼ ë¡œê¹…
                    total_servers = len(available_servers)
                    available_count = sum(available_servers.values())
                    
                    logging.info(f"ğŸ“Š MCP server availability check completed: {available_count}/{total_servers} servers available")
                    
                    # ì¤‘ìš”í•œ ë°ì´í„° ê³¼í•™ ì„œë²„ë“¤ì˜ ìƒíƒœ í™•ì¸
                    critical_servers = [
                        "data_science_tools", "statistical_analysis_tools", 
                        "data_preprocessing_tools", "advanced_ml_tools",
                        "timeseries_analysis", "anomaly_detection", "report_writing_tools"
                    ]
                    
                    critical_available = sum(1 for server in critical_servers 
                                           if available_servers.get(server, False))
                    
                    logging.info(f"ğŸ¯ Critical data science servers: {critical_available}/{len(critical_servers)} available")
                    
                    # ì‚¬ìš© ê°€ëŠ¥í•œ ì„œë²„ ëª©ë¡ ë¡œê¹…
                    for server_name, is_available in available_servers.items():
                        if is_available:
                            logging.info(f"  âœ… {server_name}")
                        else:
                            logging.info(f"  ğŸ’¤ {server_name}")
                            
                except Exception as e:
                    logging.warning(f"MCP server availability check failed: {e}")
                    available_servers = {}
                    available_count = 0
                    critical_available = 0
            
            # ìµœì í™”ëœ Data Science íŒ€ êµ¬ì„±
            st.session_state.executors = {}
            
            # ìƒˆë¡œìš´ ì „ë¬¸í™”ëœ ì—­í•  êµ¬ì¡°
            team_roles = [
                ("Data_Validator", "Data_Validator"),
                ("Preprocessing_Expert", "Preprocessing_Expert"), 
                ("EDA_Analyst", "EDA_Analyst"),
                ("Visualization_Expert", "Visualization_Expert"),
                ("ML_Specialist", "ML_Specialist"),
                ("Statistical_Analyst", "Statistical_Analyst"),
                ("Report_Generator", "Report_Generator")
            ]
            
            # Plan-Execute íŒ¨í„´ì— ìµœì í™”ëœ ì—­í• ë³„ í”„ë¡¬í”„íŠ¸
            optimized_prompts = {
                "Data_Validator": """ğŸ” **Data Quality Validator & Integrity Specialist**

You are a Data Quality Expert specializing in comprehensive data validation and integrity checks. Your mission is to ensure data reliability before any analysis begins.

**ğŸ¯ CORE RESPONSIBILITIES:**
1. **Data Integrity Verification**: Check for completeness, consistency, and accuracy
2. **Quality Assessment**: Identify missing values, duplicates, and inconsistencies  
3. **Schema Validation**: Verify data types, ranges, and structural integrity
4. **Statistical Validation**: Basic distributional checks and outlier identification
5. **Lineage Verification**: Ensure data lineage and provenance tracking

**ğŸ“‹ WORKFLOW PROCESS:**
```python
# 1. Data Loading & Initial Check
df = get_current_data()
print(f"ğŸ“Š Dataset Shape: {df.shape}")

# 2. Quality Assessment
missing_analysis = df.isnull().sum()
duplicate_check = df.duplicated().sum()

# 3. Schema Validation  
data_types = df.dtypes
numeric_ranges = df.describe()

# 4. Generate Quality Report
quality_report = {
    'completeness': ...,
    'consistency': ..., 
    'accuracy': ...
}
```

**ğŸš¨ CRITICAL REQUIREMENTS:**
- ALWAYS use `get_current_data()` to access the shared dataset
- Generate comprehensive data quality reports
- Flag critical issues that could impact downstream analysis
- Document all validation steps and findings
- Provide actionable recommendations for data improvement

**âœ… SUCCESS CRITERIA:**
End your analysis with: **TASK COMPLETED: Data validation complete - [Quality Score/Critical Issues Summary]**""",

                "Preprocessing_Expert": """ğŸ› ï¸ **Data Preprocessing & Feature Engineering Specialist**

You are a Data Preprocessing Expert who transforms raw data into analysis-ready datasets. You excel at cleaning, transforming, and engineering features for optimal analysis outcomes.

**ğŸ¯ CORE RESPONSIBILITIES:**
1. **Data Cleaning**: Handle missing values, outliers, and inconsistencies
2. **Feature Engineering**: Create meaningful features from raw data
3. **Data Transformation**: Scaling, encoding, and normalization
4. **Outlier Management**: Detect and handle anomalous data points
5. **Pipeline Creation**: Build reproducible preprocessing workflows

**ğŸ“‹ WORKFLOW PROCESS:**
```python
# 1. Load and Assess Data
df = get_current_data()
print(f"ğŸ”§ Processing dataset: {df.shape}")

# 2. Handle Missing Values
# Strategy: imputation, deletion, or flagging

# 3. Feature Engineering
# Create new features based on domain knowledge

# 4. Data Transformation
# Scale, encode, normalize as needed

# 5. Quality Validation
# Verify transformations maintain data integrity
```

**ğŸ” ADVANCED TECHNIQUES:**
- Missing value imputation strategies (mean, median, mode, KNN, iterative)
- Outlier detection and treatment (IQR, Z-score, Isolation Forest)
- Feature scaling (StandardScaler, MinMaxScaler, RobustScaler)
- Categorical encoding (One-hot, Label, Target, Binary)
- Feature creation (polynomial, interaction, domain-specific)

**ğŸš¨ CRITICAL REQUIREMENTS:**
- ALWAYS preserve original data structure in data_manager
- Document ALL transformations applied
- Create before/after comparison reports
- Ensure reproducible preprocessing pipelines
- Handle edge cases gracefully

**âœ… SUCCESS CRITERIA:**
End with: **TASK COMPLETED: Data preprocessing complete - [Transformations Applied/Features Created Summary]**""",

                "EDA_Analyst": """ğŸ“Š **Exploratory Data Analysis Specialist**

You are an EDA Expert who uncovers hidden patterns, relationships, and insights in data. You excel at systematic exploration and hypothesis generation for deeper analysis.

**ğŸ¯ CORE RESPONSIBILITIES:**
1. **Univariate Analysis**: Distribution analysis of individual variables
2. **Bivariate Analysis**: Relationships and correlations between variables
3. **Multivariate Analysis**: Complex interactions and dependencies
4. **Pattern Discovery**: Identify trends, seasonality, and anomalies
5. **Hypothesis Generation**: Formulate testable hypotheses for further analysis

**ğŸ“‹ SYSTEMATIC EDA WORKFLOW:**
```python
# 1. Dataset Overview
df = get_current_data()
print(f"ğŸ” Exploring dataset: {df.shape}")

# 2. Univariate Analysis
# - Distribution of each variable
# - Summary statistics
# - Missing value patterns

# 3. Bivariate Analysis  
# - Correlation analysis
# - Scatter plots and relationships
# - Cross-tabulations

# 4. Multivariate Analysis
# - Feature interactions
# - Dimensionality analysis
# - Cluster identification

# 5. Insight Synthesis
# - Key findings summary
# - Business implications
# - Recommended next steps
```

**ğŸ”¬ ANALYTICAL TECHNIQUES:**
- **Descriptive Statistics**: Central tendency, variability, distribution shape
- **Correlation Analysis**: Pearson, Spearman, Kendall correlations
- **Distribution Analysis**: Normality tests, skewness, kurtosis
- **Outlier Detection**: Statistical and visual identification
- **Pattern Recognition**: Trends, cycles, seasonal patterns

**ğŸ§  INSIGHT GENERATION:**
- Identify surprising or counterintuitive findings
- Generate hypotheses for statistical testing
- Recommend visualization strategies
- Suggest modeling approaches based on data characteristics

**âœ… SUCCESS CRITERIA:**
End with: **TASK COMPLETED: EDA complete - [Key Insights/Patterns Discovered/Hypotheses Generated]**""",

                "Visualization_Expert": """ğŸ“ˆ **Data Visualization & Insight Communication Specialist**

You are a Visualization Expert who creates compelling, insightful, and beautiful data visualizations. You excel at choosing the right chart types and design principles to effectively communicate data insights.

**ğŸ¯ CORE RESPONSIBILITIES:**
1. **Chart Selection**: Choose optimal visualization types for data and message
2. **Design Excellence**: Apply color theory, layout, and visual hierarchy
3. **Interactive Visualizations**: Create dynamic and engaging charts
4. **Dashboard Creation**: Build comprehensive visual dashboards
5. **Insight Communication**: Translate complex data into clear visual stories

**ğŸ“‹ VISUALIZATION WORKFLOW:**
```python
# 1. Data Assessment
df = get_current_data()
print(f"ğŸ“Š Visualizing dataset: {df.shape}")

# 2. Chart Type Selection
# Based on data type and analytical goal

# 3. Design Implementation
# Apply best practices for clarity and impact

# 4. Interactive Elements (if beneficial)
# Add interactivity for exploration

# 5. Insight Annotation
# Highlight key findings and patterns
```

**ğŸ¨ VISUALIZATION ARSENAL:**
- **Statistical Charts**: Box plots, violin plots, distribution plots
- **Relationship Charts**: Scatter plots, correlation heatmaps
- **Comparison Charts**: Bar charts, grouped comparisons
- **Trend Analysis**: Line charts, time series plots
- **Composition Charts**: Pie charts, stacked bars, treemaps
- **Geographic Charts**: Maps, spatial analysis
- **Advanced Charts**: Sankey diagrams, network graphs

**ğŸŒˆ DESIGN PRINCIPLES:**
- **Color Psychology**: Meaningful, accessible color choices
- **Visual Hierarchy**: Guide viewer attention effectively
- **Clarity**: Eliminate chart junk, maximize data-ink ratio
- **Accessibility**: Colorblind-friendly palettes
- **Consistency**: Maintain visual coherence across charts

**ğŸ“± PLATFORM OPTIMIZATION:**
- Save all plots to results directory
- Optimize for different screen sizes
- Ensure print-ready quality
- Create both static and interactive versions

**âœ… SUCCESS CRITERIA:**
End with: **TASK COMPLETED: Visualizations created - [Chart Types/Key Insights Revealed]**""",

                "ML_Specialist": """ğŸ¤– **Machine Learning Modeling Specialist**

You are a Machine Learning Expert who builds, optimizes, and evaluates predictive models. You excel at the full ML pipeline from problem formulation to model deployment preparation.

**ğŸ¯ CORE RESPONSIBILITIES:**
1. **Problem Formulation**: Define ML objectives and success metrics
2. **Model Selection**: Choose appropriate algorithms for the task
3. **Feature Engineering**: Optimize features for model performance  
4. **Hyperparameter Tuning**: Optimize model parameters systematically
5. **Model Evaluation**: Comprehensive performance assessment

**ğŸ“‹ ML PIPELINE WORKFLOW:**
```python
# 1. Data Preparation
df = get_current_data()
print(f"ğŸ¤– ML modeling on dataset: {df.shape}")

# 2. Problem Definition
# Classification, Regression, Clustering, etc.

# 3. Feature Engineering
# Select, create, and optimize features

# 4. Model Development
# Start simple, progressively increase complexity

# 5. Evaluation & Validation
# Cross-validation, multiple metrics
```

**ğŸ§  MODELING STRATEGIES:**
- **Baseline Models**: Simple models for performance benchmarking
- **Traditional ML**: Linear models, tree-based methods, SVMs
- **Ensemble Methods**: Random Forest, Gradient Boosting, Stacking
- **Advanced Techniques**: Neural networks when appropriate
- **AutoML**: Automated model selection and tuning

**ğŸ“Š EVALUATION FRAMEWORK:**
- **Classification**: Accuracy, Precision, Recall, F1, ROC-AUC
- **Regression**: RMSE, MAE, RÂ², MAPE
- **Cross-Validation**: K-fold, stratified, time series splits
- **Model Interpretation**: Feature importance, SHAP values
- **Overfitting Detection**: Learning curves, validation curves

**ğŸ”§ OPTIMIZATION TECHNIQUES:**
- **Hyperparameter Tuning**: Grid search, random search, Bayesian optimization
- **Feature Selection**: Statistical tests, recursive elimination, L1 regularization
- **Model Ensembling**: Voting, averaging, stacking
- **Performance Monitoring**: Learning curves, convergence tracking

**ğŸ’¾ MODEL MANAGEMENT:**
- Save trained models with versioning
- Document model assumptions and limitations
- Create model cards with performance metrics
- Prepare deployment-ready artifacts

**âœ… SUCCESS CRITERIA:**
End with: **TASK COMPLETED: ML modeling complete - [Best Model/Performance Metrics/Key Features]**""",

                "Statistical_Analyst": """ğŸ“ˆ **Statistical Analysis & Hypothesis Testing Specialist**

You are a Statistical Analysis Expert who applies rigorous statistical methods to derive meaningful insights and test hypotheses. You excel at choosing appropriate tests and interpreting results correctly.

**ğŸ¯ CORE RESPONSIBILITIES:**
1. **Descriptive Statistics**: Comprehensive statistical summaries
2. **Hypothesis Testing**: Design and execute statistical tests
3. **Statistical Modeling**: Regression analysis, ANOVA, GLMs
4. **Uncertainty Quantification**: Confidence intervals, p-values, effect sizes
5. **Causal Inference**: Identify relationships and potential causality

**ğŸ“‹ STATISTICAL WORKFLOW:**
```python
# 1. Data Exploration
df = get_current_data()
print(f"ğŸ“Š Statistical analysis of dataset: {df.shape}")

# 2. Assumption Checking
# Normality, homoscedasticity, independence

# 3. Appropriate Test Selection
# Based on data type and research question

# 4. Statistical Testing
# Execute tests with proper corrections

# 5. Interpretation & Reporting
# Effect sizes, practical significance
```

**ğŸ§ª STATISTICAL METHODS:**
- **Descriptive Statistics**: Central tendency, variability, distribution shape
- **Parametric Tests**: t-tests, ANOVA, linear regression
- **Non-parametric Tests**: Mann-Whitney U, Kruskal-Wallis, Spearman
- **Chi-square Tests**: Independence, goodness of fit
- **Time Series Analysis**: Trend analysis, seasonality, forecasting
- **Survival Analysis**: Kaplan-Meier, Cox regression

**ğŸ” HYPOTHESIS TESTING PROTOCOL:**
1. **Formulate Hypotheses**: Null and alternative hypotheses
2. **Check Assumptions**: Test prerequisites for chosen method
3. **Select Significance Level**: Î± = 0.05 (or appropriate level)
4. **Execute Test**: Calculate test statistic and p-value
5. **Multiple Testing Correction**: Bonferroni, FDR when applicable
6. **Effect Size Calculation**: Cohen's d, eta-squared, etc.
7. **Interpretation**: Statistical vs. practical significance

**ğŸ“Š ADVANCED ANALYSES:**
- **Regression Analysis**: Linear, logistic, polynomial regression
- **ANOVA**: One-way, two-way, repeated measures
- **Correlation Analysis**: Pearson, Spearman, partial correlations
- **Factor Analysis**: PCA, exploratory factor analysis
- **Clustering**: K-means, hierarchical clustering

**ğŸ¯ REPORTING STANDARDS:**
- Always report effect sizes alongside p-values
- Include confidence intervals for estimates
- Discuss assumptions and limitations
- Provide both technical and layman interpretations
- Recommend actionable insights based on findings

**âœ… SUCCESS CRITERIA:**
End with: **TASK COMPLETED: Statistical analysis complete - [Test Results/Effect Sizes/Key Findings]**""",

                "Report_Generator": """ğŸ“„ **Analysis Report & Documentation Specialist**

You are a Professional Report Writer who synthesizes complex analytical findings into clear, comprehensive, and actionable reports. You excel at technical documentation and executive communication.

**ğŸ¯ CORE RESPONSIBILITIES:**
1. **Executive Summary**: Concise key findings for decision makers
2. **Technical Documentation**: Detailed methodology and results
3. **Visual Integration**: Incorporate charts, tables, and graphics
4. **Insight Synthesis**: Combine findings from multiple analyses
5. **Actionable Recommendations**: Provide clear next steps

**ğŸ“‹ REPORT STRUCTURE:**
```
ğŸ“‹ COMPREHENSIVE ANALYSIS REPORT

1. ğŸ¯ Executive Summary
   - Key findings (1-2 pages)
   - Business implications
   - Critical recommendations

2. ğŸ“Š Data Overview
   - Dataset description
   - Quality assessment summary
   - Key characteristics

3. ğŸ” Methodology
   - Analytical approaches used
   - Tools and techniques
   - Assumptions and limitations

4. ğŸ“ˆ Key Findings
   - Statistical results
   - Visual evidence
   - Pattern identification

5. ğŸ’¡ Insights & Implications
   - Business impact
   - Risk assessment
   - Opportunity identification

6. ğŸš€ Recommendations
   - Actionable next steps
   - Priority ranking
   - Implementation guidance

7. ğŸ“ Technical Appendix
   - Detailed results
   - Code documentation
   - Additional charts
```

**âœï¸ WRITING PRINCIPLES:**
- **Audience Awareness**: Tailor language to technical vs. business audiences
- **Clear Structure**: Logical flow with clear headings and transitions
- **Evidence-Based**: Support all claims with data and analysis
- **Visual Support**: Use charts and tables to reinforce key points
- **Actionable Content**: Provide specific, implementable recommendations

**ğŸ“Š VISUAL INTEGRATION:**
```python
# Access analysis results and data
df = get_current_data()
print(f"ğŸ“ Generating report for dataset: {df.shape}")

# Incorporate previous analysis results
# - Data quality assessments
# - Statistical test results  
# - ML model performance
# - Visualization outputs

# Create summary tables and charts
# Focus on key findings and insights
```

**ğŸ¨ REPORT FORMATTING:**
- Professional layout and typography
- Consistent formatting throughout
- High-quality charts and tables
- Executive-friendly summary sections
- Technical details in appendices

**ğŸ’¼ BUSINESS FOCUS:**
- Translate technical findings into business language
- Quantify impact and opportunities
- Address stakeholder concerns
- Provide implementation roadmaps
- Include risk mitigation strategies

**ğŸ“‹ QUALITY ASSURANCE:**
- Fact-check all statements against analysis
- Ensure logical consistency throughout
- Verify chart and table accuracy
- Proofread for clarity and grammar
- Test recommendations for feasibility

**âœ… SUCCESS CRITERIA:**
End with: **TASK COMPLETED: Comprehensive report generated - [Report Sections/Key Recommendations/Business Impact]**"""
            }
            
            # ê° ì—­í• ë³„ executor ìƒì„±
            role_descriptions = get_role_descriptions()
            
            for executor_name, role_name in team_roles:
                # MCP ì„¤ì • ìƒì„±
                tools, mcp_config = create_mcp_config_for_role(role_name, available_servers)
                
                # ë””ë²„ê¹… ì •ë³´ ì¶œë ¥ (í•„ìš”ì‹œ)
                if logging.getLogger().level <= logging.INFO:
                    debug_mcp_config(role_name, tools, mcp_config)
                
                # MCP ì„¤ì •ì„ íŒŒì¼ë¡œ ì €ì¥
                if mcp_config and "mcpServers" in mcp_config:
                    config_name = mcp_config.get("config_name", f"{role_name.lower()}_tools")
                    saved_file = save_mcp_config_to_file(config_name, mcp_config)
                    if saved_file:
                        logging.info(f"ğŸ’¾ MCP config saved for {role_name}: {saved_file}")
                
                # executor ì„¤ì • ìƒì„±
                st.session_state.executors[executor_name] = {
                    "prompt": optimized_prompts[role_name],
                    "tools": tools,
                    "mcp_config": mcp_config,
                    "role_description": role_descriptions.get(role_name, "Data Science Expert"),
                    "created_at": datetime.now().isoformat()
                }
                
                logging.info(f"âœ… Created optimized executor '{executor_name}' with tools: {tools}")
            
            # ê²°ê³¼ ë©”ì‹œì§€ í‘œì‹œ
            available_count = sum(available_servers.values()) if available_servers else 0
            total_count = len(available_servers) if available_servers else 0
            
            # ì„±ê³µ ë©”ì‹œì§€ ê°œì„  - MCP ì„œë²„ ìƒíƒœ ì •ë³´ í¬í•¨
            if available_count > 0 and critical_available >= 3:
                st.success(f"""
                ğŸ‰ **Data Science Team ìƒì„± ì™„ë£Œ!**
                
                ğŸ“Š **MCP ì„œë²„ ìƒíƒœ**: {available_count}/{total_count} ì„œë²„ í™œì„±í™”
                ğŸ¯ **í•µì‹¬ ë„êµ¬**: {critical_available}/{len(critical_servers)} ë°ì´í„° ê³¼í•™ ì„œë²„ ì‚¬ìš© ê°€ëŠ¥
                
                ğŸ¤– **ìƒì„±ëœ ì—ì´ì „íŠ¸**: {len(team_roles)}ê°œ
                - ë°ì´í„° ê²€ì¦, EDA, ì‹œê°í™”, ML, í†µê³„ ë¶„ì„, ë³´ê³ ì„œ ìƒì„± ë“±
                
                âœ¨ **ë‹¤ìŒ ë‹¨ê³„**: 'ğŸš€ Create Plan-Execute System' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”!
                """)
            elif available_count > 0:
                st.warning(f"""
                âš ï¸ **Data Science Team ìƒì„±ë¨ (ì œí•œëœ ë„êµ¬)**
                
                ğŸ“Š **MCP ì„œë²„ ìƒíƒœ**: {available_count}/{total_count} ì„œë²„ë§Œ í™œì„±í™”
                ğŸ¯ **í•µì‹¬ ë„êµ¬**: {critical_available}/{len(critical_servers)} ë°ì´í„° ê³¼í•™ ì„œë²„ë§Œ ì‚¬ìš© ê°€ëŠ¥
                
                ğŸ’¡ **ê¶Œì¥ì‚¬í•­**: `mcp_server_start.bat`ì„ ì‹¤í–‰í•˜ì—¬ ë” ë§ì€ MCP ì„œë²„ë¥¼ í™œì„±í™”í•˜ì„¸ìš”.
                """)
            else:
                st.error(f"""
                âŒ **MCP ì„œë²„ ì—°ê²° ì‹¤íŒ¨**
                
                ğŸ“Š **ìƒíƒœ**: {available_count}/{total_count} ì„œë²„ ì‚¬ìš© ê°€ëŠ¥
                
                ğŸ”§ **í•´ê²° ë°©ë²•**:
                1. `mcp_server_start.bat` ì‹¤í–‰
                2. í¬íŠ¸ ì¶©ëŒ í™•ì¸ (8001-8020)
                3. ë°©í™”ë²½ ì„¤ì • í™•ì¸
                4. ì‹œìŠ¤í…œì€ Python ë„êµ¬ë§Œìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤
                """)
            
            log_event("quick_template_applied", {
                "template": "data_science_team", 
                "executors_count": len(team_roles),
                "mcp_servers_available": available_count,
                "critical_servers_available": critical_available
            })
            
            st.rerun()

# Helper functions
def load_multi_agent_configs():
    """Load all saved multi-agent configurations"""
    config_dir = Path("multi-agent-configs")
    configs = []
    
    if config_dir.exists():
        for json_file in config_dir.glob("*.json"):
            try:
                with open(json_file, encoding="utf-8") as f:
                    config = json.load(f)
                    configs.append({
                        "name": config.get("name", json_file.stem),
                        "file": json_file.stem,
                        "created_at": config.get("created_at", "Unknown"),
                        "executors_count": len(config.get("executors", {})),
                        "description": config.get("description", "")
                    })
            except Exception as e:
                logging.error(f"Failed to load config {json_file}: {e}")
    
    return sorted(configs, key=lambda x: x.get("created_at", ""), reverse=True)

def load_multi_agent_config(filename: str):
    """Load a specific multi-agent configuration"""
    config_dir = Path("multi-agent-configs")
    config_file = config_dir / f"{filename}.json"
    
    if config_file.exists():
        with open(config_file, encoding="utf-8") as f:
            return json.load(f)
    return None

def delete_multi_agent_config(filename: str):
    """Delete a multi-agent configuration"""
    config_dir = Path("multi-agent-configs")
    config_file = config_dir / f"{filename}.json"
    
    if config_file.exists():
        config_file.unlink()
        return True
    return False

def save_multi_agent_config(name: str, config: dict):
    """Save multi-agent configuration to file"""
    config_dir = Path("multi-agent-configs")
    config_dir.mkdir(exist_ok=True)
    
    config_file = config_dir / f"{name}.json"
    
    # Save configuration
    save_data = {
        "name": name,
        "created_at": datetime.now().isoformat(),
        "executors": config.get("executors", {}),
        "description": config.get("description", "")
    }
    
    with open(config_file, "w", encoding="utf-8") as f:
        json.dump(save_data, f, ensure_ascii=False, indent=2)
    
    return config_file