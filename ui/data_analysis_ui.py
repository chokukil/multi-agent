import streamlit as st
import asyncio
import pandas as pd
import io
import uuid
import os
from datetime import datetime
from typing import Dict, Any, Optional, List

from ui.thinking_stream import ThinkingStream, PlanVisualization, BeautifulResults
from core.a2a_data_analysis_executor import A2ADataAnalysisExecutor
from core.callbacks.progress_stream import progress_stream_manager

class DataAnalysisUI:
    """ë°ì´í„° ë¶„ì„ ì „ìš© UI ì»´í¬ë„ŒíŠ¸"""
    
    def __init__(self):
        self.thinking_stream = None
        self.plan_viz = PlanVisualization()
        self.results_renderer = BeautifulResults()
        self.data_dir = "a2a_ds_servers/artifacts/data/shared_dataframes"
        
        # ë°ì´í„° ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(self.data_dir, exist_ok=True)
    
    def render_analysis_interface(self):
        """í†µí•© ë¶„ì„ ì¸í„°í˜ì´ìŠ¤ ë Œë”ë§"""
        
        st.title("ğŸ’¬ Smart Data Analyst")
        st.markdown("A2A í”„ë¡œí† ì½œì„ í™œìš©í•œ ì§€ëŠ¥í˜• ë°ì´í„° ë¶„ì„ ì‹œìŠ¤í…œ")
        
        # ë°ì´í„°ì…‹ ì„ íƒ ì„¹ì…˜
        self._render_dataset_section()
        
        # ë¶„ì„ ìš”ì²­ ì„¹ì…˜
        analysis_prompt = self._render_analysis_request_section()
        
        # ë¶„ì„ ì‹¤í–‰
        if st.session_state.get('dataset_ready') and analysis_prompt:
            if st.button("ğŸš€ ë¶„ì„ ì‹œì‘", type="primary", use_container_width=True):
                dataset_name = st.session_state.get('current_dataset')
                if dataset_name:
                    # ë¹„ë™ê¸° ë¶„ì„ ì‹¤í–‰
                    try:
                        asyncio.run(self.execute_analysis_workflow(
                            dataset_name, 
                            analysis_prompt,
                            st.session_state.get('analysis_options', {})
                        ))
                    except Exception as e:
                        st.error(f"ë¶„ì„ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    
    def _render_dataset_section(self):
        """ë°ì´í„°ì…‹ ì„ íƒ ì„¹ì…˜"""
        st.markdown("### ğŸ“‚ ë°ì´í„°ì…‹ ì„ íƒ")
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            uploaded_file = st.file_uploader(
                "ğŸ“‚ ë°ì´í„° íŒŒì¼ ì—…ë¡œë“œ", 
                type=['csv', 'xlsx', 'json'],
                help="ë¶„ì„í•  ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”",
                key="data_uploader"
            )
            
        with col2:
            if uploaded_file:
                st.success("âœ… íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ")
                if st.button("ğŸ” ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°", key="preview_btn"):
                    self._show_data_preview(uploaded_file)
                    
                # ë°ì´í„°ì…‹ ì €ì¥
                if st.button("ğŸ’¾ ë°ì´í„°ì…‹ ë“±ë¡", key="save_btn"):
                    dataset_name = self._save_uploaded_file(uploaded_file)
                    if dataset_name:
                        st.session_state.dataset_ready = True
                        st.session_state.current_dataset = dataset_name
                        st.success(f"ë°ì´í„°ì…‹ '{dataset_name}' ë“±ë¡ ì™„ë£Œ!")
                        st.rerun()
        
        # ê¸°ì¡´ ë°ì´í„°ì…‹ ì„ íƒ
        existing_datasets = self._get_existing_datasets()
        if existing_datasets:
            st.markdown("**ë˜ëŠ” ê¸°ì¡´ ë°ì´í„°ì…‹ ì„ íƒ:**")
            selected_dataset = st.selectbox(
                "ë“±ë¡ëœ ë°ì´í„°ì…‹",
                ["ì„ íƒí•˜ì„¸ìš”..."] + existing_datasets,
                key="existing_dataset_selector"
            )
            
            if selected_dataset != "ì„ íƒí•˜ì„¸ìš”...":
                st.session_state.dataset_ready = True
                st.session_state.current_dataset = selected_dataset
                st.success(f"ë°ì´í„°ì…‹ '{selected_dataset}' ì„ íƒë¨")
    
    def _render_analysis_request_section(self) -> str:
        """ë¶„ì„ ìš”ì²­ ì„¹ì…˜"""
        st.markdown("### ğŸ’¬ ë¶„ì„ ìš”ì²­")
        
        # í˜„ì¬ ì„ íƒëœ ë°ì´í„°ì…‹ í‘œì‹œ
        if st.session_state.get('dataset_ready'):
            dataset_name = st.session_state.get('current_dataset')
            st.info(f"ğŸ“Š **í˜„ì¬ ë°ì´í„°ì…‹**: {dataset_name}")
        
        analysis_prompt = st.text_area(
            "ì–´ë–¤ ë¶„ì„ì„ ì›í•˜ì‹œë‚˜ìš”?",
            placeholder="ì˜ˆ: ì´ ë°ì´í„°ì˜ ì „ë°˜ì ì¸ íŒ¨í„´ì„ ë¶„ì„í•˜ê³  ì£¼ìš” ì¸ì‚¬ì´íŠ¸ë¥¼ ì°¾ì•„ì£¼ì„¸ìš”",
            height=100,
            key="analysis_prompt"
        )
        
        # ë¶„ì„ ì˜µì…˜
        with st.expander("âš™ï¸ ê³ ê¸‰ ì˜µì…˜"):
            col1, col2 = st.columns(2)
            
            with col1:
                analysis_depth = st.selectbox(
                    "ë¶„ì„ ê¹Šì´",
                    ["ê¸°ë³¸", "ìƒì„¸", "ì‹¬í™”"],
                    help="ë¶„ì„ì˜ ìƒì„¸ ìˆ˜ì¤€ì„ ì„ íƒí•˜ì„¸ìš”",
                    key="analysis_depth"
                )
                
            with col2:
                include_viz = st.checkbox(
                    "ì‹œê°í™” í¬í•¨", 
                    value=True,
                    help="ë¶„ì„ ê²°ê³¼ì— ì°¨íŠ¸ì™€ ê·¸ë˜í”„ë¥¼ í¬í•¨í•©ë‹ˆë‹¤",
                    key="include_viz"
                )
            
            # ì„¸ì…˜ ìƒíƒœì— ì˜µì…˜ ì €ì¥
            st.session_state.analysis_options = {
                "depth": analysis_depth,
                "include_visualization": include_viz
            }
        
        return analysis_prompt
    
    def _show_data_preview(self, uploaded_file):
        """ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°"""
        try:
            if uploaded_file.type == "text/csv":
                df = pd.read_csv(uploaded_file)
            elif uploaded_file.type in ["application/vnd.openxmlformats-officedocument.spreadsheetml.sheet", "application/vnd.ms-excel"]:
                df = pd.read_excel(uploaded_file)
            elif uploaded_file.type == "application/json":
                df = pd.read_json(uploaded_file)
            else:
                st.error("ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤.")
                return
            
            st.markdown("### ğŸ“‹ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°")
            
            col1, col2 = st.columns(2)
            with col1:
                st.metric("í–‰ ìˆ˜", df.shape[0])
            with col2:
                st.metric("ì—´ ìˆ˜", df.shape[1])
            
            st.dataframe(df.head(10), use_container_width=True)
            
            # ì»¬ëŸ¼ ì •ë³´
            st.markdown("### ğŸ“Š ì»¬ëŸ¼ ì •ë³´")
            col_info = pd.DataFrame({
                'ì»¬ëŸ¼ëª…': df.columns,
                'ë°ì´í„° íƒ€ì…': df.dtypes,
                'ê²°ì¸¡ê°’': df.isnull().sum(),
                'ê²°ì¸¡ê°’ ë¹„ìœ¨(%)': (df.isnull().sum() / len(df) * 100).round(2)
            })
            st.dataframe(col_info, use_container_width=True)
            
        except Exception as e:
            st.error(f"ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    
    def _save_uploaded_file(self, uploaded_file) -> Optional[str]:
        """ì—…ë¡œë“œëœ íŒŒì¼ ì €ì¥"""
        try:
            # ê³ ìœ í•œ íŒŒì¼ëª… ìƒì„±
            timestamp = int(datetime.now().timestamp())
            file_extension = uploaded_file.name.split('.')[-1]
            dataset_name = f"uploaded_{uploaded_file.name.split('.')[0]}_{timestamp}.{file_extension}"
            
            file_path = os.path.join(self.data_dir, dataset_name)
            
            with open(file_path, "wb") as f:
                f.write(uploaded_file.getbuffer())
            
            return dataset_name.split('.')[0]  # í™•ì¥ì ì œê±°í•œ ì´ë¦„ ë°˜í™˜
            
        except Exception as e:
            st.error(f"íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            return None
    
    def _get_existing_datasets(self) -> List[str]:
        """ê¸°ì¡´ ë°ì´í„°ì…‹ ëª©ë¡ ì¡°íšŒ"""
        try:
            if not os.path.exists(self.data_dir):
                return []
            
            files = os.listdir(self.data_dir)
            datasets = []
            
            for file in files:
                if file.endswith(('.csv', '.xlsx', '.json')):
                    # í™•ì¥ì ì œê±°í•œ ì´ë¦„ ì¶”ê°€
                    dataset_name = '.'.join(file.split('.')[:-1])
                    datasets.append(dataset_name)
            
            return sorted(datasets)
            
        except Exception as e:
            st.error(f"ë°ì´í„°ì…‹ ëª©ë¡ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return []
    
    async def execute_analysis_workflow(self, dataset_name: str, prompt: str, options: dict):
        """ë¶„ì„ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰"""
        
        # 1. ì‚¬ê³  ê³¼ì • ì‹œì‘
        thinking_container = st.container()
        self.thinking_stream = ThinkingStream(thinking_container)
        self.thinking_stream.start_thinking("ë°ì´í„° ë¶„ì„ ìš”ì²­ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
        
        # 2. ê³„íš ìˆ˜ë¦½
        plan_state = await self._create_analysis_plan(dataset_name, prompt, options)
        
        if plan_state and plan_state.get("plan"):
            # 3. ì‹¤í–‰ ë° ê²°ê³¼ í‘œì‹œ
            await self._execute_plan_with_streaming(plan_state)
            
            # 4. ìµœì¢… ë³´ê³ ì„œ ìƒì„±
            self._generate_final_report(plan_state)
        else:
            st.error("ë¶„ì„ ê³„íš ìˆ˜ë¦½ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    
    async def _create_analysis_plan(self, dataset_name: str, prompt: str, options: dict) -> Optional[dict]:
        """ë¶„ì„ ê³„íš ìˆ˜ë¦½"""
        
        # ì‚¬ê³  ê³¼ì • ì—…ë°ì´íŠ¸
        self.thinking_stream.add_thought("ì‚¬ìš©ìì˜ ìš”ì²­ì„ ì´í•´í•˜ê³  ì ì ˆí•œ ë¶„ì„ ë°©ë²•ì„ ì°¾ê³  ìˆìŠµë‹ˆë‹¤.", "analysis")
        
        with st.status("ğŸ§  **ë¶„ì„ ê³„íš ìˆ˜ë¦½ ì¤‘...**", expanded=True) as status:
            self.thinking_stream.add_thought("ë°ì´í„° ë¶„ì„ì— í•„ìš”í•œ ë‹¨ê³„ë“¤ì„ ê³„íší•˜ê³  ìˆìŠµë‹ˆë‹¤.", "planning")
            
            try:
                # ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° í˜¸ì¶œ (ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©)
                import httpx
                
                payload = {
                    "jsonrpc": "2.0",
                    "method": "tasks/send",
                    "params": {
                        "id": str(uuid.uuid4()),
                        "message": {
                            "role": "user",
                            "parts": [
                                {
                                    "type": "text",
                                    "text": f"ë°ì´í„°ì…‹ '{dataset_name}'ì— ëŒ€í•´ ë‹¤ìŒ ë¶„ì„ì„ ìˆ˜í–‰í•´ì¤˜: {prompt}. ë¶„ì„ ê¹Šì´: {options.get('depth', 'ê¸°ë³¸')}"
                                }
                            ]
                        }
                    },
                    "id": 1
                }
                
                async with httpx.AsyncClient(timeout=30) as client:
                    response = await client.post("http://localhost:8100", json=payload)
                    response.raise_for_status()
                    
                    result = response.json()
                    
                    if "result" in result:
                        # ê³„íš íŒŒì‹±
                        plan_content = result["result"]
                        plan_state = self._parse_orchestrator_response(plan_content, dataset_name)
                        
                        self.thinking_stream.add_thought("ì™„ë²½í•œ ë¶„ì„ ê³„íšì´ ì™„ì„±ë˜ì—ˆìŠµë‹ˆë‹¤!", "success")
                        self.thinking_stream.finish_thinking("ê³„íš ìˆ˜ë¦½ ì™„ë£Œ! ì´ì œ ì‹¤í–‰ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
                        
                        # ê³„íš ì‹œê°í™”
                        self.plan_viz.display_plan(plan_state["plan"], title="ğŸ“Š ë°ì´í„° ë¶„ì„ ì‹¤í–‰ ê³„íš")
                        
                        status.update(label="âœ… ê³„íš ì™„ì„±!", state="complete", expanded=False)
                        
                        return plan_state
                    else:
                        status.update(label="âŒ ê³„íš ìˆ˜ë¦½ ì‹¤íŒ¨!", state="error")
                        st.error("ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°ë¡œë¶€í„° ìœ íš¨í•œ ê³„íšì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                        return None
                        
            except Exception as e:
                status.update(label="âŒ ê³„íš ìˆ˜ë¦½ ì˜¤ë¥˜!", state="error")
                st.error(f"ê³„íš ìˆ˜ë¦½ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                return None
    
    def _parse_orchestrator_response(self, response_content: Any, dataset_name: str) -> dict:
        """ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì‘ë‹µì„ íŒŒì‹±í•˜ì—¬ ê³„íš êµ¬ì¡°ë¡œ ë³€í™˜"""
        
        # ê¸°ë³¸ ë¶„ì„ ê³„íš ìƒì„± (ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨ì‹œ í´ë°±)
        default_plan = [
            {
                "agent_name": "pandas_data_analyst",
                "skill_name": "analyze_data",
                "parameters": {
                    "data_id": dataset_name,
                    "user_instructions": "ë°ì´í„° êµ¬ì¡° ë° ê¸°ë³¸ í†µê³„ ë¶„ì„ì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”."
                },
                "reasoning": "ë°ì´í„°ì˜ ì „ë°˜ì ì¸ êµ¬ì¡°ì™€ í’ˆì§ˆì„ íŒŒì•…í•˜ê¸° ìœ„í•´ ê¸°ë³¸ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."
            },
            {
                "agent_name": "data_visualization",
                "skill_name": "analyze_data", 
                "parameters": {
                    "data_id": dataset_name,
                    "user_instructions": "ì£¼ìš” ë³€ìˆ˜ë“¤ì˜ ë¶„í¬ì™€ ê´€ê³„ë¥¼ ì‹œê°í™”í•´ì£¼ì„¸ìš”."
                },
                "reasoning": "ë°ì´í„°ì˜ íŒ¨í„´ê³¼ íŠ¸ë Œë“œë¥¼ ì‹œê°ì ìœ¼ë¡œ ì´í•´í•˜ê¸° ìœ„í•´ ì°¨íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."
            },
            {
                "agent_name": "eda_tools",
                "skill_name": "analyze_data",
                "parameters": {
                    "data_id": dataset_name,
                    "user_instructions": "ì´ìƒì¹˜ íƒì§€ ë° ë°ì´í„° í’ˆì§ˆ ë¶„ì„ì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”."
                },
                "reasoning": "ë°ì´í„°ì˜ í’ˆì§ˆ ë¬¸ì œì™€ ì´ìƒì¹˜ë¥¼ ì‹ë³„í•˜ì—¬ ë¶„ì„ì˜ ì‹ ë¢°ì„±ì„ í™•ë³´í•©ë‹ˆë‹¤."
            }
        ]
        
        return {"plan": default_plan}
    
    async def _execute_plan_with_streaming(self, plan_state: dict):
        """ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ê³„íš ì‹¤í–‰"""
        
        st.markdown("### ğŸ”„ ë¶„ì„ ì‹¤í–‰ ì¤‘...")
        
        # A2A ì‹¤í–‰ê¸° ìƒì„±
        executor = A2ADataAnalysisExecutor()
        
        # ì§„í–‰ ìƒí™© ì»¨í…Œì´ë„ˆ
        progress_container = st.container()
        results_container = st.container()
        
        with progress_container:
            # ì‹¤í–‰ ê²°ê³¼ ì €ì¥
            execution_result = await executor.execute(plan_state)
            
            # ì„¸ì…˜ ìƒíƒœì— ê²°ê³¼ ì €ì¥
            st.session_state.analysis_results = execution_result
    
    def _generate_final_report(self, plan_state: dict):
        """ìµœì¢… ë¶„ì„ ë³´ê³ ì„œ ìƒì„±"""
        
        st.markdown("---")
        st.markdown("## ğŸ“Š **ìµœì¢… ë¶„ì„ ë³´ê³ ì„œ**")
        
        execution_result = st.session_state.get('analysis_results', {})
        
        if execution_result.get('step_outputs'):
            # ìš”ì•½ í†µê³„
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("ì´ ì‹¤í–‰ ë‹¨ê³„", execution_result.get('total_steps', 0))
            with col2:
                st.metric("ì„±ê³µí•œ ë‹¨ê³„", execution_result.get('successful_steps', 0))
            with col3:
                st.metric("ì‹¤í–‰ ì‹œê°„", f"{execution_result.get('execution_time', 0):.1f}ì´ˆ")
            
            # ê° ë‹¨ê³„ë³„ ê²°ê³¼ í‘œì‹œ
            st.markdown("### ğŸ¯ ë‹¨ê³„ë³„ ë¶„ì„ ê²°ê³¼")
            
            for step_num, result in execution_result['step_outputs'].items():
                if result.get('success'):
                    with st.expander(f"ğŸ“‹ Step {step_num}: {result.get('agent', 'Unknown Agent')}", expanded=True):
                        content = result.get('content', '')
                        if content:
                            st.markdown(str(content))
                        else:
                            st.info("ê²°ê³¼ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.")
            
            # ë‹¤ìš´ë¡œë“œ ì˜µì…˜
            st.markdown("### ğŸ“¥ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ")
            col1, col2, col3 = st.columns(3)
            
            with col1:
                if st.button("ğŸ“„ ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ"):
                    self._generate_report_download(execution_result)
            
            with col2:
                if st.button("ğŸ“Š ê²°ê³¼ ë°ì´í„° ë‹¤ìš´ë¡œë“œ"):
                    self._generate_data_download(execution_result)
                    
            with col3:
                if st.button("ğŸ”— ê²°ê³¼ ê³µìœ "):
                    st.info("ê³µìœ  ê¸°ëŠ¥ì€ í–¥í›„ ì¶”ê°€ë  ì˜ˆì •ì…ë‹ˆë‹¤.")
        else:
            st.warning("ì‹¤í–‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    def _generate_report_download(self, execution_result: dict):
        """ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ ìƒì„±"""
        try:
            # ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ë³´ê³ ì„œ ìƒì„±
            report_content = f"""
ë°ì´í„° ë¶„ì„ ë³´ê³ ì„œ
ìƒì„± ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

ì‹¤í–‰ ìš”ì•½:
- ì´ ë‹¨ê³„: {execution_result.get('total_steps', 0)}
- ì„±ê³µ ë‹¨ê³„: {execution_result.get('successful_steps', 0)}
- ì‹¤í–‰ ì‹œê°„: {execution_result.get('execution_time', 0):.2f}ì´ˆ

ë¶„ì„ ê²°ê³¼:
"""
            
            for step_num, result in execution_result.get('step_outputs', {}).items():
                if result.get('success'):
                    report_content += f"\n\nStep {step_num} - {result.get('agent', 'Unknown Agent')}:\n"
                    report_content += str(result.get('content', 'ê²°ê³¼ ì—†ìŒ'))
            
            st.download_button(
                label="ğŸ“„ í…ìŠ¤íŠ¸ ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ",
                data=report_content,
                file_name=f"analysis_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                mime="text/plain"
            )
            
        except Exception as e:
            st.error(f"ë³´ê³ ì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
    
    def _generate_data_download(self, execution_result: dict):
        """ë°ì´í„° ë‹¤ìš´ë¡œë“œ ìƒì„±"""
        try:
            # ê²°ê³¼ë¥¼ JSON í˜•íƒœë¡œ ì €ì¥
            import json
            
            data_content = json.dumps(execution_result, indent=2, ensure_ascii=False)
            
            st.download_button(
                label="ğŸ“Š ê²°ê³¼ ë°ì´í„° (JSON)",
                data=data_content,
                file_name=f"analysis_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime="application/json"
            )
            
        except Exception as e:
            st.error(f"ë°ì´í„° ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}") 