#!/usr/bin/env python3
"""
Transparency Dashboard UI Component
ì‹¤ì‹œê°„ ë©€í‹°ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ íˆ¬ëª…ì„± ë¶„ì„ ëŒ€ì‹œë³´ë“œ
"""

import streamlit as st
import plotly.graph_objects as go
import plotly.express as px
import pandas as pd
import json
from typing import Dict, List, Any, Optional
import time
from datetime import datetime, timedelta
import numpy as np

# ìµœì‹  ì—°êµ¬ ê¸°ë°˜ ì»´í¬ë„ŒíŠ¸ import
try:
    from core.enhanced_tracing_system import (
        enhanced_tracer, ComponentSynergyScore, ToolUtilizationEfficacy,
        TraceLevel, IssueType
    )
    TRACING_AVAILABLE = True
except ImportError:
    TRACING_AVAILABLE = False

class TransparencyDashboard:
    """íˆ¬ëª…ì„± ë¶„ì„ ëŒ€ì‹œë³´ë“œ"""
    
    def __init__(self):
        self.dashboard_id = "transparency_dashboard"
        
    def render_comprehensive_analysis(self, 
                                    trace_analysis: Dict[str, Any],
                                    agent_results: List[Dict[str, Any]],
                                    query_info: Dict[str, Any]) -> None:
        """ì¢…í•© íˆ¬ëª…ì„± ë¶„ì„ ë Œë”ë§"""
        
        st.markdown("## ğŸ” **ë©€í‹°ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ íˆ¬ëª…ì„± ë¶„ì„**")
        
        # í•µì‹¬ íˆ¬ëª…ì„± ì§€í‘œ ìš”ì•½
        self._render_transparency_metrics_summary(trace_analysis)
        
        # íƒ­ êµ¬ì„±
        tab1, tab2, tab3, tab4, tab5 = st.tabs([
            "ğŸ¯ ë¶„ì„ í’ˆì§ˆ", "ğŸ¤ ì—ì´ì „íŠ¸ í˜‘ì—…", "ğŸ”§ ë„êµ¬ íš¨ìœ¨ì„±", 
            "ğŸ“Š ì‹¤í–‰ í”Œë¡œìš°", "ğŸ” ìƒì„¸ ì¶”ì "
        ])
        
        with tab1:
            self._render_analysis_quality_tab(trace_analysis, agent_results, query_info)
            
        with tab2:
            self._render_agent_collaboration_tab(trace_analysis)
            
        with tab3:
            self._render_tool_efficiency_tab(trace_analysis)
            
        with tab4:
            self._render_execution_flow_tab(trace_analysis)
            
        with tab5:
            self._render_detailed_tracing_tab(trace_analysis)
    
    def _render_transparency_metrics_summary(self, trace_analysis: Dict[str, Any]) -> None:
        """íˆ¬ëª…ì„± ì§€í‘œ ìš”ì•½ ë Œë”ë§"""
        
        st.markdown("### ğŸ“Š **í•µì‹¬ íˆ¬ëª…ì„± ì§€í‘œ**")
        
        col1, col2, col3, col4 = st.columns(4)
        
        transparency_metrics = trace_analysis.get("transparency_metrics", {})
        css_metrics = transparency_metrics.get("component_synergy_score", {})
        tue_metrics = transparency_metrics.get("tool_utilization_efficacy", {})
        
        with col1:
            css_score = css_metrics.get("css", 0.0)
            st.metric(
                "ğŸ¤ í˜‘ì—… í’ˆì§ˆ (CSS)",
                f"{css_score:.1%}",
                delta=f"{css_score - 0.75:.1%}" if css_score > 0.75 else None,
                help="Component Synergy Score - ì—ì´ì „íŠ¸ ê°„ í˜‘ì—… í’ˆì§ˆ ì§€í‘œ"
            )
            
        with col2:
            tue_score = tue_metrics.get("tue", 0.0)
            st.metric(
                "ğŸ”§ ë„êµ¬ íš¨ìœ¨ì„± (TUE)",
                f"{tue_score:.1%}",
                delta=f"{tue_score - 0.8:.1%}" if tue_score > 0.8 else None,
                help="Tool Utilization Efficacy - ë„êµ¬ ì‚¬ìš© íš¨ìœ¨ì„± ì§€í‘œ"
            )
            
        with col3:
            success_rate = trace_analysis.get("summary", {}).get("success_rate", 0.0)
            st.metric(
                "âœ… ì„±ê³µë¥ ",
                f"{success_rate:.1%}",
                delta=f"{success_rate - 0.9:.1%}" if success_rate > 0.9 else None,
                help="ì „ì²´ ì‹¤í–‰ ë‹¨ê³„ ì„±ê³µë¥ "
            )
            
        with col4:
            issues_detected = transparency_metrics.get("issues_detected", 0)
            st.metric(
                "âš ï¸ ì´ìŠˆ ê°ì§€",
                f"{issues_detected}ê°œ",
                delta=f"-{issues_detected}" if issues_detected == 0 else None,
                help="TRAIL í”„ë ˆì„ì›Œí¬ ê¸°ë°˜ ì´ìŠˆ ê°ì§€ ìˆ˜"
            )
        
        # ì‹¤ì‹œê°„ íˆ¬ëª…ì„± ê²Œì´ì§€
        self._render_transparency_gauge(css_score, tue_score, success_rate)
    
    def _render_transparency_gauge(self, css_score: float, tue_score: float, success_rate: float) -> None:
        """íˆ¬ëª…ì„± ì¢…í•© ê²Œì´ì§€ ì°¨íŠ¸"""
        
        # ì¢…í•© íˆ¬ëª…ì„± ì ìˆ˜ ê³„ì‚°
        transparency_score = (css_score * 0.3 + tue_score * 0.3 + success_rate * 0.4)
        
        fig = go.Figure(go.Indicator(
            mode = "gauge+number+delta",
            value = transparency_score * 100,
            domain = {'x': [0, 1], 'y': [0, 1]},
            title = {'text': "ğŸ” ì¢…í•© íˆ¬ëª…ì„± ì ìˆ˜"},
            delta = {'reference': 85, 'increasing': {'color': "RebeccaPurple"}},
            gauge = {
                'axis': {'range': [None, 100]},
                'bar': {'color': "darkblue"},
                'steps': [
                    {'range': [0, 60], 'color': "lightgray"},
                    {'range': [60, 80], 'color': "yellow"},
                    {'range': [80, 100], 'color': "lightgreen"}
                ],
                'threshold': {
                    'line': {'color': "red", 'width': 4},
                    'thickness': 0.75,
                    'value': 90
                }
            }
        ))
        
        fig.update_layout(
            height=300,
            margin=dict(l=20, r=20, t=60, b=20),
            font={'color': "darkblue", 'family': "Arial"}
        )
        
        st.plotly_chart(fig, use_container_width=True)
    
    def _render_analysis_quality_tab(self, 
                                   trace_analysis: Dict[str, Any],
                                   agent_results: List[Dict[str, Any]],
                                   query_info: Dict[str, Any]) -> None:
        """ë¶„ì„ í’ˆì§ˆ íƒ­ ë Œë”ë§"""
        
        st.markdown("### ğŸ¯ **ë¶„ì„ í’ˆì§ˆ í‰ê°€**")
        
        # ì¿¼ë¦¬ ë³µì¡ë„ ë¶„ì„
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("#### ğŸ“ **ì¿¼ë¦¬ íŠ¹ì„± ë¶„ì„**")
            
            query_text = query_info.get("original_query", "")
            query_complexity = self._calculate_query_complexity(query_text)
            
            complexity_data = {
                "ì§€í‘œ": ["ë¬¸ì ìˆ˜", "ì „ë¬¸ ìš©ì–´", "ë³µì¡í•œ êµ¬ì¡°", "ë„ë©”ì¸ ê¹Šì´"],
                "ì ìˆ˜": [
                    min(len(query_text) / 100, 1.0),
                    query_complexity.get("technical_terms", 0.5),
                    query_complexity.get("structural_complexity", 0.6),
                    query_complexity.get("domain_depth", 0.7)
                ]
            }
            
            df_complexity = pd.DataFrame(complexity_data)
            
            fig_radar = go.Figure()
            fig_radar.add_trace(go.Scatterpolar(
                r=df_complexity["ì ìˆ˜"],
                theta=df_complexity["ì§€í‘œ"],
                fill='toself',
                name='ì¿¼ë¦¬ ë³µì¡ë„'
            ))
            
            fig_radar.update_layout(
                polar=dict(
                    radialaxis=dict(
                        visible=True,
                        range=[0, 1]
                    )),
                showlegend=True,
                height=300
            )
            
            st.plotly_chart(fig_radar, use_container_width=True)
        
        with col2:
            st.markdown("#### ğŸ§  **ì—ì´ì „íŠ¸ ì„±ëŠ¥ ë¶„ì„**")
            
            agent_performance = trace_analysis.get("agent_performance", {})
            
            if agent_performance:
                performance_data = []
                for agent_id, perf in agent_performance.items():
                    error_rate = perf["errors"] / max(perf["spans"], 1)
                    avg_duration = perf["duration"] / max(perf["spans"], 1)
                    
                    performance_data.append({
                        "ì—ì´ì „íŠ¸": agent_id.replace("_", " ").title(),
                        "ì˜¤ë¥˜ìœ¨": error_rate,
                        "í‰ê·  ì‘ë‹µì‹œê°„": avg_duration,
                        "ì‘ì—… ìˆ˜": perf["spans"]
                    })
                
                df_performance = pd.DataFrame(performance_data)
                
                fig_scatter = px.scatter(
                    df_performance, 
                    x="í‰ê·  ì‘ë‹µì‹œê°„", 
                    y="ì˜¤ë¥˜ìœ¨",
                    size="ì‘ì—… ìˆ˜",
                    hover_name="ì—ì´ì „íŠ¸",
                    title="ì—ì´ì „íŠ¸ ì„±ëŠ¥ ë§¤íŠ¸ë¦­ìŠ¤"
                )
                
                st.plotly_chart(fig_scatter, use_container_width=True)
            else:
                st.info("ì—ì´ì „íŠ¸ ì„±ëŠ¥ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        # ê²°ê³¼ í’ˆì§ˆ ë¶„ì„
        st.markdown("#### ğŸ“ˆ **ê²°ê³¼ í’ˆì§ˆ ë¶„ì„**")
        
        col3, col4 = st.columns(2)
        
        with col3:
            # ì‹ ë¢°ë„ ë¶„í¬
            confidence_scores = []
            for result in agent_results:
                if isinstance(result, dict) and "confidence" in result:
                    confidence_scores.append(result["confidence"])
                elif hasattr(result, 'confidence_score'):
                    confidence_scores.append(result.confidence_score)
                else:
                    confidence_scores.append(0.8)  # ê¸°ë³¸ê°’
            
            if confidence_scores:
                fig_hist = px.histogram(
                    x=confidence_scores,
                    nbins=10,
                    title="ì‹ ë¢°ë„ ì ìˆ˜ ë¶„í¬",
                    labels={'x': 'ì‹ ë¢°ë„', 'y': 'ë¹ˆë„'}
                )
                fig_hist.update_layout(height=300)
                st.plotly_chart(fig_hist, use_container_width=True)
        
        with col4:
            # í’ˆì§ˆ ì§€í‘œ ë ˆì´ë” ì°¨íŠ¸
            quality_metrics = {
                "ì •í™•ì„±": np.mean(confidence_scores) if confidence_scores else 0.8,
                "ì™„ì „ì„±": len(agent_results) / 5.0 if len(agent_results) <= 5 else 1.0,
                "ì¼ê´€ì„±": 1.0 - np.std(confidence_scores) if confidence_scores else 0.8,
                "ê´€ë ¨ì„±": 0.85,  # ë„ë©”ì¸ ê´€ë ¨ì„± (ê³„ì‚° í•„ìš”)
                "ëª…í™•ì„±": 0.82   # ë‹µë³€ ëª…í™•ì„± (ê³„ì‚° í•„ìš”)
            }
            
            fig_quality = go.Figure()
            fig_quality.add_trace(go.Scatterpolar(
                r=list(quality_metrics.values()),
                theta=list(quality_metrics.keys()),
                fill='toself',
                name='í’ˆì§ˆ ì§€í‘œ'
            ))
            
            fig_quality.update_layout(
                polar=dict(
                    radialaxis=dict(
                        visible=True,
                        range=[0, 1]
                    )),
                showlegend=True,
                height=300,
                title="ì¢…í•© í’ˆì§ˆ ì§€í‘œ"
            )
            
            st.plotly_chart(fig_quality, use_container_width=True)
    
    def _render_agent_collaboration_tab(self, trace_analysis: Dict[str, Any]) -> None:
        """ì—ì´ì „íŠ¸ í˜‘ì—… íƒ­ ë Œë”ë§"""
        
        st.markdown("### ğŸ¤ **ì—ì´ì „íŠ¸ í˜‘ì—… ë¶„ì„**")
        
        transparency_metrics = trace_analysis.get("transparency_metrics", {})
        css_metrics = transparency_metrics.get("component_synergy_score", {})
        interaction_flow = trace_analysis.get("interaction_flow", [])
        
        # í˜‘ì—… í’ˆì§ˆ ì§€í‘œ
        col1, col2, col3 = st.columns(3)
        
        with col1:
            cooperation_quality = css_metrics.get("cooperation_quality", 0.0)
            st.metric(
                "ğŸ¤ í˜‘ì—… í’ˆì§ˆ",
                f"{cooperation_quality:.1%}",
                help="ì„±ê³µì ì¸ ìƒí˜¸ì‘ìš© ë¹„ìœ¨"
            )
        
        with col2:
            communication_efficiency = css_metrics.get("communication_efficiency", 0.0)
            st.metric(
                "ğŸ’¬ ì†Œí†µ íš¨ìœ¨ì„±",
                f"{communication_efficiency:.1%}",
                help="ì‘ë‹µ ì‹œê°„ ê¸°ë°˜ ì†Œí†µ íš¨ìœ¨ì„±"
            )
        
        with col3:
            task_distribution = css_metrics.get("task_distribution", 0.0)
            st.metric(
                "âš–ï¸ ì—…ë¬´ ë¶„ë°°",
                f"{task_distribution:.1%}",
                help="ì—ì´ì „íŠ¸ ê°„ ê· í˜•ì¡íŒ ì—…ë¬´ ë¶„ë°°"
            )
        
        # ìƒí˜¸ì‘ìš© ë„¤íŠ¸ì›Œí¬ ì‹œê°í™”
        if interaction_flow:
            st.markdown("#### ğŸŒ **ì—ì´ì „íŠ¸ ìƒí˜¸ì‘ìš© ë„¤íŠ¸ì›Œí¬**")
            
            # ë„¤íŠ¸ì›Œí¬ ê·¸ë˜í”„ ìƒì„±
            agents = set()
            edges = []
            
            for interaction in interaction_flow:
                source = interaction["source_agent"]
                target = interaction["target_agent"]
                agents.add(source)
                agents.add(target)
                edges.append((source, target, interaction["type"]))
            
            # ë„¤íŠ¸ì›Œí¬ ì‹œê°í™” (ê°„ë‹¨í•œ ë²„ì „)
            agent_list = list(agents)
            interaction_matrix = np.zeros((len(agent_list), len(agent_list)))
            
            for source, target, _ in edges:
                i = agent_list.index(source)
                j = agent_list.index(target)
                interaction_matrix[i][j] += 1
            
            fig_network = px.imshow(
                interaction_matrix,
                x=agent_list,
                y=agent_list,
                title="ì—ì´ì „íŠ¸ ê°„ ìƒí˜¸ì‘ìš© ë§¤íŠ¸ë¦­ìŠ¤",
                color_continuous_scale="Blues"
            )
            
            st.plotly_chart(fig_network, use_container_width=True)
        
        # ì‹œê°„ëŒ€ë³„ ìƒí˜¸ì‘ìš© íë¦„
        if interaction_flow:
            st.markdown("#### â±ï¸ **ì‹œê°„ëŒ€ë³„ ìƒí˜¸ì‘ìš© íë¦„**")
            
            # ìƒí˜¸ì‘ìš© íƒ€ì„ë¼ì¸
            timeline_data = []
            for i, interaction in enumerate(interaction_flow):
                timeline_data.append({
                    "ìˆœì„œ": i + 1,
                    "ì‹œê°„": datetime.fromtimestamp(interaction["timestamp"]),
                    "ìƒí˜¸ì‘ìš©": f"{interaction['source_agent']} â†’ {interaction['target_agent']}",
                    "íƒ€ì…": interaction["type"],
                    "ë°ì´í„° í¬ê¸°": interaction["data_summary"]["input_size"]
                })
            
            df_timeline = pd.DataFrame(timeline_data)
            
            fig_timeline = px.line(
                df_timeline,
                x="ì‹œê°„",
                y="ë°ì´í„° í¬ê¸°",
                hover_data=["ìƒí˜¸ì‘ìš©", "íƒ€ì…"],
                title="ìƒí˜¸ì‘ìš© íƒ€ì„ë¼ì¸",
                markers=True
            )
            
            st.plotly_chart(fig_timeline, use_container_width=True)
    
    def _render_tool_efficiency_tab(self, trace_analysis: Dict[str, Any]) -> None:
        """ë„êµ¬ íš¨ìœ¨ì„± íƒ­ ë Œë”ë§"""
        
        st.markdown("### ğŸ”§ **ë„êµ¬ ì‚¬ìš© íš¨ìœ¨ì„± ë¶„ì„**")
        
        transparency_metrics = trace_analysis.get("transparency_metrics", {})
        tue_metrics = transparency_metrics.get("tool_utilization_efficacy", {})
        
        # TUE ì§€í‘œ
        col1, col2, col3 = st.columns(3)
        
        with col1:
            success_rate = tue_metrics.get("success_rate", 0.0)
            st.metric(
                "âœ… ì„±ê³µë¥ ",
                f"{success_rate:.1%}",
                help="ë„êµ¬ í˜¸ì¶œ ì„±ê³µë¥ "
            )
        
        with col2:
            avg_response_time = tue_metrics.get("avg_response_time", 0.0)
            st.metric(
                "âš¡ í‰ê·  ì‘ë‹µì‹œê°„",
                f"{avg_response_time:.2f}s",
                help="ë„êµ¬ ì‹¤í–‰ í‰ê·  ì‘ë‹µì‹œê°„"
            )
        
        with col3:
            resource_efficiency = tue_metrics.get("resource_efficiency", 0.0)
            st.metric(
                "ğŸ¯ ë¦¬ì†ŒìŠ¤ íš¨ìœ¨ì„±",
                f"{resource_efficiency:.3f}",
                help="í† í° ì‚¬ìš©ëŸ‰ ëŒ€ë¹„ ì„±ê³µë¥ "
            )
        
        # ë„êµ¬ë³„ ì„±ëŠ¥ ë¶„ì„
        spans_hierarchy = trace_analysis.get("spans_hierarchy", {})
        tool_performance = self._extract_tool_performance(spans_hierarchy)
        
        if tool_performance:
            st.markdown("#### ğŸ› ï¸ **ë„êµ¬ë³„ ì„±ëŠ¥ ë¶„ì„**")
            
            df_tools = pd.DataFrame(tool_performance)
            
            col4, col5 = st.columns(2)
            
            with col4:
                # ë„êµ¬ë³„ ì„±ê³µë¥ 
                fig_success = px.bar(
                    df_tools,
                    x="ë„êµ¬ëª…",
                    y="ì„±ê³µë¥ ",
                    title="ë„êµ¬ë³„ ì„±ê³µë¥ ",
                    color="ì„±ê³µë¥ ",
                    color_continuous_scale="RdYlGn"
                )
                st.plotly_chart(fig_success, use_container_width=True)
            
            with col5:
                # ë„êµ¬ë³„ ì‘ë‹µì‹œê°„
                fig_time = px.box(
                    df_tools,
                    x="ë„êµ¬ëª…",
                    y="í‰ê·  ì‘ë‹µì‹œê°„",
                    title="ë„êµ¬ë³„ ì‘ë‹µì‹œê°„ ë¶„í¬"
                )
                st.plotly_chart(fig_time, use_container_width=True)
    
    def _render_execution_flow_tab(self, trace_analysis: Dict[str, Any]) -> None:
        """ì‹¤í–‰ í”Œë¡œìš° íƒ­ ë Œë”ë§"""
        
        st.markdown("### ğŸ“Š **ì‹¤í–‰ í”Œë¡œìš° ë¶„ì„**")
        
        spans_hierarchy = trace_analysis.get("spans_hierarchy", {})
        
        if spans_hierarchy:
            # ì‹¤í–‰ í”Œë¡œìš° ì‹œê°í™”
            self._render_execution_flow_chart(spans_hierarchy)
            
            # í”Œë¡œìš° í†µê³„
            st.markdown("#### ğŸ“ˆ **í”Œë¡œìš° í†µê³„**")
            
            flow_stats = self._calculate_flow_statistics(spans_hierarchy)
            
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("ì´ ë‹¨ê³„", flow_stats["total_steps"])
            with col2:
                st.metric("ë³‘ë ¬ ì‹¤í–‰", flow_stats["parallel_steps"])
            with col3:
                st.metric("ìµœëŒ€ ê¹Šì´", flow_stats["max_depth"])
            with col4:
                st.metric("í‰ê·  ë‹¨ê³„ ì‹œê°„", f"{flow_stats['avg_step_time']:.2f}s")
    
    def _render_detailed_tracing_tab(self, trace_analysis: Dict[str, Any]) -> None:
        """ìƒì„¸ ì¶”ì  íƒ­ ë Œë”ë§"""
        
        st.markdown("### ğŸ” **ìƒì„¸ ì¶”ì  ì •ë³´**")
        
        # ì›ì‹œ íŠ¸ë ˆì´ìŠ¤ ë°ì´í„° í‘œì‹œ
        with st.expander("ğŸ“‹ **ì›ì‹œ íŠ¸ë ˆì´ìŠ¤ ë°ì´í„°**"):
            st.json(trace_analysis)
        
        # ì´ìŠˆ ë¶„ì„
        transparency_metrics = trace_analysis.get("transparency_metrics", {})
        issues_detected = transparency_metrics.get("issues_detected", 0)
        issue_types = transparency_metrics.get("issue_types", [])
        
        if issues_detected > 0:
            st.markdown("#### âš ï¸ **ê°ì§€ëœ ì´ìŠˆ**")
            
            for issue_type in issue_types:
                st.warning(f"ğŸš¨ {issue_type}: {self._get_issue_description(issue_type)}")
        else:
            st.success("âœ… ê°ì§€ëœ ì´ìŠˆê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        # ì„±ëŠ¥ ê°œì„  ì œì•ˆ
        st.markdown("#### ğŸ’¡ **ì„±ëŠ¥ ê°œì„  ì œì•ˆ**")
        
        recommendations = self._generate_recommendations(trace_analysis)
        
        for recommendation in recommendations:
            st.info(f"ğŸ’¡ {recommendation}")
    
    def _calculate_query_complexity(self, query_text: str) -> Dict[str, float]:
        """ì¿¼ë¦¬ ë³µì¡ë„ ê³„ì‚°"""
        
        technical_terms = ["ê³µì •", "TW", "ì´ì˜¨ì£¼ì…", "ë°˜ë„ì²´", "ê³„ì¸¡", "ì¥ë¹„", "ë ˆì‹œí”¼"]
        technical_score = sum(1 for term in technical_terms if term in query_text) / len(technical_terms)
        
        structural_indicators = ["ë¶„ì„", "íŒë‹¨", "ì œì•ˆ", "ì›ì¸", "ì¡°ì¹˜"]
        structural_score = sum(1 for indicator in structural_indicators if indicator in query_text) / len(structural_indicators)
        
        domain_keywords = ["ì—”ì§€ë‹ˆì–´", "ë„ë©”ì¸", "íˆìŠ¤í† ë¦¬", "ì…‹íŒ…", "ë°ì´í„°"]
        domain_score = sum(1 for keyword in domain_keywords if keyword in query_text) / len(domain_keywords)
        
        return {
            "technical_terms": technical_score,
            "structural_complexity": structural_score,
            "domain_depth": domain_score
        }
    
    def _extract_tool_performance(self, spans_hierarchy: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ìŠ¤íŒ¬ ê³„ì¸µì—ì„œ ë„êµ¬ ì„±ëŠ¥ ì¶”ì¶œ"""
        
        tool_performance = []
        
        def extract_from_node(node):
            span = node.get("span")
            if span and hasattr(span, 'level') and span.level.value == "tool":
                tool_performance.append({
                    "ë„êµ¬ëª…": getattr(span, 'tool_name', 'Unknown'),
                    "ì„±ê³µë¥ ": 1.0 if not getattr(span, 'error', None) else 0.0,
                    "í‰ê·  ì‘ë‹µì‹œê°„": getattr(span, 'duration', 0.0) or 0.0,
                    "í† í° ì‚¬ìš©ëŸ‰": getattr(span, 'token_usage', {}).get('total_tokens', 0) if getattr(span, 'token_usage', None) else 0
                })
            
            for child in node.get("children", []):
                extract_from_node(child)
        
        for root_node in spans_hierarchy.values():
            extract_from_node(root_node)
        
        return tool_performance
    
    def _render_execution_flow_chart(self, spans_hierarchy: Dict[str, Any]) -> None:
        """ì‹¤í–‰ í”Œë¡œìš° ì°¨íŠ¸ ë Œë”ë§"""
        
        # ê°„ë‹¨í•œ í”Œë¡œìš°ì°¨íŠ¸ ìƒì„± (Gantt ì°¨íŠ¸ ìŠ¤íƒ€ì¼)
        flow_data = []
        
        def extract_flow_data(node, level=0):
            span = node.get("span")
            if span:
                start_time = getattr(span, 'start_time', 0)
                end_time = getattr(span, 'end_time', start_time + 1)
                
                flow_data.append({
                    "ì‘ì—…": getattr(span, 'name', 'Unknown'),
                    "ì‹œì‘": datetime.fromtimestamp(start_time),
                    "ì¢…ë£Œ": datetime.fromtimestamp(end_time),
                    "ë ˆë²¨": level,
                    "íƒ€ì…": getattr(span, 'level', 'unknown').value if hasattr(getattr(span, 'level', None), 'value') else 'unknown'
                })
            
            for child in node.get("children", []):
                extract_flow_data(child, level + 1)
        
        for root_node in spans_hierarchy.values():
            extract_flow_data(root_node)
        
        if flow_data:
            df_flow = pd.DataFrame(flow_data)
            
            fig_gantt = px.timeline(
                df_flow,
                x_start="ì‹œì‘",
                x_end="ì¢…ë£Œ",
                y="ì‘ì—…",
                color="íƒ€ì…",
                title="ì‹¤í–‰ í”Œë¡œìš° íƒ€ì„ë¼ì¸"
            )
            
            st.plotly_chart(fig_gantt, use_container_width=True)
    
    def _calculate_flow_statistics(self, spans_hierarchy: Dict[str, Any]) -> Dict[str, Any]:
        """í”Œë¡œìš° í†µê³„ ê³„ì‚°"""
        
        total_steps = 0
        max_depth = 0
        step_times = []
        
        def analyze_node(node, depth=0):
            nonlocal total_steps, max_depth
            
            total_steps += 1
            max_depth = max(max_depth, depth)
            
            span = node.get("span")
            if span and hasattr(span, 'duration') and span.duration:
                step_times.append(span.duration)
            
            for child in node.get("children", []):
                analyze_node(child, depth + 1)
        
        for root_node in spans_hierarchy.values():
            analyze_node(root_node)
        
        return {
            "total_steps": total_steps,
            "parallel_steps": len(spans_hierarchy),  # ë£¨íŠ¸ ë…¸ë“œ ìˆ˜
            "max_depth": max_depth,
            "avg_step_time": np.mean(step_times) if step_times else 0.0
        }
    
    def _get_issue_description(self, issue_type: str) -> str:
        """ì´ìŠˆ íƒ€ì…ë³„ ì„¤ëª…"""
        
        descriptions = {
            "coordination_failure": "ì—ì´ì „íŠ¸ ê°„ í˜‘ì¡° ì‹¤íŒ¨ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "tool_misuse": "ë„êµ¬ ì‚¬ìš© ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
            "reasoning_error": "ì¶”ë¡  ê³¼ì •ì—ì„œ ë…¼ë¦¬ì  ì˜¤ë¥˜ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "context_loss": "ì»¨í…ìŠ¤íŠ¸ ì†ì‹¤ì´ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
            "hallucination": "í™˜ê° í˜„ìƒì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "performance_degradation": "ì„±ëŠ¥ ì €í•˜ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤."
        }
        
        return descriptions.get(issue_type, "ì•Œ ìˆ˜ ì—†ëŠ” ì´ìŠˆì…ë‹ˆë‹¤.")
    
    def _generate_recommendations(self, trace_analysis: Dict[str, Any]) -> List[str]:
        """ì„±ëŠ¥ ê°œì„  ì œì•ˆ ìƒì„±"""
        
        recommendations = []
        
        transparency_metrics = trace_analysis.get("transparency_metrics", {})
        css_metrics = transparency_metrics.get("component_synergy_score", {})
        tue_metrics = transparency_metrics.get("tool_utilization_efficacy", {})
        
        # CSS ê¸°ë°˜ ì œì•ˆ
        if css_metrics.get("cooperation_quality", 0) < 0.7:
            recommendations.append("ì—ì´ì „íŠ¸ ê°„ í˜‘ì—… í”„ë¡œí† ì½œì„ ê°œì„ í•˜ì„¸ìš”.")
        
        if css_metrics.get("communication_efficiency", 0) < 0.6:
            recommendations.append("ì—ì´ì „íŠ¸ ê°„ í†µì‹  ì§€ì—°ì„ ìµœì í™”í•˜ì„¸ìš”.")
        
        if css_metrics.get("task_distribution", 0) < 0.5:
            recommendations.append("ì—…ë¬´ ë¶„ë°° ì•Œê³ ë¦¬ì¦˜ì„ ì¡°ì •í•˜ì„¸ìš”.")
        
        # TUE ê¸°ë°˜ ì œì•ˆ
        if tue_metrics.get("success_rate", 0) < 0.8:
            recommendations.append("ë„êµ¬ ì•ˆì •ì„±ì„ ê°œì„ í•˜ì„¸ìš”.")
        
        if tue_metrics.get("avg_response_time", 0) > 5.0:
            recommendations.append("ë„êµ¬ ì‘ë‹µ ì‹œê°„ì„ ìµœì í™”í•˜ì„¸ìš”.")
        
        if not recommendations:
            recommendations.append("ì‹œìŠ¤í…œì´ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤. í˜„ì¬ ì„¤ì •ì„ ìœ ì§€í•˜ì„¸ìš”.")
        
        return recommendations

# ì „ì—­ ëŒ€ì‹œë³´ë“œ ì¸ìŠ¤í„´ìŠ¤
transparency_dashboard = TransparencyDashboard()

# ì‚¬ìš© ì˜ˆì œ í•¨ìˆ˜
def render_transparency_analysis(trace_analysis: Dict[str, Any], 
                               agent_results: List[Dict[str, Any]] = None,
                               query_info: Dict[str, Any] = None) -> None:
    """íˆ¬ëª…ì„± ë¶„ì„ ë Œë”ë§ í•¨ìˆ˜"""
    
    if not trace_analysis:
        st.warning("ğŸ” íˆ¬ëª…ì„± ë¶„ì„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    agent_results = agent_results or []
    query_info = query_info or {"original_query": "ë¶„ì„ ì¿¼ë¦¬"}
    
    transparency_dashboard.render_comprehensive_analysis(
        trace_analysis, agent_results, query_info
    ) 