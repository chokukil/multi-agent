# File: ui/chat_interface.py
# Location: ./ui/chat_interface.py

import streamlit as st
import asyncio
import time
import logging
from typing import Dict, Tuple
from langchain_core.messages import HumanMessage
from core import data_manager
from datetime import datetime

# Core modules
from core import data_manager

# ìƒˆë¡œìš´ ì½œë°± ë° ìŠ¤íŠ¸ë¦¬ë° í•¨ìˆ˜ ì„í¬íŠ¸
from core.callbacks.chat_stream import ChatStreamCallback
from core.callbacks.progress_stream import ProgressStreamCallback
from core.callbacks.artifact_stream import ArtifactStreamCallback
from core.utils.streaming import astream_graph_with_callbacks
from core.streaming.typed_chat_stream import TypedChatStreamCallback
from core.utils.streaming import create_timeout_aware_callback
from core.execution.timeout_manager import TimeoutManager

# Query RouterëŠ” ì´ì œ ê·¸ë˜í”„ ë‚´ë¶€ì—ì„œ ì²˜ë¦¬ë¨

MAX_HISTORY_LENGTH = 20  # ìµœëŒ€ ëŒ€í™” ê¸°ë¡ ìˆ˜ (ì‚¬ìš©ì ì…ë ¥ + ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µ = 1í„´)

def render_chat_interface():
    """ë©”ì¸ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ë¥¼ ë Œë”ë§í•©ë‹ˆë‹¤."""
    st.title("ğŸ“„ Enhanced Multi-Agent Chat")
    
    # ë©”ì‹œì§€ ì´ˆê¸°í™”
    if "messages" not in st.session_state:
        st.session_state.messages = []
    
    # ë°ì´í„° ì—…ë¡œë”
    if not data_manager.is_data_loaded():
        uploaded_file = st.file_uploader("ë¨¼ì € ë°ì´í„° íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.", type=["csv", "xlsx", "json"])
        if uploaded_file:
            data_manager.load_data(uploaded_file)
            st.success(f"âœ… '{uploaded_file.name}'ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
            st.rerun()
    
    # ì±„íŒ… ê¸°ë¡ ì¶œë ¥
    print_chat_history()

    # ì‚¬ìš©ì ì…ë ¥
    if prompt := st.chat_input("ë¶„ì„í•  ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”..."):
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        st.session_state.messages.append({
            "role": "user", 
            "content": prompt,
            "timestamp": datetime.now().isoformat()
        })
        
        st.chat_message("user").write(prompt)
        with st.chat_message("assistant"):
            # UI í”Œë ˆì´ìŠ¤í™€ë” ì„¤ì •
            progress_placeholder = st.empty()
            response_placeholder = st.empty()
            
            # ë™ê¸° ì‘ì—… ì‹¤í–‰
            try:
                process_query_with_timeout_and_streaming(
                    prompt, progress_placeholder, response_placeholder
                )
            except Exception as e:
                logging.error(f"Error processing query: {e}", exc_info=True)
                st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                # ì—ëŸ¬ ë©”ì‹œì§€ë„ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": f"âŒ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}",
                    "timestamp": datetime.now().isoformat()
                })

def print_chat_history():
    """ì„¸ì…˜ì˜ ì±„íŒ… ê¸°ë¡ì„ ì¶œë ¥í•©ë‹ˆë‹¤."""
    if "messages" not in st.session_state:
        st.session_state.messages = []
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.write(msg["content"])

def process_query_with_timeout_and_streaming(
    query: str, progress_placeholder, response_placeholder, timeout_seconds: int = 180
):
    """ì¿¼ë¦¬ ì²˜ë¦¬ with ê°œì„ ëœ íƒ€ì„ì•„ì›ƒ ë° ìŠ¤íŠ¸ë¦¬ë° - ë™ê¸° ë°©ì‹"""
    
    # ğŸ†• íƒ€ì„ì•„ì›ƒ ë§¤ë‹ˆì € ì´ˆê¸°í™”
    timeout_manager = TimeoutManager()
    
    # ì¿¼ë¦¬ ë³µì¡ë„ ë¶„ì„
    complexity_info = timeout_manager.analyze_query_complexity(query)
    
    # ë™ì  íƒ€ì„ì•„ì›ƒ ê³„ì‚°
    timeout_seconds = timeout_manager.calculate_timeout(
        complexity=complexity_info['complexity'],
        agent_type='EDA_Analyst'  # ì£¼ìš” ì—ì´ì „íŠ¸
    )
    
    progress_placeholder.info(f"ğŸ“Š Query Complexity: {complexity_info['complexity'].value} | â±ï¸ Timeout: {timeout_seconds}s")
    
    # ì›Œí¬í”Œë¡œìš° í™•ì¸
    if "plan_execute_graph" not in st.session_state or not st.session_state.plan_execute_graph:
        response_placeholder.error("ğŸš« Plan-Execute ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return
    
    # ê¸°ì¡´ì˜ ì•ˆì •ì ì¸ ì½œë°± ì‚¬ìš©
    chat_callback = ChatStreamCallback(response_placeholder)
    progress_callback = ProgressStreamCallback(progress_placeholder)
    artifact_callback = ArtifactStreamCallback()
    
    callbacks = [chat_callback, progress_callback, artifact_callback]
    
    try:
        # ì„¸ì…˜ ID ì„¤ì •
        session_id = st.session_state.get('thread_id', 'default-session')
        
        # ì´ˆê¸° ìƒíƒœ ì„¤ì •
        initial_state = {
            "messages": [HumanMessage(content=query)],
            "session_id": st.session_state.get('session_id', session_id),
            "thread_id": session_id,
            "user_id": st.session_state.get('user_id', 'default-user'),
            "execution_history": [],
            "plan": [],
            "current_step": 0,
            "step_results": {},
            "task_completed": False
        }
        
        # ğŸ†• ë™ê¸° ë°©ì‹ìœ¼ë¡œ ì§ì ‘ ê·¸ë˜í”„ ì‹¤í–‰
        import time
        start_time = time.time()
        
        try:
            from langchain_core.runnables import RunnableConfig
            
            # ì„¤ì • êµ¬ì„±
            config = RunnableConfig(
                recursion_limit=st.session_state.get("recursion_limit", 30),
                configurable={"thread_id": session_id}
            )
            
            # ğŸ†• ì§ì ‘ ë™ê¸° ìŠ¤íŠ¸ë¦¬ë° (íƒ€ì„ì•„ì›ƒ ì²´í¬ í¬í•¨)
            for chunk in st.session_state.plan_execute_graph.stream(
                initial_state,
                config=config,
                stream_mode="values"
            ):
                # íƒ€ì„ì•„ì›ƒ ì²´í¬
                elapsed = time.time() - start_time
                if elapsed > timeout_seconds:
                    progress_placeholder.warning(f"â° ë¶„ì„ì´ {timeout_seconds}ì´ˆ í›„ íƒ€ì„ì•„ì›ƒë˜ì—ˆìŠµë‹ˆë‹¤.")
                    response_placeholder.error("â° ì‹œê°„ ì´ˆê³¼ë¡œ ë¶„ì„ì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. ë” ê°„ë‹¨í•œ ìš”ì²­ì„ ì‹œë„í•´ë³´ì„¸ìš”.")
                    break
                
                # ì½œë°± ì‹¤í–‰
                chunk_msg = {"content": chunk, "node": chunk.get("next_action", "unknown")}
                for callback in callbacks:
                    try:
                        if callable(callback):
                            callback(chunk_msg)
                    except Exception as cb_error:
                        logging.error(f"Callback error: {cb_error}")
                
                # ì™„ë£Œ ì¡°ê±´ ì²´í¬
                if chunk.get("task_completed") or chunk.get("next_action") == "final_responder":
                    break
                    
        except Exception as stream_error:
            logging.error(f"Stream error: {stream_error}")
            response_placeholder.error(f"âŒ ìŠ¤íŠ¸ë¦¬ë° ì˜¤ë¥˜: {str(stream_error)}")
        
        # ìµœì¢… ì‘ë‹µ ì €ì¥
        final_response = chat_callback.get_final_response()
        if final_response:
            st.session_state.messages.append({
                "role": "assistant", 
                "content": final_response,
                "timestamp": datetime.now().isoformat()
            })
        else:
            # ë°±ì—… ì‘ë‹µ
            fallback_response = "".join(chat_callback.buffer)
            if fallback_response:
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": fallback_response,
                    "timestamp": datetime.now().isoformat()
                })
            else:
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": "âœ… ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ìœ„ì˜ ê²°ê³¼ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.",
                    "timestamp": datetime.now().isoformat()
                })
        
    except Exception as e:
        logging.error(f"Query processing error: {e}", exc_info=True)
        response_placeholder.error(f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        st.session_state.messages.append({
            "role": "assistant",
            "content": f"âŒ ì£„ì†¡í•©ë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
            "timestamp": datetime.now().isoformat()
        })

def render_system_status():
    """ì‹œìŠ¤í…œ ìƒíƒœ í‘œì‹œ"""
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        executors_count = len(st.session_state.get("executors", {}))
        st.metric("Executors", executors_count)
    
    with col2:
        messages_count = len(st.session_state.get("history", []))
        st.metric("Messages", messages_count)
    
    with col3:
        status = "âœ… Ready" if st.session_state.get("graph_initialized") else "âš ï¸ Not Initialized"
        st.metric("System", status)
    
    with col4:
        has_data = "âœ… Loaded" if data_manager.is_data_loaded() else "âŒ Empty"
        st.metric("Data", has_data)