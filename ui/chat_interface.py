# File: ui/chat_interface.py
# Location: ./ui/chat_interface.py

import streamlit as st
import asyncio
import logging
from datetime import datetime
from langchain_core.messages import HumanMessage

from core.plan_execute.planner import planner_node
from core.plan_execute.a2a_executor import a2a_executor_node
from core.callbacks.progress_stream import progress_stream_manager
from ui.artifact_manager import render_artifact

def initialize_session_state():
    """ì„¸ì…˜ ìƒíƒœ ë³€ìˆ˜ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "session_id" not in st.session_state:
        st.session_state.session_id = f"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def render_chat_history():
    """ì„¸ì…˜ ìƒíƒœì—ì„œ ì±„íŒ… ê¸°ë¡ì„ ë Œë”ë§í•©ë‹ˆë‹¤."""
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            content = msg["content"]
            if isinstance(content, dict) and "plan_summary" in content:
                st.markdown(content["plan_summary"])
            elif isinstance(content, dict) and "artifact" in content:
                artifact = content["artifact"]
                agent_name = artifact.get('agent_name', 'Unknown Agent')
                exp = st.expander(f"âœ¨ **{agent_name}**ë¡œë¶€í„° ì•„í‹°íŒ©íŠ¸ ë„ì°©", expanded=True)
                render_artifact(artifact.get('output_type'), artifact.get('output'), exp)
            else:
                st.markdown(str(content))

def process_user_query(prompt: str):
    """ìƒˆë¡œìš´ A2A ê¸°ë°˜ ê³„íš-ì‹¤í–‰ íë¦„ì„ í†µí•´ ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.chat_message("user").markdown(prompt)

    with st.chat_message("assistant"):
        initial_state = {
            "messages": [HumanMessage(content=prompt)],
            "session_id": st.session_state.session_id,
        }

        # 1. í”Œë˜ë„ˆ ì‹¤í–‰
        with st.status("ğŸ§  **Thinking...** ë¶„ì„ ê³„íšì„ ìˆ˜ë¦½í•˜ê³  ìˆìŠµë‹ˆë‹¤.", expanded=True) as status:
            try:
                plan_state = planner_node(initial_state)
                if not plan_state.get("plan"):
                    status.update(label="ê³„íš ìˆ˜ë¦½ ì‹¤íŒ¨", state="error", expanded=False)
                    st.error("ìš”ì²­ì„ ì²˜ë¦¬í•  ê³„íšì„ ì„¸ìš°ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ ë‹¤ì‹œ ìš”ì²­í•´ ì£¼ì„¸ìš”.")
                    st.session_state.messages.append({"role": "assistant", "content": "ì´ ìš”ì²­ì— ëŒ€í•œ ê³„íšì„ ì„¸ìš¸ ìˆ˜ ì—†ì—ˆìŠµë‹ˆë‹¤."})
                    return

                plan_summary = "ğŸ“‹ **Execution Plan**\n\n"
                for step in plan_state["plan"]:
                    plan_summary += f"**{step['step']}. `{step['agent_name']}`** ğŸ‘‰ `{step['skill_name']}`\n"
                
                status.update(label="âœ… ê³„íš ìˆ˜ë¦½ ì™„ë£Œ!", state="complete", expanded=False)
                st.session_state.messages.append({"role": "assistant", "content": {"plan_summary": plan_summary}})
                st.markdown(plan_summary)
            except Exception as e:
                status.update(label="ê³„íš ìˆ˜ë¦½ ì¤‘ ì˜¤ë¥˜ ë°œìƒ!", state="error")
                st.error(f"ê³„íš ë‹¨ê³„ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                logging.error(f"Planning error: {e}", exc_info=True)
                return

        # 2. ì‹¤í–‰ê¸° ì‹¤í–‰
        try:
            # ë¹„ë™ê¸° í•¨ìˆ˜ ì‹¤í–‰
            asyncio.run(execute_and_render(plan_state))
        except Exception as e:
            st.error(f"ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            logging.error(f"Execution error: {e}", exc_info=True)

async def execute_and_render(execution_state: dict):
    """ì‹¤í–‰ê¸°ë¥¼ ë¹„ë™ê¸°ì ìœ¼ë¡œ ì‹¤í–‰í•˜ê³  UIì— ì—…ë°ì´íŠ¸ë¥¼ ë Œë”ë§í•©ë‹ˆë‹¤."""
    queue = asyncio.Queue()
    progress_stream_manager.register_queue(queue)
    
    executor_task = asyncio.create_task(a2a_executor_node(execution_state))

    active_statuses = {}
    is_done = False

    while not is_done:
        try:
            update = await asyncio.wait_for(queue.get(), timeout=30.0)
            event_type = update.get("event_type")
            data = update.get("data", {})
            step_num = data.get("step")

            if event_type == "agent_start":
                status = st.status(f"â³ **Step {step_num}:** `{data['agent_name']}` ì‹¤í–‰ ì¤‘...", expanded=True)
                active_statuses[step_num] = status
            
            elif event_type == "agent_end":
                if step_num in active_statuses:
                    active_statuses[step_num].update(label=f"âœ… **Step {step_num}:** `{data['agent_name']}` ì™„ë£Œ!", state="complete", expanded=False)
                
                artifact_message = {"role": "assistant", "content": {"artifact": data}}
                st.session_state.messages.append(artifact_message)
                
                with st.chat_message("assistant"):
                    agent_name = data.get('agent_name', 'Unknown Agent')
                    exp = st.expander(f"âœ¨ **{agent_name}**ë¡œë¶€í„° ì•„í‹°íŒ©íŠ¸ ë„ì°©", expanded=True)
                    render_artifact(data.get('output_type'), data.get('output'), exp)
                
            elif event_type == "agent_error":
                if step_num in active_statuses:
                    active_statuses[step_num].update(label=f"âŒ **Step {step_num}:** `{data['agent_name']}` ì˜¤ë¥˜ ë°œìƒ", state="error", expanded=True)
                    with active_statuses[step_num]:
                        st.error(data.get("error_message", "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜"))
            
            queue.task_done()

        except asyncio.TimeoutError:
            if executor_task.done():
                is_done = True
                break
    
    progress_stream_manager.unregister_queue()
    final_state = await executor_task
    if final_state.get("error"):
         st.error(f"ìµœì¢… ì‹¤í–‰ ì‹¤íŒ¨: {final_state['error']}")
    else:
         st.success("ğŸ‰ ëª¨ë“  ë¶„ì„ ë‹¨ê³„ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

def render_chat_interface():
    st.title("ğŸ’ CherryAI: A2A-Powered Data Science Team")
    
    initialize_session_state()
    render_chat_history()
    
    if prompt := st.chat_input("ì˜¤ëŠ˜ ë¬´ì—‡ì„ ë¶„ì„í•´ë“œë¦´ê¹Œìš”?"):
        process_user_query(prompt)

# This allows the app to be run directly
if __name__ == "__main__":
    render_chat_interface()

def render_system_status():
    """ì‹œìŠ¤í…œ ìƒíƒœ í‘œì‹œ"""
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        executors_count = len(st.session_state.get("executors", {}))
        st.metric("Executors", executors_count)
    
    with col2:
        messages_count = len(st.session_state.get("history", []))
        st.metric("Messages", messages_count)
    
    with col3:
        status = "âœ… Ready" if st.session_state.get("graph_initialized") else "âš ï¸ Not Initialized"
        st.metric("System", status)
    
    with col4:
        has_data = "âœ… Loaded" if data_manager.is_data_loaded() else "âŒ Empty"
        st.metric("Data", has_data)