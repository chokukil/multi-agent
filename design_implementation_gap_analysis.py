#!/usr/bin/env python3
"""
üîç Design vs Implementation Gap Analysis
ÏÑ§Í≥Ñ Î¨∏ÏÑúÏôÄ Ïã§Ï†ú Íµ¨ÌòÑ Í∞ÑÏùò Ï∞®Ïù¥Ï†ê Ïã¨Ï∏µ Î∂ÑÏÑù

Ïù¥ Ïä§ÌÅ¨Î¶ΩÌä∏Îäî LLM-First Universal EngineÏùò ÏÑ§Í≥Ñ Î¨∏ÏÑúÏôÄ Ïã§Ï†ú Íµ¨ÌòÑÎêú ÏΩîÎìú Í∞ÑÏùò
Ï∞®Ïù¥Ï†êÏùÑ ÏÉÅÏÑ∏Ìûà Î∂ÑÏÑùÌïòÏó¨ Ï†ïÌôïÌïú ÌòÑÌô©ÏùÑ ÌååÏïÖÌï©ÎãàÎã§.
"""

import os
import ast
import inspect
import importlib
import sys
from pathlib import Path
from typing import Dict, List, Any, Set
import json
from datetime import datetime
import logging

# Î°úÍπÖ ÏÑ§Ï†ï
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class DesignImplementationGapAnalyzer:
    """
    ÏÑ§Í≥Ñ Î¨∏ÏÑúÏôÄ Ïã§Ï†ú Íµ¨ÌòÑ Í∞ÑÏùò Ï∞®Ïù¥Ï†ê Î∂ÑÏÑùÍ∏∞
    """
    
    def __init__(self):
        self.project_root = Path.cwd()
        self.analysis_results = {
            "analysis_id": f"gap_analysis_{int(datetime.now().timestamp())}",
            "timestamp": datetime.now().isoformat(),
            "design_expectations": {},
            "actual_implementation": {},
            "gaps": {},
            "recommendations": []
        }
        
        # ÏÑ§Í≥Ñ Î¨∏ÏÑúÏóêÏÑú Ï†ïÏùòÎêú ÏòàÏÉÅ Íµ¨Ï°∞
        self.DESIGN_EXPECTATIONS = {
            "universal_engine_components": {
                "UniversalQueryProcessor": {
                    "expected_methods": ["process_query", "initialize", "get_status"],
                    "expected_file": "core/universal_engine/universal_query_processor.py",
                    "design_description": "ÏôÑÏ†Ñ Î≤îÏö© ÏøºÎ¶¨ Ï≤òÎ¶¨Í∏∞ - Ïñ¥Îñ§ ÎèÑÎ©îÏù∏ Í∞ÄÏ†ïÎèÑ ÌïòÏßÄ ÏïäÏùå"
                },
                "MetaReasoningEngine": {
                    "expected_methods": ["analyze_request", "perform_meta_reasoning", "assess_analysis_quality"],
                    "expected_file": "core/universal_engine/meta_reasoning_engine.py",
                    "design_description": "DeepSeek-R1 Í∏∞Î∞ò 4Îã®Í≥Ñ Ï∂îÎ°† ÏãúÏä§ÌÖú"
                },
                "DynamicContextDiscovery": {
                    "expected_methods": ["discover_context", "analyze_data_characteristics", "detect_domain"],
                    "expected_file": "core/universal_engine/dynamic_context_discovery.py",
                    "design_description": "Ï†úÎ°ú ÌïòÎìúÏΩîÎî© ÎèÑÎ©îÏù∏ ÏûêÎèô Î∞úÍ≤¨"
                },
                "AdaptiveUserUnderstanding": {
                    "expected_methods": ["estimate_user_level", "adapt_response", "update_user_profile"],
                    "expected_file": "core/universal_engine/adaptive_user_understanding.py",
                    "design_description": "ÏÇ¨Ïö©Ïûê Ï†ÑÎ¨∏ÏÑ± ÏàòÏ§Ä ÏûêÎèô Í∞êÏßÄ"
                },
                "UniversalIntentDetection": {
                    "expected_methods": ["detect_intent", "analyze_semantic_space", "clarify_ambiguity"],
                    "expected_file": "core/universal_engine/universal_intent_detection.py",
                    "design_description": "ÏùòÎØ∏ Í∏∞Î∞ò ÎùºÏö∞ÌåÖ (ÏÇ¨Ï†Ñ Ï†ïÏùò Ïπ¥ÌÖåÍ≥†Î¶¨ ÏóÜÏùå)"
                }
            },
            "a2a_integration": {
                "A2AAgentDiscoverySystem": {
                    "expected_methods": ["discover_available_agents", "validate_agent_endpoint", "monitor_agent_health"],
                    "expected_file": "core/universal_engine/a2a_integration/a2a_agent_discovery.py",
                    "design_description": "A2A ÏóêÏù¥Ï†ÑÌä∏ ÏûêÎèô Î∞úÍ≤¨ Î∞è ÏÉÅÌÉú Î™®ÎãàÌÑ∞ÎßÅ"
                },
                "A2AWorkflowOrchestrator": {
                    "expected_methods": ["execute_agent_workflow", "coordinate_agents", "manage_dependencies"],
                    "expected_file": "core/universal_engine/a2a_integration/a2a_workflow_orchestrator.py",
                    "design_description": "A2A ÏóêÏù¥Ï†ÑÌä∏ ÏõåÌÅ¨ÌîåÎ°úÏö∞ ÎèôÏ†Å Ïã§Ìñâ"
                }
            },
            "cherry_ai_integration": {
                "CherryAIUniversalEngineUI": {
                    "expected_methods": ["render_enhanced_header", "render_enhanced_chat_interface", "render_sidebar"],
                    "expected_file": "core/universal_engine/cherry_ai_integration/cherry_ai_universal_engine_ui.py",
                    "design_description": "Í∏∞Ï°¥ ChatGPT Ïä§ÌÉÄÏùº Ïù∏ÌÑ∞ÌéòÏù¥Ïä§ Ïú†ÏßÄÌïòÎ©∞ Universal Engine ÌÜµÌï©"
                }
            }
        }
    
    async def analyze_design_implementation_gaps(self) -> Dict[str, Any]:
        """
        ÏÑ§Í≥Ñ Î¨∏ÏÑúÏôÄ Ïã§Ï†ú Íµ¨ÌòÑ Í∞ÑÏùò Ï∞®Ïù¥Ï†ê Ï¢ÖÌï© Î∂ÑÏÑù
        """
        logger.info("üîç Starting Design vs Implementation Gap Analysis")
        logger.info(f"üìÇ Project root: {self.project_root}")
        
        try:
            # 1. Ïã§Ï†ú Íµ¨ÌòÑ ÏÉÅÌÉú Î∂ÑÏÑù
            logger.info("üìä Analyzing actual implementation...")
            actual_implementation = await self._analyze_actual_implementation()
            self.analysis_results["actual_implementation"] = actual_implementation
            
            # 2. ÏÑ§Í≥Ñ Í∏∞ÎåÄÏÇ¨Ìï≠ Ï†ïÎ¶¨
            logger.info("üìã Processing design expectations...")
            self.analysis_results["design_expectations"] = self.DESIGN_EXPECTATIONS
            
            # 3. Ï∞®Ïù¥Ï†ê Î∂ÑÏÑù
            logger.info("üîç Identifying gaps...")
            gaps = await self._identify_gaps(actual_implementation)
            self.analysis_results["gaps"] = gaps
            
            # 4. Í∂åÏû•ÏÇ¨Ìï≠ ÏÉùÏÑ±
            logger.info("üí° Generating recommendations...")
            recommendations = await self._generate_recommendations(gaps)
            self.analysis_results["recommendations"] = recommendations
            
            # 5. Í≤∞Í≥º Ï∂úÎ†•
            self._print_gap_analysis_summary()
            
            return self.analysis_results
            
        except Exception as e:
            logger.error(f"üí• Critical error during gap analysis: {str(e)}")
            self.analysis_results["error"] = str(e)
            return self.analysis_results
    
    async def _analyze_actual_implementation(self) -> Dict[str, Any]:
        """
        Ïã§Ï†ú Íµ¨ÌòÑÎêú ÏΩîÎìú Î∂ÑÏÑù
        """
        implementation_analysis = {
            "existing_files": {},
            "component_analysis": {},
            "method_coverage": {},
            "architecture_patterns": {}
        }
        
        # 1. ÌååÏùº Ï°¥Ïû¨ Ïó¨Î∂Ä ÌôïÏù∏
        for category, components in self.DESIGN_EXPECTATIONS.items():
            for component_name, expected_config in components.items():
                expected_file = expected_config["expected_file"]
                file_path = self.project_root / expected_file
                
                file_analysis = {
                    "exists": file_path.exists(),
                    "path": str(file_path),
                    "size": file_path.stat().st_size if file_path.exists() else 0,
                    "last_modified": datetime.fromtimestamp(file_path.stat().st_mtime).isoformat() if file_path.exists() else None
                }
                
                if file_path.exists():
                    # ÌååÏùº ÎÇ¥Ïö© Î∂ÑÏÑù
                    try:
                        with open(file_path, 'r', encoding='utf-8') as f:
                            content = f.read()
                        
                        # AST Î∂ÑÏÑù
                        tree = ast.parse(content)
                        class_analysis = self._analyze_class_structure(tree, component_name)
                        file_analysis.update(class_analysis)
                        
                    except Exception as e:
                        file_analysis["analysis_error"] = str(e)
                
                implementation_analysis["existing_files"][component_name] = file_analysis
        
        # 2. Ïã§Ï†ú Ïª¥Ìè¨ÎÑåÌä∏ ÏûÑÌè¨Ìä∏ Î∞è Î∂ÑÏÑù
        for category, components in self.DESIGN_EXPECTATIONS.items():
            for component_name, expected_config in components.items():
                try:
                    module_path = expected_config["expected_file"].replace('/', '.').replace('.py', '')
                    module = importlib.import_module(module_path)
                    
                    if hasattr(module, component_name):
                        component_class = getattr(module, component_name)
                        
                        # ÌÅ¥ÎûòÏä§ Î©îÏÑúÎìú Î∂ÑÏÑù
                        actual_methods = [method for method in dir(component_class) 
                                        if not method.startswith('_') and callable(getattr(component_class, method))]
                        
                        expected_methods = expected_config["expected_methods"]
                        missing_methods = set(expected_methods) - set(actual_methods)
                        extra_methods = set(actual_methods) - set(expected_methods)
                        
                        implementation_analysis["component_analysis"][component_name] = {
                            "class_exists": True,
                            "actual_methods": actual_methods,
                            "expected_methods": expected_methods,
                            "missing_methods": list(missing_methods),
                            "extra_methods": list(extra_methods),
                            "method_coverage": len(expected_methods) - len(missing_methods),
                            "coverage_percentage": ((len(expected_methods) - len(missing_methods)) / len(expected_methods)) * 100 if expected_methods else 100
                        }
                    else:
                        implementation_analysis["component_analysis"][component_name] = {
                            "class_exists": False,
                            "error": f"Class {component_name} not found in module"
                        }
                        
                except ImportError as e:
                    implementation_analysis["component_analysis"][component_name] = {
                        "import_error": str(e),
                        "module_path": module_path
                    }
                except Exception as e:
                    implementation_analysis["component_analysis"][component_name] = {
                        "analysis_error": str(e)
                    }
        
        return implementation_analysis
    
    def _analyze_class_structure(self, tree: ast.AST, expected_class_name: str) -> Dict[str, Any]:
        """
        ASTÎ•º ÏÇ¨Ïö©Ìïú ÌÅ¥ÎûòÏä§ Íµ¨Ï°∞ Î∂ÑÏÑù
        """
        class ClassAnalyzer(ast.NodeVisitor):
            def __init__(self):
                self.classes = {}
                self.functions = []
                self.imports = []
            
            def visit_ClassDef(self, node):
                methods = []
                for item in node.body:
                    if isinstance(item, ast.FunctionDef):
                        methods.append(item.name)
                
                self.classes[node.name] = {
                    "methods": methods,
                    "line_number": node.lineno,
                    "docstring": ast.get_docstring(node)
                }
                self.generic_visit(node)
            
            def visit_FunctionDef(self, node):
                if not any(isinstance(parent, ast.ClassDef) for parent in ast.walk(tree) if hasattr(parent, 'body') and node in getattr(parent, 'body', [])):
                    self.functions.append(node.name)
                self.generic_visit(node)
            
            def visit_Import(self, node):
                for alias in node.names:
                    self.imports.append(alias.name)
                self.generic_visit(node)
            
            def visit_ImportFrom(self, node):
                module = node.module or ""
                for alias in node.names:
                    self.imports.append(f"{module}.{alias.name}")
                self.generic_visit(node)
        
        analyzer = ClassAnalyzer()
        analyzer.visit(tree)
        
        return {
            "classes_found": list(analyzer.classes.keys()),
            "target_class_exists": expected_class_name in analyzer.classes,
            "target_class_methods": analyzer.classes.get(expected_class_name, {}).get("methods", []),
            "all_functions": analyzer.functions,
            "imports": analyzer.imports[:10]  # Ï≤òÏùå 10Í∞úÎßå
        }
    
    async def _identify_gaps(self, actual_implementation: Dict[str, Any]) -> Dict[str, Any]:
        """
        ÏÑ§Í≥ÑÏôÄ Íµ¨ÌòÑ Í∞ÑÏùò Ï∞®Ïù¥Ï†ê ÏãùÎ≥Ñ
        """
        gaps = {
            "missing_files": [],
            "missing_classes": [],
            "missing_methods": {},
            "method_coverage_gaps": {},
            "architectural_gaps": [],
            "implementation_quality_issues": []
        }
        
        # 1. ÌååÏùº Î∞è ÌÅ¥ÎûòÏä§ ÎàÑÎùΩ Î∂ÑÏÑù
        for component_name, file_analysis in actual_implementation["existing_files"].items():
            if not file_analysis["exists"]:
                gaps["missing_files"].append({
                    "component": component_name,
                    "expected_file": file_analysis["path"],
                    "impact": "Critical - Component cannot be imported"
                })
            elif not file_analysis.get("target_class_exists", False):
                gaps["missing_classes"].append({
                    "component": component_name,
                    "file": file_analysis["path"],
                    "impact": "Critical - Class not found in module"
                })
        
        # 2. Î©îÏÑúÎìú ÎàÑÎùΩ Î∂ÑÏÑù
        for component_name, component_analysis in actual_implementation["component_analysis"].items():
            if component_analysis.get("class_exists", False):
                missing_methods = component_analysis.get("missing_methods", [])
                if missing_methods:
                    gaps["missing_methods"][component_name] = {
                        "missing": missing_methods,
                        "coverage_percentage": component_analysis.get("coverage_percentage", 0),
                        "impact": "High - Interface incomplete"
                    }
                
                # Ïª§Î≤ÑÎ¶¨ÏßÄÍ∞Ä 80% ÎØ∏ÎßåÏù∏ Í≤ΩÏö∞
                coverage = component_analysis.get("coverage_percentage", 0)
                if coverage < 80:
                    gaps["method_coverage_gaps"][component_name] = {
                        "current_coverage": coverage,
                        "expected_coverage": 100,
                        "gap": 100 - coverage,
                        "impact": "Medium - Partial implementation"
                    }
        
        # 3. ÏïÑÌÇ§ÌÖçÏ≤ò Ìå®ÌÑ¥ Î∂ÑÏÑù
        # Zero-hardcoding ÏúÑÎ∞ò ÏÇ¨Ìï≠ (Ïù¥Ï†Ñ ÌÖåÏä§Ìä∏ Í≤∞Í≥º Í∏∞Î∞ò)
        gaps["architectural_gaps"] = [
            {
                "issue": "Legacy hardcoding patterns",
                "description": "31 critical hardcoding violations found in legacy files",
                "files_affected": ["cherry_ai_legacy.py", "core/query_processing/domain_extractor.py"],
                "impact": "Critical - Violates zero-hardcoding architecture"
            },
            {
                "issue": "Missing LLM factory dependency",
                "description": "Several components reference missing llm_factory module",
                "components_affected": ["ChainOfThoughtSelfConsistency", "ZeroShotAdaptiveReasoning"],
                "impact": "High - Components cannot initialize properly"
            }
        ]
        
        return gaps
    
    async def _generate_recommendations(self, gaps: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        Ï∞®Ïù¥Ï†ê Ìï¥Í≤∞ÏùÑ ÏúÑÌïú Í∂åÏû•ÏÇ¨Ìï≠ ÏÉùÏÑ±
        """
        recommendations = []
        
        # 1. ÎàÑÎùΩÎêú ÌååÏùº/ÌÅ¥ÎûòÏä§ Ìï¥Í≤∞
        if gaps["missing_files"] or gaps["missing_classes"]:
            recommendations.append({
                "priority": "Critical",
                "category": "Structure",
                "title": "Complete Missing Components",
                "description": "Implement missing files and classes to match design specifications",
                "action_items": [
                    "Create missing component files",
                    "Implement missing class definitions",
                    "Add proper class inheritance and initialization"
                ],
                "estimated_effort": "2-3 days"
            })
        
        # 2. Î©îÏÑúÎìú Ïù∏ÌÑ∞ÌéòÏù¥Ïä§ ÏôÑÏÑ±
        if gaps["missing_methods"]:
            recommendations.append({
                "priority": "High",
                "category": "Interface",
                "title": "Complete Method Interfaces",
                "description": "Implement missing methods to fulfill design contracts",
                "action_items": [
                    f"Implement missing methods for {len(gaps['missing_methods'])} components",
                    "Add proper method signatures and documentation",
                    "Implement basic functionality for each method",
                    "Add unit tests for new methods"
                ],
                "estimated_effort": "3-5 days"
            })
        
        # 3. ÏïÑÌÇ§ÌÖçÏ≤ò Ï†ïÎ¶¨
        if gaps["architectural_gaps"]:
            recommendations.append({
                "priority": "Critical",
                "category": "Architecture",
                "title": "Fix Architectural Violations",
                "description": "Remove hardcoding patterns and fix dependency issues",
                "action_items": [
                    "Remove 31 critical hardcoding violations from legacy files",
                    "Implement missing llm_factory module",
                    "Refactor hardcoded domain logic to LLM-based dynamic logic",
                    "Update component dependencies"
                ],
                "estimated_effort": "4-6 days"
            })
        
        # 4. ÌíàÏßà Í∞úÏÑ†
        recommendations.append({
            "priority": "Medium",
            "category": "Quality",
            "title": "Improve Implementation Quality",
            "description": "Enhance code quality and add comprehensive testing",
            "action_items": [
                "Add comprehensive unit tests for all components",
                "Improve error handling and logging",
                "Add performance monitoring and metrics",
                "Create integration tests"
            ],
            "estimated_effort": "5-7 days"
        })
        
        # 5. Î¨∏ÏÑúÌôî ÏóÖÎç∞Ïù¥Ìä∏
        recommendations.append({
            "priority": "Low",
            "category": "Documentation",
            "title": "Update Documentation",
            "description": "Align documentation with actual implementation",
            "action_items": [
                "Update design documents to reflect current implementation",
                "Add API documentation for all components",
                "Create implementation guides",
                "Update README and setup instructions"
            ],
            "estimated_effort": "2-3 days"
        })
        
        return recommendations
    
    def _print_gap_analysis_summary(self):
        """
        Ï∞®Ïù¥Ï†ê Î∂ÑÏÑù Í≤∞Í≥º ÏöîÏïΩ Ï∂úÎ†•
        """
        gaps = self.analysis_results["gaps"]
        recommendations = self.analysis_results["recommendations"]
        
        print("\n" + "="*80)
        print("üîç DESIGN vs IMPLEMENTATION GAP ANALYSIS SUMMARY")
        print("="*80)
        
        # Ï†ÑÏ≤¥ ÏÉÅÌô© ÏöîÏïΩ
        total_components = len(self.DESIGN_EXPECTATIONS["universal_engine_components"]) + \
                          len(self.DESIGN_EXPECTATIONS["a2a_integration"]) + \
                          len(self.DESIGN_EXPECTATIONS["cherry_ai_integration"])
        
        missing_files = len(gaps["missing_files"])
        missing_classes = len(gaps["missing_classes"])
        missing_methods_count = sum(len(methods["missing"]) for methods in gaps["missing_methods"].values())
        
        print(f"üìä Total Components Analyzed: {total_components}")
        print(f"üìÅ Missing Files: {missing_files}")
        print(f"üèóÔ∏è Missing Classes: {missing_classes}")
        print(f"‚öôÔ∏è Missing Methods: {missing_methods_count}")
        print(f"üèõÔ∏è Architectural Issues: {len(gaps['architectural_gaps'])}")
        
        # ÏÉÅÏÑ∏ Î∂ÑÏÑù
        if gaps["missing_files"]:
            print(f"\n‚ùå Missing Files ({len(gaps['missing_files'])}):")
            for missing in gaps["missing_files"]:
                print(f"  ‚Ä¢ {missing['component']}: {missing['expected_file']}")
        
        if gaps["missing_methods"]:
            print(f"\n‚öôÔ∏è Components with Missing Methods:")
            for component, method_info in gaps["missing_methods"].items():
                coverage = method_info["coverage_percentage"]
                print(f"  ‚Ä¢ {component}: {coverage:.1f}% coverage ({len(method_info['missing'])} missing)")
        
        if gaps["architectural_gaps"]:
            print(f"\nüèõÔ∏è Architectural Issues:")
            for issue in gaps["architectural_gaps"]:
                print(f"  ‚Ä¢ {issue['issue']}: {issue['description']}")
        
        # Í∂åÏû•ÏÇ¨Ìï≠ ÏöîÏïΩ
        print(f"\nüí° Recommendations ({len(recommendations)}):")
        for rec in recommendations:
            print(f"  {rec['priority']}: {rec['title']} ({rec['estimated_effort']})")
        
        # Ï†ÑÏ≤¥ ÌèâÍ∞Ä
        if missing_files == 0 and missing_classes == 0:
            if missing_methods_count == 0:
                print(f"\nüéâ Status: IMPLEMENTATION COMPLETE")
            elif missing_methods_count < 10:
                print(f"\n‚ö†Ô∏è Status: MOSTLY COMPLETE (minor method gaps)")
            else:
                print(f"\nüîß Status: INTERFACE INCOMPLETE (significant method gaps)")
        else:
            print(f"\nüí• Status: MAJOR GAPS (missing core components)")
        
        print("\n" + "="*80)
    
    def save_analysis_results(self, output_path: str = None):
        """
        Î∂ÑÏÑù Í≤∞Í≥ºÎ•º JSON ÌååÏùºÎ°ú Ï†ÄÏû•
        """
        if output_path is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_path = f"design_implementation_gap_analysis_{timestamp}.json"
        
        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(self.analysis_results, f, indent=2, ensure_ascii=False, default=str)
            logger.info(f"üíæ Gap analysis results saved to: {output_path}")
        except Exception as e:
            logger.error(f"üí• Failed to save analysis results: {str(e)}")

# ÎèÖÎ¶Ω Ïã§ÌñâÏùÑ ÏúÑÌïú Î©îÏù∏ Ìï®Ïàò
async def main():
    """
    ÏÑ§Í≥Ñ-Íµ¨ÌòÑ Ï∞®Ïù¥Ï†ê Î∂ÑÏÑù Î©îÏù∏ Ïã§Ìñâ Ìï®Ïàò
    """
    print("üîç Design vs Implementation Gap Analysis")
    print("="*60)
    
    analyzer = DesignImplementationGapAnalyzer()
    results = await analyzer.analyze_design_implementation_gaps()
    
    # Í≤∞Í≥º Ï†ÄÏû•
    analyzer.save_analysis_results()
    
    # Ï¢ÖÎ£å ÏΩîÎìú Í≤∞Ï†ï
    gaps = results["gaps"]
    if not gaps["missing_files"] and not gaps["missing_classes"] and not gaps["missing_methods"]:
        print("\nüéâ No significant gaps found!")
        return 0
    elif gaps["missing_files"] or gaps["missing_classes"]:
        print("\nüí• Critical gaps found - major components missing")
        return 2
    else:
        print("\n‚ö†Ô∏è Minor gaps found - implementation needs completion")
        return 1

if __name__ == "__main__":
    import asyncio
    exit_code = asyncio.run(main())
    sys.exit(exit_code)