"""
ğŸ§¬ AI_DS_Team Orchestrator - Advanced Data Science with A2A Protocol
Smart Data Analystì˜ ìš°ìˆ˜í•œ íŒ¨í„´ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ AI_DS_Team í†µí•© ì‹œìŠ¤í…œ

í•µì‹¬ íŠ¹ì§•:
- AI_DS_Team Integration: 9ê°œ ì „ë¬¸ ì—ì´ì „íŠ¸ í™œìš©
- A2A Orchestration: LLM ê¸°ë°˜ ì§€ëŠ¥í˜• ì—ì´ì „íŠ¸ ì„ íƒ
- Real-time Processing: ì‹¤ì‹œê°„ ì‘ì—… ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§  
- Professional Results: ì „ë¬¸ì ì¸ ë°ì´í„° ê³¼í•™ ê²°ê³¼ ì œê³µ
"""

import streamlit as st
import sys
import os
import asyncio
import logging
import platform
from datetime import datetime
from dotenv import load_dotenv
import nest_asyncio
import pandas as pd
import json
import httpx
import time
import plotly.graph_objects as go
import plotly.express as px
import plotly.io as pio
from typing import Dict, Any, Tuple, List
import traceback
from pathlib import Path
import uuid
import numpy as np
import base64
import contextlib

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€ (ai.pyëŠ” í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— ìœ„ì¹˜)
project_root = os.path.dirname(os.path.abspath(__file__))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

# ì‹ ê·œ A2A í´ë¼ì´ì–¸íŠ¸ ë° ìœ í‹¸ë¦¬í‹° ì„í¬íŠ¸
from core.a2a.a2a_streamlit_client import A2AStreamlitClient
from core.utils.logging import setup_logging
from core.data_manager import DataManager  # DataManager ì¶”ê°€
from core.session_data_manager import SessionDataManager  # ì„¸ì…˜ ê¸°ë°˜ ë°ì´í„° ê´€ë¦¬ì ì¶”ê°€
from ui.thinking_stream import ThinkingStream, PlanVisualization, BeautifulResults # ê¸°ì¡´ í´ë˜ìŠ¤ í™œìš© ê°€ëŠ¥

# Phase 3 Integration Layer ë° Expert UI ì„í¬íŠ¸
try:
    from core.phase3_integration_layer import Phase3IntegrationLayer
    from ui.expert_answer_renderer import ExpertAnswerRenderer
    PHASE3_AVAILABLE = True
    print("âœ… Phase 3 Integration Layer ë¡œë“œ ì„±ê³µ")
except ImportError as e:
    PHASE3_AVAILABLE = False
    print(f"âš ï¸ Phase 3 Integration Layer ë¡œë“œ ì‹¤íŒ¨: {e}")

# ë””ë²„ê¹… ë¡œê±° ì„¤ì •
debug_logger = logging.getLogger("ai_ds_debug")
debug_logger.setLevel(logging.DEBUG)
if not debug_logger.handlers:
    handler = logging.StreamHandler()
    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    handler.setFormatter(formatter)
    debug_logger.addHandler(handler)

def debug_log(message: str, level: str = "info"):
    """í–¥ìƒëœ ë””ë²„ê¹… ë¡œê·¸ - ì‚¬ì´ë“œë°” ì„¤ì •ì— ë”°ë¼ ì œì–´"""
    timestamp = datetime.now().strftime("%H:%M:%S.%f")[:-3]
    
    # ë””ë²„ê¹… ëª¨ë“œ í™•ì¸ (ì„¸ì…˜ ìƒíƒœì—ì„œ)
    debug_enabled = getattr(st.session_state, 'debug_enabled', False)
    
    # ë¡œê·¸ ë©”ì‹œì§€ í¬ë§·
    if level == "error":
        log_msg = f"[{timestamp}] âŒ ERROR: {message}"
        debug_logger.error(message)
    elif level == "warning":
        log_msg = f"[{timestamp}] âš ï¸  WARNING: {message}"
        debug_logger.warning(message)
    elif level == "success":
        log_msg = f"[{timestamp}] âœ… SUCCESS: {message}"
        debug_logger.info(message)
    else:
        log_msg = f"[{timestamp}] â„¹ï¸  INFO: {message}"
        debug_logger.info(message)
    
    # í„°ë¯¸ë„ ì¶œë ¥ (í•­ìƒ í‘œì‹œ)
    print(log_msg)
    
    # íŒŒì¼ì—ë„ ê¸°ë¡ (ë””ë²„ê¹…ìš©)
    try:
        os.makedirs("logs", exist_ok=True)
        with open("logs/streamlit_debug.log", "a", encoding="utf-8") as f:
            f.write(f"{log_msg}\n")
            f.flush()
    except Exception as e:
        print(f"[{timestamp}] âŒ ë¡œê·¸ íŒŒì¼ ê¸°ë¡ ì‹¤íŒ¨: {e}")
    
    # Streamlit UIì—ëŠ” ë””ë²„ê¹… ëª¨ë“œê°€ ì¼œì ¸ìˆì„ ë•Œë§Œ í‘œì‹œ
    if debug_enabled:
        try:
            if level == "error":
                st.error(f"ğŸ› DEBUG: {message}")
            elif level == "warning":
                st.warning(f"ğŸ› DEBUG: {message}")
            elif level == "success":
                st.success(f"ğŸ› DEBUG: {message}")
            else:
                st.info(f"ğŸ› DEBUG: {message}")
        except:
            pass  # Streamlit ì»¨í…ìŠ¤íŠ¸ê°€ ì—†ì„ ë•ŒëŠ” ë¬´ì‹œ

# ìƒˆë¡œìš´ UI ì»´í¬ë„ŒíŠ¸ ì„í¬íŠ¸
try:
    from core.ui.smart_display import SmartDisplayManager, AccumulativeStreamContainer
    from core.ui.a2a_orchestration_ui import A2AOrchestrationDashboard
    from core.ui.agent_preloader import AgentPreloader, get_agent_preloader, ProgressiveLoadingUI, AgentStatus
    SMART_UI_AVAILABLE = True
    print("âœ… Smart UI ì»´í¬ë„ŒíŠ¸ ë¡œë“œ ì„±ê³µ")
except ImportError as e:
    SMART_UI_AVAILABLE = False
    print(f"âš ï¸ Smart UI ì»´í¬ë„ŒíŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")

# AI_DS_Team ìœ í‹¸ë¦¬í‹° ì„í¬íŠ¸
try:
    # ë””ë²„ê¹… ì •ë³´ ì¶œë ¥
    ai_ds_team_path = os.path.join(project_root, "ai_ds_team")
    ai_data_science_team_path = os.path.join(ai_ds_team_path, "ai_data_science_team")
    tools_path = os.path.join(ai_data_science_team_path, "tools")
    dataframe_path = os.path.join(tools_path, "dataframe.py")
    
    debug_log(f"ğŸ” í”„ë¡œì íŠ¸ ë£¨íŠ¸: {project_root}")
    debug_log(f"ğŸ” ai_ds_team ê²½ë¡œ: {ai_ds_team_path} (ì¡´ì¬: {os.path.exists(ai_ds_team_path)})")
    debug_log(f"ğŸ” ai_data_science_team ê²½ë¡œ: {ai_data_science_team_path} (ì¡´ì¬: {os.path.exists(ai_data_science_team_path)})")
    debug_log(f"ğŸ” dataframe.py ê²½ë¡œ: {dataframe_path} (ì¡´ì¬: {os.path.exists(dataframe_path)})")
    
    # ai_ds_team í´ë” ì•ˆì˜ ai_data_science_team ëª¨ë“ˆ ê²½ë¡œ ì¶”ê°€
    if ai_ds_team_path not in sys.path:
        sys.path.insert(0, ai_ds_team_path)
        debug_log(f"âœ… Python pathì— ì¶”ê°€ë¨: {ai_ds_team_path}")
    
    from ai_data_science_team.tools.dataframe import get_dataframe_summary
    AI_DS_TEAM_UTILS_AVAILABLE = True
    debug_log("âœ… AI_DS_Team ìœ í‹¸ë¦¬í‹° ë¡œë“œ ì„±ê³µ")
except ImportError as e:
    # ì™„ì „íˆ ì¡°ìš©í•œ fallback (ê²½ê³  ë©”ì‹œì§€ ì œê±°)
    AI_DS_TEAM_UTILS_AVAILABLE = False
    def get_dataframe_summary(df): return [f"Shape: {df.shape}"]
    # í„°ë¯¸ë„ì—ë§Œ ë¡œê·¸ ì¶œë ¥, UIì—ëŠ” í‘œì‹œí•˜ì§€ ì•ŠìŒ
    print(f"[INFO] AI_DS_Team ìœ í‹¸ë¦¬í‹° ë¡œë“œ ì‹¤íŒ¨ (ì •ìƒ ë™ì‘): {e}")
except Exception as e:
    # ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ì˜ ê²½ìš°ì—ë§Œ ë¡œê·¸
    AI_DS_TEAM_UTILS_AVAILABLE = False
    def get_dataframe_summary(df): return [f"Shape: {df.shape}"]
    debug_log(f"âš ï¸ AI_DS_Team ìœ í‹¸ë¦¬í‹° ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}", "warning")

# Langfuse Session Tracking ì¶”ê°€
try:
    from core.langfuse_session_tracer import init_session_tracer, get_session_tracer, LANGFUSE_AVAILABLE
    LANGFUSE_SESSION_AVAILABLE = True
    print("âœ… Langfuse Session Tracer ë¡œë“œ ì„±ê³µ")
except ImportError as e:
    LANGFUSE_SESSION_AVAILABLE = False
    print(f"âš ï¸ Langfuse Session Tracer ë¡œë“œ ì‹¤íŒ¨: {e}")

# --- ì´ˆê¸° ì„¤ì • ---
setup_logging()

# Langfuse ì´ˆê¸°í™” (í™˜ê²½ë³€ìˆ˜ì—ì„œ ì„¤ì • ê°€ì ¸ì˜¤ê¸°)
if LANGFUSE_SESSION_AVAILABLE:
    try:
        langfuse_public_key = os.getenv("LANGFUSE_PUBLIC_KEY")
        langfuse_secret_key = os.getenv("LANGFUSE_SECRET_KEY")
        langfuse_host = os.getenv("LANGFUSE_HOST", "http://localhost:3000")
        
        if langfuse_public_key and langfuse_secret_key:
            init_session_tracer(langfuse_public_key, langfuse_secret_key, langfuse_host)
            debug_log("ğŸ” Langfuse Session Tracer ì´ˆê¸°í™” ì„±ê³µ", "success")
        else:
            debug_log("âš ï¸ Langfuse í™˜ê²½ë³€ìˆ˜ ë¯¸ì„¤ì • - ì¶”ì  ë¹„í™œì„±í™”", "warning")
    except Exception as e:
        debug_log(f"âŒ Langfuse ì´ˆê¸°í™” ì‹¤íŒ¨: {e}", "error")

def setup_environment():
    """í™˜ê²½ ì„¤ì •"""
    debug_log("í™˜ê²½ ì„¤ì • ì‹œì‘")
    if platform.system() == "Windows":
        asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())
        debug_log("Windows ì´ë²¤íŠ¸ ë£¨í”„ ì •ì±… ì„¤ì •")
    nest_asyncio.apply()
    load_dotenv()
    debug_log("í™˜ê²½ ì„¤ì • ì™„ë£Œ")

def apply_custom_styling():
    st.markdown("""
    <style>
        .stApp { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; }
        .agent-card { background: rgba(255, 255, 255, 0.1); color: white; padding: 1.5rem; border-radius: 12px; margin: 0.5rem; border: 1px solid rgba(255, 255, 255, 0.2); transition: transform 0.3s ease; }
        .agent-card:hover { transform: translateY(-5px); background: rgba(255, 255, 255, 0.2); }
        .stButton > button { background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%); color: white; border: none; border-radius: 8px; padding: 0.7rem 1.5rem; font-weight: 600; }
        .debug-box { background: rgba(255, 255, 255, 0.1); border: 1px solid #ffd700; border-radius: 8px; padding: 10px; margin: 5px 0; }
    </style>
    """, unsafe_allow_html=True)

# --- AI_DS_Team ì—ì´ì „íŠ¸ ì •ë³´ ---
AI_DS_TEAM_AGENTS = {
    "Orchestrator": {"port": 8100, "description": "AI DS Teamì„ ì§€íœ˜í•˜ëŠ” ë§ˆì—ìŠ¤íŠ¸ë¡œ", "capabilities": ["planning", "delegation"], "color": "#FAD02E"},
    "ğŸ§¹ Data Cleaning": {"port": 8306, "description": "ëˆ„ë½ê°’ ì²˜ë¦¬, ì´ìƒì¹˜ ì œê±°", "capabilities": ["missing_value", "outlier"], "color": "#FF6B6B"},
    "ğŸ“Š Data Visualization": {"port": 8308, "description": "ê³ ê¸‰ ì‹œê°í™” ìƒì„±", "capabilities": ["charts", "plots"], "color": "#4ECDC4"},
    "ğŸ” EDA Tools": {"port": 8312, "description": "ìë™ EDA ë° ìƒê´€ê´€ê³„ ë¶„ì„", "capabilities": ["eda", "correlation"], "color": "#45B7D1"},
    "ğŸ“ Data Loader": {"port": 8307, "description": "ë‹¤ì–‘í•œ ë°ì´í„° ì†ŒìŠ¤ ë¡œë”©", "capabilities": ["load_file", "connect_db"], "color": "#96CEB4"},
    "ğŸ”§ Data Wrangling": {"port": 8309, "description": "ë°ì´í„° ë³€í™˜ ë° ì¡°ì‘", "capabilities": ["transform", "aggregate"], "color": "#FFEAA7"},
    "âš™ï¸ Feature Engineering": {"port": 8310, "description": "ê³ ê¸‰ í”¼ì²˜ ìƒì„± ë° ì„ íƒ", "capabilities": ["feature_creation", "selection"], "color": "#DDA0DD"},
    "ğŸ—„ï¸ SQL Database": {"port": 8311, "description": "SQL ë°ì´í„°ë² ì´ìŠ¤ ë¶„ì„", "capabilities": ["sql_query", "db_analysis"], "color": "#F39C12"},
    "ğŸ¤– H2O ML": {"port": 8313, "description": "H2O AutoML ê¸°ë°˜ ë¨¸ì‹ ëŸ¬ë‹", "capabilities": ["automl", "model_training"], "color": "#9B59B6"},
    "ğŸ“ˆ MLflow Tools": {"port": 8314, "description": "MLflow ì‹¤í—˜ ê´€ë¦¬", "capabilities": ["experiment_tracking", "model_registry"], "color": "#E74C3C"}
}

# ì—ì´ì „íŠ¸ ì´ë¦„ ë§¤í•‘ (ê³„íšì—ì„œ ì‚¬ìš©í•˜ëŠ” ì´ë¦„ -> ì‹¤ì œ ì—ì´ì „íŠ¸ ì´ë¦„)
AGENT_NAME_MAPPING = {
    "data_loader": "ğŸ“ Data Loader",
    "data_cleaning": "ğŸ§¹ Data Cleaning", 
    "data_wrangling": "ğŸ”§ Data Wrangling",
    "eda_tools": "ğŸ” EDA Tools",
    "data_visualization": "ğŸ“Š Data Visualization",
    "feature_engineering": "âš™ï¸ Feature Engineering",
    "sql_database": "ğŸ—„ï¸ SQL Database",
    "h2o_ml": "ğŸ¤– H2O ML",
    "mlflow_tools": "ğŸ“ˆ MLflow Tools",
    # ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ê³„íšì—ì„œ ì‚¬ìš©í•˜ëŠ” ì´ë¦„ë“¤ ì¶”ê°€ (ì •í™•í•œ Agent Card name ì‚¬ìš©)
    "AI_DS_Team EDAToolsAgent": "ğŸ” EDA Tools",
    "AI_DS_Team DataLoaderToolsAgent": "ğŸ“ Data Loader",
    "AI_DS_Team DataCleaningAgent": "ğŸ§¹ Data Cleaning",
    "AI_DS_Team DataVisualizationAgent": "ğŸ“Š Data Visualization",
    "AI_DS_Team SQLDatabaseAgent": "ğŸ—„ï¸ SQL Database",
    "AI_DS_Team DataWranglingAgent": "ğŸ”§ Data Wrangling",
    # í˜¸í™˜ì„±ì„ ìœ„í•´ ê¸°ì¡´ ì´ë¦„ë„ ìœ ì§€
    "SessionEDAToolsAgent": "ğŸ” EDA Tools",
    # í˜¸í™˜ì„±ì„ ìœ„í•´ ê¸°ì¡´ ì´ë¦„ë„ ìœ ì§€
    "SessionEDAToolsAgent": "ğŸ” EDA Tools"
}

def map_agent_name(plan_agent_name: str) -> str:
    """ê³„íšì—ì„œ ì‚¬ìš©í•˜ëŠ” ì—ì´ì „íŠ¸ ì´ë¦„ì„ ì‹¤ì œ ì—ì´ì „íŠ¸ ì´ë¦„ìœ¼ë¡œ ë§¤í•‘"""
    return AGENT_NAME_MAPPING.get(plan_agent_name, plan_agent_name)

def initialize_session_state():
    """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
    if "messages" not in st.session_state: st.session_state.messages = []
    if "session_id" not in st.session_state: st.session_state.session_id = f"ui_{datetime.now().strftime('%Y%m%d%H%M%S')}"
    if "uploaded_data" not in st.session_state: st.session_state.uploaded_data = None
    if "data_id" not in st.session_state: st.session_state.data_id = None
    if "a2a_client" not in st.session_state: st.session_state.a2a_client = A2AStreamlitClient(AI_DS_TEAM_AGENTS)
    if "agent_status" not in st.session_state: st.session_state.agent_status = {}
    if "active_agent" not in st.session_state: st.session_state.active_agent = None
    if "data_manager" not in st.session_state: st.session_state.data_manager = DataManager()  # DataManager ì¶”ê°€
    if "session_data_manager" not in st.session_state: st.session_state.session_data_manager = SessionDataManager()  # ì„¸ì…˜ ê¸°ë°˜ ë°ì´í„° ê´€ë¦¬ì ì¶”ê°€
    # í”„ë¦¬ë¡œë” ì´ˆê¸°í™” ìƒíƒœ ì¶”ê°€
    if "preloader_initialized" not in st.session_state: st.session_state.preloader_initialized = False
    if "agents_preloaded" not in st.session_state: st.session_state.agents_preloaded = False

@st.cache_resource
def initialize_agent_preloader():
    """ì—ì´ì „íŠ¸ í”„ë¦¬ë¡œë” ì´ˆê¸°í™” (ìºì‹œë¨)"""
    return get_agent_preloader(AI_DS_TEAM_AGENTS)

async def preload_agents_with_ui():
    """UIì™€ í•¨ê»˜ ì—ì´ì „íŠ¸ í”„ë¦¬ë¡œë”©"""
    if st.session_state.agents_preloaded:
        debug_log("âœ… ì—ì´ì „íŠ¸ê°€ ì´ë¯¸ í”„ë¦¬ë¡œë“œë¨", "success")
        return st.session_state.agent_status
    
    # í”„ë¦¬ë¡œë” ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
    preloader = initialize_agent_preloader()
    
    # ë¡œë”© UI ì„¤ì •
    loading_container = st.container()
    loading_ui = ProgressiveLoadingUI(loading_container)
    loading_ui.setup_ui()
    
    # ì§„í–‰ ìƒí™© ì½œë°± í•¨ìˆ˜
    def progress_callback(completed, total, current_task):
        loading_ui.update_progress(completed, total, current_task)
        debug_log(f"ğŸ“‹ {current_task} ({completed}/{total})")
    
    try:
        # ì—ì´ì „íŠ¸ í”„ë¦¬ë¡œë”© ì‹¤í–‰
        debug_log("ğŸš€ ì—ì´ì „íŠ¸ í”„ë¦¬ë¡œë”© ì‹œì‘...", "success")
        agents_info = await preloader.preload_agents(progress_callback)
        
        # ê¸°ì¡´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (í˜¸í™˜ì„± ìœ ì§€)
        agent_status = {}
        for name, agent_info in agents_info.items():
            status_icon = "âœ…" if agent_info.status == AgentStatus.READY else "âŒ"
            agent_status[name] = {
                "status": status_icon,
                "description": agent_info.description,
                "port": agent_info.port,
                "capabilities": agent_info.capabilities,
                "color": agent_info.color,
                "initialization_time": agent_info.initialization_time,
                "error_message": agent_info.error_message
            }
        
        # ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸
        st.session_state.agent_status = agent_status
        st.session_state.agents_preloaded = True
        
        # ì™„ë£Œ ìƒíƒœ í‘œì‹œ
        summary = preloader.get_initialization_summary()
        loading_ui.show_completion(summary)
        
        debug_log(f"âœ… ì—ì´ì „íŠ¸ í”„ë¦¬ë¡œë”© ì™„ë£Œ: {summary['ready_agents']}/{summary['total_agents']} ì¤€ë¹„ë¨", "success")
        
        # ë¡œë”© UI ì •ë¦¬ (ì ì‹œ í›„)
        time.sleep(2)
        loading_container.empty()
        
        return agent_status
        
    except Exception as e:
        debug_log(f"âŒ ì—ì´ì „íŠ¸ í”„ë¦¬ë¡œë”© ì‹¤íŒ¨: {e}", "error")
        loading_container.error(f"ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        
        # í´ë°±: ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ìƒíƒœ í™•ì¸
        debug_log("ğŸ”„ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ í´ë°±...", "warning")
        try:
            fallback_status = await check_agents_status_async()
            st.session_state.agent_status = fallback_status
            debug_log("âœ… í´ë°± ì—ì´ì „íŠ¸ ìƒíƒœ í™•ì¸ ì™„ë£Œ", "success")
            return fallback_status
        except Exception as fallback_error:
            debug_log(f"âŒ í´ë°±ë„ ì‹¤íŒ¨: {fallback_error}", "error")
            # ìµœí›„ì˜ í´ë°±: ë¹ˆ ìƒíƒœ ë°˜í™˜
            return {}

async def check_agents_status_async():
    """AI_DS_Team ì—ì´ì „íŠ¸ ìƒíƒœ ë¹„ë™ê¸° í™•ì¸ (ê°œì„ ëœ ë²„ì „)"""
    debug_log("ğŸ” ì—ì´ì „íŠ¸ ìƒíƒœ ì§ì ‘ í™•ì¸ ì‹œì‘...")
    
    async with httpx.AsyncClient(timeout=5.0) as client:  # íƒ€ì„ì•„ì›ƒ ì¦ê°€
        results = {}
        
        # ê° ì—ì´ì „íŠ¸ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ í™•ì¸ (ì•ˆì •ì„± í–¥ìƒ)
        for name, info in AI_DS_TEAM_AGENTS.items():
            port = info['port']
            try:
                debug_log(f"ğŸ” {name} (í¬íŠ¸ {port}) í™•ì¸ ì¤‘...")
                response = await client.get(f"http://localhost:{port}/.well-known/agent.json")
                
                if response.status_code == 200:
                    agent_card = response.json()
                    actual_name = agent_card.get('name', 'Unknown')
                    debug_log(f"âœ… {name} ì‘ë‹µ: {actual_name}")
                    
                    results[name] = {
                        "status": "âœ…", 
                        "description": info['description'],
                        "port": port,
                        "capabilities": info.get('capabilities', []),
                        "color": info.get('color', '#ffffff'),
                        "actual_name": actual_name  # ì‹¤ì œ ì—ì´ì „íŠ¸ ì´ë¦„ ì €ì¥
                    }
                else:
                    debug_log(f"âŒ {name} ì‘ë‹µ ì‹¤íŒ¨: HTTP {response.status_code}")
                    results[name] = {
                        "status": "âŒ", 
                        "description": info['description'],
                        "port": port,
                        "capabilities": info.get('capabilities', []),
                        "color": info.get('color', '#ffffff'),
                        "error": f"HTTP {response.status_code}"
                    }
                    
            except Exception as e:
                debug_log(f"âŒ {name} ì—°ê²° ì‹¤íŒ¨: {e}")
                results[name] = {
                    "status": "âŒ", 
                    "description": info['description'],
                    "port": port,
                    "capabilities": info.get('capabilities', []),
                    "color": info.get('color', '#ffffff'),
                    "error": str(e)
                }
        
        debug_log(f"âœ… ì—ì´ì „íŠ¸ ìƒíƒœ í™•ì¸ ì™„ë£Œ: {len(results)}ê°œ")
        return results

def display_agent_status():
    st.markdown("### ğŸ§¬ AI_DS_Team ì—ì´ì „íŠ¸ ìƒíƒœ")
    cols = st.columns(3)
    status = st.session_state.agent_status
    sorted_agents = sorted(status.items(), key=lambda x: (x[1]['status'] == "âŒ", x[0]))
    for idx, (name, info) in enumerate(sorted_agents):
        border_style = "2px solid #f093fb" if st.session_state.active_agent == name else "1px solid rgba(255, 255, 255, 0.2)"
        with cols[idx % 3]:
            st.markdown(f"""
            <div class="agent-card" style="border: {border_style};">
                <h4>{info['status']} {name}</h4>
                <p><small>{info['description']}</small></p>
            </div>""", unsafe_allow_html=True)

def render_artifact(artifact_data: Dict[str, Any]):
    """ì•„í‹°íŒ©íŠ¸ ë Œë”ë§ - ì™„ì „íˆ ì¬ì‘ì„±ëœ ë²„ì „"""
    try:
        debug_log(f"ğŸ¨ ì•„í‹°íŒ©íŠ¸ ë Œë”ë§ ì‹œì‘: {artifact_data.get('name', 'Unknown')}")
        
        name = artifact_data.get('name', 'Unknown')
        parts = artifact_data.get('parts', [])
        metadata = artifact_data.get('metadata', {})
        content_type = artifact_data.get('contentType', metadata.get('content_type', 'text/plain'))
        
        if not parts:
            st.warning("ì•„í‹°íŒ©íŠ¸ì— í‘œì‹œí•  ì½˜í…ì¸ ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ì•„í‹°íŒ©íŠ¸ë³„ ì»¨í…Œì´ë„ˆ ìƒì„± (ì¤‘ë³µ ë°©ì§€)
        with st.container():
            # í—¤ë” í‘œì‹œ
            if name != 'Unknown':
                st.markdown(f"### ğŸ“¦ {name}")
            
            for i, part in enumerate(parts):
                try:
                    # Part êµ¬ì¡° íŒŒì‹±
                    if isinstance(part, dict):
                        part_kind = part.get("kind", part.get("type", "unknown"))
                        
                        if part_kind == "text":
                            text_content = part.get("text", "")
                            if not text_content:
                                continue
                            
                            # ì»¨í…ì¸  íƒ€ì…ë³„ ë Œë”ë§
                            if content_type == "application/vnd.plotly.v1+json":
                                # Plotly ì°¨íŠ¸ JSON ë°ì´í„° ì²˜ë¦¬
                                _render_plotly_chart(text_content, name, i)
                                
                            elif content_type == "text/x-python" or "```python" in text_content:
                                # Python ì½”ë“œ ë Œë”ë§
                                _render_python_code(text_content)
                                
                            elif content_type == "text/markdown" or text_content.startswith("#"):
                                # ë§ˆí¬ë‹¤ìš´ ë Œë”ë§
                                _render_markdown_content(text_content)
                                
                            else:
                                # ì¼ë°˜ í…ìŠ¤íŠ¸ ë Œë”ë§
                                _render_general_text(text_content)
                        
                        elif part_kind == "data":
                            # ë°ì´í„° Part ì²˜ë¦¬
                            data_content = part.get("data", {})
                            _render_data_content(data_content, content_type, name, i)
                        
                        else:
                            # ì•Œ ìˆ˜ ì—†ëŠ” íƒ€ì…
                            st.json(part)
                    
                    else:
                        # ë¬¸ìì—´ì´ë‚˜ ê¸°íƒ€ íƒ€ì…
                        st.text(str(part))
                        
                except Exception as part_error:
                    debug_log(f"âŒ Part {i} ë Œë”ë§ ì‹¤íŒ¨: {part_error}", "error")
                    with st.expander(f"ğŸ” Part {i} ì˜¤ë¥˜ ì •ë³´"):
                        st.error(f"ë Œë”ë§ ì˜¤ë¥˜: {part_error}")
                        st.json(part)
        
        debug_log("âœ… ì•„í‹°íŒ©íŠ¸ ë Œë”ë§ ì™„ë£Œ")
        
    except Exception as e:
        debug_log(f"ğŸ’¥ ì•„í‹°íŒ©íŠ¸ ë Œë”ë§ ì „ì²´ ì˜¤ë¥˜: {e}", "error")
        st.error(f"ì•„í‹°íŒ©íŠ¸ ë Œë”ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

def _render_plotly_chart(json_text: str, name: str, index: int):
    """Plotly ì°¨íŠ¸ ì „ìš© ë Œë”ë§"""
    try:
        import plotly.io as pio
        import plotly.graph_objects as go
        import json
        import numpy as np
        import base64
        from datetime import datetime
        import uuid
        
        debug_log("ğŸ” Plotly ì°¨íŠ¸ ë°ì´í„° íŒŒì‹± ì‹œì‘...")
        
        # JSON íŒŒì‹±
        try:
            chart_data = json.loads(json_text)
        except json.JSONDecodeError as e:
            debug_log(f"âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {e}", "error")
            st.error("ì°¨íŠ¸ ë°ì´í„° JSON íŒŒì‹± ì‹¤íŒ¨")
            with st.expander("ğŸ” ì›ì‹œ ë°ì´í„°"):
                st.text(json_text[:500] + "..." if len(json_text) > 500 else json_text)
            return
        
        # Binary data ë””ì½”ë”© í•¨ìˆ˜
        def decode_plotly_binary_data(data_dict):
            """Plotly binary dataë¥¼ ì‹¤ì œ ê°’ìœ¼ë¡œ ë³€í™˜"""
            if isinstance(data_dict, dict):
                for key, value in data_dict.items():
                    if isinstance(value, dict) and 'dtype' in value and 'bdata' in value:
                        try:
                            if value['dtype'] == 'f8':  # float64
                                binary_data = base64.b64decode(value['bdata'])
                                float_array = np.frombuffer(binary_data, dtype=np.float64)
                                data_dict[key] = float_array.tolist()
                                debug_log(f"âœ… Binary float64 ë””ì½”ë”© ì„±ê³µ: {key}")
                            elif value['dtype'] == 'i8':  # int64
                                binary_data = base64.b64decode(value['bdata'])
                                int_array = np.frombuffer(binary_data, dtype=np.int64)
                                data_dict[key] = int_array.tolist()
                                debug_log(f"âœ… Binary int64 ë””ì½”ë”© ì„±ê³µ: {key}")
                        except Exception as decode_error:
                            debug_log(f"âŒ Binary data ë””ì½”ë”© ì‹¤íŒ¨ {key}: {decode_error}", "error")
                    elif isinstance(value, (dict, list)):
                        if isinstance(value, dict):
                            decode_plotly_binary_data(value)
                        elif isinstance(value, list):
                            for item in value:
                                if isinstance(item, dict):
                                    decode_plotly_binary_data(item)
            return data_dict
        
        # Binary data ë””ì½”ë”© ì ìš©
        chart_data = decode_plotly_binary_data(chart_data)
        
        # Plotly Figure ìƒì„±
        try:
            if isinstance(chart_data, dict):
                # ë°ì´í„° êµ¬ì¡° í™•ì¸
                if 'data' in chart_data and 'layout' in chart_data:
                    # í‘œì¤€ Plotly êµ¬ì¡°
                    plot_data = chart_data['data']
                    layout = chart_data['layout']
                elif 'data' in chart_data and isinstance(chart_data['data'], dict) and 'data' in chart_data['data']:
                    # ì¤‘ì²©ëœ êµ¬ì¡°
                    plot_data = chart_data['data']['data']
                    layout = chart_data['data'].get('layout', {})
                else:
                    # ì „ì²´ë¥¼ Figureë¡œ ì‹œë„
                    plot_data = chart_data.get('data', [])
                    layout = chart_data.get('layout', {})
                
                fig = go.Figure(data=plot_data, layout=layout)
            else:
                # JSON ë¬¸ìì—´ë¡œ ì§ì ‘ ë³€í™˜
                fig = pio.from_json(json.dumps(chart_data))
            
            # ì°¨íŠ¸ ìµœì í™”
            fig.update_layout(
                showlegend=True,
                margin=dict(l=20, r=20, t=40, b=20),
                font=dict(size=12),
                plot_bgcolor='rgba(0,0,0,0)',
                paper_bgcolor='rgba(0,0,0,0)'
            )
            
            # ê³ ìœ  í‚¤ ìƒì„±
            chart_id = f"plotly_{name}_{index}_{uuid.uuid4().hex[:8]}_{datetime.now().strftime('%H%M%S%f')}"
            
            # ì°¨íŠ¸ í‘œì‹œ
            st.markdown("#### ğŸ“Š ì¸í„°ë™í‹°ë¸Œ ì°¨íŠ¸")
            st.plotly_chart(fig, key=chart_id, use_container_width=True)
            debug_log("âœ… Plotly ì°¨íŠ¸ ë Œë”ë§ ì„±ê³µ!")
            
        except Exception as fig_error:
            debug_log(f"âŒ Plotly Figure ìƒì„± ì‹¤íŒ¨: {fig_error}", "error")
            st.error(f"ì°¨íŠ¸ ìƒì„± ì˜¤ë¥˜: {fig_error}")
            
            # ìƒì„¸ ì˜¤ë¥˜ ì •ë³´
            with st.expander("ğŸ” ì°¨íŠ¸ ì˜¤ë¥˜ ìƒì„¸ ì •ë³´"):
                st.text(f"ì˜¤ë¥˜ íƒ€ì…: {type(fig_error).__name__}")
                st.text(f"ì˜¤ë¥˜ ë©”ì‹œì§€: {str(fig_error)}")
                st.markdown("**ì›ì‹œ ì°¨íŠ¸ ë°ì´í„° (ì²˜ìŒ 1000ì):**")
                st.json(json.loads(json_text[:1000]) if len(json_text) > 1000 else json.loads(json_text))
                
    except Exception as e:
        debug_log(f"âŒ Plotly ì°¨íŠ¸ ë Œë”ë§ ì „ì²´ ì‹¤íŒ¨: {e}", "error")
        st.error(f"Plotly ì°¨íŠ¸ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")

def _render_python_code(text_content: str):
    """Python ì½”ë“œ ì˜ˆì˜ê²Œ ë Œë”ë§"""
    try:
        # ì½”ë“œ ë¸”ë¡ ì¶”ì¶œ
        if "```python" in text_content:
            # ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ì—ì„œ ì½”ë“œë§Œ ì¶”ì¶œ
            parts = text_content.split("```python")
            for i, part in enumerate(parts[1:], 1):
                if "```" in part:
                    code = part.split("```")[0].strip()
                    if code:
                        st.markdown(f"#### ğŸ Python ì½”ë“œ #{i}")
                        st.code(code, language='python')
        else:
            # ì „ì²´ê°€ ì½”ë“œì¸ ê²½ìš°
            st.markdown("#### ğŸ Python ì½”ë“œ")
            st.code(text_content, language='python')
            
        debug_log("âœ… Python ì½”ë“œ ë Œë”ë§ ì™„ë£Œ")
        
    except Exception as e:
        debug_log(f"âŒ Python ì½”ë“œ ë Œë”ë§ ì‹¤íŒ¨: {e}", "error")
        st.text(text_content)

def _render_markdown_content(text_content: str):
    """ë§ˆí¬ë‹¤ìš´ ì˜ˆì˜ê²Œ ë Œë”ë§"""
    try:
        # ì»¤ìŠ¤í…€ CSS ìŠ¤íƒ€ì¼ ì ìš©
        styled_markdown = f"""
        <div style="
            background: rgba(255, 255, 255, 0.05);
            padding: 1rem;
            border-radius: 8px;
            border-left: 4px solid #3498db;
            margin: 0.5rem 0;
        ">
        {text_content}
        </div>
        """
        
        st.markdown("#### ğŸ“ ë§ˆí¬ë‹¤ìš´ ì½˜í…ì¸ ")
        st.markdown(text_content, unsafe_allow_html=True)
        debug_log("âœ… ë§ˆí¬ë‹¤ìš´ ë Œë”ë§ ì™„ë£Œ")
        
    except Exception as e:
        debug_log(f"âŒ ë§ˆí¬ë‹¤ìš´ ë Œë”ë§ ì‹¤íŒ¨: {e}", "error")
        st.text(text_content)

def _render_general_text(text_content: str):
    """ì¼ë°˜ í…ìŠ¤íŠ¸ ë Œë”ë§"""
    try:
        # ê¸´ í…ìŠ¤íŠ¸ëŠ” expanderë¡œ
        if len(text_content) > 500:
            with st.expander("ğŸ“„ í…ìŠ¤íŠ¸ ë‚´ìš© ë³´ê¸°", expanded=True):
                st.markdown(text_content)
        else:
            st.markdown(text_content)
            
        debug_log("âœ… ì¼ë°˜ í…ìŠ¤íŠ¸ ë Œë”ë§ ì™„ë£Œ")
        
    except Exception as e:
        debug_log(f"âŒ ì¼ë°˜ í…ìŠ¤íŠ¸ ë Œë”ë§ ì‹¤íŒ¨: {e}", "error")
        st.text(text_content)

def _render_data_content(data_content: Dict, content_type: str, name: str, index: int):
    """ë°ì´í„° ì½˜í…ì¸  ë Œë”ë§"""
    try:
        if content_type == "application/vnd.plotly.v1+json":
            # Plotly ë°ì´í„°
            actual_data = data_content.get("data", {})
            if isinstance(actual_data, str):
                _render_plotly_chart(actual_data, name, index)
            else:
                _render_plotly_chart(json.dumps(actual_data), name, index)
                
        elif content_type == "application/json":
            # JSON ë°ì´í„°
            st.markdown("#### ğŸ“Š JSON ë°ì´í„°")
            st.json(data_content)
            
        else:
            # ê¸°íƒ€ ë°ì´í„°
            st.markdown("#### ğŸ“„ ë°ì´í„°")
            st.json(data_content)
            
        debug_log("âœ… ë°ì´í„° ì½˜í…ì¸  ë Œë”ë§ ì™„ë£Œ")
        
    except Exception as e:
        debug_log(f"âŒ ë°ì´í„° ì½˜í…ì¸  ë Œë”ë§ ì‹¤íŒ¨: {e}", "error")
        st.json(data_content)

async def process_query_streaming(prompt: str):
    """A2A í”„ë¡œí† ì½œì„ ì‚¬ìš©í•œ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì¿¼ë¦¬ ì²˜ë¦¬ + Phase 3 ì „ë¬¸ê°€ê¸‰ ë‹µë³€ í•©ì„±"""
    debug_log(f"ğŸš€ A2A ìŠ¤íŠ¸ë¦¬ë° ì¿¼ë¦¬ ì²˜ë¦¬ ì‹œì‘: {prompt[:100]}...")
    
    # Langfuse Session ì‹œì‘
    session_tracer = None
    session_id = None
    if LANGFUSE_SESSION_AVAILABLE:
        try:
            session_tracer = get_session_tracer()
            user_id = st.session_state.get("user_id", "anonymous")
            session_metadata = {
                "streamlit_session_id": st.session_state.get("session_id", "unknown"),
                "user_interface": "streamlit",
                "query_timestamp": time.time(),
                "query_length": len(prompt)
            }
            session_id = session_tracer.start_user_session(prompt, user_id, session_metadata)
            debug_log(f"ğŸ” Langfuse Session ì‹œì‘: {session_id}", "success")
        except Exception as e:
            debug_log(f"âŒ Langfuse Session ì‹œì‘ ì‹¤íŒ¨: {e}", "error")
    
    st.session_state.messages.append({"role": "user", "content": prompt})
    
    with st.chat_message("user"):
        st.markdown(prompt)
    
    with st.chat_message("assistant", avatar="ğŸ§ "):
        try:
            # 1. A2A í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
            debug_log("ğŸ”§ A2A í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì¤‘...")
            a2a_client = A2AStreamlitClient(st.session_state.agent_status, timeout=180.0)
            
            # 2. ì„¸ì…˜ ê¸°ë°˜ ë°ì´í„° ì •ë³´ í™•ì¸
            debug_log("ğŸ“Š ì„¸ì…˜ ë°ì´í„° ì •ë³´ í™•ì¸ ì¤‘...")
            session_manager = st.session_state.session_data_manager
            current_session_id = session_manager.get_current_session_id()
            
            if current_session_id:
                active_file, selection_reason = session_manager.get_active_file_info(current_session_id)
                debug_log(f"ğŸ“ í™œì„± íŒŒì¼: {active_file}, ì„ íƒ ì´ìœ : {selection_reason}")
            else:
                debug_log("âš ï¸ í˜„ì¬ ì„¸ì…˜ì´ ì—†ìŠµë‹ˆë‹¤", "warning")
                active_file = None
            
            # 3. ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°ì—ê²Œ ê³„íš ìš”ì²­
            debug_log("ğŸ§  ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°ì—ê²Œ ê³„íš ìš”ì²­ ì¤‘...")
            try:
                plan_response = await a2a_client.get_plan(prompt)
                debug_log(f"ğŸ“‹ ê³„íš ì‘ë‹µ ìˆ˜ì‹ : {type(plan_response)}")
                
            except Exception as plan_error:
                debug_log(f"âŒ ê³„íš ìš”ì²­ ì‹¤íŒ¨: {plan_error}", "error")
                st.error(f"ê³„íš ìƒì„± ì‹¤íŒ¨: {plan_error}")
                return
            
            # 4. ê³„íš íŒŒì‹±
            debug_log("ğŸ” ê³„íš íŒŒì‹± ì‹œì‘...")
            try:
                plan_steps = a2a_client.parse_orchestration_plan(plan_response)
                debug_log(f"ğŸ“Š íŒŒì‹±ëœ ê³„íš ë‹¨ê³„ ìˆ˜: {len(plan_steps)}")
                
            except Exception as parse_error:
                debug_log(f"âŒ ê³„íš íŒŒì‹± ì‹¤íŒ¨: {parse_error}", "error")
                st.error(f"ê³„íš íŒŒì‹± ì‹¤íŒ¨: {parse_error}")
                return
            
            # 5. CherryAI v8 ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ë‹¨ì¼ ì‘ë‹µ ì²˜ë¦¬
            if not plan_steps:
                debug_log("âŒ ìœ íš¨í•œ ê³„íš ë‹¨ê³„ê°€ ì—†ìŠµë‹ˆë‹¤", "error")
                
                # CherryAI v8 ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°ì˜ comprehensive_analysis ì•„í‹°íŒ©íŠ¸ í™•ì¸
                if isinstance(plan_response, dict) and "result" in plan_response:
                    result = plan_response["result"]
                    if "artifacts" in result:
                        for artifact in result["artifacts"]:
                            if artifact.get("name") == "comprehensive_analysis":
                                debug_log("ğŸ§  CherryAI v8 ì¢…í•© ë¶„ì„ ê²°ê³¼ ë°œê²¬!", "success")
                                
                                # ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì»¨í…Œì´ë„ˆ ìƒì„±
                                streaming_container = st.empty()
                                
                                # v8 ë¶„ì„ ê²°ê³¼ë¥¼ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ í‘œì‹œ
                                parts = artifact.get("parts", [])
                                for part in parts:
                                    if part.get("kind") == "text":
                                        analysis_text = part.get("text", "")
                                        if analysis_text:
                                            # í…ìŠ¤íŠ¸ë¥¼ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í• í•˜ì—¬ ìŠ¤íŠ¸ë¦¬ë°
                                            sentences = analysis_text.split('. ')
                                            displayed_text = ""
                                            
                                            # ì¼ë°˜ í…ìŠ¤íŠ¸ í¬ê¸°ë¡œ í—¤ë” í‘œì‹œ
                                            streaming_container.markdown("**ğŸ§  CherryAI v8 Universal Intelligence ë¶„ì„ ê²°ê³¼**")
                                            text_container = st.empty()
                                            
                                            for i, sentence in enumerate(sentences):
                                                if sentence.strip():
                                                    displayed_text += sentence
                                                    if i < len(sentences) - 1:
                                                        displayed_text += ". "
                                                    
                                                    # ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ (ì¼ë°˜ í…ìŠ¤íŠ¸ë¡œ)
                                                    text_container.markdown(displayed_text)
                                                    
                                                    # ìŠ¤íŠ¸ë¦¬ë° íš¨ê³¼
                                                    import asyncio
                                                    await asyncio.sleep(0.3)
                                            
                                            debug_log("âœ… v8 ë¶„ì„ ê²°ê³¼ ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ", "success")
                                            return
                
                st.error("ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°ê°€ ìœ íš¨í•œ ê³„íšì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                return
            
            # 6. ë‹¤ë‹¨ê³„ ê³„íš ì‹¤í–‰ - ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°
            debug_log(f"ğŸš€ {len(plan_steps)}ê°œ ë‹¨ê³„ ì‹¤í–‰ ì‹œì‘...")
            
            # ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì»¨í…Œì´ë„ˆë“¤
            plan_container = st.container()
            streaming_container = st.empty()
            results_container = st.container()
            
            # ê³„íš ì‹œê°í™”
            with plan_container:
                st.markdown("### ğŸ§¬ AI_DS_Team ì‹¤í–‰ ê³„íš")
                plan_cols = st.columns(len(plan_steps))
                
                for i, step in enumerate(plan_steps):
                    with plan_cols[i]:
                        st.markdown(f"""
                        <div style="background: rgba(255,255,255,0.1); padding: 1rem; border-radius: 8px; text-align: center;">
                            <h4>ë‹¨ê³„ {i+1}</h4>
                            <p><strong>{step.get('agent_name', 'Unknown')}</strong></p>
                            <p style="font-size: 0.8em;">{step.get('task_description', '')[:50]}...</p>
                        </div>
                        """, unsafe_allow_html=True)
            
            # ê° ë‹¨ê³„ ì‹¤ì‹œê°„ ì‹¤í–‰
            all_results = []
            
            # ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°ì„ ìœ„í•œ ì»¨í…Œì´ë„ˆ ìƒì„± (ê¸°ì¡´ ë°©ì‹ í˜¸í™˜ì„±)
            live_text_container = st.empty()
            live_artifacts_container = st.empty()
            
            for step_idx, step in enumerate(plan_steps):
                step_num = step_idx + 1
                agent_name = step.get('agent_name', 'unknown')
                task_description = step.get('task_description', '')
                
                debug_log(f"ğŸ¯ ë‹¨ê³„ {step_num}/{len(plan_steps)} ì‹¤í–‰: {agent_name}")
                
                # ê° ë‹¨ê³„ë³„ ìŠ¤íŠ¸ë¦¬ë° ì»¨í…Œì´ë„ˆ ìƒì„± (ìŠ¤ì½”í”„ ë¬¸ì œ í•´ê²°)
                step_stream_container = None
                if SMART_UI_AVAILABLE:
                    step_stream_container = AccumulativeStreamContainer(f"ğŸ¤– {agent_name} ì‹¤ì‹œê°„ ì‘ë‹µ")
                
                # ê° ë‹¨ê³„ë³„ ë³€ìˆ˜ ì´ˆê¸°í™”
                step_results = []
                step_artifacts = []
                displayed_text = ""
                
                # Langfuse ì—ì´ì „íŠ¸ ì¶”ì ê³¼ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬
                with session_tracer.trace_agent_execution(
                    agent_name=agent_name,
                    task_description=task_description,
                    agent_metadata={
                        "step_number": step_num,
                        "total_steps": len(plan_steps),
                        "step_index": step_idx
                    }
                ) if session_tracer else contextlib.nullcontext():
                    async for chunk_data in a2a_client.stream_task(agent_name, task_description):
                        try:
                            chunk_type = chunk_data.get('type', 'unknown')
                            chunk_content = chunk_data.get('content', {})
                            is_final = chunk_data.get('final', False)
                            
                            step_results.append(chunk_data)
                            
                            # ì‹¤ì‹œê°„ ë©”ì‹œì§€ ìŠ¤íŠ¸ë¦¬ë° í‘œì‹œ
                            if chunk_type == 'message':
                                text = chunk_content.get('text', '')
                                if text and not text.startswith('âœ…'):  # ì™„ë£Œ ë©”ì‹œì§€ ì œì™¸
                                    # Smart UI ì‚¬ìš© ê°€ëŠ¥ ì‹œ ëˆ„ì í˜• ì»¨í…Œì´ë„ˆ ì‚¬ìš©
                                    if SMART_UI_AVAILABLE and step_stream_container:
                                        # ì²­í¬ë¥¼ ëˆ„ì í•˜ì—¬ ì¶”ê°€
                                        step_stream_container.add_chunk(text, "message")
                                        
                                    else:
                                        # ê¸°ì¡´ ë°©ì‹ - í•˜ì§€ë§Œ ì¤‘ë³µ í‘œì‹œ ë°©ì§€
                                        displayed_text += text + " "
                                        
                                        # ë‹¨ê³„ë³„ ì§„í–‰ ìƒí™©ë§Œ í‘œì‹œ (ì¤‘ë³µ ë°©ì§€)
                                        with streaming_container:
                                            st.markdown(f"**ğŸ”„ {agent_name} ì²˜ë¦¬ ì¤‘...**")
                                            # ìƒì„¸ í…ìŠ¤íŠ¸ëŠ” Smart Displayë‚˜ ìµœì¢… ê²°ê³¼ì—ì„œë§Œ í‘œì‹œ
                            
                            # ì•„í‹°íŒ©íŠ¸ ì‹¤ì‹œê°„ í‘œì‹œ
                            elif chunk_type == 'artifact':
                                step_artifacts.append(chunk_content)
                                
                                if SMART_UI_AVAILABLE and step_stream_container:
                                    # Smart Displayë¡œ ì•„í‹°íŒ©íŠ¸ ë Œë”ë§
                                    step_stream_container.add_chunk(chunk_content, "artifact")
                                    
                                else:
                                    # ê¸°ì¡´ ë°©ì‹
                                    with live_artifacts_container:
                                        st.markdown("**ìƒì„±ëœ ì•„í‹°íŒ©íŠ¸:**")
                                        for i, artifact in enumerate(step_artifacts):
                                            with st.expander(f"ğŸ“„ {artifact.get('name', f'Artifact {i+1}')}", expanded=True):
                                                render_artifact(artifact)
                            
                            # final í”Œë˜ê·¸ í™•ì¸
                            if is_final:
                                debug_log(f"âœ… ë‹¨ê³„ {step_num} ìµœì¢… ì²­í¬ ìˆ˜ì‹ ", "success")
                                break
                        
                        except Exception as step_error:
                            debug_log(f"âŒ ë‹¨ê³„ {step_num} ì‹¤í–‰ ì‹¤íŒ¨: {step_error}", "error")
                            
                            with live_text_container:
                                st.error(f"ë‹¨ê³„ {step_num} ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {step_error}")
                            
                            all_results.append({
                                'step': step_num,
                                'agent': agent_name,
                                'task': task_description,
                                'error': str(step_error)
                            })
                
                # Langfuse ì—ì´ì „íŠ¸ ê²°ê³¼ ê¸°ë¡
                if session_tracer:
                    try:
                        session_tracer.record_agent_result(
                            agent_name=agent_name,
                            result={
                                "step_results": step_results,
                                "artifacts_count": len(step_artifacts),
                                "displayed_text_length": len(displayed_text)
                            },
                            confidence=0.9 if step_artifacts else 0.7,
                            artifacts=[{"name": a.get("name", "unknown"), "type": "artifact", "size": 0} for a in step_artifacts]
                        )
                        debug_log(f"ğŸ” Langfuse ì—ì´ì „íŠ¸ ê²°ê³¼ ê¸°ë¡: {agent_name}", "success")
                    except Exception as record_error:
                        debug_log(f"âŒ Langfuse ì—ì´ì „íŠ¸ ê²°ê³¼ ê¸°ë¡ ì‹¤íŒ¨: {record_error}", "error")
                
                # ê° ë‹¨ê³„ ê²°ê³¼ë¥¼ all_resultsì— ì¶”ê°€
                all_results.append({
                    'step': step_num,
                    'agent': agent_name,
                    'task': task_description,
                    'results': step_results,
                    'artifacts': step_artifacts,
                    'displayed_text': displayed_text
                })
            
            # 7. ìµœì¢… ê²°ê³¼ ì •ë¦¬ í‘œì‹œ
            debug_log("ğŸ“Š ìµœì¢… ê²°ê³¼ ì •ë¦¬ ì¤‘...")
            
            with streaming_container:
                st.markdown("### âœ… ëª¨ë“  ë‹¨ê³„ ì™„ë£Œ!")
                st.success("AI_DS_Team ë¶„ì„ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            
            # 8. ì¢…í•© ê²°ê³¼ í‘œì‹œ
            with results_container:
                st.markdown("---")
                st.markdown("### ğŸ¯ AI_DS_Team ë¶„ì„ ì¢…í•© ê²°ê³¼")
                
                # ì„±ê³µí•œ ë‹¨ê³„ë“¤ì˜ ê²°ê³¼ ìš”ì•½
                successful_steps = [r for r in all_results if 'error' not in r]
                total_artifacts = sum(len(r.get('artifacts', [])) for r in successful_steps)
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("ì™„ë£Œëœ ë‹¨ê³„", f"{len(successful_steps)}/{len(plan_steps)}")
                with col2:
                    st.metric("ìƒì„±ëœ ì•„í‹°íŒ©íŠ¸", total_artifacts)
                with col3:
                    st.metric("ì²˜ë¦¬ ì‹œê°„", f"{len(plan_steps) * 5}ì´ˆ (ì˜ˆìƒ)")
                
                # ê° ë‹¨ê³„ë³„ ìƒì„¸ ê²°ê³¼
                for result in all_results:
                    step_num = result['step']
                    agent_name = result['agent']
                    
                    with st.expander(f"ğŸ“‹ ë‹¨ê³„ {step_num}: {agent_name}", expanded=True):
                        if 'error' in result:
                            st.error(f"ì˜¤ë¥˜: {result['error']}")
                        else:
                            # ìµœì¢… í…ìŠ¤íŠ¸ ì‘ë‹µ í‘œì‹œ
                            if result.get('displayed_text'):
                                st.markdown("#### ğŸ’¬ ì—ì´ì „íŠ¸ ì‘ë‹µ")
                                st.markdown(result['displayed_text'])
                            
                            # ì•„í‹°íŒ©íŠ¸ í‘œì‹œ
                            if result.get('artifacts'):
                                st.markdown("#### ğŸ“¦ ìƒì„±ëœ ì•„í‹°íŒ©íŠ¸")
                                for artifact in result['artifacts']:
                                    artifact_name = artifact.get('name', 'Unknown')
                                    with st.expander(f"ğŸ“„ {artifact_name}", expanded=True):
                                        render_artifact(artifact)
            
            # 9. ìµœì¢… ì¢…í•© ì‘ë‹µ ìš”ì²­ (í•µì‹¬ ì¶”ê°€!)
            debug_log("ğŸ“ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°ì—ê²Œ ìµœì¢… ì¢…í•© ì‘ë‹µ ìš”ì²­ ì¤‘...")
            try:
                # ëª¨ë“  ë‹¨ê³„ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ìµœì¢… ë³´ê³ ì„œ ìš”ì²­
                comprehensive_prompt = f"""
                ë‹¤ìŒ ë‹¨ê³„ë“¤ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤:
                {chr(10).join([f"- {step.get('agent_name', 'Unknown')}: {step.get('task_description', '')}" for step in plan_steps])}
                
                ì›ë³¸ ì‚¬ìš©ì ìš”ì²­: {prompt}
                
                ìœ„ ëª¨ë“  ë¶„ì„ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ì‚¬ìš©ì ìš”ì²­ì— ëŒ€í•œ ì™„ì „í•œ ìµœì¢… ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.
                ë°˜ë“œì‹œ ë‹¤ìŒì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤:
                1. ë¶„ì„ ê°œìš” ë° í•µì‹¬ ë°œê²¬ì‚¬í•­
                2. ë°ì´í„° í’ˆì§ˆ ë° íŠ¹ì„± ë¶„ì„
                3. ì‹œê°í™” ì°¨íŠ¸ í•´ì„
                4. ì‹¤ë¬´ì  ê¶Œì¥ì‚¬í•­
                5. ì¶”ê°€ ë¶„ì„ ì œì•ˆ
                """
                
                # ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°ì—ê²Œ ì¢…í•© ì‘ë‹µ ìš”ì²­
                final_response = await a2a_client.get_plan(comprehensive_prompt)
                
                if final_response and isinstance(final_response, dict) and "result" in final_response:
                    result = final_response["result"]
                    
                    # ì¢…í•© ë¶„ì„ ì•„í‹°íŒ©íŠ¸ í™•ì¸
                    if "artifacts" in result:
                        for artifact in result["artifacts"]:
                            if artifact.get("name") in ["execution_plan", "comprehensive_analysis"]:
                                debug_log("ğŸ¯ ìµœì¢… ì¢…í•© ì‘ë‹µ ë°œê²¬!", "success")
                                
                                # ìµœì¢… ë³´ê³ ì„œ í‘œì‹œ
                                st.markdown("---")
                                st.markdown("### ğŸ¯ ìµœì¢… ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ")
                                
                                parts = artifact.get("parts", [])
                                for part in parts:
                                    if part.get("kind") == "text":
                                        final_text = part.get("text", "")
                                        if final_text:
                                            # êµ¬ì¡°í™”ëœ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ í‘œì‹œ
                                            st.markdown(final_text)
                                            debug_log("âœ… ìµœì¢… ì¢…í•© ë³´ê³ ì„œ í‘œì‹œ ì™„ë£Œ", "success")
                                            break
                    
                    # ìƒíƒœ ë©”ì‹œì§€ë„ í™•ì¸
                    if "status" in result and result["status"] == "completed":
                        if "message" in result and "parts" in result["message"]:
                            for part in result["message"]["parts"]:
                                if part.get("kind") == "text":
                                    status_text = part.get("text", "")
                                    if status_text and len(status_text) > 100:  # ì‹¤ì§ˆì ì¸ ë‚´ìš©ì´ ìˆëŠ” ê²½ìš°
                                        st.markdown("---")
                                        st.markdown("### ğŸ¯ ìµœì¢… ì¢…í•© ë¶„ì„ ê²°ê³¼")
                                        st.markdown(status_text)
                                        debug_log("âœ… ìƒíƒœ ë©”ì‹œì§€ì—ì„œ ìµœì¢… ì‘ë‹µ í‘œì‹œ ì™„ë£Œ", "success")
                                        break
                
            except Exception as final_error:
                debug_log(f"âŒ ìµœì¢… ì¢…í•© ì‘ë‹µ ìš”ì²­ ì‹¤íŒ¨: {final_error}", "error")
                # í´ë°±: ê¸°ë³¸ ìš”ì•½ ì œê³µ
                st.markdown("---")
                st.markdown("### ğŸ¯ ë¶„ì„ ì™„ë£Œ ìš”ì•½")
                st.info(f"ì´ {len(plan_steps)}ê°œ ë‹¨ê³„ê°€ ì‹¤í–‰ë˜ì—ˆìŠµë‹ˆë‹¤. ê° ë‹¨ê³„ë³„ ê²°ê³¼ëŠ” ìœ„ì—ì„œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            
            # Phase 3: ì „ë¬¸ê°€ê¸‰ ë‹µë³€ í•©ì„±
            if PHASE3_AVAILABLE:
                await _process_phase3_expert_synthesis(prompt, plan_steps, a2a_client, session_tracer, session_id)
            
            debug_log("ğŸ‰ ì „ì²´ ìŠ¤íŠ¸ë¦¬ë° í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ!", "success")
            
            # Langfuse Session ì¢…ë£Œ (ì„±ê³µ ì¼€ì´ìŠ¤) - Phase 3 ì™„ë£Œ í›„ ì¢…ë£Œ
            if session_tracer and session_id:
                try:
                    final_result = {
                        "success": True,
                        "total_steps": len(plan_steps),
                        "total_artifacts": sum(len(r.get('artifacts', [])) for r in all_results),
                        "processing_completed": True,
                        "phase3_executed": PHASE3_AVAILABLE
                    }
                    session_summary = {
                        "steps_executed": len(plan_steps),
                        "agents_used": list(set(step.get('agent_name', 'unknown') for step in plan_steps)),
                        "phase3_enabled": PHASE3_AVAILABLE
                    }
                    session_tracer.end_user_session(final_result, session_summary)
                    debug_log(f"ğŸ” Langfuse Session ì¢…ë£Œ (ì„±ê³µ): {session_id}", "success")
                except Exception as session_end_error:
                    debug_log(f"âŒ Langfuse Session ì¢…ë£Œ ì‹¤íŒ¨: {session_end_error}", "error")
            
        except Exception as e:
            debug_log(f"ğŸ’¥ ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì˜¤ë¥˜: {e}", "error")
            st.error(f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            import traceback
            debug_log(f"ğŸ” ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤: {traceback.format_exc()}", "error")
            
            # Langfuse Session ì¢…ë£Œ (ì˜¤ë¥˜ ì¼€ì´ìŠ¤)
            if session_tracer and session_id:
                try:
                    final_result = {
                        "success": False,
                        "error": str(e),
                        "error_type": type(e).__name__,
                        "processing_completed": False
                    }
                    session_summary = {
                        "error_occurred": True,
                        "error_step": "process_query_streaming"
                    }
                    session_tracer.end_user_session(final_result, session_summary)
                    debug_log(f"ğŸ” Langfuse Session ì¢…ë£Œ (ì˜¤ë¥˜): {session_id}", "success")
                except Exception as session_end_error:
                    debug_log(f"âŒ Langfuse Session ì¢…ë£Œ ì‹¤íŒ¨: {session_end_error}", "error")

async def _process_phase3_expert_synthesis(prompt: str, plan_steps: List[Dict], a2a_client, session_tracer=None, session_id=None):
    """Phase 3 ì „ë¬¸ê°€ê¸‰ ë‹µë³€ í•©ì„± ì²˜ë¦¬ - Langfuse ì„¸ì…˜ í†µí•©"""
    try:
        debug_log("ğŸ§  Phase 3 ì „ë¬¸ê°€ê¸‰ ë‹µë³€ í•©ì„± ì‹œì‘...", "info")
        
        # Phase 3 ì „ìš© span ìƒì„± (ê¸°ì¡´ ì„¸ì…˜ ë‚´ì—ì„œ)
        phase3_span = None
        if session_tracer and LANGFUSE_AVAILABLE:
            try:
                phase3_span = session_tracer.create_agent_execution_span(
                    "Phase 3 Expert Synthesis",
                    {
                        "operation": "expert_answer_synthesis",
                        "user_query": prompt[:200] + "..." if len(prompt) > 200 else prompt,
                        "previous_steps": len(plan_steps),
                        "synthesis_type": "holistic_integration"
                    }
                )
                debug_log("âœ… Phase 3 Langfuse span ìƒì„± ì™„ë£Œ", "success")
            except Exception as span_error:
                debug_log(f"âŒ Phase 3 Langfuse span ìƒì„± ì‹¤íŒ¨: {span_error}", "error")
                phase3_span = None
        
        # 1. Phase 3 Integration Layer ì´ˆê¸°í™”
        phase3_layer = Phase3IntegrationLayer()
        expert_renderer = ExpertAnswerRenderer()
        
        # 2. A2A ì—ì´ì „íŠ¸ ê²°ê³¼ ìˆ˜ì§‘
        a2a_agent_results = await _collect_a2a_agent_results(plan_steps, a2a_client)
        
        # 3. ì‚¬ìš©ì ë° ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„ (ê¸°ì¡´ ì„¸ì…˜ ì •ë³´ í™œìš©)
        user_context = {
            "user_id": st.session_state.get("user_id", "anonymous"),
            "role": "data_scientist",
            "domain_expertise": {"data_science": 0.9, "analytics": 0.8},
            "preferences": {"visualization": True, "detailed_analysis": True},
            "personalization_level": "advanced"
        }
        
        session_context = {
            "session_id": session_id or st.session_state.get("session_id", f"session_{int(time.time())}"),
            "timestamp": time.time(),
            "context_history": st.session_state.get("messages", []),
            "phase3_continuation": True,  # Phase 3ê°€ ê¸°ì¡´ ì„¸ì…˜ì˜ ì—°ì†ì„ì„ í‘œì‹œ
            "langfuse_session_active": session_tracer is not None
        }
        
        # 4. ì „ë¬¸ê°€ê¸‰ ë‹µë³€ í•©ì„± ì‹¤í–‰
        st.markdown("---")
        st.markdown("## ğŸ§  ì „ë¬¸ê°€ê¸‰ ì§€ëŠ¥í˜• ë¶„ì„ ì‹œì‘")
        
        synthesis_start_time = time.time()
        
        with st.spinner("ì „ë¬¸ê°€ê¸‰ ë‹µë³€ì„ í•©ì„±í•˜ëŠ” ì¤‘..."):
            expert_answer = await phase3_layer.process_user_query_to_expert_answer(
                user_query=prompt,
                a2a_agent_results=a2a_agent_results,
                user_context=user_context,
                session_context=session_context
            )
        
        synthesis_time = time.time() - synthesis_start_time
        
        # 5. Phase 3 ê²°ê³¼ë¥¼ Langfuseì— ê¸°ë¡
        if phase3_span and session_tracer:
            try:
                phase3_result = {
                    "success": expert_answer.get("success", False),
                    "confidence_score": expert_answer.get("confidence_score", 0.0),
                    "processing_time": synthesis_time,
                    "quality_score": expert_answer.get("metadata", {}).get("phase3_quality_score", 0.0),
                    "synthesis_strategy": expert_answer.get("metadata", {}).get("synthesis_strategy", "unknown"),
                    "total_agents_integrated": expert_answer.get("metadata", {}).get("total_agents_used", 0)
                }
                
                session_tracer.end_agent_execution_span(
                    phase3_span,
                    phase3_result,
                    success=expert_answer.get("success", False),
                    metadata={
                        "phase3_metrics": expert_answer.get("metadata", {}),
                        "synthesis_time": synthesis_time,
                        "expert_answer_sections": len(expert_answer.get("synthesized_answer", {}).get("main_sections", [])) if expert_answer.get("synthesized_answer") else 0
                    }
                )
                debug_log("âœ… Phase 3 Langfuse span ì™„ë£Œ", "success")
            except Exception as span_end_error:
                debug_log(f"âŒ Phase 3 Langfuse span ì™„ë£Œ ì‹¤íŒ¨: {span_end_error}", "error")
        
        # 6. ì „ë¬¸ê°€ê¸‰ ë‹µë³€ ë Œë”ë§
        if expert_answer.get("success"):
            debug_log("âœ… ì „ë¬¸ê°€ê¸‰ ë‹µë³€ í•©ì„± ì„±ê³µ!", "success")
            st.markdown("---")
            expert_renderer.render_expert_answer(expert_answer)
            
            # ì„¸ì…˜ ìƒíƒœì— ì €ì¥
            st.session_state.messages.append({
                "role": "assistant",
                "content": f"ì „ë¬¸ê°€ê¸‰ ë‹µë³€ì´ ì™„ì„±ë˜ì—ˆìŠµë‹ˆë‹¤. (ì‹ ë¢°ë„: {expert_answer['confidence_score']:.1%})",
                "expert_answer": expert_answer,
                "timestamp": time.time(),
                "phase3_integrated": True,  # Phase 3 í†µí•© ì™„ë£Œ í‘œì‹œ
                "synthesis_time": synthesis_time
            })
            
            # Phase 3 ì„±ê³µ ë©”íŠ¸ë¦­ ê¸°ë¡
            if session_tracer:
                try:
                    session_tracer.log_system_event(
                        "phase3_completion",
                        {
                            "synthesis_time": synthesis_time,
                            "confidence_score": expert_answer['confidence_score'],
                            "integration_success": True
                        }
                    )
                except Exception as metric_error:
                    debug_log(f"âŒ Phase 3 ë©”íŠ¸ë¦­ ê¸°ë¡ ì‹¤íŒ¨: {metric_error}", "error")
        else:
            debug_log("âŒ ì „ë¬¸ê°€ê¸‰ ë‹µë³€ í•©ì„± ì‹¤íŒ¨", "error")
            st.error("ì „ë¬¸ê°€ê¸‰ ë‹µë³€ í•©ì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            
            # ì˜¤ë¥˜ ì •ë³´ í‘œì‹œ
            error_details = expert_answer.get("error", "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜")
            st.error(f"ì˜¤ë¥˜ ì„¸ë¶€ì‚¬í•­: {error_details}")
            
            # í´ë°± ë©”ì‹œì§€ í‘œì‹œ
            if expert_answer.get("fallback_message"):
                st.info(expert_answer["fallback_message"])
            
            # Phase 3 ì‹¤íŒ¨ ë©”íŠ¸ë¦­ ê¸°ë¡
            if session_tracer:
                try:
                    session_tracer.log_system_event(
                        "phase3_failure",
                        {
                            "synthesis_time": synthesis_time,
                            "error": error_details,
                            "integration_success": False
                        }
                    )
                except Exception as metric_error:
                    debug_log(f"âŒ Phase 3 ì‹¤íŒ¨ ë©”íŠ¸ë¦­ ê¸°ë¡ ì‹¤íŒ¨: {metric_error}", "error")
        
        debug_log(f"ğŸ¯ Phase 3 ì „ë¬¸ê°€ê¸‰ ë‹µë³€ í•©ì„± ì™„ë£Œ ({synthesis_time:.2f}ì´ˆ)", "success")
        
    except Exception as e:
        debug_log(f"ğŸ’¥ Phase 3 ì²˜ë¦¬ ì˜¤ë¥˜: {e}", "error")
        st.error(f"ì „ë¬¸ê°€ê¸‰ ë‹µë³€ í•©ì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        import traceback
        debug_log(f"ğŸ” Phase 3 ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤: {traceback.format_exc()}", "error")
        
        # Phase 3 ì˜¤ë¥˜ span ê¸°ë¡
        if phase3_span and session_tracer:
            try:
                session_tracer.end_agent_execution_span(
                    phase3_span,
                    {"error": str(e), "success": False},
                    success=False,
                    metadata={"error_traceback": traceback.format_exc()}
                )
            except Exception as span_error:
                debug_log(f"âŒ Phase 3 ì˜¤ë¥˜ span ê¸°ë¡ ì‹¤íŒ¨: {span_error}", "error")

async def _collect_a2a_agent_results(plan_steps: List[Dict], a2a_client) -> List[Dict[str, Any]]:
    """A2A ì—ì´ì „íŠ¸ ì‹¤í–‰ ê²°ê³¼ ìˆ˜ì§‘"""
    try:
        debug_log("ğŸ“Š A2A ì—ì´ì „íŠ¸ ê²°ê³¼ ìˆ˜ì§‘ ì‹œì‘...", "info")
        
        agent_results = []
        
        for i, step in enumerate(plan_steps):
            step_name = step.get("name", f"Step {i+1}")
            agent_name = step.get("agent", "Unknown")
            
            # ê° ë‹¨ê³„ì—ì„œ ì—ì´ì „íŠ¸ ê²°ê³¼ ìˆ˜ì§‘
            try:
                # ì‹¤ì œ ë‹¨ê³„ ì‹¤í–‰ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë°ì´í„° êµ¬ì¡°í™”
                # (ì´ë¯¸ ì‹¤í–‰ëœ A2A ìŠ¤íŠ¸ë¦¬ë° ê²°ê³¼ë¥¼ í™œìš©)
                result_data = {
                    "agent_name": agent_name,
                    "step_name": step_name,
                    "success": True,
                    "confidence": 0.85,  # ê¸°ë³¸ ì‹ ë¢°ë„
                    "artifacts": [],
                    "metadata": {
                        "step_index": i,
                        "processing_time": step.get("execution_time", 5.0),
                        "description": step.get("description", "")
                    }
                }
                
                # ë‹¨ê³„ ì‹¤í–‰ ê²°ê³¼ê°€ ìˆë‹¤ë©´ ì¶”ê°€ ì •ë³´ í¬í•¨
                if "result" in step:
                    result_data["artifacts"] = step["result"]
                    result_data["success"] = True
                    result_data["confidence"] = 0.9
                elif "error" in step:
                    result_data["success"] = False
                    result_data["confidence"] = 0.2
                    result_data["metadata"]["error"] = step["error"]
                
                agent_results.append(result_data)
                debug_log(f"âœ… {agent_name} ê²°ê³¼ ìˆ˜ì§‘ ì™„ë£Œ", "success")
                    
            except Exception as step_error:
                debug_log(f"âŒ {agent_name} ê²°ê³¼ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {step_error}", "error")
                
                # ì˜¤ë¥˜ ì •ë³´ë„ í¬í•¨
                result_data = {
                    "agent_name": agent_name,
                    "step_name": step_name,
                    "success": False,
                    "confidence": 0.1,
                    "artifacts": [],
                    "metadata": {
                        "step_index": i,
                        "error": str(step_error)
                    }
                }
                agent_results.append(result_data)
        
        debug_log(f"ğŸ“Š ì´ {len(agent_results)}ê°œ ì—ì´ì „íŠ¸ ê²°ê³¼ ìˆ˜ì§‘ ì™„ë£Œ", "success")
        return agent_results
        
    except Exception as e:
        debug_log(f"ğŸ’¥ A2A ê²°ê³¼ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}", "error")
        return []

def get_file_size_info(file_id: str) -> str:
    """íŒŒì¼ í¬ê¸° ì •ë³´ë¥¼ ë°˜í™˜í•˜ëŠ” í—¬í¼ í•¨ìˆ˜"""
    try:
        # DataManagerì—ì„œ íŒŒì¼ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        if hasattr(st.session_state, 'data_manager'):
            df = st.session_state.data_manager.get_dataframe(file_id)
            if df is not None:
                memory_mb = round(df.memory_usage(deep=True).sum() / 1024**2, 2)
                return f"{df.shape[0]}í–‰ Ã— {df.shape[1]}ì—´, {memory_mb}MB"
        
        # SessionDataManagerì—ì„œ ë©”íƒ€ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        if hasattr(st.session_state, 'session_data_manager'):
            session_id = st.session_state.session_data_manager.get_current_session_id()
            if session_id and session_id in st.session_state.session_data_manager._session_metadata:
                session_meta = st.session_state.session_data_manager._session_metadata[session_id]
                for file_meta in session_meta.uploaded_files:
                    if file_meta.data_id == file_id:
                        size_mb = round(file_meta.file_size / 1024**2, 2)
                        return f"{file_meta.file_type}, {size_mb}MB"
        
        return "í¬ê¸° ì •ë³´ ì—†ìŒ"
    except Exception as e:
        debug_log(f"íŒŒì¼ í¬ê¸° ì •ë³´ ì¡°íšŒ ì˜¤ë¥˜: {e}", "warning")
        return "í¬ê¸° ì¡°íšŒ ì‹¤íŒ¨"

def handle_file_name_conflict(new_file_name: str, session_id: str) -> Tuple[str, bool]:
    """íŒŒì¼ëª… ì¤‘ë³µ ì²˜ë¦¬ UI"""
    try:
        session_manager = st.session_state.session_data_manager
        existing_files = session_manager.get_session_files(session_id)
        
        if new_file_name in existing_files:
            st.warning(f"âš ï¸ **íŒŒì¼ëª… ì¤‘ë³µ**: `{new_file_name}`ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤.")
            
            col1, col2 = st.columns(2)
            
            with col1:
                if st.button("ğŸ”„ ë®ì–´ì“°ê¸°", key=f"overwrite_{new_file_name}"):
                    st.info(f"ê¸°ì¡´ `{new_file_name}` íŒŒì¼ì„ ë®ì–´ì”ë‹ˆë‹¤.")
                    return new_file_name, True
            
            with col2:
                if st.button("ğŸ“ ìƒˆ ì´ë¦„ìœ¼ë¡œ ì €ì¥", key=f"rename_{new_file_name}"):
                    # ìë™ìœ¼ë¡œ ìƒˆ ì´ë¦„ ìƒì„±
                    base_name = Path(new_file_name).stem
                    extension = Path(new_file_name).suffix
                    counter = 1
                    
                    while f"{base_name}_{counter}{extension}" in existing_files:
                        counter += 1
                    
                    new_name = f"{base_name}_{counter}{extension}"
                    st.success(f"ìƒˆ ì´ë¦„ìœ¼ë¡œ ì €ì¥: `{new_name}`")
                    return new_name, True
            
            # ì‚¬ìš©ìê°€ ì•„ì§ ì„ íƒí•˜ì§€ ì•ŠìŒ
            return new_file_name, False
        
        # ì¤‘ë³µ ì—†ìŒ
        return new_file_name, True
        
    except Exception as e:
        debug_log(f"íŒŒì¼ëª… ì¤‘ë³µ ì²˜ë¦¬ ì˜¤ë¥˜: {e}", "error")
        return new_file_name, True

def display_session_status():
    """ì„¸ì…˜ ìƒíƒœ í‘œì‹œ"""
    try:
        if hasattr(st.session_state, 'session_data_manager'):
            session_manager = st.session_state.session_data_manager
            current_session_id = session_manager.get_current_session_id()
            
            if current_session_id:
                session_age_info = session_manager.check_session_age(current_session_id)
                
                # ì„¸ì…˜ ìƒíƒœì— ë”°ë¥¸ ìƒ‰ìƒ í‘œì‹œ
                if session_age_info["status"] == "active":
                    status_color = "ğŸŸ¢"
                elif session_age_info["status"] == "warning":
                    status_color = "ğŸŸ¡"
                else:
                    status_color = "ğŸ”´"
                
                st.sidebar.markdown(f"""
                ### {status_color} ì„¸ì…˜ ìƒíƒœ
                - **ì„¸ì…˜ ID**: `{current_session_id}`
                - **ìƒíƒœ**: {session_age_info["status"]}
                - **ìƒì„± ì‹œê°„**: {session_age_info["age_hours"]:.1f}ì‹œê°„ ì „
                - **ì •ë¦¬ê¹Œì§€**: {session_age_info["hours_until_cleanup"]:.1f}ì‹œê°„
                """)
                
                # íŒŒì¼ ëª©ë¡
                files = session_manager.get_session_files(current_session_id)
                if files:
                    st.sidebar.markdown("### ğŸ“ ì„¸ì…˜ íŒŒì¼")
                    for file_id in files:
                        file_info = get_file_size_info(file_id)
                        active_file, _ = session_manager.get_active_file_info(current_session_id)
                        
                        if file_id == active_file:
                            st.sidebar.markdown(f"ğŸ¯ **{file_id}** ({file_info})")
                        else:
                            st.sidebar.markdown(f"ğŸ“„ {file_id} ({file_info})")
            else:
                st.sidebar.markdown("### âšª ì„¸ì…˜ ì—†ìŒ")
                st.sidebar.info("íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ ìƒˆ ì„¸ì…˜ì´ ìƒì„±ë©ë‹ˆë‹¤.")
    
    except Exception as e:
        debug_log(f"ì„¸ì…˜ ìƒíƒœ í‘œì‹œ ì˜¤ë¥˜: {e}", "warning")

def handle_data_upload_with_ai_ds_team():
    """SessionDataManagerë¥¼ ì‚¬ìš©í•œ ì„¸ì…˜ ê¸°ë°˜ íŒŒì¼ ì—…ë¡œë“œ ì²˜ë¦¬"""
    data_manager = st.session_state.data_manager
    session_data_manager = st.session_state.session_data_manager
    
    # í˜„ì¬ ë¡œë“œëœ ë°ì´í„°ì…‹ í‘œì‹œ
    loaded_data_info = data_manager.list_dataframe_info()
    
    if loaded_data_info:
        st.success(f"âœ… {len(loaded_data_info)}ê°œì˜ ë°ì´í„°ì…‹ì´ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # ì„¸ì…˜ ë™ê¸°í™” í™•ì¸ ë° ë³µêµ¬
        current_session_id = session_data_manager.get_current_session_id()
        if not current_session_id or current_session_id not in session_data_manager._session_metadata:
            # ì„¸ì…˜ì´ ì—†ê±°ë‚˜ ë©”íƒ€ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš° ë³µêµ¬
            debug_log("ì„¸ì…˜ ì •ë³´ê°€ ì—†ì–´ ë°ì´í„°ë¡œë¶€í„° ì„¸ì…˜ì„ ë³µêµ¬í•©ë‹ˆë‹¤.")
            first_data_id = loaded_data_info[0]['data_id']
            df = data_manager.get_dataframe(first_data_id)
            if df is not None:
                new_session_id = session_data_manager.create_session_with_data(
                    data_id=first_data_id,
                    data=df,
                    user_instructions="ê¸°ì¡´ ë°ì´í„°ë¡œë¶€í„° ì„¸ì…˜ ë³µêµ¬"
                )
                debug_log(f"ì„¸ì…˜ ë³µêµ¬ ì™„ë£Œ: {new_session_id}")
                st.info(f"ğŸ”„ ì„¸ì…˜ì´ ë³µêµ¬ë˜ì—ˆìŠµë‹ˆë‹¤: {new_session_id}")
        
        # ë¡œë“œëœ ë°ì´í„°ì…‹ ëª©ë¡ì„ expanderë¡œ í‘œì‹œ
        with st.expander("ğŸ“‹ ë¡œë“œëœ ë°ì´í„°ì…‹ ë³´ê¸°", expanded=False):
            for info in loaded_data_info:
                data_id = info['data_id']
                shape = info['shape']
                col1, col2 = st.columns([3, 1])
                with col1:
                    st.markdown(f"**{data_id}** (í˜•íƒœ: {shape[0]}í–‰ x {shape[1]}ì—´)")
                with col2:
                    if st.button(f"ğŸ—‘ï¸ ì‚­ì œ", key=f"del_{data_id}"):
                        if data_manager.delete_dataframe(data_id):
                            st.toast(f"'{data_id}'ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
                            st.rerun()
                        else:
                            st.toast(f"'{data_id}' ì‚­ì œ ì‹¤íŒ¨.", icon="âŒ")
        
        # ì²« ë²ˆì§¸ ë°ì´í„°ì…‹ì„ ê¸°ë³¸ìœ¼ë¡œ ì„¤ì •
        if not st.session_state.data_id or st.session_state.data_id not in [info['data_id'] for info in loaded_data_info]:
            st.session_state.data_id = loaded_data_info[0]['data_id']
            st.session_state.uploaded_data = data_manager.get_dataframe(st.session_state.data_id)
    else:
        st.info("í˜„ì¬ ë¡œë“œëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. CSV ë˜ëŠ” Excel íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
    
    # íŒŒì¼ ì—…ë¡œë“œ (ë‹¤ì¤‘ íŒŒì¼ ì§€ì›)
    uploaded_files = st.file_uploader(
        "CSV ë˜ëŠ” Excel íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš” (ë‹¤ì¤‘ ì„ íƒ ê°€ëŠ¥)",
        type=["csv", "xlsx"],
        accept_multiple_files=True,
        help="ì—¬ëŸ¬ íŒŒì¼ì„ í•œ ë²ˆì— ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    )
    
    if uploaded_files:
        # ì´ë¯¸ ë¡œë“œëœ íŒŒì¼ë“¤ í™•ì¸
        existing_df_ids = set(data_manager.list_dataframes())
        files_to_process = []
        
        for file in uploaded_files:
            file_id = file.name
            if file_id not in existing_df_ids:
                files_to_process.append(file)
        
        if files_to_process:
            files_loaded = 0
            
            for file in files_to_process:
                try:
                    with st.spinner(f"'{file.name}' ì²˜ë¦¬ ì¤‘..."):
                        # íŒŒì¼ ì½ê¸°
                        if file.name.endswith('.csv'):
                            df = pd.read_csv(file)
                        else:
                            df = pd.read_excel(file)
                        
                        # DataManagerì— ì¶”ê°€ (ìë™ìœ¼ë¡œ shared_dataframesì— ì €ì¥ë¨)
                        file_id = file.name
                        data_manager.add_dataframe(data_id=file_id, data=df, source="File Upload")
                        
                        # ì„¸ì…˜ ê¸°ë°˜ AI DS Team í™˜ê²½ ì¤€ë¹„
                        # ì´ íŒŒì¼ì´ AI DS Teamì—ì„œ ì‚¬ìš©ë  ì˜ˆì •ì´ë¯€ë¡œ ì„¸ì…˜ì— ì¶”ê°€
                        session_id = session_data_manager.create_session_with_data(
                            data_id=file_id,
                            data=df,
                            user_instructions="íŒŒì¼ ì—…ë¡œë“œë¥¼ í†µí•œ ë°ì´í„° ë¡œë“œ"
                        )
                        
                        # AI DS Team í™˜ê²½ ì¤€ë¹„ (ai_ds_team/data/ í´ë”ì— íŒŒì¼ ë°°ì¹˜)
                        env_info = session_data_manager.prepare_ai_ds_team_environment(session_id)
                        
                        files_loaded += 1
                        debug_log(f"íŒŒì¼ ì—…ë¡œë“œ ì„±ê³µ: {file_id}, shape={df.shape}, session={session_id}")
                        
                        # ì²« ë²ˆì§¸ íŒŒì¼ì„ ê¸°ë³¸ ë°ì´í„°ë¡œ ì„¤ì •
                        if not st.session_state.data_id:
                            st.session_state.data_id = file_id
                            st.session_state.uploaded_data = df
                            st.session_state.current_session_id = session_id
                            
                except Exception as e:
                    st.error(f"'{file.name}' ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
                    debug_log(f"íŒŒì¼ ì—…ë¡œë“œ ì‹¤íŒ¨: {file.name} - {e}", "error")
            
            if files_loaded > 0:
                st.toast(f"âœ… {files_loaded}ê°œì˜ íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!", icon="ğŸ‰")
                st.success("ğŸ”„ AI DS Team í™˜ê²½ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ì œ ì—ì´ì „íŠ¸ë“¤ì´ ì˜¬ë°”ë¥¸ ë°ì´í„°ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                st.rerun()
        else:
            # ëª¨ë“  íŒŒì¼ì´ ì´ë¯¸ ë¡œë“œë¨
            file_names = [f.name for f in uploaded_files]
            if len(file_names) == 1:
                st.info(f"'{file_names[0]}'ëŠ” ì´ë¯¸ ë¡œë“œë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
            else:
                st.info(f"ì„ íƒëœ {len(file_names)}ê°œ íŒŒì¼ì´ ëª¨ë‘ ì´ë¯¸ ë¡œë“œë˜ì–´ ìˆìŠµë‹ˆë‹¤.")

def display_data_summary_ai_ds_team(data):
    """DataManager ê¸°ë°˜ ë°ì´í„° ìš”ì•½ í‘œì‹œ"""
    if data is not None:
        st.markdown("---")
        st.markdown("### ğŸ“Š ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°")
        
        # ê¸°ë³¸ ì •ë³´
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("í–‰ ìˆ˜", f"{data.shape[0]:,}")
        with col2:
            st.metric("ì—´ ìˆ˜", f"{data.shape[1]:,}")
        with col3:
            st.metric("ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰", f"{data.memory_usage(deep=True).sum() / 1024 / 1024:.1f} MB")
        
        # ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
        st.dataframe(data.head(10), use_container_width=True)
        
        # AI_DS_Team ìœ í‹¸ë¦¬í‹°ê°€ ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš° ì¶”ê°€ ì •ë³´
        if AI_DS_TEAM_UTILS_AVAILABLE:
            with st.expander("ğŸ“ˆ ìƒì„¸ ì •ë³´", expanded=False):
                summaries = get_dataframe_summary(data)
                for summary in summaries:
                    st.text(summary)

def main():
    """ë©”ì¸ Streamlit ì• í”Œë¦¬ì¼€ì´ì…˜"""
    st.set_page_config(
        page_title="ğŸ§¬ AI DS Team - í†µí•© ë°ì´í„° ì‚¬ì´ì–¸ìŠ¤ í”Œë«í¼",
        page_icon="ğŸ§¬",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    # ì‚¬ì´ë“œë°”ì— ë””ë²„ê¹… ì œì–´ ì¶”ê°€
    with st.sidebar:
        st.markdown("### ğŸ”§ ì‹œìŠ¤í…œ ì„¤ì •")
        
        # ë””ë²„ê¹… í† ê¸€
        debug_enabled = st.toggle(
            "ğŸ› ë””ë²„ê¹… ëª¨ë“œ",
            value=getattr(st.session_state, 'debug_enabled', False),
            help="ë””ë²„ê¹… ë©”ì‹œì§€ë¥¼ UIì— í‘œì‹œí• ì§€ ì„ íƒí•©ë‹ˆë‹¤. í„°ë¯¸ë„ê³¼ ë¡œê·¸ íŒŒì¼ì—ëŠ” í•­ìƒ ê¸°ë¡ë©ë‹ˆë‹¤."
        )
        st.session_state.debug_enabled = debug_enabled
        
        if debug_enabled:
            st.success("ğŸ› ë””ë²„ê¹… ëª¨ë“œ í™œì„±í™”")
        else:
            st.info("ğŸ”‡ ë””ë²„ê¹… ë©”ì‹œì§€ ìˆ¨ê¹€")
    
    # ê°•í™”ëœ ë””ë²„ê¹… ë¡œê¹…
    debug_log("ğŸš€ Streamlit ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘", "success")
    
    try:
        # 1. ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
        debug_log("ğŸ”§ ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ì‹œì‘...")
        initialize_session_state()
        debug_log("âœ… ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ì™„ë£Œ", "success")
        
        # 2. ì—ì´ì „íŠ¸ ìƒíƒœ í™•ì¸ ë° ì´ˆê¸°í™”
        debug_log("ğŸ¤– ì—ì´ì „íŠ¸ ìƒíƒœ í™•ì¸ ì‹œì‘...")
        if "agent_status" not in st.session_state or not st.session_state.agent_status:
            debug_log("âš ï¸ ì—ì´ì „íŠ¸ ìƒíƒœê°€ ì—†ìŒ, ìƒˆë¡œ ì´ˆê¸°í™”...", "warning")
            
            try:
                # í”„ë¦¬ë¡œë” ì‚¬ìš© (ìƒë‹¨ ìˆ«ìê°€ ì •í™•í•˜ë¯€ë¡œ)
                agent_status = asyncio.run(preload_agents_with_ui())
                st.session_state.agent_status = agent_status
                
                # ì—ì´ì „íŠ¸ ìƒíƒœ ìƒì„¸ ë¡œê¹…
                debug_log(f"ğŸ“Š ì´ {len(agent_status)}ê°œ ì—ì´ì „íŠ¸ ìƒíƒœ í™•ì¸ë¨")
                available_count = sum(1 for status in agent_status.values() if status.get("status") == "âœ…")
                debug_log(f"âœ… ì‚¬ìš© ê°€ëŠ¥í•œ ì—ì´ì „íŠ¸: {available_count}ê°œ")
                
                for agent_name, status in agent_status.items():
                    if status.get("status") == "âœ…":
                        debug_log(f"  âœ… {agent_name} (í¬íŠ¸: {status.get('port')})")
                    else:
                        debug_log(f"  âŒ {agent_name} - {status.get('description')}", "warning")
                        
            except Exception as e:
                debug_log(f"âŒ ì—ì´ì „íŠ¸ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}", "error")
                import traceback
                debug_log(f"ğŸ” ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤: {traceback.format_exc()}", "error")
                st.session_state.agent_status = {}
        else:
            debug_log(f"âœ… ê¸°ì¡´ ì—ì´ì „íŠ¸ ìƒíƒœ ì‚¬ìš©: {len(st.session_state.agent_status)}ê°œ ì—ì´ì „íŠ¸")
        
        # 3. UI ë Œë”ë§
        debug_log("ğŸ¨ UI ë Œë”ë§ ì‹œì‘...")
        st.title("ğŸ§¬ AI_DS_Team Orchestrator")
        st.markdown("> A2A í”„ë¡œí† ì½œ ê¸°ë°˜, 9ê°œ ì „ë¬¸ ë°ì´í„° ê³¼í•™ ì—ì´ì „íŠ¸ íŒ€ì˜ ì‹¤ì‹œê°„ í˜‘ì—… ì‹œìŠ¤í…œ")
        
        # ì„¸ì…˜ ìƒíƒœ í‘œì‹œ
        display_session_status()

        if st.button("ğŸ”„ ì—ì´ì „íŠ¸ ìƒíƒœ ìƒˆë¡œê³ ì¹¨") or not st.session_state.agent_status:
            debug_log("ğŸ”„ ì—ì´ì „íŠ¸ ìƒíƒœ ê°•ì œ ìƒˆë¡œê³ ì¹¨ ì‹œì‘...")
            st.session_state.agents_preloaded = False  # í”„ë¦¬ë¡œë” ì¬ì‹œì‘ ê°•ì œ
            st.session_state.agent_status = asyncio.run(preload_agents_with_ui())
            st.rerun()  # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨ìœ¼ë¡œ UI ì—…ë°ì´íŠ¸
        display_agent_status()

        with st.container(border=True):
            st.subheader("ğŸ“‚ ë°ì´í„° ì†ŒìŠ¤")
            handle_data_upload_with_ai_ds_team()
            if st.session_state.uploaded_data is not None:
                display_data_summary_ai_ds_team(st.session_state.uploaded_data)

        st.subheader("ğŸ’¬ AI DS Teamê³¼ ëŒ€í™”í•˜ê¸°")
        for msg in st.session_state.messages:
            with st.chat_message(msg["role"]): st.markdown(msg["content"])
        
        if prompt := st.chat_input("ë°ì´í„°ì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”..."):
            debug_log(f"ğŸ“ ì‚¬ìš©ì ì…ë ¥: {prompt[:100]}...")
            # Streamlitì—ì„œ ë¹„ë™ê¸° í•¨ìˆ˜ë¥¼ ì•ˆì „í•˜ê²Œ ì‹¤í–‰
            try:
                debug_log("ğŸ”„ ë¹„ë™ê¸° ì²˜ë¦¬ ì‹œì‘...")
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                loop.run_until_complete(process_query_streaming(prompt))
                loop.close()
                debug_log("âœ… ë¹„ë™ê¸° ì²˜ë¦¬ ì™„ë£Œ", "success")
            except Exception as e:
                debug_log(f"âŒ ë¹„ë™ê¸° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}", "error")
                import traceback
                debug_log(f"ğŸ” ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤: {traceback.format_exc()}", "error")
                
                st.error(f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                # ë™ê¸° ë²„ì „ìœ¼ë¡œ í´ë°±
                st.session_state.messages.append({"role": "user", "content": prompt})
                with st.chat_message("assistant", avatar="ğŸ§¬"):
                    st.error("ë¹„ë™ê¸° ì²˜ë¦¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì‹œìŠ¤í…œ ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.")
        
        debug_log("âœ… UI ë Œë”ë§ ì™„ë£Œ", "success")
        
    except Exception as e:
        debug_log(f"ğŸ’¥ ë©”ì¸ í•¨ìˆ˜ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}", "error")
        import traceback
        debug_log(f"ğŸ” ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤: {traceback.format_exc()}", "error")
        
        # ì‚¬ìš©ìì—ê²Œ ì˜¤ë¥˜ í‘œì‹œ
        st.error(f"ğŸš¨ ì• í”Œë¦¬ì¼€ì´ì…˜ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        st.error("ê°œë°œì ë„êµ¬ì—ì„œ ì½˜ì†” ë¡œê·¸ë¥¼ í™•ì¸í•˜ê±°ë‚˜ í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•´ë³´ì„¸ìš”.")
        
        # ê¸°ë³¸ UIë¼ë„ í‘œì‹œ
        st.title("ğŸ§¬ AI DS Team")
        st.warning("ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

if __name__ == "__main__":
    main()