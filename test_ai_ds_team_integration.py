#!/usr/bin/env python3
"""
AI_DS_Team A2A Integration Test Suite
=====================================

AI_DS_Team ì—ì´ì „íŠ¸ë“¤ì´ A2A í”„ë¡œí† ì½œì„ í†µí•´ ì˜¬ë°”ë¥´ê²Œ ì‘ë™í•˜ëŠ”ì§€ ê²€ì¦í•˜ëŠ” í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤
ai_ds_team/examplesì˜ ëª¨ë“  ì˜ˆì œë“¤ì´ A2A í™˜ê²½ì—ì„œ ë™ì‘í•˜ëŠ”ì§€ í™•ì¸
"""

import asyncio
import httpx
import pandas as pd
import json
import time
import os
import sys
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / "ai_ds_team"))

# Test Configuration
TEST_CONFIG = {
    "base_url": "http://localhost",
    "timeout": 30.0,
    "agents": {
        "orchestrator": {"port": 8100, "name": "Universal_AI_Orchestrator"},
        "data_cleaning": {"port": 8306, "name": "AI_DS_Team_DataCleaningAgent"},
        "data_loader": {"port": 8307, "name": "AI_DS_Team_DataLoaderAgent"},
        "data_visualization": {"port": 8308, "name": "AI_DS_Team_DataVisualizationAgent"}, 
        "data_wrangling": {"port": 8309, "name": "AI_DS_Team_DataWranglingAgent"},
        "feature_engineering": {"port": 8310, "name": "AI_DS_Team_FeatureEngineeringAgent"},
        "sql_database": {"port": 8311, "name": "AI_DS_Team_SQLDatabaseAgent"},
        "eda_tools": {"port": 8312, "name": "AI_DS_Team_EDAToolsAgent"},
        "h2o_ml": {"port": 8313, "name": "AI_DS_Team_H2OMLAgent"},
        "mlflow_tools": {"port": 8314, "name": "AI_DS_Team_MLflowToolsAgent"}
    }
}

# AI_DS_Team ì˜ˆì œ ê¸°ë°˜ í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ë“¤
TEST_SCENARIOS = [
    {
        "name": "EDA_Tools_Agent_Test",
        "description": "ai_ds_team/examples/ds_agents/eda_tools_agent.ipynb ê¸°ë°˜ í…ŒìŠ¤íŠ¸",
        "agent": "eda_tools",
        "data_file": "churn_data.csv",
        "test_cases": [
            "What tools do you have access to? Return a table.",
            "Give me information on the correlation funnel tool.",
            "What are the first 5 rows of the data?",
            "Describe the dataset.",
            "Analyze missing data patterns using missingno.",
            "Generate a sweetviz EDA report.",
            "Create a correlation funnel analysis."
        ]
    },
    {
        "name": "Pandas_Data_Analyst_Test", 
        "description": "ai_ds_team/examples/multiagents/pandas_data_analyst.ipynb ê¸°ë°˜ í…ŒìŠ¤íŠ¸",
        "agent": "data_wrangling",
        "data_file": "churn_data.csv",
        "test_cases": [
            "What are the first 5 rows of the data?",
            "Calculate summary statistics for numerical columns.",
            "Filter customers who have churned.",
            "Group by customer segment and calculate average monthly charges.",
            "Create a pivot table of churn by contract type and payment method."
        ]
    },
    {
        "name": "SQL_Data_Analyst_Test",
        "description": "ai_ds_team/examples/multiagents/sql_data_analyst.ipynb ê¸°ë°˜ í…ŒìŠ¤íŠ¸", 
        "agent": "sql_database",
        "data_file": "churn_data.csv",
        "test_cases": [
            "Convert the dataset to SQL format and analyze.",
            "Write SQL query to find high-value customers.",
            "Analyze churn rate by customer demographics using SQL.",
            "Create a SQL report on customer retention patterns."
        ]
    },
    {
        "name": "H2O_ML_Agent_Test",
        "description": "ai_ds_team/examples/ml_agents/h2o_machine_learning_agent.ipynb ê¸°ë°˜ í…ŒìŠ¤íŠ¸",
        "agent": "h2o_ml", 
        "data_file": "churn_data.csv",
        "test_cases": [
            "Train an H2O AutoML model to predict customer churn.",
            "Evaluate the model performance using H2O metrics.",
            "Generate feature importance analysis.",
            "Create model interpretation plots."
        ]
    },
    {
        "name": "MLflow_Tools_Test",
        "description": "ai_ds_team/examples/ml_agents/mlflow_tools_agent.ipynb ê¸°ë°˜ í…ŒìŠ¤íŠ¸",
        "agent": "mlflow_tools",
        "data_file": "churn_data.csv", 
        "test_cases": [
            "Set up MLflow experiment tracking.",
            "Log model metrics and parameters.",
            "Register a model in MLflow model registry.",
            "Compare different model versions."
        ]
    },
    {
        "name": "Data_Visualization_Test",
        "description": "ë°ì´í„° ì‹œê°í™” ì¢…í•© í…ŒìŠ¤íŠ¸",
        "agent": "data_visualization",
        "data_file": "churn_data.csv",
        "test_cases": [
            "Create a distribution plot of monthly charges.",
            "Plot churn rate by customer tenure.",
            "Generate a correlation heatmap.",
            "Create an interactive dashboard showing key metrics."
        ]
    },
    {
        "name": "Orchestrator_Integration_Test",
        "description": "ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°ë¥¼ í†µí•œ í†µí•© ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸",
        "agent": "orchestrator",
        "data_file": "churn_data.csv",
        "test_cases": [
            "Perform a complete data science analysis on the customer churn dataset including EDA, feature engineering, and modeling.",
            "Clean the data, create visualizations, and build a predictive model.",
            "Generate a comprehensive report with data insights and model recommendations."
        ]
    }
]

class AIDataScienceTeamTester:
    """AI_DS_Team A2A í†µí•© í…ŒìŠ¤í„°"""
    
    def __init__(self):
        self.base_url = TEST_CONFIG["base_url"]
        self.timeout = TEST_CONFIG["timeout"]
        self.agents = TEST_CONFIG["agents"]
        self.results = {}
        
    async def check_agent_health(self, agent_key: str) -> bool:
        """ì—ì´ì „íŠ¸ ìƒíƒœ í™•ì¸"""
        agent_info = self.agents[agent_key]
        port = agent_info["port"]
        
        try:
            async with httpx.AsyncClient(timeout=self.timeout) as client:
                response = await client.get(f"{self.base_url}:{port}/.well-known/agent.json")
                if response.status_code == 200:
                    agent_card = response.json()
                    print(f"âœ… {agent_info['name']} (port {port}): {agent_card.get('name', 'Unknown')}")
                    return True
                else:
                    print(f"âŒ {agent_info['name']} (port {port}): HTTP {response.status_code}")
                    return False
        except Exception as e:
            print(f"âŒ {agent_info['name']} (port {port}): {str(e)}")
            return False
    
    async def prepare_test_data(self, data_file: str) -> bool:
        """í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„"""
        try:
            # ai_ds_team/data ê²½ë¡œì—ì„œ ë°ì´í„° ë¡œë“œ
            source_path = f"ai_ds_team/data/{data_file}"
            target_path = f"a2a_ds_servers/artifacts/data/shared_dataframes/{data_file}"
            
            if os.path.exists(source_path):
                # ë°ì´í„° ë³µì‚¬
                df = pd.read_csv(source_path)
                os.makedirs(os.path.dirname(target_path), exist_ok=True)
                df.to_csv(target_path, index=False)
                print(f"ğŸ“Š Test data prepared: {data_file} ({df.shape[0]} rows, {df.shape[1]} columns)")
                return True
            else:
                print(f"âŒ Test data not found: {source_path}")
                return False
        except Exception as e:
            print(f"âŒ Error preparing test data: {e}")
            return False
    
    async def test_agent(self, agent_key: str, prompt: str) -> dict:
        """ê°œë³„ ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸"""
        agent_info = self.agents[agent_key]
        port = agent_info["port"]
        
        try:
            task_id = f"test_{agent_key}_{int(time.time())}"
            
            async with httpx.AsyncClient(timeout=self.timeout) as client:
                response = await client.post(
                    f"{self.base_url}:{port}/invoke",
                    json={
                        "message": {
                            "parts": [{"text": prompt}]
                        },
                        "context_id": f"test_session_{int(time.time())}",
                        "task_id": task_id
                    }
                )
                
                if response.status_code == 200:
                    result = response.json()
                    response_text = result.get("response", {}).get("parts", [{}])[0].get("text", "")
                    
                    return {
                        "success": True,
                        "response": response_text,
                        "task_id": task_id,
                        "agent": agent_info["name"]
                    }
                else:
                    return {
                        "success": False,
                        "error": f"HTTP {response.status_code}",
                        "response": response.text
                    }
                    
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "response": ""
            }
    
    async def run_scenario(self, scenario: dict) -> dict:
        """í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰"""
        print(f"\nğŸ§ª Testing Scenario: {scenario['name']}")
        print(f"ğŸ“‹ Description: {scenario['description']}")
        print(f"ğŸ¤– Agent: {scenario['agent']}")
        
        # ë°ì´í„° ì¤€ë¹„
        if not await self.prepare_test_data(scenario['data_file']):
            return {"success": False, "error": "Failed to prepare test data"}
        
        # ì—ì´ì „íŠ¸ ìƒíƒœ í™•ì¸
        if not await self.check_agent_health(scenario['agent']):
            return {"success": False, "error": "Agent not available"}
        
        # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì‹¤í–‰
        results = []
        for i, test_case in enumerate(scenario['test_cases'], 1):
            print(f"\n  ğŸ“ Test Case {i}/{len(scenario['test_cases'])}: {test_case[:50]}...")
            
            result = await self.test_agent(scenario['agent'], test_case)
            results.append({
                "test_case": test_case,
                "result": result
            })
            
            if result['success']:
                print(f"    âœ… Success")
                print(f"    ğŸ“„ Response: {result['response'][:100]}..." if len(result['response']) > 100 else f"    ğŸ“„ Response: {result['response']}")
            else:
                print(f"    âŒ Failed: {result['error']}")
            
            # í…ŒìŠ¤íŠ¸ ê°„ ê°„ê²©
            await asyncio.sleep(2)
        
        # ì‹œë‚˜ë¦¬ì˜¤ ê²°ê³¼ ìš”ì•½
        successful_tests = sum(1 for r in results if r['result']['success'])
        total_tests = len(results)
        
        scenario_result = {
            "success": successful_tests == total_tests,
            "successful_tests": successful_tests,
            "total_tests": total_tests,
            "test_results": results
        }
        
        print(f"ğŸ“Š Scenario Result: {successful_tests}/{total_tests} tests passed")
        return scenario_result
    
    async def run_all_scenarios(self):
        """ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰"""
        print("ğŸ§¬ AI_DS_Team A2A Integration Test Suite")
        print("=" * 50)
        
        # ì „ì²´ ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
        print("\nğŸ” System Health Check:")
        available_agents = []
        for agent_key in self.agents.keys():
            if await self.check_agent_health(agent_key):
                available_agents.append(agent_key)
        
        print(f"\nğŸ“Š Available Agents: {len(available_agents)}/{len(self.agents)}")
        
        if len(available_agents) < 3:  # ìµœì†Œ 3ê°œ ì—ì´ì „íŠ¸ í•„ìš”
            print("âŒ Insufficient agents available for testing")
            return
        
        # ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰
        scenario_results = {}
        for scenario in TEST_SCENARIOS:
            if scenario['agent'] in available_agents:
                result = await self.run_scenario(scenario)
                scenario_results[scenario['name']] = result
            else:
                print(f"\nâ­ï¸  Skipping {scenario['name']}: Agent {scenario['agent']} not available")
        
        # ìµœì¢… ê²°ê³¼ ìš”ì•½
        self.generate_test_report(scenario_results)
    
    def generate_test_report(self, scenario_results: dict):
        """í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„±"""
        print("\n" + "=" * 50)
        print("ğŸ“Š AI_DS_Team A2A Integration Test Report")
        print("=" * 50)
        
        total_scenarios = len(scenario_results)
        successful_scenarios = sum(1 for r in scenario_results.values() if r['success'])
        
        total_tests = sum(r['total_tests'] for r in scenario_results.values())
        successful_tests = sum(r['successful_tests'] for r in scenario_results.values())
        
        print(f"ğŸ¯ Overall Results:")
        print(f"   Scenarios: {successful_scenarios}/{total_scenarios} passed")
        print(f"   Test Cases: {successful_tests}/{total_tests} passed")
        print(f"   Success Rate: {(successful_tests/total_tests*100):.1f}%")
        
        print(f"\nğŸ“‹ Scenario Details:")
        for scenario_name, result in scenario_results.items():
            status = "âœ…" if result['success'] else "âŒ"
            print(f"   {status} {scenario_name}: {result['successful_tests']}/{result['total_tests']}")
        
        # ì‹¤íŒ¨í•œ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ìƒì„¸ ì •ë³´
        failed_tests = []
        for scenario_name, result in scenario_results.items():
            for test_result in result.get('test_results', []):
                if not test_result['result']['success']:
                    failed_tests.append({
                        'scenario': scenario_name,
                        'test_case': test_result['test_case'],
                        'error': test_result['result']['error']
                    })
        
        if failed_tests:
            print(f"\nâŒ Failed Test Cases ({len(failed_tests)}):")
            for failed in failed_tests[:5]:  # ì²˜ìŒ 5ê°œë§Œ í‘œì‹œ
                print(f"   â€¢ {failed['scenario']}: {failed['test_case'][:50]}...")
                print(f"     Error: {failed['error']}")
        
        # ì¶”ì²œ ì‚¬í•­
        print(f"\nğŸ’¡ Recommendations:")
        if successful_scenarios == total_scenarios:
            print("   ğŸ‰ All scenarios passed! AI_DS_Team A2A integration is working well.")
        else:
            print("   ğŸ”§ Some scenarios failed. Check agent implementations and A2A protocol compliance.")
            print("   ğŸ“ Review failed test cases and fix underlying issues.")
        
        # ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥
        report_data = {
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "summary": {
                "total_scenarios": total_scenarios,
                "successful_scenarios": successful_scenarios,
                "total_tests": total_tests,
                "successful_tests": successful_tests,
                "success_rate": successful_tests/total_tests*100
            },
            "scenario_results": scenario_results
        }
        
        report_file = f"ai_ds_team_test_report_{int(time.time())}.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ“„ Detailed report saved: {report_file}")


async def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    tester = AIDataScienceTeamTester()
    await tester.run_all_scenarios()


if __name__ == "__main__":
    asyncio.run(main()) 