# Universal Engine Deployment Guide

## ğŸš€ ê°œìš”

ì´ ê°€ì´ë“œëŠ” Universal Engineì„ ë‹¤ì–‘í•œ í™˜ê²½ì—ì„œ ë°°í¬í•˜ê³  ìš´ì˜í•˜ëŠ” ë°©ë²•ì„ ì œê³µí•©ë‹ˆë‹¤. ê°œë°œ, ìŠ¤í…Œì´ì§•, í”„ë¡œë•ì…˜ í™˜ê²½ë³„ ë°°í¬ ì „ëµê³¼ ëª¨ë‹ˆí„°ë§ ë°©ë²•ì„ ë‹¤ë£¹ë‹ˆë‹¤.

## ğŸ“‹ ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­

### ìµœì†Œ ìš”êµ¬ì‚¬í•­

#### í•˜ë“œì›¨ì–´
- **CPU**: 4ì½”ì–´ ì´ìƒ
- **ë©”ëª¨ë¦¬**: 8GB RAM
- **ë””ìŠ¤í¬**: 20GB SSD
- **ë„¤íŠ¸ì›Œí¬**: 1Gbps

#### ì†Œí”„íŠ¸ì›¨ì–´
- **OS**: Ubuntu 20.04 LTS ì´ìƒ, macOS 12+, Windows 10+
- **Python**: 3.9 ì´ìƒ
- **Docker**: 20.10 ì´ìƒ (ì„ íƒì‚¬í•­)
- **Git**: 2.30 ì´ìƒ

### ê¶Œì¥ ìš”êµ¬ì‚¬í•­

#### í•˜ë“œì›¨ì–´
- **CPU**: 8ì½”ì–´ ì´ìƒ
- **ë©”ëª¨ë¦¬**: 16GB RAM
- **ë””ìŠ¤í¬**: 100GB NVMe SSD
- **GPU**: NVIDIA RTX 3060 ì´ìƒ (ì„ íƒì‚¬í•­)
- **ë„¤íŠ¸ì›Œí¬**: 10Gbps

#### ì†Œí”„íŠ¸ì›¨ì–´
- **OS**: Ubuntu 22.04 LTS
- **Python**: 3.11
- **Docker Compose**: 2.0 ì´ìƒ
- **Kubernetes**: 1.25+ (í´ëŸ¬ìŠ¤í„° ë°°í¬ ì‹œ)

## ğŸ›  ë°°í¬ ì¤€ë¹„

### 1. í™˜ê²½ ì„¤ì •

#### Python ê°€ìƒí™˜ê²½ ì„¤ì •
```bash
# Python 3.11 ì„¤ì¹˜ (Ubuntu)
sudo apt update
sudo apt install python3.11 python3.11-venv python3.11-dev

# ê°€ìƒí™˜ê²½ ìƒì„±
python3.11 -m venv universal_engine_env
source universal_engine_env/bin/activate

# pip ì—…ê·¸ë ˆì´ë“œ
pip install --upgrade pip setuptools wheel
```

#### ì‹œìŠ¤í…œ íŒ¨í‚¤ì§€ ì„¤ì¹˜
```bash
# Ubuntu/Debian
sudo apt install -y build-essential git curl wget

# macOS
brew install git curl wget

# CentOS/RHEL
sudo yum groupinstall -y "Development Tools"
sudo yum install -y git curl wget
```

### 2. ì†ŒìŠ¤ ì½”ë“œ ì¤€ë¹„

```bash
# ì €ì¥ì†Œ í´ë¡ 
git clone <repository-url> universal-engine
cd universal-engine

# ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt

# ê°œë°œ ì˜ì¡´ì„± ì„¤ì¹˜ (ê°œë°œ í™˜ê²½)
pip install -r requirements-dev.txt
```

### 3. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

#### `.env` íŒŒì¼ ìƒì„±
```bash
# í™˜ê²½ ì„¤ì • íŒŒì¼ ìƒì„±
cp .env.example .env
```

#### í•„ìˆ˜ í™˜ê²½ ë³€ìˆ˜
```bash
# LLM ì„¤ì •
LLM_PROVIDER=ollama
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama2

# ë˜ëŠ” OpenAI ì‚¬ìš© ì‹œ
# LLM_PROVIDER=openai
# OPENAI_API_KEY=your_openai_api_key

# A2A ì—ì´ì „íŠ¸ ì„¤ì •
A2A_PORT_START=8306
A2A_PORT_END=8315
A2A_TIMEOUT=30

# ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • (ì„ íƒì‚¬í•­)
DATABASE_URL=sqlite:///./universal_engine.db

# ë¡œê¹… ì„¤ì •
LOG_LEVEL=INFO
LOG_FILE=/var/log/universal_engine.log

# ë³´ì•ˆ ì„¤ì •
SECRET_KEY=your_secret_key_here
ENCRYPTION_KEY=your_encryption_key_here
```

## ğŸ—ï¸ ë°°í¬ ë°©ë²•

### 1. ë¡œì»¬ ê°œë°œ ë°°í¬

#### ê¸°ë³¸ ì‹¤í–‰
```bash
# ê°€ìƒí™˜ê²½ í™œì„±í™”
source universal_engine_env/bin/activate

# Ollama ì„œë²„ ì‹œì‘ (ë³„ë„ í„°ë¯¸ë„)
ollama serve

# Universal Engine ì´ˆê¸°í™” ë° ì‹¤í–‰
python -m core.universal_engine.initialization.system_initializer
```

#### ê°œë°œ ëª¨ë“œ ì‹¤í–‰
```bash
# ê°œë°œ ëª¨ë“œë¡œ ì‹¤í–‰ (í•« ë¦¬ë¡œë“œ)
python -m uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

### 2. Docker ë°°í¬

#### Dockerfile ìƒì„±
```dockerfile
FROM python:3.11-slim

# ì‹œìŠ¤í…œ íŒ¨í‚¤ì§€ ì„¤ì¹˜
RUN apt-get update && apt-get install -y \
    build-essential \
    git \
    curl \
    && rm -rf /var/lib/apt/lists/*

# ì‘ì—… ë””ë ‰í† ë¦¬ ì„¤ì •
WORKDIR /app

# ì˜ì¡´ì„± íŒŒì¼ ë³µì‚¬ ë° ì„¤ì¹˜
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# ì†ŒìŠ¤ ì½”ë“œ ë³µì‚¬
COPY . .

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
ENV PYTHONPATH=/app
ENV LOG_LEVEL=INFO

# í¬íŠ¸ ë…¸ì¶œ
EXPOSE 8000 8306-8315

# ì‹¤í–‰ ëª…ë ¹
CMD ["python", "-m", "uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

#### Docker Compose ì„¤ì •
```yaml
version: '3.8'

services:
  universal-engine:
    build: .
    ports:
      - "8000:8000"
      - "8306-8315:8306-8315"
    environment:
      - LLM_PROVIDER=ollama
      - OLLAMA_BASE_URL=http://ollama:11434
    volumes:
      - ./logs:/app/logs
      - ./data:/app/data
    depends_on:
      - ollama
    restart: unless-stopped

  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    restart: unless-stopped
    command: ["ollama", "serve"]

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    restart: unless-stopped

volumes:
  ollama_data:
```

#### Docker ì‹¤í–‰
```bash
# ë¹Œë“œ ë° ì‹¤í–‰
docker-compose up -d

# ë¡œê·¸ í™•ì¸
docker-compose logs -f universal-engine

# ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
docker-compose ps
```

### 3. Kubernetes ë°°í¬

#### Namespace ìƒì„±
```yaml
apiVersion: v1
kind: Namespace
metadata:
  name: universal-engine
```

#### ConfigMap ì„¤ì •
```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: universal-engine-config
  namespace: universal-engine
data:
  LLM_PROVIDER: "ollama"
  OLLAMA_BASE_URL: "http://ollama-service:11434"
  A2A_PORT_START: "8306"
  A2A_PORT_END: "8315"
  LOG_LEVEL: "INFO"
```

#### Deployment ì„¤ì •
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: universal-engine
  namespace: universal-engine
spec:
  replicas: 3
  selector:
    matchLabels:
      app: universal-engine
  template:
    metadata:
      labels:
        app: universal-engine
    spec:
      containers:
      - name: universal-engine
        image: universal-engine:latest
        ports:
        - containerPort: 8000
        - containerPort: 8306
        - containerPort: 8315
        envFrom:
        - configMapRef:
            name: universal-engine-config
        resources:
          requests:
            memory: "2Gi"
            cpu: "1000m"
          limits:
            memory: "4Gi"
            cpu: "2000m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5
```

#### Service ì„¤ì •
```yaml
apiVersion: v1
kind: Service
metadata:
  name: universal-engine-service
  namespace: universal-engine
spec:
  selector:
    app: universal-engine
  ports:
  - name: http
    port: 80
    targetPort: 8000
  - name: a2a-start
    port: 8306
    targetPort: 8306
  - name: a2a-end
    port: 8315
    targetPort: 8315
  type: LoadBalancer
```

#### Ingress ì„¤ì •
```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: universal-engine-ingress
  namespace: universal-engine
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  rules:
  - host: universal-engine.yourdomain.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: universal-engine-service
            port:
              number: 80
```

### 4. í´ë¼ìš°ë“œ ë°°í¬

#### AWS ECS ë°°í¬

**Task Definition**
```json
{
  "family": "universal-engine",
  "networkMode": "awsvpc",
  "requiresCompatibilities": ["FARGATE"],
  "cpu": "2048",
  "memory": "4096",
  "executionRoleArn": "arn:aws:iam::account:role/ecsTaskExecutionRole",
  "containerDefinitions": [
    {
      "name": "universal-engine",
      "image": "your-account.dkr.ecr.region.amazonaws.com/universal-engine:latest",
      "portMappings": [
        {
          "containerPort": 8000,
          "protocol": "tcp"
        }
      ],
      "environment": [
        {
          "name": "LLM_PROVIDER",
          "value": "openai"
        },
        {
          "name": "OPENAI_API_KEY",
          "valueFrom": "arn:aws:ssm:region:account:parameter/universal-engine/openai-api-key"
        }
      ],
      "logConfiguration": {
        "logDriver": "awslogs",
        "options": {
          "awslogs-group": "/ecs/universal-engine",
          "awslogs-region": "us-west-2",
          "awslogs-stream-prefix": "ecs"
        }
      }
    }
  ]
}
```

#### Google Cloud Run ë°°í¬

```bash
# ì´ë¯¸ì§€ ë¹Œë“œ ë° í‘¸ì‹œ
docker build -t gcr.io/project-id/universal-engine .
docker push gcr.io/project-id/universal-engine

# Cloud Run ë°°í¬
gcloud run deploy universal-engine \
  --image gcr.io/project-id/universal-engine \
  --platform managed \
  --region us-central1 \
  --allow-unauthenticated \
  --port 8000 \
  --memory 4Gi \
  --cpu 2 \
  --set-env-vars LLM_PROVIDER=openai,OPENAI_API_KEY=your-key
```

#### Azure Container Instances ë°°í¬

```bash
# ë¦¬ì†ŒìŠ¤ ê·¸ë£¹ ìƒì„±
az group create --name universal-engine-rg --location eastus

# ì»¨í…Œì´ë„ˆ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
az container create \
  --resource-group universal-engine-rg \
  --name universal-engine \
  --image universal-engine:latest \
  --cpu 2 \
  --memory 4 \
  --ports 8000 \
  --environment-variables LLM_PROVIDER=openai OPENAI_API_KEY=your-key
```

## ğŸ”§ ë°°í¬ í›„ ì„¤ì •

### 1. í—¬ìŠ¤ ì²´í¬ ì„¤ì •

#### í—¬ìŠ¤ ì²´í¬ ì—”ë“œí¬ì¸íŠ¸
```python
@app.get("/health")
async def health_check():
    """ì‹œìŠ¤í…œ í—¬ìŠ¤ ì²´í¬"""
    return {
        "status": "healthy",
        "timestamp": datetime.now(),
        "version": "1.0.0"
    }

@app.get("/ready")
async def readiness_check():
    """ì„œë¹„ìŠ¤ ì¤€ë¹„ ìƒíƒœ ì²´í¬"""
    # LLM ì„œë¹„ìŠ¤ ì—°ê²° í™•ì¸
    # A2A ì—ì´ì „íŠ¸ ìƒíƒœ í™•ì¸
    # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í™•ì¸
    return {"status": "ready"}
```

### 2. ë¡œê¹… ì„¤ì •

#### ë¡œê·¸ ì„¤ì • íŒŒì¼ (`logging.conf`)
```ini
[loggers]
keys=root,universal_engine

[handlers]
keys=console,file,rotating_file

[formatters]
keys=detailed,simple

[logger_root]
level=INFO
handlers=console

[logger_universal_engine]
level=DEBUG
handlers=file,rotating_file
qualname=universal_engine
propagate=0

[handler_console]
class=StreamHandler
level=INFO
formatter=simple
args=(sys.stdout,)

[handler_file]
class=FileHandler
level=DEBUG
formatter=detailed
args=('/var/log/universal_engine.log',)

[handler_rotating_file]
class=handlers.RotatingFileHandler
level=DEBUG
formatter=detailed
args=('/var/log/universal_engine.log', 'a', 10485760, 5)

[formatter_detailed]
format=%(asctime)s %(name)-15s %(levelname)-8s %(processName)-10s %(message)s

[formatter_simple]
format=%(asctime)s - %(name)s - %(levelname)s - %(message)s
```

### 3. ë³´ì•ˆ ì„¤ì •

#### SSL/TLS ì„¤ì •
```bash
# Let's Encrypt ì¸ì¦ì„œ ìƒì„±
sudo certbot --nginx -d universal-engine.yourdomain.com

# ë˜ëŠ” ìì²´ ì„œëª… ì¸ì¦ì„œ ìƒì„±
openssl req -x509 -newkey rsa:4096 -keyout key.pem -out cert.pem -days 365 -nodes
```

#### ë°©í™”ë²½ ì„¤ì •
```bash
# Ubuntu UFW ì„¤ì •
sudo ufw allow 22/tcp
sudo ufw allow 80/tcp
sudo ufw allow 443/tcp
sudo ufw allow 8306:8315/tcp
sudo ufw enable

# ë˜ëŠ” iptables ì„¤ì •
sudo iptables -A INPUT -p tcp --dport 8000 -j ACCEPT
sudo iptables -A INPUT -p tcp --dport 8306:8315 -j ACCEPT
```

## ğŸ“Š ëª¨ë‹ˆí„°ë§ ë° ê´€ì°°ì„±

### 1. Prometheus ë©”íŠ¸ë¦­ ìˆ˜ì§‘

#### ë©”íŠ¸ë¦­ ì„¤ì •
```python
from prometheus_client import Counter, Histogram, Gauge, generate_latest

# ë©”íŠ¸ë¦­ ì •ì˜
query_total = Counter('queries_total', 'Total queries processed')
query_duration = Histogram('query_duration_seconds', 'Query processing duration')
active_sessions = Gauge('active_sessions', 'Number of active sessions')

@app.get("/metrics")
async def metrics():
    """Prometheus ë©”íŠ¸ë¦­ ì—”ë“œí¬ì¸íŠ¸"""
    return Response(generate_latest(), media_type="text/plain")
```

#### Prometheus ì„¤ì • (`prometheus.yml`)
```yaml
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'universal-engine'
    static_configs:
      - targets: ['localhost:8000']
    metrics_path: '/metrics'
    scrape_interval: 10s
```

### 2. Grafana ëŒ€ì‹œë³´ë“œ

#### ëŒ€ì‹œë³´ë“œ ì„¤ì •
```json
{
  "dashboard": {
    "title": "Universal Engine Dashboard",
    "panels": [
      {
        "title": "Query Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(queries_total[5m])",
            "legendFormat": "Queries/sec"
          }
        ]
      },
      {
        "title": "Response Time",
        "type": "graph",
        "targets": [
          {
            "expr": "query_duration_seconds",
            "legendFormat": "Response Time"
          }
        ]
      },
      {
        "title": "Active Sessions",
        "type": "singlestat",
        "targets": [
          {
            "expr": "active_sessions",
            "legendFormat": "Sessions"
          }
        ]
      }
    ]
  }
}
```

### 3. ELK Stack ë¡œê·¸ ë¶„ì„

#### Filebeat ì„¤ì • (`filebeat.yml`)
```yaml
filebeat.inputs:
- type: log
  enabled: true
  paths:
    - /var/log/universal_engine.log
  fields:
    service: universal-engine
  fields_under_root: true

output.elasticsearch:
  hosts: ["localhost:9200"]

processors:
  - add_host_metadata:
      when.not.contains.tags: forwarded
```

#### Logstash íŒŒì´í”„ë¼ì¸
```ruby
input {
  beats {
    port => 5044
  }
}

filter {
  if [service] == "universal-engine" {
    grok {
      match => { "message" => "%{TIMESTAMP_ISO8601:timestamp} %{WORD:logger} %{LOGLEVEL:level} %{GREEDYDATA:message}" }
    }
    
    date {
      match => [ "timestamp", "ISO8601" ]
    }
  }
}

output {
  elasticsearch {
    hosts => ["localhost:9200"]
    index => "universal-engine-%{+YYYY.MM.dd}"
  }
}
```

### 4. ì•Œë¦¼ ì„¤ì •

#### AlertManager ì„¤ì •
```yaml
route:
  group_by: ['alertname']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 1h
  receiver: 'web.hook'

receivers:
- name: 'web.hook'
  slack_configs:
  - api_url: 'https://hooks.slack.com/your-webhook-url'
    channel: '#universal-engine-alerts'
    title: 'Universal Engine Alert'
    text: '{{ range .Alerts }}{{ .Annotations.summary }}{{ end }}'
```

#### ì•Œë¦¼ ê·œì¹™
```yaml
groups:
- name: universal-engine
  rules:
  - alert: HighQueryLatency
    expr: query_duration_seconds > 10
    for: 2m
    annotations:
      summary: "High query latency detected"
      
  - alert: LowSuccessRate
    expr: rate(queries_total{status="success"}[5m]) / rate(queries_total[5m]) < 0.9
    for: 5m
    annotations:
      summary: "Success rate below 90%"
      
  - alert: ServiceDown
    expr: up{job="universal-engine"} == 0
    for: 1m
    annotations:
      summary: "Universal Engine service is down"
```

## ğŸ”„ ë°°í¬ ìë™í™”

### 1. CI/CD íŒŒì´í”„ë¼ì¸

#### GitHub Actions
```yaml
name: Deploy Universal Engine

on:
  push:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.11'
    - name: Install dependencies
      run: |
        pip install -r requirements.txt
        pip install -r requirements-dev.txt
    - name: Run tests
      run: |
        python -m pytest tests/ -v --cov=core

  deploy:
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    steps:
    - uses: actions/checkout@v2
    - name: Build Docker image
      run: docker build -t universal-engine:${{ github.sha }} .
    - name: Deploy to production
      run: |
        # í”„ë¡œë•ì…˜ ë°°í¬ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
        ./scripts/deploy.sh ${{ github.sha }}
```

#### Jenkins Pipeline
```groovy
pipeline {
    agent any
    
    stages {
        stage('Test') {
            steps {
                sh 'pip install -r requirements.txt'
                sh 'python -m pytest tests/'
            }
        }
        
        stage('Build') {
            steps {
                sh 'docker build -t universal-engine:${BUILD_NUMBER} .'
            }
        }
        
        stage('Deploy') {
            when {
                branch 'main'
            }
            steps {
                sh 'docker-compose -f docker-compose.prod.yml up -d'
            }
        }
    }
    
    post {
        failure {
            mail to: 'devops@company.com',
                 subject: "Build Failed: ${env.JOB_NAME} - ${env.BUILD_NUMBER}",
                 body: "Build failed. Check console output at ${env.BUILD_URL}"
        }
    }
}
```

### 2. Blue-Green ë°°í¬

#### ë°°í¬ ìŠ¤í¬ë¦½íŠ¸
```bash
#!/bin/bash

# Blue-Green ë°°í¬ ìŠ¤í¬ë¦½íŠ¸
set -e

VERSION=$1
CURRENT_ENV=$(curl -s http://localhost:8000/env | jq -r '.environment')

if [ "$CURRENT_ENV" = "blue" ]; then
    NEW_ENV="green"
    OLD_ENV="blue"
else
    NEW_ENV="blue"
    OLD_ENV="green"
fi

echo "Deploying to $NEW_ENV environment..."

# ìƒˆ í™˜ê²½ì— ë°°í¬
docker-compose -f docker-compose.$NEW_ENV.yml up -d
docker-compose -f docker-compose.$NEW_ENV.yml exec universal-engine python -c "
from core.universal_engine.initialization.system_initializer import UniversalEngineInitializer
import asyncio
asyncio.run(UniversalEngineInitializer().initialize_system())
"

# í—¬ìŠ¤ ì²´í¬
sleep 30
HEALTH=$(curl -s http://localhost:800$([[ "$NEW_ENV" = "blue" ]] && echo "1" || echo "2")/health | jq -r '.status')

if [ "$HEALTH" = "healthy" ]; then
    echo "Health check passed. Switching traffic..."
    # ë¡œë“œ ë°¸ëŸ°ì„œ ì„¤ì • ë³€ê²½
    ./scripts/switch_traffic.sh $NEW_ENV
    
    # ì´ì „ í™˜ê²½ ì •ë¦¬
    sleep 60
    docker-compose -f docker-compose.$OLD_ENV.yml down
    
    echo "Deployment completed successfully!"
else
    echo "Health check failed. Rolling back..."
    docker-compose -f docker-compose.$NEW_ENV.yml down
    exit 1
fi
```

## ğŸ” ë¬¸ì œ í•´ê²°

### ì¼ë°˜ì ì¸ ë°°í¬ ë¬¸ì œ

#### 1. í¬íŠ¸ ì¶©ëŒ
```bash
# í¬íŠ¸ ì‚¬ìš© í˜„í™© í™•ì¸
netstat -tulpn | grep 8306

# í¬íŠ¸ë¥¼ ì‚¬ìš©í•˜ëŠ” í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ
sudo kill -9 $(sudo lsof -t -i:8306)
```

#### 2. ë©”ëª¨ë¦¬ ë¶€ì¡±
```bash
# ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
free -h

# ìŠ¤ì™‘ ìƒì„± (ì„ì‹œ í•´ê²°)
sudo fallocate -l 4G /swapfile
sudo chmod 600 /swapfile
sudo mkswap /swapfile
sudo swapon /swapfile
```

#### 3. LLM ì„œë¹„ìŠ¤ ì—°ê²° ì˜¤ë¥˜
```bash
# Ollama ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
systemctl status ollama

# Ollama ì„œë¹„ìŠ¤ ì¬ì‹œì‘
sudo systemctl restart ollama

# OpenAI API í‚¤ í™•ì¸
curl -H "Authorization: Bearer $OPENAI_API_KEY" \
     https://api.openai.com/v1/models
```

### ì„±ëŠ¥ íŠœë‹

#### 1. ì‹œìŠ¤í…œ ìµœì í™”
```bash
# íŒŒì¼ ë””ìŠ¤í¬ë¦½í„° ì œí•œ ì¦ê°€
echo "* soft nofile 65536" >> /etc/security/limits.conf
echo "* hard nofile 65536" >> /etc/security/limits.conf

# ì»¤ë„ íŒŒë¼ë¯¸í„° íŠœë‹
echo "net.core.somaxconn = 65536" >> /etc/sysctl.conf
echo "net.ipv4.tcp_max_syn_backlog = 65536" >> /etc/sysctl.conf
sysctl -p
```

#### 2. Python ìµœì í™”
```bash
# PyPy ì‚¬ìš© (í˜¸í™˜ì„± í™•ì¸ í•„ìš”)
pip install pypy3

# JIT ì»´íŒŒì¼ í™œì„±í™”
export PYTHONDONTWRITEBYTECODE=1
export PYTHONUNBUFFERED=1
```

## ğŸ“š ì¶”ê°€ ë¦¬ì†ŒìŠ¤

### ê´€ë ¨ ë¬¸ì„œ
- [Universal Engine User Guide](./UNIVERSAL_ENGINE_USER_GUIDE.md)
- [API Reference](./UNIVERSAL_ENGINE_API_REFERENCE.md)
- [Troubleshooting Guide](./UNIVERSAL_ENGINE_TROUBLESHOOTING.md)

### ëª¨ë‹ˆí„°ë§ ë„êµ¬
- **Prometheus**: ë©”íŠ¸ë¦­ ìˆ˜ì§‘
- **Grafana**: ëŒ€ì‹œë³´ë“œ ë° ì‹œê°í™”
- **ELK Stack**: ë¡œê·¸ ë¶„ì„
- **Jaeger**: ë¶„ì‚° ì¶”ì 

### ë³´ì•ˆ ë„êµ¬
- **OWASP ZAP**: ë³´ì•ˆ ìŠ¤ìºë‹
- **Bandit**: Python ì½”ë“œ ë³´ì•ˆ ë¶„ì„
- **Safety**: ì˜ì¡´ì„± ë³´ì•ˆ ì²´í¬

---

ì´ ë°°í¬ ê°€ì´ë“œë¥¼ í†µí•´ Universal Engineì„ ì•ˆì „í•˜ê³  íš¨ìœ¨ì ìœ¼ë¡œ ìš´ì˜ í™˜ê²½ì— ë°°í¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¶”ê°€ ì§€ì›ì´ í•„ìš”í•œ ê²½ìš° ê¸°ìˆ  ì§€ì›íŒ€ì— ë¬¸ì˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.