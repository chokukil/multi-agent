# ğŸ”§ CherryAI v2.0 ë¬¸ì œ í•´ê²° ê°€ì´ë“œ

**ì¼ë°˜ì ì¸ ë¬¸ì œë“¤ê³¼ ì²´ê³„ì ì¸ í•´ê²° ë°©ë²•**

## ğŸ“‹ ëª©ì°¨

- [ì„¤ì¹˜ ê´€ë ¨ ë¬¸ì œ](#-ì„¤ì¹˜-ê´€ë ¨-ë¬¸ì œ)
- [A2A ì„œë²„ ë¬¸ì œ](#-a2a-ì„œë²„-ë¬¸ì œ)
- [íŒŒì¼ ì—…ë¡œë“œ ë¬¸ì œ](#-íŒŒì¼-ì—…ë¡œë“œ-ë¬¸ì œ)
- [ì„±ëŠ¥ ê´€ë ¨ ë¬¸ì œ](#-ì„±ëŠ¥-ê´€ë ¨-ë¬¸ì œ)
- [UI ë° ë¸Œë¼ìš°ì € ë¬¸ì œ](#-ui-ë°-ë¸Œë¼ìš°ì €-ë¬¸ì œ)
- [API ë° ì—°ê²° ë¬¸ì œ](#-api-ë°-ì—°ê²°-ë¬¸ì œ)
- [ë°ì´í„° ë¶„ì„ ë¬¸ì œ](#-ë°ì´í„°-ë¶„ì„-ë¬¸ì œ)
- [ë¡œê¹… ë° ì¶”ì  ë¬¸ì œ](#-ë¡œê¹…-ë°-ì¶”ì -ë¬¸ì œ)
- [ê³ ê¸‰ ë¬¸ì œ í•´ê²°](#-ê³ ê¸‰-ë¬¸ì œ-í•´ê²°)

## ğŸš€ ì„¤ì¹˜ ê´€ë ¨ ë¬¸ì œ

### ë¬¸ì œ 1: Python ë²„ì „ í˜¸í™˜ì„±

**ì¦ìƒ:**
```bash
ERROR: This package requires Python >=3.12
```

**í•´ê²°ì±…:**
```bash
# 1. Python ë²„ì „ í™•ì¸
python --version

# 2. Python 3.12+ ì„¤ì¹˜ (macOS)
brew install python@3.12

# 3. Python 3.12+ ì„¤ì¹˜ (Ubuntu)
sudo apt update
sudo apt install python3.12 python3.12-venv

# 4. pyenv ì‚¬ìš© (ê¶Œì¥)
pyenv install 3.12.10
pyenv local 3.12.10
```

### ë¬¸ì œ 2: UV íŒ¨í‚¤ì§€ ë§¤ë‹ˆì € ì„¤ì¹˜ ì‹¤íŒ¨

**ì¦ìƒ:**
```bash
uv: command not found
```

**í•´ê²°ì±…:**
```bash
# ë°©ë²• 1: ê³µì‹ ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸
curl -LsSf https://astral.sh/uv/install.sh | sh

# ë°©ë²• 2: pipë¡œ ì„¤ì¹˜
pip install uv

# ë°©ë²• 3: í™ˆë¸Œë£¨ (macOS)
brew install uv

# ì„¤ì¹˜ í™•ì¸
uv --version
```

### ë¬¸ì œ 3: ì˜ì¡´ì„± ì„¤ì¹˜ ì‹¤íŒ¨

**ì¦ìƒ:**
```bash
ERROR: Could not find a version that satisfies the requirement
```

**í•´ê²°ì±…:**
```bash
# 1. ê°€ìƒí™˜ê²½ ì¬ìƒì„±
rm -rf .venv
uv venv
source .venv/bin/activate

# 2. ìºì‹œ ì •ë¦¬
uv cache clean

# 3. ê°œë³„ ì„¤ì¹˜ ì‹œë„
uv pip install pandas numpy streamlit

# 4. í˜¸í™˜ì„± í™•ì¸ëœ ë²„ì „ ì„¤ì¹˜
uv pip install pandas==2.3.0 numpy==2.1.3 streamlit==1.46.0
```

### ë¬¸ì œ 4: ê¶Œí•œ ë¬¸ì œ

**ì¦ìƒ:**
```bash
Permission denied: '/usr/local/lib/python3.12'
```

**í•´ê²°ì±…:**
```bash
# 1. ê°€ìƒí™˜ê²½ ì‚¬ìš© (ê¶Œì¥)
uv venv .venv
source .venv/bin/activate

# 2. ì‚¬ìš©ì ë””ë ‰í† ë¦¬ì— ì„¤ì¹˜
pip install --user package_name

# 3. sudo ì‚¬ìš© (ë¹„ê¶Œì¥)
sudo pip install package_name
```

## ğŸ¤– A2A ì„œë²„ ë¬¸ì œ

### ë¬¸ì œ 1: A2A ì„œë²„ ì‹œì‘ ì‹¤íŒ¨

**ì¦ìƒ:**
```bash
Error: Address already in use (port 8100)
```

**í•´ê²°ì±…:**
```bash
# 1. í¬íŠ¸ ì‚¬ìš© í™•ì¸
lsof -i :8100
netstat -ln | grep 8100

# 2. í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ
kill -9 <PID>

# 3. ëª¨ë“  CherryAI í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ
./ai_ds_team_system_stop.sh

# 4. í¬íŠ¸ ë³€ê²½ (í•„ìš”ì‹œ)
export A2A_ORCHESTRATOR_PORT=8110
```

### ë¬¸ì œ 2: Agent Card ì ‘ê·¼ ë¶ˆê°€

**ì¦ìƒ:**
```bash
curl: (7) Failed to connect to localhost port 8100
```

**ì§„ë‹¨:**
```bash
# 1. ì„œë²„ ìƒíƒœ í™•ì¸
ps aux | grep python | grep 8100

# 2. ë¡œê·¸ í™•ì¸
tail -f logs/orchestrator.log

# 3. ë„¤íŠ¸ì›Œí¬ ì—°ê²° í™•ì¸
curl -v http://localhost:8100/health
```

**í•´ê²°ì±…:**
```bash
# 1. ì„œë²„ ì¬ì‹œì‘
python a2a_orchestrator.py

# 2. ë°©í™”ë²½ í™•ì¸
sudo ufw status
sudo iptables -L

# 3. í™˜ê²½ë³€ìˆ˜ í™•ì¸
echo $A2A_ORCHESTRATOR_PORT
```

### ë¬¸ì œ 3: A2A í†µì‹  ì˜¤ë¥˜

**ì¦ìƒ:**
```json
{
  "error": "Agent not responding",
  "code": "AGENT_TIMEOUT"
}
```

**í•´ê²°ì±…:**
```bash
# 1. ëª¨ë“  ì—ì´ì „íŠ¸ ìƒíƒœ í™•ì¸
curl http://localhost:8100/.well-known/agent.json
curl http://localhost:8200/.well-known/agent.json
curl http://localhost:8203/.well-known/agent.json

# 2. íƒ€ì„ì•„ì›ƒ ì„¤ì • ì¦ê°€
export A2A_TIMEOUT=300

# 3. ê°œë³„ ì—ì´ì „íŠ¸ ì¬ì‹œì‘
python a2a_ds_servers/pandas_data_analyst_server.py
```

## ğŸ“ íŒŒì¼ ì—…ë¡œë“œ ë¬¸ì œ

### ë¬¸ì œ 1: íŒŒì¼ í¬ê¸° ì œí•œ

**ì¦ìƒ:**
```
File size exceeds maximum limit (100MB)
```

**í•´ê²°ì±…:**
```python
# 1. Streamlit ì„¤ì • ë³€ê²½
# .streamlit/config.toml
[server]
maxUploadSize = 200

# 2. íŒŒì¼ ì••ì¶•
gzip large_file.csv

# 3. ë°ì´í„° ìƒ˜í”Œë§
df_sample = df.sample(n=10000)
df_sample.to_csv('sample_data.csv')
```

### ë¬¸ì œ 2: ì¸ì½”ë”© ë¬¸ì œ

**ì¦ìƒ:**
```
UnicodeDecodeError: 'utf-8' codec can't decode
```

**í•´ê²°ì±…:**
```python
# 1. ì¸ì½”ë”© ê°ì§€ ë° ë³€í™˜
import chardet

def detect_encoding(file_path):
    with open(file_path, 'rb') as f:
        result = chardet.detect(f.read())
    return result['encoding']

# 2. íŒŒì¼ ì¬ì €ì¥
import pandas as pd

# ë‹¤ì–‘í•œ ì¸ì½”ë”© ì‹œë„
encodings = ['utf-8', 'cp949', 'euc-kr', 'latin1']
for encoding in encodings:
    try:
        df = pd.read_csv(file_path, encoding=encoding)
        df.to_csv('fixed_file.csv', encoding='utf-8')
        break
    except UnicodeDecodeError:
        continue
```

### ë¬¸ì œ 3: íŒŒì¼ í˜•ì‹ ì¸ì‹ ì˜¤ë¥˜

**ì¦ìƒ:**
```
File format not supported or corrupted
```

**í•´ê²°ì±…:**
```bash
# 1. íŒŒì¼ íƒ€ì… í™•ì¸
file sample.csv
head -5 sample.csv

# 2. êµ¬ë¶„ì í™•ì¸
python -c "
import pandas as pd
try:
    df = pd.read_csv('sample.csv', nrows=5)
    print('ê¸°ë³¸ êµ¬ë¶„ì ì„±ê³µ')
except:
    df = pd.read_csv('sample.csv', sep=';', nrows=5)
    print('ì„¸ë¯¸ì½œë¡  êµ¬ë¶„ì ì„±ê³µ')
"

# 3. Excel íŒŒì¼ ë³µêµ¬
python -c "
import pandas as pd
df = pd.read_excel('file.xlsx', engine='openpyxl')
df.to_csv('converted.csv')
"
```

## âš¡ ì„±ëŠ¥ ê´€ë ¨ ë¬¸ì œ

### ë¬¸ì œ 1: ëŠë¦° ì‘ë‹µ ì†ë„

**ì¦ìƒ:**
- ë¶„ì„ ìš”ì²­ í›„ 30ì´ˆ ì´ìƒ ì†Œìš”
- ë¸Œë¼ìš°ì €ê°€ ì‘ë‹µ ì—†ìŒ

**ì§„ë‹¨:**
```python
# ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ í™•ì¸
import psutil

print(f"CPU ì‚¬ìš©ë¥ : {psutil.cpu_percent()}%")
print(f"ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ : {psutil.virtual_memory().percent}%")
print(f"ë””ìŠ¤í¬ I/O: {psutil.disk_io_counters()}")
```

**í•´ê²°ì±…:**
```python
# 1. ë°ì´í„° ìƒ˜í”Œë§
if len(df) > 50000:
    df_sample = df.sample(n=10000)
    print("ëŒ€ìš©ëŸ‰ ë°ì´í„°ë¥¼ ìƒ˜í”Œë§í–ˆìŠµë‹ˆë‹¤.")

# 2. ì²­í¬ ë‹¨ìœ„ ì²˜ë¦¬
def process_large_file(file_path, chunk_size=10000):
    chunks = []
    for chunk in pd.read_csv(file_path, chunksize=chunk_size):
        processed_chunk = process_chunk(chunk)
        chunks.append(processed_chunk)
    return pd.concat(chunks)

# 3. ë©”ëª¨ë¦¬ ìµœì í™”
import gc
gc.collect()  # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ê°•ì œ ì‹¤í–‰
```

### ë¬¸ì œ 2: ë©”ëª¨ë¦¬ ë¶€ì¡±

**ì¦ìƒ:**
```
MemoryError: Unable to allocate array
```

**í•´ê²°ì±…:**
```python
# 1. ë°ì´í„° íƒ€ì… ìµœì í™”
def optimize_dtypes(df):
    for col in df.columns:
        if df[col].dtype == 'object':
            try:
                df[col] = pd.to_numeric(df[col], downcast='integer')
            except:
                pass
        elif df[col].dtype == 'float64':
            df[col] = pd.to_numeric(df[col], downcast='float')
    return df

# 2. ì²­í¬ ë‹¨ìœ„ ì²˜ë¦¬
def memory_efficient_processing(file_path):
    result = None
    for chunk in pd.read_csv(file_path, chunksize=1000):
        processed = process_chunk(chunk)
        if result is None:
            result = processed
        else:
            result = pd.concat([result, processed])
        del chunk, processed
        gc.collect()
    return result

# 3. ìŠ¤ì™‘ ë©”ëª¨ë¦¬ í™•ì¸ (Linux/Mac)
# sudo swapon --show
```

### ë¬¸ì œ 3: A2A ì—ì´ì „íŠ¸ íƒ€ì„ì•„ì›ƒ

**ì¦ìƒ:**
```
RequestTimeout: Agent did not respond within 30 seconds
```

**í•´ê²°ì±…:**
```python
# 1. íƒ€ì„ì•„ì›ƒ ì„¤ì • ì¦ê°€
import os
os.environ['A2A_TIMEOUT'] = '300'  # 5ë¶„

# 2. ë¹„ë™ê¸° ì²˜ë¦¬ ê°œì„ 
import asyncio

async def robust_agent_call(agent_url, request, max_retries=3):
    for attempt in range(max_retries):
        try:
            response = await call_agent(agent_url, request, timeout=300)
            return response
        except asyncio.TimeoutError:
            if attempt == max_retries - 1:
                raise
            await asyncio.sleep(2 ** attempt)  # ì§€ìˆ˜ ë°±ì˜¤í”„

# 3. ì—ì´ì „íŠ¸ í—¬ìŠ¤ì²´í¬
def check_agent_health():
    agents = ['8100', '8200', '8203', '8202']
    for port in agents:
        try:
            response = requests.get(f'http://localhost:{port}/health', timeout=5)
            print(f"Agent {port}: {response.status_code}")
        except:
            print(f"Agent {port}: OFFLINE")
```

## ğŸ–¥ï¸ UI ë° ë¸Œë¼ìš°ì € ë¬¸ì œ

### ë¬¸ì œ 1: Streamlit í˜ì´ì§€ ë¡œë“œ ì‹¤íŒ¨

**ì¦ìƒ:**
```
This site can't be reached
localhost refused to connect
```

**í•´ê²°ì±…:**
```bash
# 1. Streamlit í”„ë¡œì„¸ìŠ¤ í™•ì¸
ps aux | grep streamlit

# 2. í¬íŠ¸ í™•ì¸
lsof -i :8501

# 3. ìˆ˜ë™ ì‹œì‘
streamlit run ai.py --server.port 8501 --server.address 0.0.0.0

# 4. ë¡œê·¸ í™•ì¸
streamlit run ai.py --logger.level debug
```

### ë¬¸ì œ 2: ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”

**ì¦ìƒ:**
- ì—…ë¡œë“œí•œ íŒŒì¼ì´ ì‚¬ë¼ì§
- ë¶„ì„ ê²°ê³¼ê°€ ì´ˆê¸°í™”ë¨

**í•´ê²°ì±…:**
```python
# 1. ì„¸ì…˜ ìƒíƒœ ë””ë²„ê¹…
import streamlit as st

print("Current session state:")
for key, value in st.session_state.items():
    print(f"{key}: {type(value)}")

# 2. ì„¸ì…˜ ìƒíƒœ ìœ ì§€
if 'uploaded_files' not in st.session_state:
    st.session_state.uploaded_files = {}

if 'analysis_results' not in st.session_state:
    st.session_state.analysis_results = {}

# 3. ìºì‹± ì‚¬ìš©
@st.cache_data
def load_and_cache_data(file_path):
    return pd.read_csv(file_path)
```

### ë¬¸ì œ 3: ì°¨íŠ¸ ë Œë”ë§ ì˜¤ë¥˜

**ì¦ìƒ:**
```
PlotlyJSONEncoder: Object of type 'DataFrame' is not JSON serializable
```

**í•´ê²°ì±…:**
```python
# 1. ë°ì´í„° ì§ë ¬í™” í™•ì¸
import json
import plotly.graph_objects as go

def safe_plotly_chart(fig):
    try:
        st.plotly_chart(fig, use_container_width=True)
    except Exception as e:
        st.error(f"ì°¨íŠ¸ ë Œë”ë§ ì˜¤ë¥˜: {e}")
        # ëŒ€ì•ˆìœ¼ë¡œ matplotlib ì‚¬ìš©
        st.pyplot(create_matplotlib_alternative(fig))

# 2. ë°ì´í„° íƒ€ì… í™•ì¸
def prepare_chart_data(df):
    # NaN ê°’ ì²˜ë¦¬
    df = df.dropna()
    
    # ë°ì´í„° íƒ€ì… ë³€í™˜
    for col in df.columns:
        if df[col].dtype == 'object':
            df[col] = df[col].astype(str)
    
    return df
```

## ğŸ”Œ API ë° ì—°ê²° ë¬¸ì œ

### ë¬¸ì œ 1: OpenAI API í‚¤ ì˜¤ë¥˜

**ì¦ìƒ:**
```
AuthenticationError: Incorrect API key provided
```

**í•´ê²°ì±…:**
```bash
# 1. API í‚¤ í™•ì¸
echo $OPENAI_API_KEY

# 2. .env íŒŒì¼ í™•ì¸
cat .env | grep OPENAI_API_KEY

# 3. API í‚¤ í…ŒìŠ¤íŠ¸
python -c "
import openai
import os
client = openai.OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
response = client.chat.completions.create(
    model='gpt-3.5-turbo',
    messages=[{'role': 'user', 'content': 'test'}],
    max_tokens=10
)
print('API í‚¤ ì •ìƒ ì‘ë™')
"

# 4. ìƒˆë¡œìš´ API í‚¤ ë°œê¸‰
# https://platform.openai.com/api-keys ì ‘ì†
```

### ë¬¸ì œ 2: Langfuse ì—°ê²° ì‹¤íŒ¨

**ì¦ìƒ:**
```
ConnectionError: Unable to connect to Langfuse host
```

**í•´ê²°ì±…:**
```python
# 1. ì—°ê²° í…ŒìŠ¤íŠ¸
import requests
import os

langfuse_host = os.getenv('LANGFUSE_HOST')
public_key = os.getenv('LANGFUSE_PUBLIC_KEY')

try:
    response = requests.get(f"{langfuse_host}/api/public/health")
    print(f"Langfuse ìƒíƒœ: {response.status_code}")
except Exception as e:
    print(f"Langfuse ì—°ê²° ì‹¤íŒ¨: {e}")

# 2. í™˜ê²½ë³€ìˆ˜ í™•ì¸
required_vars = ['LANGFUSE_HOST', 'LANGFUSE_PUBLIC_KEY', 'LANGFUSE_SECRET_KEY']
for var in required_vars:
    value = os.getenv(var)
    print(f"{var}: {'ì„¤ì •ë¨' if value else 'ëˆ„ë½'}")

# 3. ëŒ€ì•ˆ ì„¤ì •
# Self-hosted Langfuse ì‚¬ìš© ì‹œ
os.environ['LANGFUSE_HOST'] = 'http://localhost:3000'
```

### ë¬¸ì œ 3: ë„¤íŠ¸ì›Œí¬ í”„ë¡ì‹œ ë¬¸ì œ

**ì¦ìƒ:**
```
ProxyError: Cannot connect to proxy
```

**í•´ê²°ì±…:**
```bash
# 1. í”„ë¡ì‹œ ì„¤ì • í™•ì¸
echo $http_proxy
echo $https_proxy

# 2. í”„ë¡ì‹œ ìš°íšŒ ì„¤ì •
export no_proxy="localhost,127.0.0.1"

# 3. Python requests í”„ë¡ì‹œ ì„¤ì •
python -c "
import requests
import os

proxies = {
    'http': os.getenv('http_proxy'),
    'https': os.getenv('https_proxy')
}

response = requests.get('https://api.openai.com/v1/models', 
                       proxies=proxies, 
                       timeout=30)
print(f'ì—°ê²° ì„±ê³µ: {response.status_code}')
"
```

## ğŸ“Š ë°ì´í„° ë¶„ì„ ë¬¸ì œ

### ë¬¸ì œ 1: ë¶„ì„ ê²°ê³¼ê°€ ë¶€ì •í™•í•¨

**ì¦ìƒ:**
- í†µê³„ ìˆ˜ì¹˜ê°€ ì˜ˆìƒê³¼ ë‹¤ë¦„
- ì°¨íŠ¸ê°€ ì˜ëª» í‘œì‹œë¨

**ì§„ë‹¨:**
```python
# 1. ë°ì´í„° í’ˆì§ˆ í™•ì¸
def diagnose_data_quality(df):
    print("=== ë°ì´í„° í’ˆì§ˆ ì§„ë‹¨ ===")
    print(f"ì´ í–‰ ìˆ˜: {len(df)}")
    print(f"ì´ ì—´ ìˆ˜: {len(df.columns)}")
    print(f"ê²°ì¸¡ê°’: {df.isnull().sum().sum()}")
    print(f"ì¤‘ë³µ í–‰: {df.duplicated().sum()}")
    print("\në°ì´í„° íƒ€ì…:")
    print(df.dtypes)
    print("\nê¸°ë³¸ í†µê³„:")
    print(df.describe())

# 2. ì´ìƒì¹˜ íƒì§€
def detect_outliers(df, column):
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1
    lower = Q1 - 1.5 * IQR
    upper = Q3 + 1.5 * IQR
    outliers = df[(df[column] < lower) | (df[column] > upper)]
    print(f"{column} ì´ìƒì¹˜: {len(outliers)}ê°œ")
    return outliers
```

### ë¬¸ì œ 2: ë©”ëª¨ë¦¬ ì˜¤ë¥˜ë¡œ ë¶„ì„ ì¤‘ë‹¨

**ì¦ìƒ:**
```
MemoryError during statistical computation
```

**í•´ê²°ì±…:**
```python
# 1. ì²­í¬ ë‹¨ìœ„ í†µê³„ ê³„ì‚°
def chunk_statistics(df, chunk_size=10000):
    chunks = [df[i:i+chunk_size] for i in range(0, len(df), chunk_size)]
    
    # í‰ê·  ê³„ì‚°
    means = [chunk.mean() for chunk in chunks]
    overall_mean = pd.concat(means).mean()
    
    return overall_mean

# 2. ìƒ˜í”Œë§ ê¸°ë°˜ ë¶„ì„
def sample_analysis(df, sample_size=10000):
    if len(df) > sample_size:
        sample_df = df.sample(n=sample_size, random_state=42)
        print(f"ìƒ˜í”Œ í¬ê¸°: {len(sample_df)}")
        return sample_df
    return df

# 3. ìŠ¤íŒŒìŠ¤ ë§¤íŠ¸ë¦­ìŠ¤ ì‚¬ìš©
from scipy.sparse import csr_matrix

def optimize_categorical_data(df):
    for col in df.select_dtypes(include=['object']):
        df[col] = pd.Categorical(df[col])
    return df
```

### ë¬¸ì œ 3: ì‹œê°í™” ìƒì„± ì‹¤íŒ¨

**ì¦ìƒ:**
```
PlotlyError: Invalid figure specification
```

**í•´ê²°ì±…:**
```python
# 1. ì•ˆì „í•œ ì‹œê°í™” í•¨ìˆ˜
def safe_visualization(df, chart_type='bar', x_col=None, y_col=None):
    try:
        if chart_type == 'bar' and x_col and y_col:
            fig = px.bar(df, x=x_col, y=y_col)
        elif chart_type == 'line' and x_col and y_col:
            fig = px.line(df, x=x_col, y=y_col)
        else:
            # ê¸°ë³¸ ì°¨íŠ¸
            numeric_cols = df.select_dtypes(include=[np.number]).columns
            if len(numeric_cols) >= 2:
                fig = px.scatter(df, x=numeric_cols[0], y=numeric_cols[1])
            else:
                fig = px.histogram(df, x=numeric_cols[0])
        
        return fig
    except Exception as e:
        st.error(f"ì‹œê°í™” ìƒì„± ì‹¤íŒ¨: {e}")
        return None

# 2. ë°ì´í„° ì „ì²˜ë¦¬
def prepare_visualization_data(df):
    # ë¬´í•œëŒ€ ê°’ ì œê±°
    df = df.replace([np.inf, -np.inf], np.nan)
    
    # NaN ê°’ ì²˜ë¦¬
    df = df.dropna()
    
    # ë„ˆë¬´ í° ê°’ ì²˜ë¦¬
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    for col in numeric_cols:
        if df[col].max() > 1e10:
            df[col] = df[col].clip(upper=df[col].quantile(0.99))
    
    return df
```

## ğŸ“ ë¡œê¹… ë° ì¶”ì  ë¬¸ì œ

### ë¬¸ì œ 1: Langfuse íŠ¸ë ˆì´ìŠ¤ ëˆ„ë½

**ì¦ìƒ:**
- ë¶„ì„ ê³¼ì •ì´ Langfuseì— ê¸°ë¡ë˜ì§€ ì•ŠìŒ
- ëŒ€ì‹œë³´ë“œì— ë°ì´í„°ê°€ ì—†ìŒ

**í•´ê²°ì±…:**
```python
# 1. ìˆ˜ë™ íŠ¸ë ˆì´ìŠ¤ í™•ì¸
from core.enhanced_langfuse_tracer import get_enhanced_tracer

tracer = get_enhanced_tracer()

# ì—°ê²° í…ŒìŠ¤íŠ¸
try:
    test_trace = tracer.start_span("test_trace", TraceLevel.SYSTEM)
    tracer.end_span(test_trace, {"test": "success"})
    print("Langfuse ì—°ê²° ì •ìƒ")
except Exception as e:
    print(f"Langfuse ì—°ê²° ì‹¤íŒ¨: {e}")

# 2. í™˜ê²½ë³€ìˆ˜ ì¬í™•ì¸
import os
required_env = ['LANGFUSE_PUBLIC_KEY', 'LANGFUSE_SECRET_KEY', 'LANGFUSE_HOST']
for env_var in required_env:
    if not os.getenv(env_var):
        print(f"ëˆ„ë½ëœ í™˜ê²½ë³€ìˆ˜: {env_var}")

# 3. ëŒ€ì•ˆ ë¡œê¹…
import logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def fallback_logging(operation, data):
    logger.info(f"Operation: {operation}, Data: {data}")
```

### ë¬¸ì œ 2: ë¡œê·¸ íŒŒì¼ ì ‘ê·¼ ë¶ˆê°€

**ì¦ìƒ:**
```
PermissionError: [Errno 13] Permission denied: 'logs/system.log'
```

**í•´ê²°ì±…:**
```bash
# 1. ë¡œê·¸ ë””ë ‰í† ë¦¬ ê¶Œí•œ í™•ì¸
ls -la logs/

# 2. ê¶Œí•œ ìˆ˜ì •
chmod 755 logs/
chmod 644 logs/*.log

# 3. ë¡œê·¸ ë””ë ‰í† ë¦¬ ì¬ìƒì„±
rm -rf logs/
mkdir logs
chmod 755 logs/

# 4. ëŒ€ì•ˆ ë¡œê·¸ ìœ„ì¹˜
export LOG_DIR=/tmp/cherryai_logs
mkdir -p $LOG_DIR
```

## ğŸ”¬ ê³ ê¸‰ ë¬¸ì œ í•´ê²°

### ì‹œìŠ¤í…œ ì§„ë‹¨ ìŠ¤í¬ë¦½íŠ¸

```python
#!/usr/bin/env python3
"""
CherryAI ì‹œìŠ¤í…œ ì¢…í•© ì§„ë‹¨ ìŠ¤í¬ë¦½íŠ¸
"""

import subprocess
import requests
import psutil
import pandas as pd
import numpy as np
import sys
import os

def comprehensive_diagnosis():
    print("ğŸ” CherryAI ì‹œìŠ¤í…œ ì¢…í•© ì§„ë‹¨")
    print("=" * 50)
    
    # 1. Python í™˜ê²½ ì§„ë‹¨
    print(f"Python ë²„ì „: {sys.version}")
    print(f"Pandas ë²„ì „: {pd.__version__}")
    print(f"NumPy ë²„ì „: {np.__version__}")
    
    # 2. ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ì§„ë‹¨
    print(f"\nğŸ’» ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤:")
    print(f"CPU ì‚¬ìš©ë¥ : {psutil.cpu_percent()}%")
    print(f"ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ : {psutil.virtual_memory().percent}%")
    print(f"ë””ìŠ¤í¬ ì‚¬ìš©ë¥ : {psutil.disk_usage('/').percent}%")
    
    # 3. A2A ì„œë²„ ìƒíƒœ ì§„ë‹¨
    print(f"\nğŸ¤– A2A ì„œë²„ ìƒíƒœ:")
    servers = {
        "Orchestrator": 8100,
        "Pandas Analyst": 8200,
        "EDA Tools": 8203,
        "Data Visualization": 8202
    }
    
    for name, port in servers.items():
        try:
            response = requests.get(f"http://localhost:{port}/health", timeout=5)
            status = "âœ… ì •ìƒ" if response.status_code == 200 else f"âš ï¸ ì‘ë‹µ ì½”ë“œ: {response.status_code}"
        except:
            status = "âŒ ì ‘ê·¼ ë¶ˆê°€"
        print(f"{name} (í¬íŠ¸ {port}): {status}")
    
    # 4. í™˜ê²½ë³€ìˆ˜ ì§„ë‹¨
    print(f"\nğŸ”‘ í™˜ê²½ë³€ìˆ˜ ìƒíƒœ:")
    required_env = [
        'OPENAI_API_KEY', 'LANGFUSE_PUBLIC_KEY', 
        'LANGFUSE_SECRET_KEY', 'LANGFUSE_HOST'
    ]
    
    for env_var in required_env:
        value = os.getenv(env_var)
        status = "âœ… ì„¤ì •ë¨" if value else "âŒ ëˆ„ë½"
        print(f"{env_var}: {status}")
    
    # 5. ë„¤íŠ¸ì›Œí¬ ì§„ë‹¨
    print(f"\nğŸŒ ë„¤íŠ¸ì›Œí¬ ì—°ê²°:")
    try:
        response = requests.get("https://api.openai.com/v1/models", timeout=10)
        print("OpenAI API: âœ… ì—°ê²° ì„±ê³µ")
    except:
        print("OpenAI API: âŒ ì—°ê²° ì‹¤íŒ¨")
    
    # 6. íŒŒì¼ ì‹œìŠ¤í…œ ì§„ë‹¨
    print(f"\nğŸ“ íŒŒì¼ ì‹œìŠ¤í…œ:")
    directories = ['logs/', 'ai_ds_team/data/', 'artifacts/']
    for directory in directories:
        if os.path.exists(directory):
            print(f"{directory}: âœ… ì¡´ì¬")
        else:
            print(f"{directory}: âŒ ëˆ„ë½")

if __name__ == "__main__":
    comprehensive_diagnosis()
```

### ìë™ ë³µêµ¬ ìŠ¤í¬ë¦½íŠ¸

```bash
#!/bin/bash
# auto_recovery.sh - ìë™ ë³µêµ¬ ìŠ¤í¬ë¦½íŠ¸

echo "ğŸ”§ CherryAI ìë™ ë³µêµ¬ ì‹œì‘"

# 1. í”„ë¡œì„¸ìŠ¤ ì •ë¦¬
echo "1ï¸âƒ£ ê¸°ì¡´ í”„ë¡œì„¸ìŠ¤ ì •ë¦¬"
pkill -f streamlit
pkill -f "python.*a2a.*server"
sleep 3

# 2. í¬íŠ¸ ì •ë¦¬
echo "2ï¸âƒ£ í¬íŠ¸ ì •ë¦¬"
ports=(8100 8200 8202 8203 8501)
for port in "${ports[@]}"; do
    pid=$(lsof -ti:$port)
    if [ ! -z "$pid" ]; then
        kill -9 $pid
        echo "í¬íŠ¸ $port ì •ë¦¬ ì™„ë£Œ"
    fi
done

# 3. ìºì‹œ ì •ë¦¬
echo "3ï¸âƒ£ ìºì‹œ ì •ë¦¬"
rm -rf __pycache__
rm -rf */__pycache__
rm -rf .streamlit/

# 4. ë¡œê·¸ ë””ë ‰í† ë¦¬ ì¬ìƒì„±
echo "4ï¸âƒ£ ë¡œê·¸ ë””ë ‰í† ë¦¬ ì„¤ì •"
mkdir -p logs
chmod 755 logs

# 5. ê°€ìƒí™˜ê²½ í™•ì¸
echo "5ï¸âƒ£ ê°€ìƒí™˜ê²½ í™•ì¸"
if [ ! -d ".venv" ]; then
    echo "ê°€ìƒí™˜ê²½ ì¬ìƒì„±"
    uv venv
fi

source .venv/bin/activate

# 6. í•µì‹¬ íŒ¨í‚¤ì§€ ì¬ì„¤ì¹˜
echo "6ï¸âƒ£ í•µì‹¬ íŒ¨í‚¤ì§€ í™•ì¸"
uv pip install --upgrade streamlit pandas numpy a2a-sdk

# 7. ì„œë²„ ì¬ì‹œì‘
echo "7ï¸âƒ£ ì„œë²„ ì‹œìŠ¤í…œ ì¬ì‹œì‘"
./ai_ds_team_system_start.sh

# 8. ê±´ê°•ì„± ì²´í¬
echo "8ï¸âƒ£ ì‹œìŠ¤í…œ ê±´ê°•ì„± ì²´í¬"
sleep 10
python -c "
import requests
import time

servers = [8100, 8200, 8203, 8202]
for port in servers:
    try:
        response = requests.get(f'http://localhost:{port}/health', timeout=5)
        print(f'í¬íŠ¸ {port}: âœ… ì •ìƒ')
    except:
        print(f'í¬íŠ¸ {port}: âŒ ì˜¤ë¥˜')
"

echo "ğŸ‰ ìë™ ë³µêµ¬ ì™„ë£Œ"
```

### ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

```python
# performance_monitor.py - ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

import time
import psutil
import requests
from datetime import datetime

class PerformanceMonitor:
    def __init__(self):
        self.start_time = time.time()
        self.metrics = []
    
    def collect_metrics(self):
        """ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        current_time = datetime.now()
        
        # ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­
        cpu_percent = psutil.cpu_percent(interval=1)
        memory = psutil.virtual_memory()
        disk = psutil.disk_usage('/')
        
        # A2A ì„œë²„ ì‘ë‹µ ì‹œê°„
        server_response_times = {}
        servers = [8100, 8200, 8203, 8202]
        
        for port in servers:
            try:
                start = time.time()
                requests.get(f'http://localhost:{port}/health', timeout=5)
                response_time = (time.time() - start) * 1000
                server_response_times[port] = response_time
            except:
                server_response_times[port] = None
        
        metrics = {
            'timestamp': current_time,
            'cpu_percent': cpu_percent,
            'memory_percent': memory.percent,
            'disk_percent': disk.percent,
            'server_response_times': server_response_times
        }
        
        self.metrics.append(metrics)
        return metrics
    
    def check_thresholds(self, metrics):
        """ì„ê³„ê°’ í™•ì¸ ë° ì•Œë¦¼"""
        alerts = []
        
        if metrics['cpu_percent'] > 80:
            alerts.append(f"âš ï¸ ë†’ì€ CPU ì‚¬ìš©ë¥ : {metrics['cpu_percent']}%")
        
        if metrics['memory_percent'] > 85:
            alerts.append(f"âš ï¸ ë†’ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ : {metrics['memory_percent']}%")
        
        for port, response_time in metrics['server_response_times'].items():
            if response_time is None:
                alerts.append(f"âŒ ì„œë²„ {port} ì‘ë‹µ ì—†ìŒ")
            elif response_time > 5000:
                alerts.append(f"âš ï¸ ì„œë²„ {port} ëŠë¦° ì‘ë‹µ: {response_time:.1f}ms")
        
        return alerts
    
    def run_monitoring(self, duration_minutes=60):
        """ì§€ì •ëœ ì‹œê°„ ë™ì•ˆ ëª¨ë‹ˆí„°ë§ ì‹¤í–‰"""
        end_time = time.time() + (duration_minutes * 60)
        
        while time.time() < end_time:
            metrics = self.collect_metrics()
            alerts = self.check_thresholds(metrics)
            
            if alerts:
                print(f"\nğŸš¨ {metrics['timestamp']} ì•Œë¦¼:")
                for alert in alerts:
                    print(f"  {alert}")
            else:
                print(f"âœ… {metrics['timestamp']} ì •ìƒ")
            
            time.sleep(30)  # 30ì´ˆë§ˆë‹¤ ì²´í¬

if __name__ == "__main__":
    monitor = PerformanceMonitor()
    monitor.run_monitoring(duration_minutes=30)
```

## ğŸ“ ì§€ì› ë° ë„ì›€

### 1. ë¬¸ì œ ë³´ê³ 

ë²„ê·¸ë‚˜ ë¬¸ì œ ë°œê²¬ ì‹œ:

1. **ë¡œê·¸ ìˆ˜ì§‘**
```bash
# ì‹œìŠ¤í…œ ë¡œê·¸ ìˆ˜ì§‘
python diagnosis_script.py > system_diagnosis.txt

# ì—ëŸ¬ ë¡œê·¸ ìˆ˜ì§‘
tail -100 logs/*.log > error_logs.txt
```

2. **í™˜ê²½ ì •ë³´ ìˆ˜ì§‘**
```bash
python -c "
import sys, platform
print(f'OS: {platform.system()} {platform.release()}')
print(f'Python: {sys.version}')
print(f'Architecture: {platform.machine()}')
"
```

3. **ì¬í˜„ ë‹¨ê³„ ê¸°ë¡**
- ì •í™•í•œ ì˜¤ë¥˜ ë©”ì‹œì§€
- ìˆ˜í–‰í•œ ì‘ì—… ìˆœì„œ
- ì‚¬ìš©í•œ ë°ì´í„° íŒŒì¼ ì •ë³´

### 2. ì»¤ë®¤ë‹ˆí‹° ì§€ì›

- **GitHub Issues**: ê¸°ìˆ ì  ë¬¸ì œ ë° ë²„ê·¸ ë¦¬í¬íŠ¸
- **í† ë¡  í¬ëŸ¼**: ì‚¬ìš©ë²• ì§ˆë¬¸ ë° ê²½í—˜ ê³µìœ 
- **ë¬¸ì„œ Wiki**: ì¶”ê°€ íŒ ë° ì‚¬ìš© ì‚¬ë¡€

### 3. ì „ë¬¸ ì§€ì›

í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ ì¤‘ìš”í•œ ë¬¸ì œ ë°œìƒ ì‹œ:
- ìš°ì„ ìˆœìœ„ ì§€ì› ì±„ë„ ì´ìš©
- ìƒì„¸í•œ ì§„ë‹¨ ë³´ê³ ì„œ ì œê³µ
- ì›ê²© ì§€ì› ì„¸ì…˜ ì˜ˆì•½

---

**ğŸ’ CherryAI v2.0** - *ë¬¸ì œê°€ ë°œìƒí•˜ë©´ ì²´ê³„ì ìœ¼ë¡œ í•´ê²°í•˜ì„¸ìš”*

*ì´ ê°€ì´ë“œë¡œ í•´ê²°ë˜ì§€ ì•ŠëŠ” ë¬¸ì œê°€ ìˆë‹¤ë©´ GitHub Issuesì— ì‹ ê³ í•´ ì£¼ì„¸ìš”.* 