# ğŸ’ CherryAI í†µí•© ë°ì´í„° ë¡œë”© ì‹œìŠ¤í…œ ì„¤ê³„ ë¬¸ì„œ

**í”„ë¡œì íŠ¸**: CherryAI LLM First Architecture  
**ë¬¸ì„œ ë²„ì „**: 1.0  
**ì‘ì„±ì¼**: 2025ë…„ 1ì›” 27ì¼  
**ê¸°ì¤€**: pandas_agent íŒ¨í„´ì„ í™œìš©í•œ 12ê°œ A2A ì—ì´ì „íŠ¸ í‘œì¤€í™”  

---

## ğŸ“Š 1. ê°œìš” ë° ëª©ì 

### 1.1 ë°°ê²½
í˜„ì¬ CherryAI ì‹œìŠ¤í…œì˜ 12ê°œ A2A ì—ì´ì „íŠ¸ë“¤ì´ ê°ê° ë‹¤ë¥¸ ë°ì´í„° ë¡œë”© ë°©ì‹ì„ ì‚¬ìš©í•˜ì—¬ ë‹¤ìŒê³¼ ê°™ì€ ë¬¸ì œë“¤ì´ ë°œìƒí•˜ê³  ìˆìŠµë‹ˆë‹¤:

- **ì¼ê´€ì„± ë¶€ì¡±**: 6ê°€ì§€ ì„œë¡œ ë‹¤ë¥¸ ë°ì´í„° ë¡œë”© íŒ¨í„´ ì‚¬ìš©
- **ì‹ ë¢°ì„± ë¬¸ì œ**: UTF-8 ì¸ì½”ë”© ì˜¤ë¥˜, íŒŒì¼ ì„ íƒ ì‹¤íŒ¨
- **ì„±ëŠ¥ ì €í•˜**: ìºì‹± ì—†ìŒ, ì¤‘ë³µ ë¡œë”©
- **ìœ ì§€ë³´ìˆ˜ ì–´ë ¤ì›€**: ì—ì´ì „íŠ¸ë³„ ê°œë³„ ë¡œì§ ê´€ë¦¬

### 1.2 ëª©ì 
pandas_agentì˜ ìš°ìˆ˜í•œ ì•„í‚¤í…ì²˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ëª¨ë“  A2A ì—ì´ì „íŠ¸ì˜ ë°ì´í„° ë¡œë”©ì„ í‘œì¤€í™”í•˜ì—¬:

- **LLM First ì›ì¹™** ì™„ì „ ì¤€ìˆ˜
- **A2A SDK 0.2.9 í‘œì¤€** ì™„ë²½ ì ìš©  
- **100% ê¸°ëŠ¥ ìœ ì§€** í•˜ë©´ì„œ ë°ì´í„° ê³„ì¸µë§Œ í†µí•©
- **Mock ì‚¬ìš© ê¸ˆì§€**, ì‹¤ì œ ë™ì‘í•˜ëŠ” í†µí•© ì‹œìŠ¤í…œ êµ¬ì¶•

---

## ğŸ” 2. í˜„ì¬ ìƒí™© ë¶„ì„

### 2.1 12ê°œ A2A ì—ì´ì „íŠ¸ ì™„ì „ í˜„í™© ë¶„ì„

| # | Agent | Port | í˜„ì¬ ë°ì´í„° ë¡œë”© ë°©ì‹ | ì£¼ìš” ë¬¸ì œì  | ìš°ì„ ìˆœìœ„ | ë§ˆì´ê·¸ë ˆì´ì…˜ ë³µì¡ë„ |
|---|-------|------|---------------------|------------|---------|-------------------|
| 1 | **orchestrator** | 8100 | Agent Registry ê´€ë¦¬ë§Œ | ë°ì´í„° ì§ì ‘ ì²˜ë¦¬ ì•ˆí•¨ | LOW | ğŸŸ¢ ë‹¨ìˆœ |
| 2 | **data_cleaning** | 8306 | IntelligentDataHandler | ë¹ˆ ë°ì´í„° ì˜¤ë¥˜, ì»¬ëŸ¼ ì—†ìŒ ì—ëŸ¬ | HIGH | ğŸŸ¡ ì¤‘ê°„ |
| 3 | **data_loader** | 8307 | AIDataScienceTeamWrapper | ë‹¤ì¤‘ êµ¬í˜„ì²´ í˜¼ì¬, ë¶ˆì¼ì¹˜ | CRITICAL | ğŸ”´ ë³µì¡ |
| 4 | **data_visualization** | 8308 | SafeDataLoader | UTF-8 ì¸ì½”ë”© ì˜¤ë¥˜, ì°¨íŠ¸ ìƒì„± ì‹¤íŒ¨ | HIGH | ğŸŸ¡ ì¤‘ê°„ |
| 5 | **data_wrangling** | 8309 | UnifiedDataLoader | íŒŒì¼ ì„ íƒ ë¶ˆì•ˆì •, ë³€í™˜ ì˜¤ë¥˜ | HIGH | ğŸŸ¡ ì¤‘ê°„ |
| 6 | **feature_engineering** | 8310 | SafeDataLoader ì§ì ‘ í˜¸ì¶œ | ìºì‹± ì—†ìŒ, ë°˜ë³µ ë¡œë”© | MEDIUM | ğŸŸ¢ ë‹¨ìˆœ |
| 7 | **sql_database** | 8311 | ì§ì ‘ pandas ë¡œë”© | ì˜ˆì™¸ ì²˜ë¦¬ ë¶€ì¡±, DB ì—°ê²° ë¶ˆì•ˆì • | MEDIUM | ğŸŸ¡ ì¤‘ê°„ |
| 8 | **eda_tools** | 8312 | íŒŒì¼ ìŠ¤ìº” + ì§ì ‘ ë¡œë”© | ì¸ì½”ë”© ë¬¸ì œ, í†µê³„ ê³„ì‚° ì˜¤ë¥˜ | HIGH | ğŸŸ¡ ì¤‘ê°„ |
| 9 | **h2o_ml** | 8313 | SafeDataLoader | ì—ëŸ¬ ì²˜ë¦¬ ë¶€ì¡±, ëª¨ë¸ë§ ì‹¤íŒ¨ | MEDIUM | ğŸŸ¡ ì¤‘ê°„ |
| 10 | **mlflow_tools** | 8314 | SafeDataLoader | ë™ì¼í•œ íŒ¨í„´, ì‹¤í—˜ ì¶”ì  ë¶ˆì•ˆì • | MEDIUM | ğŸŸ¢ ë‹¨ìˆœ |
| 11 | **pandas_agent** | 8210 | **FileConnector íŒ¨í„´** â­ | **ê¸°ì¤€ ëª¨ë¸ - ìš°ìˆ˜í•¨** | **TEMPLATE** | âœ… **ê¸°ì¤€** |
| 12 | **report_generator** | 8316 | Agent ê²°ê³¼ ìˆ˜ì§‘ | ë‹¤ë¥¸ ì—ì´ì „íŠ¸ ì˜ì¡´, ì¢…í•© ë¶„ì„ í•œê³„ | LOW | ğŸŸ¢ ë‹¨ìˆœ |

**ğŸ“Š ì „ì²´ í†µê³„:**
- **CRITICAL**: 1ê°œ (data_loader)
- **HIGH**: 4ê°œ (data_cleaning, data_visualization, data_wrangling, eda_tools)  
- **MEDIUM**: 4ê°œ (feature_engineering, sql_database, h2o_ml, mlflow_tools)
- **LOW**: 2ê°œ (orchestrator, report_generator)
- **TEMPLATE**: 1ê°œ (pandas_agent - ê¸°ì¤€ ëª¨ë¸)

### 2.2 pandas_agent ìš°ìˆ˜ íŒ¨í„´ ë¶„ì„

```python
# ğŸ¯ pandas_agentì˜ í•µì‹¬ ì•„í‚¤í…ì²˜
class PandasAgent:
    """LLM First + FileConnector Patternì˜ ì™„ë²½í•œ êµ¬í˜„"""
    
    # 1. LLM í†µí•© ë°ì´í„° ì²˜ë¦¬
    def load_dataframe(self, df: pd.DataFrame, name: str = "main") -> str
    def load_from_file(self, file_path: str, name: str = "main") -> str
    
    # 2. FileConnector í™•ì¥ì„±
    async def _handle_data_loading(self, query_analysis, task_updater)
    
    # 3. SmartDataFrame ì§€ëŠ¥í˜• ì²˜ë¦¬
    # 4. Cache Manager ì„±ëŠ¥ ìµœì í™”
    # 5. A2A TaskUpdater ì™„ë²½ í†µí•©
```

**â­ í•µì‹¬ ìš°ìˆ˜ì„±:**
- **5ë‹¨ê³„ LLM ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸**: ì˜ë„ë¶„ì„ â†’ ì½”ë“œìƒì„± â†’ ì‹¤í–‰ â†’ ê²°ê³¼í•´ì„ â†’ ì‹œê°í™”
- **Connector Pattern**: í™•ì¥ ê°€ëŠ¥í•œ ë°ì´í„° ì†ŒìŠ¤ ì§€ì›
- **ì§€ëŠ¥í˜• ìºì‹±**: LRU + TTL + íƒœê·¸ ê¸°ë°˜ ìµœì í™”
- **ì™„ë²½í•œ A2A í†µí•©**: TaskUpdater + ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°

---

## ğŸ—ï¸ 3. í†µí•© ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

### 3.1 ì „ì²´ ì•„í‚¤í…ì²˜ ì„¤ê³„

```
ğŸ“Š CherryAI Unified Data Loading System Architecture

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ğŸ¯ A2A Agent Layer                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  [data_cleaning] [data_visualization] [eda_tools] ... [12ê°œ]    â”‚
â”‚                          â†“                                     â”‚
â”‚              ğŸ“ UnifiedDataInterface                           â”‚
â”‚                    (í‘œì¤€í™”ëœ API)                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                ğŸ§  LLM First Data Engine                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚ğŸ” Intent    â”‚  â”‚ğŸ¯ File      â”‚  â”‚ğŸ“Š Smart     â”‚              â”‚
â”‚  â”‚  Analyzer   â”‚  â”‚  Selector   â”‚  â”‚  DataFrame  â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                ğŸ“ Unified Connector Layer                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚ğŸ“„ File      â”‚  â”‚ğŸ—„ï¸ SQL       â”‚  â”‚ğŸŒ API       â”‚              â”‚
â”‚  â”‚  Connector  â”‚  â”‚  Connector  â”‚  â”‚  Connector  â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                ğŸš€ Performance & Caching Layer                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚ğŸ’¾ Cache     â”‚  â”‚âš¡ Async     â”‚  â”‚ğŸ”’ Security  â”‚              â”‚
â”‚  â”‚  Manager    â”‚  â”‚  Pipeline   â”‚  â”‚  Manager    â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 í•µì‹¬ ì»´í¬ë„ŒíŠ¸ ì„¤ê³„

#### 3.2.1 UnifiedDataInterface (í‘œì¤€ API)

```python
class UnifiedDataInterface:
    """ëª¨ë“  A2A ì—ì´ì „íŠ¸ê°€ ì‚¬ìš©í•  í‘œì¤€ ë°ì´í„° ì¸í„°í˜ì´ìŠ¤"""
    
    # í•„ìˆ˜ ë©”ì„œë“œ (ëª¨ë“  ì—ì´ì „íŠ¸ êµ¬í˜„ í•„ìˆ˜)
    async def load_data(self, intent: DataIntent, context: A2AContext) -> SmartDataFrame
    async def get_data_info(self) -> DataProfile
    async def validate_data_quality(self) -> QualityReport
    
    # ì„ íƒì  ë©”ì„œë“œ (ì—ì´ì „íŠ¸ë³„ íŠ¹í™”)
    async def transform_data(self, operations: List[Operation]) -> SmartDataFrame
    async def cache_data(self, key: str, ttl: int = 3600) -> bool
```

#### 3.2.2 LLMFirstDataEngine (í•µì‹¬ ì—”ì§„)

```python
class LLMFirstDataEngine:
    """LLM ê¸°ë°˜ ì§€ëŠ¥í˜• ë°ì´í„° ì²˜ë¦¬ ì—”ì§„"""
    
    async def analyze_intent(self, user_query: str, context: A2AContext) -> DataIntent
    async def select_optimal_file(self, intent: DataIntent, available_files: List[str]) -> str
    async def create_smart_dataframe(self, df: pd.DataFrame, metadata: Dict) -> SmartDataFrame
    async def optimize_loading_strategy(self, file_info: FileInfo) -> LoadConfig
```

---

## ğŸ“‹ 4. ì—ì´ì „íŠ¸ë³„ ë§ˆì´ê·¸ë ˆì´ì…˜ ê³„íš

### 4.1 ìš°ì„ ìˆœìœ„ ê·¸ë£¹ ë¶„ë¥˜ (12ê°œ ì—ì´ì „íŠ¸ ì™„ì „ ì»¤ë²„ë¦¬ì§€)

#### ğŸ”´ CRITICAL (ì¦‰ì‹œ ì²˜ë¦¬ í•„ìš” - 1ê°œ)
- **data_loader (8307)**: ëª¨ë“  ì—ì´ì „íŠ¸ì˜ ë°ì´í„° ê³µê¸‰ì›, ë‹¤ì¤‘ êµ¬í˜„ì²´ í˜¼ì¬ ë¬¸ì œ í•´ê²° ì‹œê¸‰

#### ğŸŸ¡ HIGH (1ì£¼ ë‚´ ì²˜ë¦¬ í•„ìš” - 4ê°œ)
- **data_cleaning (8306)**: ë¹ˆ ë°ì´í„° ì˜¤ë¥˜, "Cannot describe DataFrame without columns" í•´ê²° ì‹œê¸‰
- **data_visualization (8308)**: UTF-8 ì¸ì½”ë”© ë¬¸ì œ, ì°¨íŠ¸ ìƒì„± ì‹¤íŒ¨ í•´ê²°
- **data_wrangling (8309)**: íŒŒì¼ ì„ íƒ ë¶ˆì•ˆì •ì„±, ë°ì´í„° ë³€í™˜ ì˜¤ë¥˜ í•´ê²°
- **eda_tools (8312)**: ì¸ì½”ë”© ë¬¸ì œ, í†µê³„ ê³„ì‚° ì˜¤ë¥˜ í•´ê²° (ì£¼ìš” ë¶„ì„ ë„êµ¬)

#### ğŸŸ¢ MEDIUM (2ì£¼ ë‚´ ì²˜ë¦¬ - 4ê°œ)
- **feature_engineering (8310)**: ìºì‹± ì‹œìŠ¤í…œ ë„ì…, ë°˜ë³µ ë¡œë”© ìµœì í™”
- **sql_database (8311)**: ì˜ˆì™¸ ì²˜ë¦¬ ê°•í™”, DB ì—°ê²° ì•ˆì •ì„± ê°œì„ 
- **h2o_ml (8313)**: ì—ëŸ¬ ì²˜ë¦¬ ê°•í™”, ëª¨ë¸ë§ ì•ˆì •ì„± ê°œì„ 
- **mlflow_tools (8314)**: í‘œì¤€í™” ì ìš©, ì‹¤í—˜ ì¶”ì  ì•ˆì •ì„± ê°œì„ 

#### ğŸ”µ LOW (ë§ˆì§€ë§‰ ì²˜ë¦¬ - 2ê°œ)
- **orchestrator (8100)**: ë°ì´í„° ì§ì ‘ ì²˜ë¦¬ ì•ˆí•¨, Agent Registry ê´€ë¦¬ë§Œ
- **report_generator (8316)**: ë‹¤ë¥¸ ì—ì´ì „íŠ¸ ê²°ê³¼ ìˆ˜ì§‘ ë° ì¢…í•©, ì˜ì¡´ì„± ê´€ë¦¬

#### â­ TEMPLATE (ê¸°ì¤€ ëª¨ë¸ - 1ê°œ)
- **pandas_agent (8210)**: FileConnector íŒ¨í„´ ê¸°ì¤€ ëª¨ë¸, ëª¨ë“  ì—ì´ì „íŠ¸ê°€ ë”°ë¼ì•¼ í•  í‘œì¤€

### 4.2 ìƒì„¸ ë§ˆì´ê·¸ë ˆì´ì…˜ ê°€ì´ë“œ

#### 4.2.1 data_loader (8307) - CRITICAL

**í˜„ì¬ ë¬¸ì œì :**
- 3ê°€ì§€ ë‹¤ë¥¸ êµ¬í˜„ì²´ í˜¼ì¬ (AIDataScienceTeamWrapper, DataLoaderAgent, ì§ì ‘ pandas)
- A2A í‘œì¤€ ë¶ˆì¼ì¹˜
- ì—ëŸ¬ ì²˜ë¦¬ ë¶€ì¡±

**ë§ˆì´ê·¸ë ˆì´ì…˜ ê³„íš:**
```python
# 1ë‹¨ê³„: ê¸°ì¡´ ì½”ë“œ ë¶„ì„ ë° ë°±ì—…
# íŒŒì¼: a2a_ds_servers/ai_ds_team_data_loader_server.py
# ë°±ì—…: a2a_ds_servers/backup/data_loader_original.py

# 2ë‹¨ê³„: UnifiedDataInterface êµ¬í˜„
class DataLoaderExecutor(AgentExecutor, UnifiedDataInterface):
    def __init__(self):
        self.data_engine = LLMFirstDataEngine()
        self.file_connector = FileConnector()
        self.cache_manager = CacheManager()
    
    async def execute(self, context: RequestContext, task_updater: TaskUpdater):
        # pandas_agent íŒ¨í„´ ì ìš©
        user_query = self._extract_user_query(context)
        intent = await self.data_engine.analyze_intent(user_query, context)
        smart_df = await self.load_data(intent, context)
        
        # A2A í‘œì¤€ ì‘ë‹µ
        await self._send_a2a_response(smart_df, task_updater)

# 3ë‹¨ê³„: A2A SDK 0.2.9 í‘œì¤€ ì ìš©
# - TaskUpdater íŒ¨í„´ ì™„ë²½ êµ¬í˜„
# - TextPart + JSON ì§ë ¬í™”
# - ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì§€ì›

# 4ë‹¨ê³„: í…ŒìŠ¤íŠ¸ ë° ê²€ì¦
# - ê¸°ì¡´ ê¸°ëŠ¥ 100% ë³´ì¥
# - ì„±ëŠ¥ ê°œì„  í™•ì¸
# - ì—ëŸ¬ ì²˜ë¦¬ ê°•í™”
```

**êµ¬ì²´ì  êµ¬í˜„ ì§€ì¹¨:**
1. **ê¸°ì¡´ ê¸°ëŠ¥ ë³´ì¡´**: `DataLoaderToolsAgent` ì™„ì „ í˜¸í™˜
2. **ì—ëŸ¬ ì²˜ë¦¬**: UTF-8, íŒŒì¼ ì—†ìŒ, ê¶Œí•œ ë¬¸ì œ ëŒ€ì‘
3. **ì„±ëŠ¥ ìµœì í™”**: íŒŒì¼ í¬ê¸°ë³„ ë¡œë”© ì „ëµ ìˆ˜ë¦½
4. **A2A í†µí•©**: TaskUpdater + ì•„í‹°íŒ©íŠ¸ ìƒì„±

#### 4.2.2 data_cleaning (8306) - HIGH

**í˜„ì¬ ë¬¸ì œì :**
- `IntelligentDataHandler` ì‚¬ìš©í•˜ì§€ë§Œ ë¹ˆ ë°ì´í„° ì˜¤ë¥˜
- `Cannot describe a DataFrame without columns` ì—ëŸ¬

**ë§ˆì´ê·¸ë ˆì´ì…˜ ê³„íš:**
```python
# ë¬¸ì œ í•´ê²° ì „ëµ
class DataCleaningExecutor(AgentExecutor, UnifiedDataInterface):
    async def execute(self, context: RequestContext, task_updater: TaskUpdater):
        # 1. ë°ì´í„° ê²€ì¦ ê°•í™”
        smart_df = await self.load_data(intent, context)
        
        if smart_df.is_empty():
            await self._handle_empty_data(context, task_updater)
            return
        
        # 2. ë°ì´í„° ì •ì œ ì‹¤í–‰
        cleaning_results = await self._perform_cleaning(smart_df, intent)
        
        # 3. ê²°ê³¼ ê²€ì¦ ë° ë°˜í™˜
        await self._validate_and_return(cleaning_results, task_updater)

    async def _handle_empty_data(self, context, task_updater):
        """ë¹ˆ ë°ì´í„° ì „ìš© ì²˜ë¦¬ ë¡œì§"""
        await task_updater.update_status(
            TaskState.completed,
            message="âš ï¸ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ íŒŒì¼ì„ ì‹œë„í•˜ê±°ë‚˜ ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”."
        )
```

**êµ¬ì²´ì  êµ¬í˜„ ì§€ì¹¨:**
1. **ë¹ˆ ë°ì´í„° ê°ì§€**: ë¡œë”© ì¦‰ì‹œ ê²€ì¦
2. **ì‚¬ìš©ì ì•ˆë‚´**: ëª…í™•í•œ ì—ëŸ¬ ë©”ì‹œì§€ì™€ í•´ê²°ì±… ì œê³µ
3. **í´ë°± ì „ëµ**: ë‹¤ë¥¸ íŒŒì¼ ìë™ ì‹œë„
4. **í’ˆì§ˆ ë³´ê³ ì„œ**: ì •ì œ ì „í›„ ë¹„êµ ë¦¬í¬íŠ¸

#### 4.2.3 data_visualization (8308) - HIGH

**í˜„ì¬ ë¬¸ì œì :**
- UTF-8 ì¸ì½”ë”© ì˜¤ë¥˜
- SafeDataLoader ì‚¬ìš©í•˜ì§€ë§Œ ì œí•œì 

**ë§ˆì´ê·¸ë ˆì´ì…˜ ê³„íš:**
```python
class DataVisualizationExecutor(AgentExecutor, UnifiedDataInterface):
    def __init__(self):
        self.visualization_engine = VisualizationEngine()
        self.encoding_handler = EncodingHandler()
    
    async def load_data(self, intent: DataIntent, context: A2AContext) -> SmartDataFrame:
        # pandas_agent íŒ¨í„´ + ì¸ì½”ë”© ì²˜ë¦¬ ê°•í™”
        file_path = await self.data_engine.select_optimal_file(intent, available_files)
        
        # ë‹¤ì¤‘ ì¸ì½”ë”© ì‹œë„
        for encoding in ['utf-8', 'cp949', 'euc-kr', 'latin1']:
            try:
                df = pd.read_csv(file_path, encoding=encoding)
                break
            except UnicodeDecodeError:
                continue
        
        return SmartDataFrame(df, metadata={'encoding': encoding})
```

**êµ¬ì²´ì  êµ¬í˜„ ì§€ì¹¨:**
1. **ì¸ì½”ë”© ìë™ ê°ì§€**: ë‹¤ì¤‘ ì¸ì½”ë”© ì‹œë„ ë¡œì§
2. **ì‹œê°í™” ìµœì í™”**: ë°ì´í„° íƒ€ì…ë³„ ìµœì  ì°¨íŠ¸ ì¶”ì²œ
3. **interactive ì°¨íŠ¸**: Plotly + Streamlit í†µí•©
4. **ë©”ëª¨ë¦¬ ìµœì í™”**: ëŒ€ìš©ëŸ‰ ë°ì´í„° ìƒ˜í”Œë§

#### 4.2.4 eda_tools (8312) - HIGH

**í˜„ì¬ ë¬¸ì œì :**
- íŒŒì¼ ìŠ¤ìº” í›„ ì§ì ‘ ë¡œë”©
- ì¸ì½”ë”© ë¬¸ì œ ì¡´ì¬

**ë§ˆì´ê·¸ë ˆì´ì…˜ ê³„íš:**
```python
class EDAToolsExecutor(AgentExecutor, UnifiedDataInterface):
    async def execute(self, context: RequestContext, task_updater: TaskUpdater):
        # pandas_agentì˜ 5ë‹¨ê³„ ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì ìš©
        
        # 1. ì˜ë„ ë¶„ì„
        eda_intent = await self._analyze_eda_intent(user_query)
        
        # 2. ë°ì´í„° ë¡œë”© (í†µí•© ì¸í„°í˜ì´ìŠ¤)
        smart_df = await self.load_data(eda_intent, context)
        
        # 3. EDA ë¶„ì„ ìˆ˜í–‰
        eda_results = await self._perform_comprehensive_eda(smart_df, eda_intent)
        
        # 4. ì¸ì‚¬ì´íŠ¸ ìƒì„± (LLM)
        insights = await self._generate_insights(eda_results, smart_df)
        
        # 5. ê²°ê³¼ í¬ë§·íŒ… ë° ë°˜í™˜
        await self._format_and_return_results(eda_results, insights, task_updater)
```

**êµ¬ì²´ì  êµ¬í˜„ ì§€ì¹¨:**
1. **í¬ê´„ì  EDA**: ê¸°ìˆ í†µê³„, ë¶„í¬, ìƒê´€ê´€ê³„, ì´ìƒê°’
2. **LLM ì¸ì‚¬ì´íŠ¸**: íŒ¨í„´ ë°œê²¬ ë° í•´ì„
3. **ì‹œê°í™” í†µí•©**: ì°¨íŠ¸ + í‘œ + í…ìŠ¤íŠ¸ ì¡°í•©
4. **ì„±ëŠ¥ ìµœì í™”**: ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬

#### 4.2.5 data_wrangling (8309) - HIGH

**í˜„ì¬ ë¬¸ì œì :**
- UnifiedDataLoader ì‚¬ìš©í•˜ì§€ë§Œ íŒŒì¼ ì„ íƒ ë¶ˆì•ˆì •
- ë°ì´í„° ë³€í™˜ ê³¼ì •ì—ì„œ ì˜¤ë¥˜ ë°œìƒ

**ë§ˆì´ê·¸ë ˆì´ì…˜ ê³„íš:**
```python
class DataWranglingExecutor(AgentExecutor, UnifiedDataInterface):
    async def execute(self, context: RequestContext, task_updater: TaskUpdater):
        # pandas_agent íŒ¨í„´ + ë³€í™˜ íŠ¹í™”
        
        # 1. ë³€í™˜ ì˜ë„ ë¶„ì„ (LLM)
        wrangling_intent = await self._analyze_wrangling_intent(user_query)
        
        # 2. ì•ˆì „í•œ ë°ì´í„° ë¡œë”©
        smart_df = await self.load_data(wrangling_intent, context)
        
        # 3. ë³€í™˜ ì‘ì—… ì‹¤í–‰
        transformed_df = await self._perform_transformations(smart_df, wrangling_intent)
        
        # 4. ë³€í™˜ ê²°ê³¼ ê²€ì¦
        await self._validate_transformations(transformed_df, task_updater)
```

**êµ¬ì²´ì  êµ¬í˜„ ì§€ì¹¨:**
1. **ë³€í™˜ ì•ˆì „ì„±**: ì›ë³¸ ë°ì´í„° ë°±ì—… í›„ ë³€í™˜ ìˆ˜í–‰
2. **LLM ê°€ì´ë“œ**: ë³€í™˜ ë¡œì§ì„ LLMì´ ë™ì  ìƒì„±
3. **ë‹¨ê³„ë³„ ê²€ì¦**: ê° ë³€í™˜ ë‹¨ê³„ë§ˆë‹¤ ë°ì´í„° ë¬´ê²°ì„± í™•ì¸
4. **ë¡¤ë°± ê¸°ëŠ¥**: ë³€í™˜ ì‹¤íŒ¨ ì‹œ ì´ì „ ìƒíƒœë¡œ ë³µêµ¬

### 4.3 MEDIUM ìš°ì„ ìˆœìœ„ ì—ì´ì „íŠ¸ ë§ˆì´ê·¸ë ˆì´ì…˜ (4ê°œ)

#### 4.3.1 feature_engineering (8310) - MEDIUM

**í˜„ì¬ ë¬¸ì œì :**
- SafeDataLoader ì§ì ‘ í˜¸ì¶œ, ìºì‹± ì—†ìŒ
- ë°˜ë³µì ì¸ íŒŒì¼ ë¡œë”©ìœ¼ë¡œ ì„±ëŠ¥ ì €í•˜

**ë§ˆì´ê·¸ë ˆì´ì…˜ ê³„íš:**
```python
class FeatureEngineeringExecutor(AgentExecutor, UnifiedDataInterface):
    def __init__(self):
        super().__init__()
        self.feature_cache = FeatureCache()  # íŠ¹ì„± ìºì‹± ì‹œìŠ¤í…œ
        
    async def execute(self, context: RequestContext, task_updater: TaskUpdater):
        # 1. íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ ì˜ë„ ë¶„ì„
        feature_intent = await self._analyze_feature_intent(user_query)
        
        # 2. ìºì‹œëœ íŠ¹ì„± í™•ì¸
        cached_features = await self.feature_cache.get(feature_intent.cache_key)
        
        # 3. ë°ì´í„° ë¡œë”© (ìºì‹œ ë¯¸ìŠ¤ ì‹œë§Œ)
        if not cached_features:
            smart_df = await self.load_data(feature_intent, context)
            features = await self._engineer_features(smart_df, feature_intent)
            await self.feature_cache.set(feature_intent.cache_key, features)
        
        # 4. íŠ¹ì„± ì„ íƒ ë° ìµœì í™”
        optimized_features = await self._optimize_features(features, feature_intent)
```

#### 4.3.2 sql_database (8311) - MEDIUM

**í˜„ì¬ ë¬¸ì œì :**
- ì§ì ‘ pandas ë¡œë”©, ì˜ˆì™¸ ì²˜ë¦¬ ë¶€ì¡±
- DB ì—°ê²° ë¶ˆì•ˆì •ì„±

**ë§ˆì´ê·¸ë ˆì´ì…˜ ê³„íš:**
```python
class SQLDatabaseExecutor(AgentExecutor, UnifiedDataInterface):
    def __init__(self):
        super().__init__()
        self.sql_connector = SQLConnector()  # pandas_agent íŒ¨í„´
        self.connection_pool = ConnectionPool()
        
    async def execute(self, context: RequestContext, task_updater: TaskUpdater):
        # 1. SQL ì˜ë„ ë¶„ì„
        sql_intent = await self._analyze_sql_intent(user_query)
        
        # 2. ì—°ê²° í’€ì—ì„œ ì•ˆì „í•œ DB ì—°ê²°
        async with self.connection_pool.get_connection() as conn:
            # 3. SQL ì¿¼ë¦¬ ìƒì„± (LLM)
            sql_query = await self._generate_sql_query(sql_intent)
            
            # 4. ì¿¼ë¦¬ ì‹¤í–‰ ë° DataFrame ë³€í™˜
            smart_df = await self.sql_connector.execute_query(sql_query, conn)
            
            # 5. ê²°ê³¼ ë¶„ì„ ë° ì¸ì‚¬ì´íŠ¸ ìƒì„±
            insights = await self._analyze_sql_results(smart_df, sql_intent)
```

#### 4.3.3 h2o_ml (8313) - MEDIUM

**í˜„ì¬ ë¬¸ì œì :**
- SafeDataLoader ì‚¬ìš©, ì—ëŸ¬ ì²˜ë¦¬ ë¶€ì¡±
- ëª¨ë¸ë§ ê³¼ì •ì—ì„œ ì•ˆì •ì„± ë¬¸ì œ

**ë§ˆì´ê·¸ë ˆì´ì…˜ ê³„íš:**
```python
class H2OMLExecutor(AgentExecutor, UnifiedDataInterface):
    def __init__(self):
        super().__init__()
        self.h2o_manager = H2OManager()
        self.model_cache = ModelCache()
        
    async def execute(self, context: RequestContext, task_updater: TaskUpdater):
        # 1. ML ì˜ë„ ë¶„ì„
        ml_intent = await self._analyze_ml_intent(user_query)
        
        # 2. ë°ì´í„° ë¡œë”© ë° ML ì¤€ë¹„
        smart_df = await self.load_data(ml_intent, context)
        h2o_frame = await self._convert_to_h2o_frame(smart_df)
        
        # 3. H2O í™˜ê²½ ì´ˆê¸°í™”
        await self.h2o_manager.ensure_cluster()
        
        # 4. AutoML ì‹¤í–‰
        automl_results = await self._run_h2o_automl(h2o_frame, ml_intent)
        
        # 5. ëª¨ë¸ í•´ì„ ë° ê²°ê³¼ ë¶„ì„
        interpretations = await self._interpret_models(automl_results)
```

#### 4.3.4 mlflow_tools (8314) - MEDIUM

**í˜„ì¬ ë¬¸ì œì :**
- SafeDataLoader ë™ì¼ íŒ¨í„´
- ì‹¤í—˜ ì¶”ì  ë¶ˆì•ˆì •ì„±

**ë§ˆì´ê·¸ë ˆì´ì…˜ ê³„íš:**
```python
class MLflowToolsExecutor(AgentExecutor, UnifiedDataInterface):
    def __init__(self):
        super().__init__()
        self.mlflow_client = MLflowClient()
        self.experiment_tracker = ExperimentTracker()
        
    async def execute(self, context: RequestContext, task_updater: TaskUpdater):
        # 1. ì‹¤í—˜ ì˜ë„ ë¶„ì„
        experiment_intent = await self._analyze_experiment_intent(user_query)
        
        # 2. ë°ì´í„° ë¡œë”© ë° ì‹¤í—˜ ì„¤ì •
        smart_df = await self.load_data(experiment_intent, context)
        
        # 3. MLflow ì‹¤í—˜ ì‹œì‘
        with self.mlflow_client.start_run() as run:
            # 4. ëª¨ë¸ í•™ìŠµ ë° ì¶”ì 
            model_results = await self._train_and_track_model(smart_df, experiment_intent)
            
            # 5. ì‹¤í—˜ ê²°ê³¼ ë¡œê¹…
            await self._log_experiment_results(model_results, run)
```

### 4.4 LOW ìš°ì„ ìˆœìœ„ ì—ì´ì „íŠ¸ ë§ˆì´ê·¸ë ˆì´ì…˜ (2ê°œ)

#### 4.4.1 orchestrator (8100) - LOW

**í˜„ì¬ ë¬¸ì œì :**
- ë°ì´í„° ì§ì ‘ ì²˜ë¦¬ ì•ˆí•¨, Agent Registry ê´€ë¦¬ë§Œ

**ë§ˆì´ê·¸ë ˆì´ì…˜ ê³„íš:**
```python
class OrchestratorExecutor(AgentExecutor):
    # ë°ì´í„° ì§ì ‘ ì²˜ë¦¬ ì—†ìŒ, Agent ë°œê²¬ ë° ì¡°ì •ë§Œ
    async def execute(self, context: RequestContext, task_updater: TaskUpdater):
        # 1. ì‚¬ìš©ì ìš”ì²­ ë¶„ì„
        orchestration_plan = await self._analyze_orchestration_needs(user_query)
        
        # 2. ì—ì´ì „íŠ¸ ë°œê²¬ ë° ê³„íš ìˆ˜ë¦½
        available_agents = await self._discover_agents()
        execution_plan = await self._create_execution_plan(orchestration_plan, available_agents)
        
        # 3. ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¡°ì • (ë°ì´í„°ëŠ” ê° ì—ì´ì „íŠ¸ê°€ ê°œë³„ ë¡œë”©)
        results = await self._execute_multi_agent_plan(execution_plan)
```

#### 4.4.2 report_generator (8316) - LOW

**í˜„ì¬ ë¬¸ì œì :**
- ë‹¤ë¥¸ ì—ì´ì „íŠ¸ ê²°ê³¼ ìˆ˜ì§‘, ì¢…í•© ë¶„ì„ í•œê³„

**ë§ˆì´ê·¸ë ˆì´ì…˜ ê³„íš:**
```python
class ReportGeneratorExecutor(AgentExecutor, UnifiedDataInterface):
    async def execute(self, context: RequestContext, task_updater: TaskUpdater):
        # 1. ë³´ê³ ì„œ ìš”êµ¬ì‚¬í•­ ë¶„ì„
        report_intent = await self._analyze_report_intent(user_query)
        
        # 2. ë°ì´í„° ì†ŒìŠ¤ ì‹ë³„ (ì›ë³¸ ë°ì´í„° + ì—ì´ì „íŠ¸ ê²°ê³¼)
        data_sources = await self._identify_data_sources(report_intent)
        
        # 3. í†µí•© ë°ì´í„° ë¡œë”©
        unified_data = await self._load_unified_data(data_sources, context)
        
        # 4. ì¢…í•© ë³´ê³ ì„œ ìƒì„±
        comprehensive_report = await self._generate_comprehensive_report(unified_data, report_intent)
```

### 4.5 ê³µí†µ ë§ˆì´ê·¸ë ˆì´ì…˜ íŒ¨í„´

#### ëª¨ë“  ì—ì´ì „íŠ¸ ê³µí†µ í…œí”Œë¦¿:
```python
# í‘œì¤€í™”ëœ ë§ˆì´ê·¸ë ˆì´ì…˜ í…œí”Œë¦¿ (12ê°œ ì—ì´ì „íŠ¸ ê³µí†µ)
class StandardUnifiedAgentExecutor(AgentExecutor, UnifiedDataInterface):
    def __init__(self, agent_name: str, specialized_config: Dict[str, Any]):
        super().__init__()
        self.agent_name = agent_name
        self.data_engine = LLMFirstDataEngine()
        self.cache_manager = CacheManager()
        self.specialized_processor = self._create_specialized_processor(specialized_config)
    
    async def execute(self, context: RequestContext, task_updater: TaskUpdater):
        # 1. í‘œì¤€ ë°ì´í„° ë¡œë”© (pandas_agent íŒ¨í„´)
        intent = await self.data_engine.analyze_intent(user_query, context)
        smart_df = await self.load_data(intent, context)
        
        # 2. ì—ì´ì „íŠ¸ë³„ íŠ¹í™” ì²˜ë¦¬
        results = await self.specialized_processor.process(smart_df, intent)
        
        # 3. í‘œì¤€ A2A ì‘ë‹µ
        await self._send_standard_response(results, task_updater)
```

---

## ğŸ”§ 5. êµ¬í˜„ ì„¸ë¶€ì‚¬í•­

### 5.1 í•µì‹¬ í´ë˜ìŠ¤ ì„¤ê³„

#### 5.1.1 UnifiedDataInterface

```python
from abc import ABC, abstractmethod
from typing import Dict, List, Optional, Any
from dataclasses import dataclass
from enum import Enum

class DataIntentType(Enum):
    ANALYSIS = "analysis"
    VISUALIZATION = "visualization"
    CLEANING = "cleaning"
    TRANSFORMATION = "transformation"
    MODELING = "modeling"

@dataclass
class DataIntent:
    intent_type: DataIntentType
    confidence: float
    file_preferences: List[str]
    operations: List[str]
    constraints: Dict[str, Any]

@dataclass
class DataProfile:
    shape: tuple
    dtypes: Dict[str, str]
    missing_values: Dict[str, int]
    memory_usage: int
    encoding: str
    file_size: int

@dataclass
class QualityReport:
    overall_score: float
    completeness: float
    consistency: float
    validity: float
    issues: List[str]
    recommendations: List[str]

class UnifiedDataInterface(ABC):
    """ëª¨ë“  A2A ì—ì´ì „íŠ¸ê°€ êµ¬í˜„í•´ì•¼ í•  í‘œì¤€ ë°ì´í„° ì¸í„°í˜ì´ìŠ¤"""
    
    @abstractmethod
    async def load_data(self, intent: DataIntent, context: 'A2AContext') -> 'SmartDataFrame':
        """ë°ì´í„° ë¡œë”© (í•„ìˆ˜ êµ¬í˜„)"""
        pass
    
    @abstractmethod
    async def get_data_info(self) -> DataProfile:
        """ë°ì´í„° ì •ë³´ ì¡°íšŒ (í•„ìˆ˜ êµ¬í˜„)"""
        pass
    
    @abstractmethod
    async def validate_data_quality(self) -> QualityReport:
        """ë°ì´í„° í’ˆì§ˆ ê²€ì¦ (í•„ìˆ˜ êµ¬í˜„)"""
        pass
    
    # ì„ íƒì  êµ¬í˜„ ë©”ì„œë“œë“¤
    async def transform_data(self, operations: List['Operation']) -> 'SmartDataFrame':
        """ë°ì´í„° ë³€í™˜ (ì„ íƒì  êµ¬í˜„)"""
        raise NotImplementedError("This agent doesn't support data transformation")
    
    async def cache_data(self, key: str, ttl: int = 3600) -> bool:
        """ë°ì´í„° ìºì‹± (ì„ íƒì  êµ¬í˜„)"""
        return False  # ê¸°ë³¸ì ìœ¼ë¡œ ìºì‹± ë¹„í™œì„±í™”
```

#### 5.1.2 LLMFirstDataEngine

```python
class LLMFirstDataEngine:
    """LLM ê¸°ë°˜ ì§€ëŠ¥í˜• ë°ì´í„° ì²˜ë¦¬ ì—”ì§„"""
    
    def __init__(self, llm_client=None):
        self.llm = llm_client or self._create_llm_client()
        self.intent_analyzer = IntentAnalyzer(self.llm)
        self.file_selector = IntelligentFileSelector(self.llm)
        self.encoding_detector = EncodingDetector()
    
    async def analyze_intent(self, user_query: str, context: 'A2AContext') -> DataIntent:
        """ì‚¬ìš©ì ì˜ë„ ë¶„ì„"""
        
        # LLM í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = f"""
        ì‚¬ìš©ì ìš”ì²­ì„ ë¶„ì„í•˜ì—¬ ë°ì´í„° ì²˜ë¦¬ ì˜ë„ë¥¼ íŒŒì•…í•´ì£¼ì„¸ìš”:
        
        ìš”ì²­: {user_query}
        ì»¨í…ìŠ¤íŠ¸: {context.to_dict()}
        
        ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
        {{
            "intent_type": "analysis|visualization|cleaning|transformation|modeling",
            "confidence": 0.0-1.0,
            "file_preferences": ["íŠ¹ì • íŒŒì¼ëª…ì´ë‚˜ íŒ¨í„´"],
            "operations": ["ìˆ˜í–‰í•  ì‘ì—…ë“¤"],
            "constraints": {{"ì œì•½ì¡°ê±´ë“¤": "ê°’"}}
        }}
        """
        
        response = await self.llm.agenerate([prompt])
        intent_data = json.loads(response.generations[0][0].text)
        
        return DataIntent(
            intent_type=DataIntentType(intent_data['intent_type']),
            confidence=intent_data['confidence'],
            file_preferences=intent_data['file_preferences'],
            operations=intent_data['operations'],
            constraints=intent_data['constraints']
        )
    
    async def select_optimal_file(self, intent: DataIntent, available_files: List[str]) -> str:
        """ìµœì  íŒŒì¼ ì„ íƒ"""
        
        if not available_files:
            raise ValueError("ì‚¬ìš© ê°€ëŠ¥í•œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
        
        # íŒŒì¼ ì •ë³´ ìˆ˜ì§‘
        file_infos = []
        for file_path in available_files:
            info = await self._analyze_file_info(file_path)
            file_infos.append(info)
        
        # LLM ê¸°ë°˜ íŒŒì¼ ì„ íƒ
        prompt = f"""
        ì‚¬ìš©ì ì˜ë„ì— ê°€ì¥ ì í•©í•œ íŒŒì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”:
        
        ì˜ë„: {intent.intent_type.value}
        ì„ í˜¸ë„: {intent.file_preferences}
        ì‘ì—…: {intent.operations}
        
        ì‚¬ìš© ê°€ëŠ¥í•œ íŒŒì¼ë“¤:
        {json.dumps(file_infos, indent=2, ensure_ascii=False)}
        
        ê°€ì¥ ì í•©í•œ íŒŒì¼ì˜ ê²½ë¡œë§Œ ë°˜í™˜í•´ì£¼ì„¸ìš”.
        """
        
        response = await self.llm.agenerate([prompt])
        selected_file = response.generations[0][0].text.strip()
        
        return selected_file
```

#### 5.1.3 SmartDataFrame

```python
class SmartDataFrame:
    """ì§€ëŠ¥í˜• DataFrame í´ë˜ìŠ¤ (pandas_agent íŒ¨í„´)"""
    
    def __init__(self, df: pd.DataFrame, metadata: Dict[str, Any] = None):
        self.df = df
        self.metadata = metadata or {}
        self.profile: Optional[DataProfile] = None
        self.quality_report: Optional[QualityReport] = None
        self._cache_info = {}
    
    @property
    def shape(self) -> tuple:
        return self.df.shape
    
    def is_empty(self) -> bool:
        """ë¹ˆ ë°ì´í„° ê²€ì‚¬"""
        return self.df.empty or self.df.shape[0] == 0 or self.df.shape[1] == 0
    
    async def auto_profile(self) -> DataProfile:
        """ìë™ ë°ì´í„° í”„ë¡œíŒŒì¼ë§"""
        if self.profile is None:
            self.profile = DataProfile(
                shape=self.df.shape,
                dtypes={col: str(dtype) for col, dtype in self.df.dtypes.items()},
                missing_values=self.df.isnull().sum().to_dict(),
                memory_usage=self.df.memory_usage(deep=True).sum(),
                encoding=self.metadata.get('encoding', 'unknown'),
                file_size=self.metadata.get('file_size', 0)
            )
        return self.profile
    
    async def validate_quality(self) -> QualityReport:
        """ë°ì´í„° í’ˆì§ˆ ê²€ì¦"""
        if self.quality_report is None:
            # ì™„ì „ì„± ê³„ì‚°
            total_cells = self.df.shape[0] * self.df.shape[1]
            missing_cells = self.df.isnull().sum().sum()
            completeness = (total_cells - missing_cells) / total_cells if total_cells > 0 else 0
            
            # ì¼ê´€ì„± ê³„ì‚° (ë°ì´í„° íƒ€ì… ì¼ê´€ì„±)
            consistency = 1.0  # ê¸°ë³¸ê°’, ë” ì •êµí•œ ë¡œì§ í•„ìš”
            
            # ìœ íš¨ì„± ê³„ì‚°
            validity = 1.0  # ê¸°ë³¸ê°’, ë” ì •êµí•œ ë¡œì§ í•„ìš”
            
            # ì „ì²´ ì ìˆ˜
            overall_score = (completeness + consistency + validity) / 3
            
            issues = []
            recommendations = []
            
            if completeness < 0.9:
                issues.append(f"Missing values: {missing_cells} cells")
                recommendations.append("Consider imputation or removal of missing values")
            
            self.quality_report = QualityReport(
                overall_score=overall_score,
                completeness=completeness,
                consistency=consistency,
                validity=validity,
                issues=issues,
                recommendations=recommendations
            )
        
        return self.quality_report
```

### 5.2 A2A SDK 0.2.9 í‘œì¤€ ì ìš©

#### 5.2.1 í‘œì¤€ AgentExecutor í…œí”Œë¦¿

```python
class StandardUnifiedAgentExecutor(AgentExecutor, UnifiedDataInterface):
    """A2A SDK 0.2.9 í‘œì¤€ + í†µí•© ë°ì´í„° ì¸í„°í˜ì´ìŠ¤"""
    
    def __init__(self, agent_name: str, specialized_config: Dict[str, Any]):
        super().__init__()
        self.agent_name = agent_name
        self.data_engine = LLMFirstDataEngine()
        self.cache_manager = CacheManager()
        self.specialized_config = specialized_config
        
        # ë¡œê¹… ì„¤ì •
        self.logger = logging.getLogger(f"UnifiedAgent.{agent_name}")
        
    async def execute(self, context: RequestContext, task_updater: TaskUpdater) -> None:
        """A2A í‘œì¤€ ì‹¤í–‰ ë©”ì„œë“œ"""
        try:
            # ì‘ì—… ì‹œì‘
            await task_updater.submit()
            await task_updater.start_work()
            
            # 1ë‹¨ê³„: ì‚¬ìš©ì ì¿¼ë¦¬ ì¶”ì¶œ
            user_query = self._extract_user_query(context)
            self.logger.info(f"Processing query: {user_query}")
            
            await task_updater.update_status(
                TaskState.working,
                message=f"ğŸ§‘ğŸ» {self.agent_name} ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤..."
            )
            
            # 2ë‹¨ê³„: ì˜ë„ ë¶„ì„
            intent = await self.data_engine.analyze_intent(user_query, context)
            
            await task_updater.update_status(
                TaskState.working,
                message=f"ğŸ’ ì˜ë„ ë¶„ì„ ì™„ë£Œ: {intent.intent_type.value} (ì‹ ë¢°ë„: {intent.confidence:.2f})"
            )
            
            # 3ë‹¨ê³„: ë°ì´í„° ë¡œë”©
            smart_df = await self.load_data(intent, context)
            
            await task_updater.update_status(
                TaskState.working,
                message=f"ğŸ’ ë°ì´í„° ë¡œë”© ì™„ë£Œ: {smart_df.shape[0]}í–‰ x {smart_df.shape[1]}ì—´"
            )
            
            # 4ë‹¨ê³„: ì—ì´ì „íŠ¸ë³„ íŠ¹í™” ì²˜ë¦¬
            results = await self._perform_specialized_processing(smart_df, intent, task_updater)
            
            # 5ë‹¨ê³„: ê²°ê³¼ ë°˜í™˜ (A2A í‘œì¤€)
            await self._send_a2a_results(results, task_updater)
            
            # ì™„ë£Œ
            await task_updater.update_status(
                TaskState.completed,
                message="âœ… ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."
            )
            
        except Exception as e:
            self.logger.error(f"Error in {self.agent_name}: {e}")
            await task_updater.update_status(
                TaskState.failed,
                message=f"âŒ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            )
    
    def _extract_user_query(self, context: RequestContext) -> str:
        """ì‚¬ìš©ì ì¿¼ë¦¬ ì¶”ì¶œ (A2A í‘œì¤€)"""
        user_query = ""
        if context.message and context.message.parts:
            for part in context.message.parts:
                if hasattr(part, 'root') and hasattr(part.root, 'text'):
                    user_query += part.root.text + " "
        return user_query.strip()
    
    async def load_data(self, intent: DataIntent, context) -> SmartDataFrame:
        """í†µí•© ë°ì´í„° ë¡œë”© êµ¬í˜„"""
        # ìºì‹œ í™•ì¸
        cache_key = f"{self.agent_name}:{intent.intent_type.value}:{hash(str(intent.file_preferences))}"
        cached_df = await self.cache_manager.get(cache_key)
        
        if cached_df:
            self.logger.info("Using cached data")
            return cached_df
        
        # íŒŒì¼ ì„ íƒ
        available_files = await self._scan_available_files()
        selected_file = await self.data_engine.select_optimal_file(intent, available_files)
        
        # ë°ì´í„° ë¡œë”©
        smart_df = await self._load_file_safely(selected_file)
        
        # ìºì‹±
        await self.cache_manager.set(cache_key, smart_df, ttl=3600)
        
        return smart_df
    
    async def _send_a2a_results(self, results: Dict[str, Any], task_updater: TaskUpdater):
        """A2A í‘œì¤€ ê²°ê³¼ ì „ì†¡"""
        
        # ì•„í‹°íŒ©íŠ¸ ìƒì„±
        artifacts = []
        
        if 'dataframes' in results:
            for name, df in results['dataframes'].items():
                artifacts.append({
                    'name': f"{name}_data",
                    'type': 'dataframe', 
                    'data': df.to_json(),
                    'metadata': {'shape': df.shape}
                })
        
        if 'plots' in results:
            for plot_name, plot_data in results['plots'].items():
                artifacts.append({
                    'name': f"{plot_name}_plot",
                    'type': 'visualization',
                    'data': plot_data,
                    'metadata': {'format': 'plotly_json'}
                })
        
        # TextPartë¡œ ê²°ê³¼ ì „ì†¡ (A2A SDK 0.2.9 í‘œì¤€)
        for artifact in artifacts:
            await task_updater.add_artifact(
                parts=[TextPart(text=json.dumps(artifact))],
                name=artifact['name'],
                metadata=artifact['metadata']
            )
    
    @abstractmethod
    async def _perform_specialized_processing(self, smart_df: SmartDataFrame, intent: DataIntent, task_updater: TaskUpdater) -> Dict[str, Any]:
        """ì—ì´ì „íŠ¸ë³„ íŠ¹í™” ì²˜ë¦¬ (í•˜ìœ„ í´ë˜ìŠ¤ì—ì„œ êµ¬í˜„)"""
        pass
```

---

## ğŸ§ª 6. í…ŒìŠ¤íŠ¸ ë° ê²€ì¦ ê³„íš

### 6.1 í…ŒìŠ¤íŠ¸ ì „ëµ

#### 6.1.1 ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ (pytest)
```bash
# í•µì‹¬ ì»´í¬ë„ŒíŠ¸ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
tests/unit/unified_data_loading/
â”œâ”€â”€ test_unified_data_interface.py
â”œâ”€â”€ test_llm_first_data_engine.py
â”œâ”€â”€ test_smart_dataframe.py
â”œâ”€â”€ test_cache_manager.py
â””â”€â”€ test_file_connectors.py
```

#### 6.1.2 í†µí•© í…ŒìŠ¤íŠ¸ (pytest)
```bash
# ì—ì´ì „íŠ¸ë³„ í†µí•© í…ŒìŠ¤íŠ¸
tests/integration/agent_migration/
â”œâ”€â”€ test_data_loader_migration.py
â”œâ”€â”€ test_data_cleaning_migration.py
â”œâ”€â”€ test_data_visualization_migration.py
â”œâ”€â”€ test_eda_tools_migration.py
â””â”€â”€ test_complete_pipeline.py
```

#### 6.1.3 A2A í”„ë¡œí† ì½œ í…ŒìŠ¤íŠ¸ (pytest)
```bash
# A2A SDK 0.2.9 í‘œì¤€ ì¤€ìˆ˜ í…ŒìŠ¤íŠ¸
tests/a2a_compliance/
â”œâ”€â”€ test_task_updater_pattern.py
â”œâ”€â”€ test_text_part_serialization.py
â”œâ”€â”€ test_artifact_generation.py
â””â”€â”€ test_streaming_compliance.py
```

#### 6.1.4 ìµœì¢… UI í…ŒìŠ¤íŠ¸ (Playwright MCP)
```bash
# ì‹¤ì œ ì‚¬ìš©ì ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸
tests/ui_validation/
â”œâ”€â”€ test_file_upload_workflow.py
â”œâ”€â”€ test_agent_collaboration.py
â”œâ”€â”€ test_error_handling.py
â””â”€â”€ test_performance_metrics.py
```

### 6.2 ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

#### 6.2.1 ë¡œë”© ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
```python
# íŒŒì¼ í¬ê¸°ë³„ ë¡œë”© ì„±ëŠ¥ ì¸¡ì •
test_files = {
    'small': '< 1MB',
    'medium': '1MB - 100MB', 
    'large': '100MB - 1GB',
    'extra_large': '> 1GB'
}

# ì¸¡ì • ì§€í‘œ
metrics = [
    'loading_time',
    'memory_usage',
    'cache_hit_ratio',
    'error_rate'
]
```

#### 6.2.2 ì—ì´ì „íŠ¸ë³„ ì„±ëŠ¥ ë¹„êµ
- **Before**: ê¸°ì¡´ ê°œë³„ ë¡œë”© ë°©ì‹
- **After**: í†µí•© ì‹œìŠ¤í…œ ì ìš©
- **Target**: 30% ì„±ëŠ¥ ê°œì„ , 90% ì—ëŸ¬ ê°ì†Œ

### 6.3 ê¸°ëŠ¥ í˜¸í™˜ì„± ê²€ì¦

#### 6.3.1 100% ê¸°ëŠ¥ ë³´ì¡´ ì²´í¬ë¦¬ìŠ¤íŠ¸
```yaml
# ê° ì—ì´ì „íŠ¸ë³„ ê¸°ëŠ¥ ì²´í¬ë¦¬ìŠ¤íŠ¸
data_loader:
  - âœ… CSV, Excel, JSON, Parquet ë¡œë”©
  - âœ… ì¸ì½”ë”© ìë™ ê°ì§€
  - âœ… ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬
  - âœ… ì—ëŸ¬ ë³µêµ¬ ë©”ì»¤ë‹ˆì¦˜

data_cleaning:
  - âœ… ê²°ì¸¡ê°’ ì²˜ë¦¬
  - âœ… ì´ìƒê°’ íƒì§€
  - âœ… ë°ì´í„° íƒ€ì… ìµœì í™”
  - âœ… í’ˆì§ˆ ë³´ê³ ì„œ ìƒì„±

# ... ê° ì—ì´ì „íŠ¸ë³„ ìƒì„¸ ì²´í¬ë¦¬ìŠ¤íŠ¸
```

---

## ğŸ“… 7. êµ¬í˜„ ì¼ì • ë° ë§ˆì¼ìŠ¤í†¤

### 7.1 ì „ì²´ ì¼ì • (ì´ 3ì£¼, 12ê°œ ì—ì´ì „íŠ¸ ì™„ì „ ë§ˆì´ê·¸ë ˆì´ì…˜)

#### Week 1: í•µì‹¬ ì¸í”„ë¼ + CRITICAL (7ì¼)
- **Day 1-2**: í•µì‹¬ ì¸í”„ë¼ êµ¬ì¶•
  - UnifiedDataInterface + LLMFirstDataEngine êµ¬í˜„
  - SmartDataFrame + CacheManager êµ¬í˜„
- **Day 3-5**: CRITICAL ì—ì´ì „íŠ¸ (1ê°œ)
  - **data_loader (8307)** ì™„ì „ ë§ˆì´ê·¸ë ˆì´ì…˜
  - ë‹¤ì¤‘ êµ¬í˜„ì²´ í†µí•©, FileConnector íŒ¨í„´ ì ìš©
- **Day 6-7**: CRITICAL ê²€ì¦ ë° HIGH ì¤€ë¹„
  - data_loader í†µí•© í…ŒìŠ¤íŠ¸
  - HIGH ê·¸ë£¹ ë§ˆì´ê·¸ë ˆì´ì…˜ ì¤€ë¹„

#### Week 2: HIGH ìš°ì„ ìˆœìœ„ ì—ì´ì „íŠ¸ (7ì¼)
- **Day 8-9**: HIGH ê·¸ë£¹ 1ì°¨ (2ê°œ)
  - **data_cleaning (8306)**: ë¹ˆ ë°ì´í„° ì˜¤ë¥˜ í•´ê²°
  - **data_visualization (8308)**: UTF-8 ì¸ì½”ë”© ë¬¸ì œ í•´ê²°
- **Day 10-11**: HIGH ê·¸ë£¹ 2ì°¨ (2ê°œ)
  - **data_wrangling (8309)**: íŒŒì¼ ì„ íƒ ì•ˆì •ì„± ê°œì„ 
  - **eda_tools (8312)**: í†µê³„ ê³„ì‚° ì˜¤ë¥˜ í•´ê²°
- **Day 12-13**: HIGH ê·¸ë£¹ í†µí•© í…ŒìŠ¤íŠ¸
  - 4ê°œ ì—ì´ì „íŠ¸ ìƒí˜¸ í˜¸í™˜ì„± ê²€ì¦
- **Day 14**: MEDIUM ê·¸ë£¹ ë§ˆì´ê·¸ë ˆì´ì…˜ ì¤€ë¹„

#### Week 3: MEDIUM + LOW + ìµœì¢… ê²€ì¦ (7ì¼)
- **Day 15-16**: MEDIUM ê·¸ë£¹ 1ì°¨ (2ê°œ)
  - **feature_engineering (8310)**: ìºì‹± ì‹œìŠ¤í…œ ë„ì…
  - **sql_database (8311)**: DB ì—°ê²° ì•ˆì •ì„± ê°œì„ 
- **Day 17**: MEDIUM ê·¸ë£¹ 2ì°¨ (2ê°œ)
  - **h2o_ml (8313)**: ëª¨ë¸ë§ ì•ˆì •ì„± ê°œì„ 
  - **mlflow_tools (8314)**: ì‹¤í—˜ ì¶”ì  ì•ˆì •ì„± ê°œì„ 
- **Day 18**: LOW ê·¸ë£¹ (2ê°œ)
  - **orchestrator (8100)**: ë ˆì§€ìŠ¤íŠ¸ë¦¬ í†µí•©
  - **report_generator (8316)**: ì¢…í•© ë³´ê³ ì„œ í†µí•©
- **Day 19**: ì „ì²´ ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤íŠ¸ (12ê°œ ì—ì´ì „íŠ¸)
- **Day 20-21**: ìµœì¢… ê²€ì¦ ë° ë¬¸ì„œí™”
  - Playwright MCP ì™„ì „ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸
  - **pandas_agent (8210)** ê¸°ì¤€ ëª¨ë¸ ìµœì¢… ê²€ì¦

### 7.2 ì£¼ìš” ë§ˆì¼ìŠ¤í†¤ (12ê°œ ì—ì´ì „íŠ¸ ì™„ì „ ì¶”ì )

| ë§ˆì¼ìŠ¤í†¤ | ì¼ì • | ëŒ€ìƒ ì—ì´ì „íŠ¸ | ì„±ê³µ ê¸°ì¤€ | ê²€ì¦ ë°©ë²• |
|---------|------|-------------|-----------|----------|
| **M1: í•µì‹¬ ì¸í”„ë¼** | Day 2 | ê³µí†µ ì¸í”„ë¼ | UnifiedDataInterface + LLMFirstDataEngine ì™„ì„± | ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ 100% í†µê³¼ |
| **M2: CRITICAL ì™„ë£Œ** | Day 5 | data_loader (8307) | ë‹¤ì¤‘ êµ¬í˜„ì²´ í†µí•©, ì™„ë²½ ë™ì‘ | UIì—ì„œ íŒŒì¼ ë¡œë”© ì„±ê³µ |
| **M3: HIGH 1ì°¨ ì™„ë£Œ** | Day 9 | data_cleaning (8306)<br/>data_visualization (8308) | ë¹ˆ ë°ì´í„° + ì¸ì½”ë”© ë¬¸ì œ í•´ê²° | ì°¨íŠ¸ ìƒì„± ì„±ê³µ |
| **M4: HIGH 2ì°¨ ì™„ë£Œ** | Day 11 | data_wrangling (8309)<br/>eda_tools (8312) | ë³€í™˜ + í†µê³„ ë¶„ì„ ì•ˆì •í™” | EDA ë¦¬í¬íŠ¸ ìƒì„± ì„±ê³µ |
| **M5: HIGH í†µí•© ì™„ë£Œ** | Day 13 | HIGH ê·¸ë£¹ 4ê°œ | ìƒí˜¸ í˜¸í™˜ì„± ê²€ì¦ ì™„ë£Œ | í†µí•© ì›Œí¬í”Œë¡œìš° ì„±ê³µ |
| **M6: MEDIUM 1ì°¨ ì™„ë£Œ** | Day 16 | feature_engineering (8310)<br/>sql_database (8311) | ìºì‹± + DB ì—°ê²° ì•ˆì •ì„± | íŠ¹ì„± ìƒì„± + SQL ì¿¼ë¦¬ ì„±ê³µ |
| **M7: MEDIUM 2ì°¨ ì™„ë£Œ** | Day 17 | h2o_ml (8313)<br/>mlflow_tools (8314) | ML ëª¨ë¸ë§ + ì‹¤í—˜ ì¶”ì  ì•ˆì •í™” | AutoML + ì‹¤í—˜ ë¡œê¹… ì„±ê³µ |
| **M8: LOW ì™„ë£Œ** | Day 18 | orchestrator (8100)<br/>report_generator (8316) | ì¡°ì • + ë³´ê³ ì„œ í†µí•© ì™„ë£Œ | ë©€í‹° ì—ì´ì „íŠ¸ ì¡°ì • ì„±ê³µ |
| **M9: ì „ì²´ í†µí•©** | Day 19 | **12ê°œ ì—ì´ì „íŠ¸ ì „ì²´** | ëª¨ë“  ì—ì´ì „íŠ¸ ì •ìƒ ë™ì‘ | ì™„ì „í•œ ë°ì´í„° ë¶„ì„ íŒŒì´í”„ë¼ì¸ |
| **M10: ìµœì¢… ê²€ì¦** | Day 21 | pandas_agent (8210) ê¸°ì¤€ | í”„ë¡œë•ì…˜ ì¤€ë¹„ ì™„ë£Œ | Playwright ì „ì²´ ì‹œë‚˜ë¦¬ì˜¤ í†µê³¼ |

**ğŸ“Š ì§„í–‰ë¥  ì¶”ì :**
- **Week 1 ì™„ë£Œ**: 1/12 (8.3%) - CRITICAL
- **Week 2 ì™„ë£Œ**: 5/12 (41.7%) - CRITICAL + HIGH  
- **Week 3 ì™„ë£Œ**: 12/12 (100%) - ì „ì²´ ì‹œìŠ¤í…œ

---

## ğŸš€ 8. ë°°í¬ ë° ëª¨ë‹ˆí„°ë§

### 8.1 ì ì§„ì  ë°°í¬ ì „ëµ

#### 8.1.1 ë‹¨ê³„ë³„ ë°°í¬
1. **Stage 1**: data_loaderë§Œ ìƒˆ ì‹œìŠ¤í…œ ì ìš© (ë‹¤ë¥¸ ì—ì´ì „íŠ¸ëŠ” ê¸°ì¡´ ë°©ì‹)
2. **Stage 2**: HIGH ìš°ì„ ìˆœìœ„ ì—ì´ì „íŠ¸ ì¶”ê°€
3. **Stage 3**: ì „ì²´ ì‹œìŠ¤í…œ ì™„ì „ ì „í™˜

#### 8.1.2 ë¡¤ë°± ê³„íš
```bash
# ê° ì—ì´ì „íŠ¸ë³„ ë°±ì—… ë³´ê´€
a2a_ds_servers/backup/
â”œâ”€â”€ data_loader_original.py
â”œâ”€â”€ data_cleaning_original.py
â”œâ”€â”€ data_visualization_original.py
â””â”€â”€ ... (ì „ì²´ ë°±ì—…)

# ì¦‰ì‹œ ë¡¤ë°± ìŠ¤í¬ë¦½íŠ¸
./scripts/rollback_agent.sh [agent_name]
```

### 8.2 ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ

#### 8.2.1 í•µì‹¬ ì§€í‘œ
```python
# ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì§€í‘œ
monitoring_metrics = {
    'data_loading': {
        'success_rate': '> 95%',
        'average_loading_time': '< 5ì´ˆ', 
        'cache_hit_ratio': '> 70%',
        'encoding_error_rate': '< 1%'
    },
    'agent_performance': {
        'response_time': '< 30ì´ˆ',
        'memory_usage': '< 1GB',
        'error_rate': '< 2%',
        'throughput': '> 10 requests/min'
    }
}
```

#### 8.2.2 ì•Œë¦¼ ì‹œìŠ¤í…œ
- **Critical**: ì—ì´ì „íŠ¸ ë‹¤ìš´, ë°ì´í„° ë¡œë”© ì‹¤íŒ¨ > 10%
- **Warning**: ì„±ëŠ¥ ì €í•˜, ìºì‹œ ë¯¸ìŠ¤ ì¦ê°€
- **Info**: ì •ìƒ ì‘ë™, ì„±ëŠ¥ ê°œì„  í™•ì¸

---

## ğŸ“– 9. ë¬¸ì„œí™” ë° ê°€ì´ë“œ

### 9.1 ê°œë°œì ê°€ì´ë“œ

#### 9.1.1 ìƒˆ ì—ì´ì „íŠ¸ ì¶”ê°€ ê°€ì´ë“œ
```python
# ìƒˆ ì—ì´ì „íŠ¸ ìƒì„± í…œí”Œë¦¿
class NewAgentExecutor(StandardUnifiedAgentExecutor):
    def __init__(self):
        super().__init__(
            agent_name="NewAgent",
            specialized_config={
                "specific_feature": "value"
            }
        )
    
    async def _perform_specialized_processing(self, smart_df, intent, task_updater):
        # ì—ì´ì „íŠ¸ë³„ íŠ¹í™” ë¡œì§ êµ¬í˜„
        results = await self._custom_analysis(smart_df, intent)
        return results
```

#### 9.1.2 íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ê°€ì´ë“œ
```yaml
common_issues:
  utf8_encoding_error:
    symptoms: "'utf-8' codec can't decode"
    solution: "í†µí•© ì¸ì½”ë”© ê°ì§€ ì‹œìŠ¤í…œì´ ìë™ í•´ê²°"
    
  empty_dataframe_error:
    symptoms: "Cannot describe a DataFrame without columns"
    solution: "SmartDataFrame.is_empty() ê²€ì¦ í†µê³¼"
    
  file_selection_failure:
    symptoms: "No suitable file found"
    solution: "LLM ê¸°ë°˜ ì§€ëŠ¥í˜• íŒŒì¼ ì„ íƒê¸° í™œìš©"
```

### 9.2 ì‚¬ìš©ì ê°€ì´ë“œ

#### 9.2.1 ë°ì´í„° ì—…ë¡œë“œ ê°€ì´ë“œ
- **ì§€ì› í˜•ì‹**: CSV, Excel (.xlsx/.xls), JSON, Parquet
- **ê¶Œì¥ ì¸ì½”ë”©**: UTF-8
- **ìµœëŒ€ íŒŒì¼ í¬ê¸°**: 1GB (ìë™ ìƒ˜í”Œë§ ì ìš©)
- **ì—…ë¡œë“œ ìœ„ì¹˜**: `a2a_ds_servers/artifacts/data/shared_dataframes/`

#### 9.2.2 ì—ì´ì „íŠ¸ ì‚¬ìš©ë²•
ê° ì—ì´ì „íŠ¸ë³„ ìµœì  ì‚¬ìš© íŒ¨í„´ê³¼ ì˜ˆì‹œ ì¿¼ë¦¬ ì œê³µ

---

## âœ… 10. ì„±ê³µ ê¸°ì¤€ ë° KPI

### 10.1 ê¸°ìˆ ì  ì„±ê³µ ê¸°ì¤€

| ì§€í‘œ | í˜„ì¬ | ëª©í‘œ | ì¸¡ì • ë°©ë²• |
|------|------|------|----------|
| **ë°ì´í„° ë¡œë”© ì„±ê³µë¥ ** | ~70% | >95% | í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ê²°ê³¼ |
| **ì¸ì½”ë”© ì˜¤ë¥˜ìœ¨** | ~20% | <1% | ì—ëŸ¬ ë¡œê·¸ ë¶„ì„ |
| **í‰ê·  ë¡œë”© ì‹œê°„** | ~15ì´ˆ | <5ì´ˆ | ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ |
| **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰** | ì œí•œ ì—†ìŒ | <1GB | ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ |
| **ìºì‹œ íš¨ìœ¨ì„±** | 0% | >70% | ìºì‹œ íˆíŠ¸ìœ¨ ì¸¡ì • |

### 10.2 ì‚¬ìš©ì ê²½í—˜ ê°œì„ 

| í•­ëª© | ê°œì„  ëª©í‘œ | ê²€ì¦ ë°©ë²• |
|------|-----------|----------|
| **ì—ëŸ¬ ë©”ì‹œì§€** | ëª…í™•í•˜ê³  í•´ê²°ì±… í¬í•¨ | ì‚¬ìš©ì í”¼ë“œë°± |
| **ì‘ë‹µ ì†ë„** | 30ì´ˆ ì´ë‚´ ì™„ë£Œ | Playwright í…ŒìŠ¤íŠ¸ |
| **ì•ˆì •ì„±** | 24ì‹œê°„ ë¬´ì¤‘ë‹¨ ìš´ì˜ | ì—°ì† ì‹¤í–‰ í…ŒìŠ¤íŠ¸ |
| **ì¼ê´€ì„±** | ëª¨ë“  ì—ì´ì „íŠ¸ ë™ì¼í•œ ê²½í—˜ | í¬ë¡œìŠ¤ ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸ |

### 10.3 ì—ì´ì „íŠ¸ë³„ ì„±ê³µ ê¸°ì¤€ (12ê°œ ì™„ì „ ì¶”ì )

#### ğŸ”´ CRITICAL
- **data_loader (8307)**: ë‹¤ì¤‘ êµ¬í˜„ì²´ â†’ ë‹¨ì¼ FileConnector íŒ¨í„´, ë¡œë”© ì„±ê³µë¥  95%+

#### ğŸŸ¡ HIGH  
- **data_cleaning (8306)**: ë¹ˆ ë°ì´í„° ì˜¤ë¥˜ 0%, ì»¬ëŸ¼ ì—†ìŒ ì—ëŸ¬ ì™„ì „ í•´ê²°
- **data_visualization (8308)**: UTF-8 ì¸ì½”ë”© ì˜¤ë¥˜ 0%, ì°¨íŠ¸ ìƒì„± ì„±ê³µë¥  98%+
- **data_wrangling (8309)**: íŒŒì¼ ì„ íƒ ì‹¤íŒ¨ìœ¨ < 2%, ë³€í™˜ ì˜¤ë¥˜ ì™„ì „ í•´ê²°
- **eda_tools (8312)**: ì¸ì½”ë”© ë¬¸ì œ 0%, í†µê³„ ê³„ì‚° ì •í™•ë„ 99%+

#### ğŸŸ¢ MEDIUM
- **feature_engineering (8310)**: ìºì‹œ íˆíŠ¸ìœ¨ 70%+, ë°˜ë³µ ë¡œë”© ì‹œê°„ 80% ë‹¨ì¶•
- **sql_database (8311)**: DB ì—°ê²° ì‹¤íŒ¨ìœ¨ < 1%, ì¿¼ë¦¬ ì‹¤í–‰ ì•ˆì •ì„± 99%+
- **h2o_ml (8313)**: ëª¨ë¸ë§ ì‹¤íŒ¨ìœ¨ < 5%, AutoML ì„±ê³µë¥  95%+
- **mlflow_tools (8314)**: ì‹¤í—˜ ì¶”ì  ì†ì‹¤ìœ¨ < 1%, ë¡œê¹… ì™„ì „ì„± 99%+

#### ğŸ”µ LOW
- **orchestrator (8100)**: ì—ì´ì „íŠ¸ ë°œê²¬ìœ¨ 100%, ì¡°ì • ì‹¤íŒ¨ìœ¨ 0%
- **report_generator (8316)**: ì¢…í•© ë¶„ì„ ì„±ê³µë¥  98%+, ë‹¤ì¤‘ ì†ŒìŠ¤ í†µí•© ì™„ì„±

#### â­ TEMPLATE
- **pandas_agent (8210)**: ëª¨ë“  íŒ¨í„´ì˜ ê¸°ì¤€, ì™„ë²½ ë™ì‘ ìœ ì§€

### 10.4 ì „ì²´ ì‹œìŠ¤í…œ ì„±ê³µ ê¸°ì¤€

- **ğŸ¯ LLM First ì›ì¹™ 100% ì¤€ìˆ˜**: 12ê°œ ì—ì´ì „íŠ¸ ëª¨ë‘ LLMì´ ë™ì ìœ¼ë¡œ ê²°ì • ìˆ˜í–‰
- **ğŸ”§ A2A SDK 0.2.9 ì™„ë²½ ì ìš©**: 12ê°œ ì—ì´ì „íŠ¸ í‘œì¤€ í”„ë¡œí† ì½œ ì™„ì „ ì¤€ìˆ˜  
- **ğŸ“Š ê¸°ëŠ¥ ë¬´ì†ì‹¤ ë§ˆì´ê·¸ë ˆì´ì…˜**: 12ê°œ ì—ì´ì „íŠ¸ ê¸°ì¡´ ê¸°ëŠ¥ 100% ë³´ì¡´
- **ğŸš€ ì„±ëŠ¥ 30% ê°œì„ **: ì „ì²´ ì‹œìŠ¤í…œ ë¡œë”© ì†ë„ ë° ì•ˆì •ì„± í–¥ìƒ
- **ğŸ› ï¸ ìœ ì§€ë³´ìˆ˜ì„± í–¥ìƒ**: 12ê°œ ì—ì´ì „íŠ¸ ë‹¨ì¼ ì½”ë“œë² ì´ìŠ¤ë¡œ í†µí•© ê´€ë¦¬
- **ğŸ“ˆ ì „ì²´ ì‹ ë¢°ë„ 95%+**: 12ê°œ ì—ì´ì „íŠ¸ í‰ê·  ì‹ ë¢°ë„ ëª©í‘œ ë‹¬ì„±

---

## ğŸ”š ê²°ë¡ 

ì´ ì„¤ê³„ ë¬¸ì„œëŠ” CherryAI ì‹œìŠ¤í…œì˜ **12ê°œ A2A ì—ì´ì „íŠ¸ë¥¼ í•˜ë‚˜ë„ ë¹ ëœ¨ë¦¬ì§€ ì•Šê³ ** pandas_agentì˜ ìš°ìˆ˜í•œ íŒ¨í„´ì„ ê¸°ì¤€ìœ¼ë¡œ í†µí•©í•˜ëŠ” ì™„ì „í•œ ë¡œë“œë§µì„ ì œê³µí•©ë‹ˆë‹¤.

### ğŸ“Š ì™„ì „í•œ 12ê°œ ì—ì´ì „íŠ¸ ì»¤ë²„ë¦¬ì§€

**ğŸ”´ CRITICAL (1ê°œ)**: data_loader (8307)  
**ğŸŸ¡ HIGH (4ê°œ)**: data_cleaning (8306), data_visualization (8308), data_wrangling (8309), eda_tools (8312)  
**ğŸŸ¢ MEDIUM (4ê°œ)**: feature_engineering (8310), sql_database (8311), h2o_ml (8313), mlflow_tools (8314)  
**ğŸ”µ LOW (2ê°œ)**: orchestrator (8100), report_generator (8316)  
**â­ TEMPLATE (1ê°œ)**: pandas_agent (8210)

### ğŸ¯ í•µì‹¬ ì›ì¹™ (12ê°œ ì—ì´ì „íŠ¸ ê³µí†µ)

- âœ… **LLM First**: 12ê°œ ì—ì´ì „íŠ¸ ëª¨ë‘ ë°ì´í„° ê´€ë ¨ ê²°ì •ì„ LLMì´ ë‹´ë‹¹
- âœ… **A2A í‘œì¤€**: 12ê°œ ì—ì´ì „íŠ¸ SDK 0.2.9 ì™„ë²½ ì¤€ìˆ˜
- âœ… **ê¸°ëŠ¥ ë³´ì¡´**: 12ê°œ ì—ì´ì „íŠ¸ Mock ì—†ì´ 100% ì‹¤ì œ ê¸°ëŠ¥ ìœ ì§€
- âœ… **í™•ì¥ì„±**: ìƒˆë¡œìš´ ì—ì´ì „íŠ¸ ì‰½ê²Œ ì¶”ê°€ ê°€ëŠ¥í•œ í†µí•© ì•„í‚¤í…ì²˜

### ğŸš€ ì˜ˆìƒ íš¨ê³¼ (ì „ì²´ ì‹œìŠ¤í…œ)

- ğŸ¯ **70% â†’ 95%** ì „ì²´ ì‹œìŠ¤í…œ ë°ì´í„° ë¡œë”© ì„±ê³µë¥  í–¥ìƒ
- âš¡ **15ì´ˆ â†’ 5ì´ˆ** 12ê°œ ì—ì´ì „íŠ¸ í‰ê·  ì‘ë‹µ ì‹œê°„ ë‹¨ì¶•  
- ğŸ›¡ï¸ **20% â†’ 1%** ì „ì²´ ì‹œìŠ¤í…œ ì¸ì½”ë”© ì˜¤ë¥˜ìœ¨ ê°ì†Œ
- ğŸ§  **100% LLM ê¸°ë°˜** 12ê°œ ì—ì´ì „íŠ¸ ì§€ëŠ¥í˜• ë°ì´í„° ì²˜ë¦¬
- ğŸ“ˆ **95%+ ì‹ ë¢°ë„** 12ê°œ ì—ì´ì „íŠ¸ í‰ê·  ë¶„ì„ ì‹ ë¢°ë„ ë‹¬ì„±

### ğŸ† ìµœì¢… ëª©í‘œ

ì´ ê³„íšì— ë”°ë¼ ë‹¨ê³„ì ìœ¼ë¡œ êµ¬í˜„í•˜ë©´ **12ê°œ A2A ì—ì´ì „íŠ¸ê°€ ì™„ë²½í•˜ê²Œ í†µí•©ëœ** ì„¸ê³„ ìµœì´ˆì˜ ì™„ì „í•œ LLM First + A2A í†µí•© ë°ì´í„° ê³¼í•™ í”Œë«í¼ì„ ì™„ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**ğŸ’ CherryAI = 12ê°œ ì—ì´ì „íŠ¸ + pandas_agent íŒ¨í„´ + LLM First + A2A SDK 0.2.9** 