# CherryAI ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì•„í‚¤í…ì²˜ ì„¤ê³„ì„œ

## ğŸ“‹ ë¬¸ì„œ ê°œìš”

**ë²„ì „**: 1.0  
**ì‘ì„±ì¼**: 2025ë…„ 1ì›” 27ì¼  
**ëª©ì **: CherryAI í”Œë«í¼ì˜ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì•„í‚¤í…ì²˜ êµ¬í˜„ ê°€ì´ë“œ  
**ëŒ€ìƒ**: ê°œë°œíŒ€, ê²€ì¦íŒ€, ì•„í‚¤í…ì²˜ ë¦¬ë·°ì–´  

---

## ğŸ¯ í•µì‹¬ ëª©í‘œ

### 1. **LLM First ì² í•™ ì¤€ìˆ˜**
- LLMì˜ ëŠ¥ë ¥ì„ ìµœëŒ€í•œ ëŒì–´ë‚´ëŠ” ë²”ìš©ì  ë©€í‹°ì—ì´ì „íŠ¸ í”Œë«í¼
- Rule ê¸°ë°˜ í•˜ë“œì½”ë”© ë° íŒ¨í„´ ë§¤ì¹­ ì™„ì „ ì œê±°
- A2A SDK 0.2.9 í‘œì¤€ ì™„ì „ ì¤€ìˆ˜

### 2. **ì‹¤ì‹œê°„ ì‚¬ìš©ì ê²½í—˜**
- ChatGPT/Claude ìˆ˜ì¤€ì˜ ë°˜ì‘í˜• UI/UX
- A2A ì—ì´ì „íŠ¸ì™€ MCP ë„êµ¬ì˜ ì‹¤ì‹œê°„ ê²°ê³¼ ìŠ¤íŠ¸ë¦¬ë°
- SSE ê¸°ë°˜ ë¹„ë™ê¸° í†µì‹  í‘œì¤€í™”

### 3. **í™•ì¥ ê°€ëŠ¥í•œ ì•„í‚¤í…ì²˜**
- 11ê°œ A2A ì—ì´ì „íŠ¸ + 7ê°œ MCP ë„êµ¬ íš¨ìœ¨ì  ê´€ë¦¬
- ëª¨ë“ˆí™”ëœ êµ¬ì¡°ë¡œ ìœ ì§€ë³´ìˆ˜ì„± í™•ë³´
- ì„±ëŠ¥ ìµœì í™” ë° ì—ëŸ¬ í•¸ë“¤ë§

---

## ğŸ—ï¸ ì „ì²´ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

```mermaid
graph TB
    subgraph "Frontend Layer"
        UI[Streamlit UI]
        RC[Realtime Chat Container]
        MS[Message Streaming Manager]
    end
    
    subgraph "Streaming Layer"
        UMB[Unified Message Broker]
        SO[Streaming Orchestrator]
        USM[UI State Manager]
    end
    
    subgraph "A2A Layer"
        A2AC[A2A SSE Client]
        A2AO[A2A Orchestrator]
        A2AA[11 A2A Agents]
    end
    
    subgraph "MCP Layer"
        MCPB[MCP STDIO Bridge]
        MCPT[7 MCP Tools]
    end
    
    UI --> RC
    RC --> MS
    MS --> UMB
    UMB --> SO
    SO --> USM
    USM --> UI
    
    UMB --> A2AC
    A2AC --> A2AO
    A2AO --> A2AA
    
    UMB --> MCPB
    MCPB --> MCPT
```

---

## ğŸ”§ Phase 1: Streamlit UI/UX ì¦‰ì‹œ ê°œì„ 

### **í˜„ì¬ ë¬¸ì œì **
1. **ì»¨í…Œì´ë„ˆ ì¤‘ë³µ**: 3ê°œì˜ ê²¹ì¹œ ì»¨í…Œì´ë„ˆë¡œ ì¸í•œ ê³µê°„ ë‚­ë¹„
2. **ê³¼ë„í•œ ë¹ˆ ê³µê°„**: ìœ ì˜ë¯¸í•œ ì •ë³´ ëŒ€ë¹„ ê³¼ë„í•œ ì—¬ë°±
3. **ìŠ¤íŠ¸ë¦¬ë° ë¶€ì¬**: A2A/MCP ê²°ê³¼ê°€ ì‹¤ì‹œê°„ìœ¼ë¡œ í‘œì‹œë˜ì§€ ì•ŠìŒ

### **í•´ê²° ë°©ì•ˆ**

#### A. ì»¨í…Œì´ë„ˆ í†µí•© ë° ê³µê°„ ìµœì í™”

```python
# ui/components/unified_chat_interface.py

class UnifiedChatInterface:
    def __init__(self):
        self.message_container = st.empty()
        self.input_container = st.container()
        
    def render(self):
        """ë‹¨ì¼ ì»¨í…Œì´ë„ˆ ê¸°ë°˜ í†µí•© ì±„íŒ… ì¸í„°í˜ì´ìŠ¤"""
        
        # í—¤ë” ìµœì†Œí™” (ê¸°ì¡´ ëŒ€ë¹„ 60% ê³µê°„ ì ˆì•½)
        st.markdown("""
        <div class="cherry-header" style="
            padding: 0.5rem 0;
            margin-bottom: 1rem;
            border-bottom: 1px solid #e0e0e0;
        ">
            <h3 style="margin: 0;">ğŸ’ CherryAI</h3>
        </div>
        """, unsafe_allow_html=True)
        
        # í†µí•© ì±„íŒ… ì˜ì—­
        with self.message_container.container():
            self._render_messages()
            
        # í•˜ë‹¨ ê³ ì • ì…ë ¥ì°½
        with self.input_container:
            self._render_input_area()
```

#### B. ì‹¤ì‹œê°„ ë©”ì‹œì§€ ìŠ¤íŠ¸ë¦¬ë°

```python
# ui/streaming/realtime_chat_container.py

class RealtimeChatContainer:
    def __init__(self):
        self.messages = []
        self.active_streams = {}
        
    def add_streaming_message(self, source: str, agent_type: str):
        """ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ë©”ì‹œì§€ ì»¨í…Œì´ë„ˆ ì¶”ê°€"""
        
        message_id = f"{source}_{agent_type}_{int(time.time())}"
        placeholder = st.empty()
        
        self.active_streams[message_id] = {
            'placeholder': placeholder,
            'content': "",
            'metadata': {
                'source': source,  # 'a2a' or 'mcp'
                'agent_type': agent_type,
                'status': 'streaming'
            }
        }
        
        return message_id
    
    def update_streaming_message(self, message_id: str, chunk: str):
        """ìŠ¤íŠ¸ë¦¬ë° ë©”ì‹œì§€ ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸"""
        
        if message_id in self.active_streams:
            stream_data = self.active_streams[message_id]
            stream_data['content'] += chunk
            
            # ì‹¤ì‹œê°„ ë Œë”ë§
            stream_data['placeholder'].markdown(f"""
            <div class="streaming-message">
                <div class="message-header">
                    <span class="agent-badge">{stream_data['metadata']['agent_type']}</span>
                    <span class="status-indicator">ğŸ”„ ë¶„ì„ ì¤‘...</span>
                </div>
                <div class="message-content">
                    {stream_data['content']}
                </div>
            </div>
            """, unsafe_allow_html=True)
```

---

## ğŸŒŠ Phase 2: A2A SDK 0.2.9 SSE ìŠ¤íŠ¸ë¦¬ë° êµ¬í˜„

### **A2A í‘œì¤€ SSE ì•„í‚¤í…ì²˜**

#### A. A2A SSE í´ë¼ì´ì–¸íŠ¸

```python
# core/streaming/a2a_sse_client.py

import asyncio
import aiohttp
from typing import AsyncGenerator, Dict, Any
from a2a.types import RequestContext, TaskState
from a2a.client import A2AClient

class A2ASSEClient:
    """A2A SDK 0.2.9 í‘œì¤€ SSE í´ë¼ì´ì–¸íŠ¸"""
    
    def __init__(self, base_url: str, agents: Dict[str, str]):
        self.base_url = base_url
        self.agents = agents  # {'pandas': 'http://localhost:8001', ...}
        self.active_connections = {}
        
    async def stream_agent_response(
        self, 
        agent_name: str, 
        query: str, 
        session_id: str
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """A2A ì—ì´ì „íŠ¸ë¡œë¶€í„° ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ìˆ˜ì‹ """
        
        agent_url = self.agents[agent_name]
        sse_endpoint = f"{agent_url}/stream/{session_id}"
        
        async with aiohttp.ClientSession() as session:
            async with session.get(
                sse_endpoint,
                headers={
                    'Accept': 'text/event-stream',
                    'Cache-Control': 'no-cache'
                }
            ) as response:
                
                async for line in response.content:
                    if line:
                        event_data = self._parse_sse_event(line.decode())
                        if event_data:
                            yield {
                                'source': 'a2a',
                                'agent': agent_name,
                                'type': event_data.get('event', 'message'),
                                'data': event_data.get('data', ''),
                                'final': event_data.get('final', False)
                            }
    
    def _parse_sse_event(self, line: str) -> Dict[str, Any]:
        """A2A í‘œì¤€ SSE ì´ë²¤íŠ¸ íŒŒì‹±"""
        
        if line.startswith('data: '):
            try:
                return json.loads(line[6:])  # 'data: ' ì œê±°
            except json.JSONDecodeError:
                return {'data': line[6:]}
        return None
```

#### B. A2A ì„œë²„ ì¸¡ SSE êµ¬í˜„

```python
# a2a_ds_servers/base/streaming_server.py

from fastapi import FastAPI
from fastapi.responses import StreamingResponse
from a2a.server import A2AFastAPIApplication
from a2a.server.tasks.task_updater import TaskUpdater
from a2a.types import RequestContext, TaskState

class A2AStreamingServer:
    """A2A SDK 0.2.9 í‘œì¤€ ìŠ¤íŠ¸ë¦¬ë° ì„œë²„"""
    
    def __init__(self, agent_executor):
        self.app = A2AFastAPIApplication()
        self.agent_executor = agent_executor
        
    async def stream_response(
        self, 
        context: RequestContext,
        task_updater: TaskUpdater
    ) -> StreamingResponse:
        """A2A í‘œì¤€ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ"""
        
        async def event_generator():
            try:
                # ì‘ì—… ì‹œì‘ ì•Œë¦¼
                yield self._create_sse_event(
                    event_type="start",
                    data={"message": "ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...", "final": False}
                )
                
                # ì—ì´ì „íŠ¸ ì‹¤í–‰ ë° ì¤‘ê°„ ê²°ê³¼ ìŠ¤íŠ¸ë¦¬ë°
                async for chunk in self.agent_executor.stream(context):
                    yield self._create_sse_event(
                        event_type="progress", 
                        data={
                            "content": chunk.content,
                            "metadata": chunk.metadata,
                            "final": False
                        }
                    )
                    
                    # TaskUpdaterë¡œ ìƒíƒœ ì—…ë°ì´íŠ¸
                    await task_updater.update_status(
                        TaskState.working,
                        message=f"ì²˜ë¦¬ ì¤‘: {chunk.content[:50]}..."
                    )
                
                # ì™„ë£Œ ì´ë²¤íŠ¸
                yield self._create_sse_event(
                    event_type="complete",
                    data={"message": "ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.", "final": True}
                )
                
                await task_updater.update_status(TaskState.completed)
                
            except Exception as e:
                # ì—ëŸ¬ ì´ë²¤íŠ¸
                yield self._create_sse_event(
                    event_type="error",
                    data={"error": str(e), "final": True}
                )
                await task_updater.update_status(TaskState.failed, str(e))
        
        return StreamingResponse(
            event_generator(), 
            media_type="text/event-stream"
        )
    
    def _create_sse_event(self, event_type: str, data: Dict) -> str:
        """A2A í‘œì¤€ SSE ì´ë²¤íŠ¸ ìƒì„±"""
        
        return f"event: {event_type}\ndata: {json.dumps(data)}\n\n"
```

---

## ğŸ”Œ Phase 3: MCP STDIO â†’ SSE í‘œì¤€í™”

### **MCP í†µí•© ë¸Œë¦¬ì§€ ì‹œìŠ¤í…œ**

#### A. MCP STDIO ë¸Œë¦¬ì§€

```python
# core/streaming/mcp_stdio_bridge.py

import asyncio
import subprocess
import json
from typing import AsyncGenerator, Dict, Any

class MCPSTDIOBridge:
    """MCP STDIOë¥¼ SSEë¡œ ë³€í™˜í•˜ëŠ” ë¸Œë¦¬ì§€"""
    
    def __init__(self, mcp_tools: Dict[str, str]):
        self.mcp_tools = mcp_tools  # {'pandas': '/path/to/mcp-pandas', ...}
        self.active_processes = {}
        
    async def stream_mcp_tool(
        self, 
        tool_name: str, 
        command: str, 
        session_id: str
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """MCP ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ SSEë¡œ ìŠ¤íŠ¸ë¦¬ë°"""
        
        tool_path = self.mcp_tools[tool_name]
        
        # STDIO í”„ë¡œì„¸ìŠ¤ ì‹œì‘
        process = await asyncio.create_subprocess_exec(
            tool_path,
            stdin=subprocess.PIPE,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE
        )
        
        self.active_processes[session_id] = process
        
        try:
            # MCP JSON-RPC ìš”ì²­ ì „ì†¡
            request = {
                "jsonrpc": "2.0",
                "id": 1,
                "method": "execute",
                "params": {"command": command}
            }
            
            process.stdin.write(json.dumps(request).encode() + b'\n')
            await process.stdin.drain()
            
            # ì‹¤ì‹œê°„ ì¶œë ¥ ìŠ¤íŠ¸ë¦¬ë°
            while True:
                line = await process.stdout.readline()
                if not line:
                    break
                    
                try:
                    response = json.loads(line.decode())
                    
                    yield {
                        'source': 'mcp',
                        'tool': tool_name,
                        'type': 'response',
                        'data': response.get('result', ''),
                        'final': 'id' in response  # JSON-RPC ì‘ë‹µ ì™„ë£Œ
                    }
                    
                except json.JSONDecodeError:
                    # ì›ì‹œ ì¶œë ¥ë„ ìŠ¤íŠ¸ë¦¬ë°
                    yield {
                        'source': 'mcp',
                        'tool': tool_name,
                        'type': 'output',
                        'data': line.decode().strip(),
                        'final': False
                    }
                    
        finally:
            # í”„ë¡œì„¸ìŠ¤ ì •ë¦¬
            if session_id in self.active_processes:
                process.terminate()
                await process.wait()
                del self.active_processes[session_id]
```

#### B. í†µí•© ë©”ì‹œì§€ ë¸Œë¡œì»¤

```python
# core/streaming/unified_message_broker.py

class UnifiedMessageBroker:
    """A2A + MCP í†µí•© ë©”ì‹œì§€ ë¸Œë¡œì»¤"""
    
    def __init__(self):
        self.a2a_client = A2ASSEClient(
            base_url="http://localhost:8100",
            agents={
                'orchestrator': 'http://localhost:8100',
                'pandas': 'http://localhost:8001',
                'visualization': 'http://localhost:8002',
                'ml_modeling': 'http://localhost:8003',
                # ... 11ê°œ A2A ì—ì´ì „íŠ¸
            }
        )
        
        self.mcp_bridge = MCPSTDIOBridge(
            mcp_tools={
                'data_preprocessing': '/path/to/mcp-data-preprocessing',
                'statistical_analysis': '/path/to/mcp-statistical-analysis',
                'advanced_visualization': '/path/to/mcp-advanced-visualization',
                # ... 7ê°œ MCP ë„êµ¬
            }
        )
        
        self.message_queues = {}  # ì„¸ì…˜ë³„ ë©”ì‹œì§€ í
        
    async def process_query_with_streaming(
        self, 
        query: str, 
        session_id: str
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """í†µí•© ì¿¼ë¦¬ ì²˜ë¦¬ ë° ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°"""
        
        # 1. A2A ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°ë¡œ ê³„íš ìˆ˜ë¦½
        async for plan_chunk in self.a2a_client.stream_agent_response(
            'orchestrator', query, session_id
        ):
            yield plan_chunk
            
            # ê³„íšì—ì„œ í•„ìš”í•œ ì—ì´ì „íŠ¸/ë„êµ¬ ì¶”ì¶œ (LLM First)
            if plan_chunk['final']:
                execution_plan = self._parse_execution_plan(plan_chunk['data'])
                
                # 2. ë³‘ë ¬ ì‹¤í–‰ ë° ìŠ¤íŠ¸ë¦¬ë°
                tasks = []
                
                for step in execution_plan:
                    if step['type'] == 'a2a_agent':
                        tasks.append(
                            self.a2a_client.stream_agent_response(
                                step['agent'], step['query'], session_id
                            )
                        )
                    elif step['type'] == 'mcp_tool':
                        tasks.append(
                            self.mcp_bridge.stream_mcp_tool(
                                step['tool'], step['command'], session_id
                            )
                        )
                
                # 3. ëª¨ë“  ê²°ê³¼ ì‹¤ì‹œê°„ ë³‘í•© ìŠ¤íŠ¸ë¦¬ë°
                async for merged_result in self._merge_streams(tasks):
                    yield merged_result
    
    async def _merge_streams(self, streams) -> AsyncGenerator[Dict[str, Any], None]:
        """ì—¬ëŸ¬ ìŠ¤íŠ¸ë¦¼ì„ ì‹œê°„ìˆœìœ¼ë¡œ ë³‘í•©"""
        
        async def stream_wrapper(stream, source_id):
            async for item in stream:
                item['stream_id'] = source_id
                yield item
        
        # ëª¨ë“  ìŠ¤íŠ¸ë¦¼ì„ íì— ë³‘í•©
        queue = asyncio.Queue()
        
        async def producer(stream, source_id):
            async for item in stream_wrapper(stream, source_id):
                await queue.put(item)
        
        # ëª¨ë“  ìŠ¤íŠ¸ë¦¼ ë³‘ë ¬ ì‹¤í–‰
        producers = [
            asyncio.create_task(producer(stream, i)) 
            for i, stream in enumerate(streams)
        ]
        
        try:
            while any(not p.done() for p in producers):
                try:
                    item = await asyncio.wait_for(queue.get(), timeout=0.1)
                    yield item
                except asyncio.TimeoutError:
                    continue
        finally:
            for p in producers:
                p.cancel()
```

---

## ğŸ”„ Phase 4: Streamlit í†µí•© ì‹œìŠ¤í…œ

### **ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°**

```python
# core/streaming/streaming_orchestrator.py

class StreamingOrchestrator:
    """Streamlitê³¼ ë°±ì—”ë“œ ìŠ¤íŠ¸ë¦¬ë° ì‹œìŠ¤í…œ í†µí•©"""
    
    def __init__(self):
        self.broker = UnifiedMessageBroker()
        self.ui_state = UIStateManager()
        
    async def handle_user_query(
        self, 
        query: str, 
        session_id: str,
        ui_container: RealtimeChatContainer
    ):
        """ì‚¬ìš©ì ì¿¼ë¦¬ ì²˜ë¦¬ ë° UI ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸"""
        
        active_messages = {}  # í™œì„± ë©”ì‹œì§€ ì¶”ì 
        
        async for stream_chunk in self.broker.process_query_with_streaming(
            query, session_id
        ):
            source = stream_chunk['source']  # 'a2a' or 'mcp'
            agent_or_tool = stream_chunk.get('agent', stream_chunk.get('tool'))
            
            # ìƒˆë¡œìš´ ìŠ¤íŠ¸ë¦¼ ì‹œì‘
            if stream_chunk['type'] == 'start':
                message_id = ui_container.add_streaming_message(
                    source, agent_or_tool
                )
                active_messages[f"{source}_{agent_or_tool}"] = message_id
                
            # ì§„í–‰ ì¤‘ ì—…ë°ì´íŠ¸
            elif stream_chunk['type'] in ['progress', 'response', 'output']:
                key = f"{source}_{agent_or_tool}"
                if key in active_messages:
                    ui_container.update_streaming_message(
                        active_messages[key], 
                        stream_chunk['data']
                    )
                    
            # ìŠ¤íŠ¸ë¦¼ ì™„ë£Œ
            elif stream_chunk['final']:
                key = f"{source}_{agent_or_tool}"
                if key in active_messages:
                    ui_container.finalize_streaming_message(
                        active_messages[key]
                    )
                    del active_messages[key]
        
        # ëª¨ë“  ìŠ¤íŠ¸ë¦¼ ì™„ë£Œ í›„ ì¢…í•© ê²°ê³¼ ìƒì„±
        await self._generate_final_summary(session_id, ui_container)
```

### **ê°œì„ ëœ main.py êµ¬ì¡°**

```python
# main.py (ê°œì„ ëœ ë²„ì „)

import asyncio
from ui.streaming.realtime_chat_container import RealtimeChatContainer
from core.streaming.streaming_orchestrator import StreamingOrchestrator

def main():
    st.set_page_config(
        page_title="ğŸ’ CherryAI", 
        layout="wide",
        initial_sidebar_state="collapsed"  # ì‚¬ì´ë“œë°” ì œê±°
    )
    
    # ì„¸ì…˜ ì´ˆê¸°í™”
    if 'session_id' not in st.session_state:
        st.session_state.session_id = str(uuid.uuid4())
    if 'chat_container' not in st.session_state:
        st.session_state.chat_container = RealtimeChatContainer()
    
    # í†µí•© ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ (ì»¨í…Œì´ë„ˆ 1ê°œ)
    with st.container():
        # íŒŒì¼ ì—…ë¡œë“œ (ì¡°ê±´ë¶€ í‘œì‹œ)
        render_conditional_file_upload()
        
        # ì‹¤ì‹œê°„ ì±„íŒ… ì˜ì—­
        chat_container = st.session_state.chat_container
        chat_container.render()
        
        # í•˜ë‹¨ ê³ ì • ì…ë ¥ì°½
        with st.container():
            user_input = st.chat_input("CherryAIì—ê²Œ ì§ˆë¬¸í•˜ì„¸ìš”...")
            
            if user_input:
                # ì‚¬ìš©ì ë©”ì‹œì§€ ì¦‰ì‹œ í‘œì‹œ
                chat_container.add_user_message(user_input)
                
                # ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬
                orchestrator = StreamingOrchestrator()
                
                # ë¹„ë™ê¸° ì²˜ë¦¬ë¥¼ ìœ„í•œ ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰
                asyncio.run(
                    orchestrator.handle_user_query(
                        user_input,
                        st.session_state.session_id,
                        chat_container
                    )
                )
                
                # UI ìë™ ìŠ¤í¬ë¡¤
                st.rerun()

def render_conditional_file_upload():
    """ì¡°ê±´ë¶€ íŒŒì¼ ì—…ë¡œë“œ (ì™„ë£Œ ì‹œ ìë™ ì ‘í˜)"""
    
    upload_completed = st.session_state.get('upload_completed', False)
    
    with st.expander("ğŸ“ íŒŒì¼ ì—…ë¡œë“œ", expanded=not upload_completed):
        uploaded_files = st.file_uploader(
            "ë°ì´í„° íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”",
            accept_multiple_files=True,
            type=['csv', 'xlsx', 'json', 'parquet']
        )
        
        if uploaded_files and not upload_completed:
            # íŒŒì¼ ì²˜ë¦¬ ë° í™˜ì˜ ë©”ì‹œì§€
            process_uploaded_files(uploaded_files)
            st.session_state.upload_completed = True
            st.rerun()

if __name__ == "__main__":
    main()
```

---

## ğŸ“Š ì„±ëŠ¥ ìµœì í™” ì „ëµ

### **1. ì—°ê²° í’€ë§ ë° ë¦¬ì†ŒìŠ¤ ê´€ë¦¬**

```python
# core/performance/connection_pool.py

class A2AMCPConnectionPool:
    """A2A + MCP ì—°ê²° í’€ ê´€ë¦¬"""
    
    def __init__(self, max_connections: int = 50):
        self.a2a_pools = {}  # ì—ì´ì „íŠ¸ë³„ ì—°ê²° í’€
        self.mcp_processes = {}  # MCP í”„ë¡œì„¸ìŠ¤ í’€
        self.max_connections = max_connections
        
    async def get_a2a_connection(self, agent_name: str):
        """A2A ì—ì´ì „íŠ¸ ì—°ê²° í’€ì—ì„œ ì—°ê²° íšë“"""
        
        if agent_name not in self.a2a_pools:
            self.a2a_pools[agent_name] = aiohttp.ClientSession(
                connector=aiohttp.TCPConnector(
                    limit=self.max_connections // len(A2A_AGENTS)
                )
            )
        
        return self.a2a_pools[agent_name]
    
    async def get_mcp_process(self, tool_name: str):
        """MCP ë„êµ¬ í”„ë¡œì„¸ìŠ¤ í’€ì—ì„œ í”„ë¡œì„¸ìŠ¤ íšë“"""
        
        if tool_name not in self.mcp_processes:
            # í”„ë¡œì„¸ìŠ¤ í’€ ìƒì„± (ìµœëŒ€ 3ê°œ í”„ë¡œì„¸ìŠ¤)
            self.mcp_processes[tool_name] = []
            for _ in range(3):
                process = await self._create_mcp_process(tool_name)
                self.mcp_processes[tool_name].append(process)
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ í”„ë¡œì„¸ìŠ¤ ë°˜í™˜
        return self._get_available_process(tool_name)
```

### **2. ìºì‹± ë° ì„¸ì…˜ ê´€ë¦¬**

```python
# core/performance/session_cache.py

@st.cache_resource
def get_global_orchestrator():
    """ê¸€ë¡œë²Œ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì‹±ê¸€í†¤"""
    return StreamingOrchestrator()

@st.cache_data(ttl=300)  # 5ë¶„ ìºì‹œ
def get_agent_capabilities():
    """ì—ì´ì „íŠ¸ ëŠ¥ë ¥ ì •ë³´ ìºì‹±"""
    return {
        'pandas': ['data_analysis', 'cleaning', 'transformation'],
        'visualization': ['charts', 'plots', 'dashboards'],
        'ml_modeling': ['regression', 'classification', 'clustering'],
        # ...
    }

class SessionStateManager:
    """íš¨ìœ¨ì ì¸ ì„¸ì…˜ ìƒíƒœ ê´€ë¦¬"""
    
    @staticmethod
    def cleanup_old_sessions():
        """ì˜¤ë˜ëœ ì„¸ì…˜ ì •ë¦¬ (ë©”ëª¨ë¦¬ ìµœì í™”)"""
        
        current_time = time.time()
        for key in list(st.session_state.keys()):
            if key.startswith('session_') and isinstance(st.session_state[key], dict):
                last_activity = st.session_state[key].get('last_activity', 0)
                if current_time - last_activity > 1800:  # 30ë¶„
                    del st.session_state[key]
```

---

## ğŸ§ª í…ŒìŠ¤íŠ¸ ì „ëµ

### **1. ë‹¨ìœ„ í…ŒìŠ¤íŠ¸**

```python
# tests/unit/test_streaming.py

import pytest
import asyncio
from core.streaming.unified_message_broker import UnifiedMessageBroker

class TestStreamingComponents:
    
    @pytest.mark.asyncio
    async def test_a2a_sse_streaming(self):
        """A2A SSE ìŠ¤íŠ¸ë¦¬ë° í…ŒìŠ¤íŠ¸"""
        
        broker = UnifiedMessageBroker()
        
        messages = []
        async for chunk in broker.a2a_client.stream_agent_response(
            'pandas', 'analyze test data', 'test_session'
        ):
            messages.append(chunk)
            
        assert len(messages) > 0
        assert messages[0]['source'] == 'a2a'
        assert messages[-1]['final'] == True
    
    @pytest.mark.asyncio
    async def test_mcp_stdio_bridge(self):
        """MCP STDIO ë¸Œë¦¬ì§€ í…ŒìŠ¤íŠ¸"""
        
        broker = UnifiedMessageBroker()
        
        results = []
        async for chunk in broker.mcp_bridge.stream_mcp_tool(
            'data_preprocessing', 'clean_data', 'test_session'
        ):
            results.append(chunk)
            
        assert len(results) > 0
        assert results[0]['source'] == 'mcp'
```

### **2. í†µí•© í…ŒìŠ¤íŠ¸**

```python
# tests/integration/test_full_streaming.py

class TestFullStreamingIntegration:
    
    @pytest.mark.asyncio
    async def test_end_to_end_streaming(self):
        """ì „ì²´ ìŠ¤íŠ¸ë¦¬ë° íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸"""
        
        orchestrator = StreamingOrchestrator()
        mock_ui = MockUIContainer()
        
        await orchestrator.handle_user_query(
            "ì—…ë¡œë“œëœ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ì‹œê°í™”í•´ì£¼ì„¸ìš”",
            "test_session",
            mock_ui
        )
        
        # ë©”ì‹œì§€ê°€ ì˜¬ë°”ë¥¸ ìˆœì„œë¡œ ìˆ˜ì‹ ë˜ì—ˆëŠ”ì§€ í™•ì¸
        assert mock_ui.message_count > 0
        assert any(msg['source'] == 'a2a' for msg in mock_ui.messages)
        assert any(msg['source'] == 'mcp' for msg in mock_ui.messages)
```

### **3. UI í…ŒìŠ¤íŠ¸ (Playwright)**

```python
# tests/ui/test_streamlit_interface.py

from playwright.sync_api import Page, expect

def test_realtime_streaming_ui(page: Page):
    """ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° UI í…ŒìŠ¤íŠ¸"""
    
    page.goto("http://localhost:8501")
    
    # íŒŒì¼ ì—…ë¡œë“œ
    page.get_by_test_id("stFileUploader").set_input_files("test_data.csv")
    
    # ì¿¼ë¦¬ ì…ë ¥
    page.get_by_placeholder("CherryAIì—ê²Œ ì§ˆë¬¸í•˜ì„¸ìš”").fill("ë°ì´í„° ë¶„ì„í•´ì£¼ì„¸ìš”")
    page.keyboard.press("Enter")
    
    # ìŠ¤íŠ¸ë¦¬ë° ë©”ì‹œì§€ í™•ì¸
    expect(page.locator(".streaming-message")).to_be_visible()
    expect(page.locator(".agent-badge")).to_contain_text("pandas")
    
    # ìµœì¢… ê²°ê³¼ í™•ì¸
    expect(page.locator(".message-final")).to_be_visible(timeout=30000)
```

---

## ğŸ“ˆ ëª¨ë‹ˆí„°ë§ ë° ê´€ì°°ê°€ëŠ¥ì„±

### **ë©”íŠ¸ë¦­ ìˆ˜ì§‘**

```python
# core/monitoring/metrics_collector.py

import time
import psutil
from prometheus_client import Counter, Histogram, Gauge

class StreamingMetrics:
    """ìŠ¤íŠ¸ë¦¬ë° ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
    
    def __init__(self):
        self.message_count = Counter('streaming_messages_total', 'Total streaming messages', ['source', 'agent'])
        self.response_time = Histogram('streaming_response_seconds', 'Response time per stream')
        self.active_streams = Gauge('streaming_active_total', 'Active streaming connections')
        
    def record_message(self, source: str, agent: str):
        self.message_count.labels(source=source, agent=agent).inc()
        
    def record_response_time(self, duration: float):
        self.response_time.observe(duration)
        
    def set_active_streams(self, count: int):
        self.active_streams.set(count)
```

---

## ğŸš€ ë°°í¬ ë° ìš´ì˜ ê°€ì´ë“œ

### **1. í™˜ê²½ ì„¤ì •**

```bash
# requirements.txt (ì¶”ê°€ëœ ì˜ì¡´ì„±)
streamlit>=1.30.0
aiohttp>=3.8.0
asyncio>=3.4.3
sse-starlette>=2.0.0
prometheus-client>=0.19.0

# A2A SDK
a2a-sdk==0.2.9

# MCP Tools
mcp-data-preprocessing
mcp-statistical-analysis
mcp-advanced-visualization
```

### **2. ì‹œìŠ¤í…œ ì‹œì‘ ìŠ¤í¬ë¦½íŠ¸ ì—…ë°ì´íŠ¸**

```bash
#!/bin/bash
# ai_ds_team_system_start_streaming.sh

echo "ğŸ’ CherryAI ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì‹œìŠ¤í…œ ì‹œì‘..."

# A2A ì„œë²„ë“¤ ì‹œì‘ (SSE ì§€ì›)
python a2a_ds_servers/a2a_orchestrator.py --sse-enabled &
python a2a_ds_servers/pandas_server_streaming.py &
python a2a_ds_servers/visualization_server_streaming.py &
# ... 11ê°œ A2A ì„œë²„

# MCP ë„êµ¬ë“¤ ì¤€ë¹„
echo "MCP ë„êµ¬ ì´ˆê¸°í™” ì¤‘..."
./scripts/initialize_mcp_tools.sh

# Streamlit ì•± ì‹œì‘
echo "Streamlit ì‹¤ì‹œê°„ ì¸í„°í˜ì´ìŠ¤ ì‹œì‘..."
streamlit run main.py --server.port 8501 --server.enableWebsocketCompression=true

echo "âœ… ëª¨ë“  ì„œë¹„ìŠ¤ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤!"
echo "ğŸŒ http://localhost:8501 ì—ì„œ CherryAIë¥¼ ì‚¬ìš©í•˜ì„¸ìš”"
```

### **3. ì„±ëŠ¥ íŠœë‹**

```python
# config/streaming_config.py

STREAMING_CONFIG = {
    # A2A ì„¤ì •
    'a2a': {
        'max_concurrent_agents': 5,
        'stream_buffer_size': 1024,
        'reconnect_interval': 5.0,
        'timeout_seconds': 30.0
    },
    
    # MCP ì„¤ì •
    'mcp': {
        'max_concurrent_tools': 3,
        'process_timeout': 60.0,
        'stdio_buffer_size': 8192
    },
    
    # UI ì„¤ì •
    'ui': {
        'update_interval': 0.1,  # 100ms
        'max_messages_displayed': 100,
        'auto_scroll_threshold': 5
    }
}
```

---

## ğŸ“‹ êµ¬í˜„ ì²´í¬ë¦¬ìŠ¤íŠ¸

### **Phase 1: UI/UX ê°œì„ **
- [ ] ì»¨í…Œì´ë„ˆ ì¤‘ë³µ ì œê±° (3ê°œ â†’ 1ê°œ)
- [ ] ë¹ˆ ê³µê°„ ìµœì†Œí™” (padding/margin ìµœì í™”)
- [ ] íŒŒì¼ ì—…ë¡œë“œ ì¡°ê±´ë¶€ í‘œì‹œ êµ¬í˜„
- [ ] ì±„íŒ… ì…ë ¥ì°½ í•˜ë‹¨ ê³ ì •
- [ ] ìë™ ìŠ¤í¬ë¡¤ ê¸°ëŠ¥ êµ¬í˜„

### **Phase 2: A2A SSE ìŠ¤íŠ¸ë¦¬ë°**
- [ ] A2ASSEClient êµ¬í˜„
- [ ] A2A ì„œë²„ SSE ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€
- [ ] TaskUpdater ì‹¤ì‹œê°„ ìƒíƒœ ì—…ë°ì´íŠ¸
- [ ] ì—ëŸ¬ í•¸ë“¤ë§ ë° ì¬ì—°ê²° ë¡œì§

### **Phase 3: MCP STDIO ë¸Œë¦¬ì§€**
- [ ] MCPSTDIOBridge êµ¬í˜„
- [ ] JSON-RPC â†’ SSE ë³€í™˜ ë¡œì§
- [ ] í”„ë¡œì„¸ìŠ¤ í’€ ê´€ë¦¬
- [ ] ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ë©”ì»¤ë‹ˆì¦˜

### **Phase 4: í†µí•© ì‹œìŠ¤í…œ**
- [ ] UnifiedMessageBroker êµ¬í˜„
- [ ] StreamingOrchestrator êµ¬í˜„
- [ ] ì„¸ì…˜ ìƒíƒœ ê´€ë¦¬ ê°œì„ 
- [ ] main.py ë¦¬íŒ©í† ë§

### **Phase 5: ì„±ëŠ¥ ìµœì í™”**
- [ ] ì—°ê²° í’€ë§ êµ¬í˜„
- [ ] ìºì‹± ì „ëµ ì ìš©
- [ ] ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”
- [ ] ë™ì‹œ ì—°ê²° ìˆ˜ ì œí•œ

### **Phase 6: í…ŒìŠ¤íŠ¸ ë° ê²€ì¦**
- [ ] ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±
- [ ] í†µí•© í…ŒìŠ¤íŠ¸ êµ¬í˜„
- [ ] Playwright UI í…ŒìŠ¤íŠ¸
- [ ] ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸

---

## ğŸ¯ ì„±ê³µ ê¸°ì¤€

### **ê¸°ëŠ¥ ìš”êµ¬ì‚¬í•­**
1. âœ… A2A ì—ì´ì „íŠ¸ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° (11ê°œ)
2. âœ… MCP ë„êµ¬ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° (7ê°œ)
3. âœ… ChatGPT/Claude ìˆ˜ì¤€ UI/UX
4. âœ… ì»¨í…Œì´ë„ˆ ìµœì í™” ë° ê³µê°„ íš¨ìœ¨ì„±
5. âœ… LLM First ì² í•™ ì™„ì „ ì¤€ìˆ˜

### **ì„±ëŠ¥ ìš”êµ¬ì‚¬í•­**
1. **ì‘ë‹µ ì‹œê°„**: ì²« ì‘ë‹µ < 2ì´ˆ
2. **ìŠ¤íŠ¸ë¦¬ë° ì§€ì—°**: < 100ms
3. **ë™ì‹œ ì‚¬ìš©ì**: ìµœëŒ€ 50ëª…
4. **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰**: < 2GB
5. **CPU ì‚¬ìš©ë¥ **: í‰ê·  < 70%

### **ì•ˆì •ì„± ìš”êµ¬ì‚¬í•­**
1. **ê°€ìš©ì„±**: 99.9%
2. **ì—ëŸ¬ìœ¨**: < 1%
3. **ìë™ ë³µêµ¬**: ì—°ê²° ëŠê¹€ ì‹œ 5ì´ˆ ë‚´
4. **ë°ì´í„° ë¬´ê²°ì„±**: 100%

---

## ğŸ“š ì°¸ê³  ìë£Œ

1. **A2A SDK 0.2.9 Documentation**: [A2A ê³µì‹ ë¬¸ì„œ]
2. **Streamlit SSE Guide**: [Streamlit ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ ê°€ì´ë“œ]
3. **FastAPI SSE Implementation**: [FastAPI ìŠ¤íŠ¸ë¦¬ë° êµ¬í˜„]
4. **MCP Protocol Specification**: [MCP í”„ë¡œí† ì½œ ëª…ì„¸]
5. **Python Async Streaming**: [Python ë¹„ë™ê¸° ìŠ¤íŠ¸ë¦¬ë° íŒ¨í„´]

---

**ë¬¸ì„œ ë²„ì „**: 1.0  
**ìµœì¢… ìˆ˜ì •**: 2025ë…„ 1ì›” 27ì¼  
**ë‹¤ìŒ ë¦¬ë·°**: 2025ë…„ 2ì›” 10ì¼  

---

*ì´ ë¬¸ì„œëŠ” CherryAI ê°œë°œíŒ€ì˜ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì•„í‚¤í…ì²˜ êµ¬í˜„ì„ ìœ„í•œ ì™„ì „í•œ ê°€ì´ë“œì…ë‹ˆë‹¤. ëª¨ë“  êµ¬í˜„ì€ LLM First ì² í•™ê³¼ A2A + MCP í‘œì¤€ì„ ì¤€ìˆ˜í•´ì•¼ í•©ë‹ˆë‹¤.* 