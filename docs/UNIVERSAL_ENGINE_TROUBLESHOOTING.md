# Universal Engine Troubleshooting Guide

## ğŸš¨ ê°œìš”

ì´ ê°€ì´ë“œëŠ” Universal Engine ì‚¬ìš© ì¤‘ ë°œìƒí•  ìˆ˜ ìˆëŠ” ì¼ë°˜ì ì¸ ë¬¸ì œë“¤ê³¼ í•´ê²° ë°©ë²•ì„ ì œê³µí•©ë‹ˆë‹¤. ë¬¸ì œ ì§„ë‹¨ë¶€í„° í•´ê²°ê¹Œì§€ ë‹¨ê³„ë³„ë¡œ ì„¤ëª…í•©ë‹ˆë‹¤.

## ğŸ” ì¼ë°˜ì ì¸ ë¬¸ì œ í•´ê²°

### 1. ì‹œìŠ¤í…œ ì´ˆê¸°í™” ë¬¸ì œ

#### ğŸ”´ ë¬¸ì œ: System initialization failed
```
Error: Universal Engine initialization failed
```

**ì›ì¸:**
- LLM ì„œë¹„ìŠ¤ ì—°ê²° ì‹¤íŒ¨
- í•„ìˆ˜ í™˜ê²½ ë³€ìˆ˜ ëˆ„ë½
- í¬íŠ¸ ì¶©ëŒ

**í•´ê²° ë°©ë²•:**
```bash
# 1. í™˜ê²½ ë³€ìˆ˜ í™•ì¸
echo $LLM_PROVIDER
echo $OLLAMA_BASE_URL

# 2. Ollama ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
curl http://localhost:11434/api/version

# 3. í¬íŠ¸ ì¶©ëŒ í™•ì¸
netstat -tulpn | grep -E ":(8306|8307|8308|8309|8310|8311|8312|8313|8314|8315)\s"

# 4. ì‹œìŠ¤í…œ ì¬ì´ˆê¸°í™”
python -c "
from core.universal_engine.initialization.system_initializer import UniversalEngineInitializer
import asyncio
asyncio.run(UniversalEngineInitializer().initialize_system())
"
```

#### ğŸ”´ ë¬¸ì œ: A2A agents not discovered
```
Error: No A2A agents found in port range 8306-8315
```

**í•´ê²° ë°©ë²•:**
```bash
# 1. í¬íŠ¸ ë²”ìœ„ í™•ì¸
for port in {8306..8315}; do
  nc -z localhost $port && echo "Port $port is open" || echo "Port $port is closed"
done

# 2. A2A ì—ì´ì „íŠ¸ ìˆ˜ë™ ì‹œì‘ (ê°œë°œ ëª¨ë“œ)
python scripts/start_a2a_agents.py

# 3. ë°©í™”ë²½ í™•ì¸ ë° í¬íŠ¸ í—ˆìš©
sudo ufw allow 8306:8315/tcp
```

### 2. LLM ì—°ê²° ë¬¸ì œ

#### ğŸ”´ ë¬¸ì œ: LLM service unavailable
```
Error: Failed to connect to LLM service
```

**Ollama ì‚¬ìš© ì‹œ:**
```bash
# 1. Ollama ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
systemctl status ollama

# 2. Ollama ì„œë¹„ìŠ¤ ì‹œì‘
ollama serve

# 3. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ í™•ì¸
ollama list

# 4. ëª¨ë¸ì´ ì—†ëŠ” ê²½ìš° ë‹¤ìš´ë¡œë“œ
ollama pull llama2

# 5. ì—°ê²° í…ŒìŠ¤íŠ¸
curl -X POST http://localhost:11434/api/generate \
  -H "Content-Type: application/json" \
  -d '{"model": "llama2", "prompt": "Hello", "stream": false}'
```

**OpenAI ì‚¬ìš© ì‹œ:**
```bash
# 1. API í‚¤ í™•ì¸
echo $OPENAI_API_KEY

# 2. API ì—°ê²° í…ŒìŠ¤íŠ¸
curl -H "Authorization: Bearer $OPENAI_API_KEY" \
     https://api.openai.com/v1/models

# 3. í™˜ê²½ ë³€ìˆ˜ ì„¤ì • í™•ì¸
export LLM_PROVIDER=openai
export OPENAI_API_KEY=your_api_key_here
```

#### ğŸ”´ ë¬¸ì œ: Token limit exceeded
```
Error: Request exceeds token limit
```

**í•´ê²° ë°©ë²•:**
```python
# 1. ì…ë ¥ ë°ì´í„° í¬ê¸° í™•ì¸ ë° ì²­í¬ ë¶„í• 
import pandas as pd

def chunk_dataframe(df, max_rows=1000):
    """ëŒ€ìš©ëŸ‰ ë°ì´í„°ë¥¼ ì²­í¬ ë‹¨ìœ„ë¡œ ë¶„í• """
    for i in range(0, len(df), max_rows):
        yield df[i:i + max_rows]

# 2. ì¿¼ë¦¬ ê¸¸ì´ ì œí•œ
def truncate_query(query, max_tokens=2000):
    """ì¿¼ë¦¬ ê¸¸ì´ ì œí•œ"""
    words = query.split()
    if len(words) > max_tokens:
        return ' '.join(words[:max_tokens]) + "..."
    return query

# 3. ì»¨í…ìŠ¤íŠ¸ ìµœì í™”
context = {
    "session_id": "sess123",
    "summarized_history": True,  # ê¸´ íˆìŠ¤í† ë¦¬ ìš”ì•½
    "essential_only": True       # í•„ìˆ˜ ì •ë³´ë§Œ í¬í•¨
}
```

### 3. A2A í†µí•© ì‹œìŠ¤í…œ ë¬¸ì œ

#### ğŸ”´ ë¬¸ì œ: A2A agent timeout
```
Error: Timeout waiting for agent response on port 8307
```

**í•´ê²° ë°©ë²•:**
```python
# 1. ì—ì´ì „íŠ¸ ìƒíƒœ í™•ì¸
from core.universal_engine.a2a_integration.a2a_agent_discovery import A2AAgentDiscoverySystem
import asyncio

async def check_agents():
    discovery = A2AAgentDiscoverySystem()
    status = await discovery.check_agent_health()
    for agent_id, info in status.items():
        print(f"Agent {agent_id}: {info['status']} (Port: {info.get('port', 'N/A')})")

asyncio.run(check_agents())

# 2. íƒ€ì„ì•„ì›ƒ ì¦ê°€
context = {
    "a2a_timeout": 60,  # ê¸°ë³¸ 30ì´ˆì—ì„œ 60ì´ˆë¡œ ì¦ê°€
    "retry_count": 3    # ì¬ì‹œë„ íšŸìˆ˜ ì¦ê°€
}

# 3. ì—ì´ì „íŠ¸ ì¬ì‹œì‘
./scripts/restart_a2a_agents.sh
```

#### ğŸ”´ ë¬¸ì œ: Circuit breaker is open
```
Warning: Circuit breaker open for agent on port 8309
```

**í•´ê²° ë°©ë²•:**
```python
# 1. Circuit Breaker ìƒíƒœ í™•ì¸
from core.universal_engine.a2a_integration.a2a_error_handler import A2AErrorHandler

error_handler = A2AErrorHandler()
# Circuit Breaker ìƒíƒœ ë¦¬ì…‹ (ê´€ë¦¬ì ê¶Œí•œ í•„ìš”)

# 2. ë¬¸ì œ ì—ì´ì „íŠ¸ ìˆ˜ë™ ë³µêµ¬
import requests

try:
    response = requests.get("http://localhost:8309/health", timeout=5)
    if response.status_code == 200:
        print("Agent is healthy, resetting circuit breaker")
except requests.exceptions.RequestException as e:
    print(f"Agent still unhealthy: {e}")

# 3. ëŒ€ì²´ ì—ì´ì „íŠ¸ ì‚¬ìš©
context = {
    "exclude_agents": ["statistical_analyzer"],  # ë¬¸ì œ ì—ì´ì „íŠ¸ ì œì™¸
    "fallback_mode": True
}
```

### 4. ì„±ëŠ¥ ê´€ë ¨ ë¬¸ì œ

#### ğŸ”´ ë¬¸ì œ: Slow query processing
```
Warning: Query processing took 45.2 seconds (threshold: 10.0s)
```

**í•´ê²° ë°©ë²•:**
```python
# 1. ì¿¼ë¦¬ ë³µì¡ë„ ë¶„ì„
def analyze_query_complexity(query, data):
    complexity_score = 0
    
    # ë°ì´í„° í¬ê¸°
    if hasattr(data, 'shape'):
        rows, cols = data.shape
        complexity_score += rows * 0.001 + cols * 0.01
    
    # ì¿¼ë¦¬ í‚¤ì›Œë“œ
    complex_keywords = ['machine learning', 'clustering', 'regression', 'neural network']
    for keyword in complex_keywords:
        if keyword.lower() in query.lower():
            complexity_score += 5
    
    return complexity_score

# 2. ë°ì´í„° ìƒ˜í”Œë§
def sample_large_data(df, max_rows=10000):
    if len(df) > max_rows:
        return df.sample(n=max_rows)
    return df

# 3. ìºì‹± í™œìš©
import hashlib
import pickle
import os

def cache_result(query, data, result):
    cache_key = hashlib.md5(f"{query}{str(data.shape) if hasattr(data, 'shape') else ''}".encode()).hexdigest()
    cache_file = f"cache/{cache_key}.pkl"
    os.makedirs("cache", exist_ok=True)
    with open(cache_file, 'wb') as f:
        pickle.dump(result, f)

def get_cached_result(query, data):
    cache_key = hashlib.md5(f"{query}{str(data.shape) if hasattr(data, 'shape') else ''}".encode()).hexdigest()
    cache_file = f"cache/{cache_key}.pkl"
    if os.path.exists(cache_file):
        with open(cache_file, 'rb') as f:
            return pickle.load(f)
    return None
```

#### ğŸ”´ ë¬¸ì œ: High memory usage
```
Error: Memory usage exceeded 80% threshold (current: 85%)
```

**í•´ê²° ë°©ë²•:**
```bash
# 1. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
ps aux | grep python | sort -nrk 4 | head -5

# 2. ë©”ëª¨ë¦¬ í”„ë¡œíŒŒì¼ë§
pip install memory-profiler
python -m memory_profiler your_script.py

# 3. ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ê°•ì œ ì‹¤í–‰
python -c "import gc; gc.collect()"

# 4. ì‹œìŠ¤í…œ ìŠ¤ì™‘ í™•ì¸ ë° ì¶”ê°€
free -h
sudo swapon --show

# ì„ì‹œ ìŠ¤ì™‘ íŒŒì¼ ìƒì„±
sudo fallocate -l 2G /swapfile
sudo chmod 600 /swapfile
sudo mkswap /swapfile
sudo swapon /swapfile
```

### 5. ë°ì´í„° ê´€ë ¨ ë¬¸ì œ

#### ğŸ”´ ë¬¸ì œ: Data format not supported
```
Error: Unsupported data format: .xlsx
```

**í•´ê²° ë°©ë²•:**
```python
# 1. ì§€ì› í˜•ì‹ í™•ì¸
supported_formats = ['.csv', '.json', '.parquet', '.pkl']

# 2. ë°ì´í„° í˜•ì‹ ë³€í™˜
import pandas as pd

# Excel íŒŒì¼ ì½ê¸°
if file_path.endswith('.xlsx') or file_path.endswith('.xls'):
    df = pd.read_excel(file_path)
    # CSVë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥
    csv_path = file_path.replace('.xlsx', '.csv').replace('.xls', '.csv')
    df.to_csv(csv_path, index=False)
    
# JSON íŒŒì¼ ì²˜ë¦¬
elif file_path.endswith('.json'):
    df = pd.read_json(file_path)

# 3. ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬
def validate_data(df):
    issues = []
    
    # ë¹ˆ ë°ì´í„°í”„ë ˆì„
    if df.empty:
        issues.append("DataFrame is empty")
    
    # ë„ˆë¬´ ë§ì€ ê²°ì¸¡ê°’
    missing_ratio = df.isnull().sum().sum() / (df.shape[0] * df.shape[1])
    if missing_ratio > 0.5:
        issues.append(f"High missing values ratio: {missing_ratio:.2%}")
    
    # ë°ì´í„° íƒ€ì… ë¬¸ì œ
    object_cols = df.select_dtypes(include=['object']).columns
    if len(object_cols) == len(df.columns):
        issues.append("All columns are object type")
    
    return issues
```

#### ğŸ”´ ë¬¸ì œ: Data corruption detected
```
Error: Data integrity check failed
```

**í•´ê²° ë°©ë²•:**
```python
# 1. ë°ì´í„° ë¬´ê²°ì„± ê²€ì‚¬
import pandas as pd
import numpy as np

def data_integrity_check(df):
    report = {
        'total_rows': len(df),
        'total_columns': len(df.columns),
        'missing_values': df.isnull().sum().to_dict(),
        'duplicate_rows': df.duplicated().sum(),
        'infinite_values': {}
    }
    
    # ë¬´í•œê°’ ê²€ì‚¬
    for col in df.select_dtypes(include=[np.number]).columns:
        inf_count = np.isinf(df[col]).sum()
        if inf_count > 0:
            report['infinite_values'][col] = inf_count
    
    return report

# 2. ë°ì´í„° ì •ë¦¬
def clean_data(df):
    # ì¤‘ë³µ í–‰ ì œê±°
    df = df.drop_duplicates()
    
    # ë¬´í•œê°’ ì²˜ë¦¬
    df = df.replace([np.inf, -np.inf], np.nan)
    
    # ê²°ì¸¡ê°’ ì²˜ë¦¬ (ìˆ˜ì¹˜í˜•ì€ ì¤‘ì•™ê°’, ë²”ì£¼í˜•ì€ ìµœë¹ˆê°’)
    for col in df.columns:
        if df[col].dtype in ['int64', 'float64']:
            df[col].fillna(df[col].median(), inplace=True)
        else:
            df[col].fillna(df[col].mode()[0] if not df[col].mode().empty else 'Unknown', inplace=True)
    
    return df
```

### 6. ë³´ì•ˆ ê´€ë ¨ ë¬¸ì œ

#### ğŸ”´ ë¬¸ì œ: Malicious input detected
```
Warning: Potentially malicious input blocked
```

**í•´ê²° ë°©ë²•:**
```python
# 1. ì…ë ¥ ê²€ì¦ ë¡œì§ í™•ì¸
import re

def is_malicious_input(query):
    malicious_patterns = [
        r"'; *DROP +TABLE",  # SQL Injection
        r"<script.*?>",      # XSS
        r"\.\.\/",           # Path Traversal
        r"system\s*\(",      # Command Injection
        r"\$\{.*\}",         # Template Injection
    ]
    
    for pattern in malicious_patterns:
        if re.search(pattern, query, re.IGNORECASE):
            return True, pattern
    return False, None

# 2. ì…ë ¥ ì •í™”
def sanitize_input(query):
    # ìœ„í—˜í•œ ë¬¸ì ì œê±°
    query = re.sub(r"[<>\"';\\]", "", query)
    # ê¸¸ì´ ì œí•œ
    if len(query) > 10000:
        query = query[:10000] + "..."
    return query

# 3. í—ˆìš© ëª©ë¡ ê¸°ë°˜ í•„í„°ë§
allowed_keywords = [
    'analyze', 'show', 'display', 'calculate', 'summarize',
    'plot', 'chart', 'graph', 'trend', 'pattern', 'correlation'
]

def validate_query_keywords(query):
    words = query.lower().split()
    has_allowed = any(keyword in ' '.join(words) for keyword in allowed_keywords)
    return has_allowed
```

#### ğŸ”´ ë¬¸ì œ: Session security violation
```
Error: Session validation failed
```

**í•´ê²° ë°©ë²•:**
```python
# 1. ì„¸ì…˜ ìœ íš¨ì„± ê²€ì‚¬
from datetime import datetime, timedelta
import hashlib

def validate_session(session_data):
    current_time = datetime.now()
    
    # ì„¸ì…˜ ë§Œë£Œ í™•ì¸
    if 'expires_at' in session_data:
        expires_at = datetime.fromisoformat(session_data['expires_at'])
        if current_time > expires_at:
            return False, "Session expired"
    
    # ì„¸ì…˜ ID í˜•ì‹ í™•ì¸
    if not re.match(r'^[a-zA-Z0-9_-]{16,}$', session_data.get('session_id', '')):
        return False, "Invalid session ID format"
    
    # ì‚¬ìš©ì ì¸ì¦ í™•ì¸
    if 'user_id' not in session_data or not session_data['user_id']:
        return False, "Missing user authentication"
    
    return True, "Valid session"

# 2. ì„¸ì…˜ ì¬ìƒì„±
def regenerate_session(old_session):
    new_session = {
        'session_id': hashlib.sha256(f"{datetime.now()}{old_session['user_id']}".encode()).hexdigest()[:32],
        'user_id': old_session['user_id'],
        'created_at': datetime.now().isoformat(),
        'expires_at': (datetime.now() + timedelta(hours=24)).isoformat(),
        'messages': [],
        'user_profile': old_session.get('user_profile', {})
    }
    return new_session
```

## ğŸ›  ì§„ë‹¨ ë„êµ¬

### 1. ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸ ìŠ¤í¬ë¦½íŠ¸

```python
#!/usr/bin/env python3
"""
Universal Engine ì‹œìŠ¤í…œ ì§„ë‹¨ ë„êµ¬
"""

import asyncio
import requests
import sys
import json
from datetime import datetime
import pandas as pd

async def system_diagnostics():
    """ì‹œìŠ¤í…œ ì „ë°˜ì ì¸ ìƒíƒœ ì§„ë‹¨"""
    
    report = {
        'timestamp': datetime.now().isoformat(),
        'system_status': {},
        'component_status': {},
        'recommendations': []
    }
    
    print("ğŸ” Universal Engine ì‹œìŠ¤í…œ ì§„ë‹¨ ì‹œì‘...")
    
    # 1. LLM ì„œë¹„ìŠ¤ í™•ì¸
    print("\n1. LLM ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸...")
    try:
        response = requests.get("http://localhost:11434/api/version", timeout=5)
        if response.status_code == 200:
            report['system_status']['llm_service'] = 'healthy'
            print("   âœ… LLM ì„œë¹„ìŠ¤ ì •ìƒ")
        else:
            report['system_status']['llm_service'] = 'unhealthy'
            print("   âŒ LLM ì„œë¹„ìŠ¤ ì‘ë‹µ ì˜¤ë¥˜")
    except requests.exceptions.RequestException:
        report['system_status']['llm_service'] = 'unreachable'
        print("   âŒ LLM ì„œë¹„ìŠ¤ ì—°ê²° ì‹¤íŒ¨")
        report['recommendations'].append("Ollama ì„œë¹„ìŠ¤ë¥¼ í™•ì¸í•˜ê³  ì¬ì‹œì‘í•˜ì„¸ìš”")
    
    # 2. A2A ì—ì´ì „íŠ¸ ìƒíƒœ í™•ì¸
    print("\n2. A2A ì—ì´ì „íŠ¸ ìƒíƒœ í™•ì¸...")
    agent_ports = range(8306, 8316)
    healthy_agents = 0
    
    for port in agent_ports:
        try:
            response = requests.get(f"http://localhost:{port}/health", timeout=2)
            if response.status_code == 200:
                healthy_agents += 1
                print(f"   âœ… Port {port}: ì •ìƒ")
            else:
                print(f"   âŒ Port {port}: ì‘ë‹µ ì˜¤ë¥˜")
        except requests.exceptions.RequestException:
            print(f"   âŒ Port {port}: ì—°ê²° ì‹¤íŒ¨")
    
    report['system_status']['a2a_agents'] = f"{healthy_agents}/{len(agent_ports)}"
    if healthy_agents < len(agent_ports) * 0.8:
        report['recommendations'].append("A2A ì—ì´ì „íŠ¸ ì„œë¹„ìŠ¤ë¥¼ í™•ì¸í•˜ì„¸ìš”")
    
    # 3. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
    print("\n3. ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ í™•ì¸...")
    import psutil
    
    memory_percent = psutil.virtual_memory().percent
    cpu_percent = psutil.cpu_percent(interval=1)
    disk_percent = psutil.disk_usage('/').percent
    
    report['system_status']['memory_usage'] = f"{memory_percent}%"
    report['system_status']['cpu_usage'] = f"{cpu_percent}%"
    report['system_status']['disk_usage'] = f"{disk_percent}%"
    
    print(f"   ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {memory_percent}%")
    print(f"   CPU ì‚¬ìš©ëŸ‰: {cpu_percent}%")
    print(f"   ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰: {disk_percent}%")
    
    if memory_percent > 80:
        report['recommendations'].append("ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ë†’ìŠµë‹ˆë‹¤. ì‹œìŠ¤í…œ ìµœì í™”ê°€ í•„ìš”í•©ë‹ˆë‹¤")
    if disk_percent > 90:
        report['recommendations'].append("ë””ìŠ¤í¬ ê³µê°„ì´ ë¶€ì¡±í•©ë‹ˆë‹¤")
    
    # 4. ì»´í¬ë„ŒíŠ¸ í…ŒìŠ¤íŠ¸
    print("\n4. Universal Engine ì»´í¬ë„ŒíŠ¸ í…ŒìŠ¤íŠ¸...")
    try:
        from core.universal_engine.universal_query_processor import UniversalQueryProcessor
        processor = UniversalQueryProcessor()
        
        test_data = pd.DataFrame({'test': [1, 2, 3]})
        result = await processor.process_query(
            query="í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬",
            data=test_data,
            context={'diagnostic_test': True}
        )
        
        report['component_status']['query_processor'] = 'working'
        print("   âœ… Query Processor ì •ìƒ")
        
    except Exception as e:
        report['component_status']['query_processor'] = f'error: {str(e)}'
        print(f"   âŒ Query Processor ì˜¤ë¥˜: {e}")
        report['recommendations'].append("Universal Engine ì»´í¬ë„ŒíŠ¸ë¥¼ ì¬ì´ˆê¸°í™”í•˜ì„¸ìš”")
    
    # ì§„ë‹¨ ë³´ê³ ì„œ ì¶œë ¥
    print("\n" + "="*60)
    print("ğŸ“Š ì§„ë‹¨ ê²°ê³¼ ìš”ì•½")
    print("="*60)
    
    for component, status in report['system_status'].items():
        print(f"{component}: {status}")
    
    if report['recommendations']:
        print("\nğŸ”§ ê¶Œì¥ ì¡°ì¹˜ì‚¬í•­:")
        for i, recommendation in enumerate(report['recommendations'], 1):
            print(f"{i}. {recommendation}")
    else:
        print("\nâœ… ëª¨ë“  ì‹œìŠ¤í…œì´ ì •ìƒ ìƒíƒœì…ë‹ˆë‹¤!")
    
    # ì§„ë‹¨ ê²°ê³¼ JSON íŒŒì¼ë¡œ ì €ì¥
    with open('system_diagnosis.json', 'w') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ“„ ìƒì„¸ ì§„ë‹¨ ê²°ê³¼ê°€ 'system_diagnosis.json'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤")
    
    return report

if __name__ == "__main__":
    asyncio.run(system_diagnostics())
```

### 2. ë¡œê·¸ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸

```python
#!/usr/bin/env python3
"""
Universal Engine ë¡œê·¸ ë¶„ì„ ë„êµ¬
"""

import re
import json
from collections import Counter, defaultdict
from datetime import datetime, timedelta

def analyze_logs(log_file_path="/var/log/universal_engine.log"):
    """ë¡œê·¸ íŒŒì¼ ë¶„ì„"""
    
    analysis_result = {
        'total_entries': 0,
        'error_count': 0,
        'warning_count': 0,
        'performance_issues': [],
        'frequent_errors': {},
        'recommendations': []
    }
    
    error_patterns = []
    response_times = []
    
    try:
        with open(log_file_path, 'r') as f:
            for line in f:
                analysis_result['total_entries'] += 1
                
                # ì—ëŸ¬ íŒ¨í„´ ì¶”ì¶œ
                if 'ERROR' in line:
                    analysis_result['error_count'] += 1
                    error_msg = re.search(r'ERROR.*?:(.*)', line)
                    if error_msg:
                        error_patterns.append(error_msg.group(1).strip())
                
                # ê²½ê³  íŒ¨í„´ ì¶”ì¶œ
                elif 'WARNING' in line:
                    analysis_result['warning_count'] += 1
                
                # ì‘ë‹µ ì‹œê°„ ì¶”ì¶œ
                response_time_match = re.search(r'processing took ([\d.]+) seconds', line)
                if response_time_match:
                    response_times.append(float(response_time_match.group(1)))
        
        # ìì£¼ ë°œìƒí•˜ëŠ” ì—ëŸ¬ ë¶„ì„
        error_counter = Counter(error_patterns)
        analysis_result['frequent_errors'] = dict(error_counter.most_common(5))
        
        # ì„±ëŠ¥ ì´ìŠˆ ë¶„ì„
        if response_times:
            avg_response_time = sum(response_times) / len(response_times)
            slow_queries = [t for t in response_times if t > 10]
            
            analysis_result['average_response_time'] = avg_response_time
            analysis_result['slow_query_count'] = len(slow_queries)
            
            if avg_response_time > 5:
                analysis_result['recommendations'].append(
                    f"í‰ê·  ì‘ë‹µ ì‹œê°„ì´ {avg_response_time:.2f}ì´ˆë¡œ ë†’ìŠµë‹ˆë‹¤. ì„±ëŠ¥ ìµœì í™”ê°€ í•„ìš”í•©ë‹ˆë‹¤"
                )
        
        # ì—ëŸ¬ìœ¨ ë¶„ì„
        error_rate = analysis_result['error_count'] / analysis_result['total_entries'] * 100
        if error_rate > 5:
            analysis_result['recommendations'].append(
                f"ì—ëŸ¬ìœ¨ì´ {error_rate:.1f}%ë¡œ ë†’ìŠµë‹ˆë‹¤. ì‹œìŠ¤í…œ ì•ˆì •ì„± ê²€í† ê°€ í•„ìš”í•©ë‹ˆë‹¤"
            )
        
    except FileNotFoundError:
        analysis_result['error'] = f"ë¡œê·¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {log_file_path}"
    
    return analysis_result

def print_log_analysis(analysis):
    """ë¡œê·¸ ë¶„ì„ ê²°ê³¼ ì¶œë ¥"""
    print("ğŸ“Š ë¡œê·¸ ë¶„ì„ ê²°ê³¼")
    print("="*50)
    
    if 'error' in analysis:
        print(f"âŒ {analysis['error']}")
        return
    
    print(f"ì´ ë¡œê·¸ ì—”íŠ¸ë¦¬: {analysis['total_entries']:,}")
    print(f"ì—ëŸ¬ ë°œìƒ ìˆ˜: {analysis['error_count']:,}")
    print(f"ê²½ê³  ë°œìƒ ìˆ˜: {analysis['warning_count']:,}")
    
    if 'average_response_time' in analysis:
        print(f"í‰ê·  ì‘ë‹µ ì‹œê°„: {analysis['average_response_time']:.2f}ì´ˆ")
        print(f"ëŠë¦° ì¿¼ë¦¬ ìˆ˜: {analysis['slow_query_count']:,}")
    
    if analysis['frequent_errors']:
        print("\nğŸ”´ ìì£¼ ë°œìƒí•˜ëŠ” ì—ëŸ¬:")
        for error, count in analysis['frequent_errors'].items():
            print(f"  â€¢ {error} ({count}íšŒ)")
    
    if analysis['recommendations']:
        print("\nğŸ”§ ê¶Œì¥ ì¡°ì¹˜ì‚¬í•­:")
        for rec in analysis['recommendations']:
            print(f"  â€¢ {rec}")

if __name__ == "__main__":
    import sys
    log_file = sys.argv[1] if len(sys.argv) > 1 else "/var/log/universal_engine.log"
    analysis = analyze_logs(log_file)
    print_log_analysis(analysis)
```

### 3. ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ

```python
#!/usr/bin/env python3
"""
Universal Engine ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ
"""

import time
import psutil
import requests
from datetime import datetime
import json

class PerformanceMonitor:
    def __init__(self):
        self.metrics_history = []
    
    def collect_metrics(self):
        """ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        metrics = {
            'timestamp': datetime.now().isoformat(),
            'system': {
                'cpu_percent': psutil.cpu_percent(),
                'memory_percent': psutil.virtual_memory().percent,
                'disk_percent': psutil.disk_usage('/').percent,
                'load_average': psutil.getloadavg()[0] if hasattr(psutil, 'getloadavg') else 0
            },
            'network': {
                'connections': len(psutil.net_connections()),
                'bytes_sent': psutil.net_io_counters().bytes_sent,
                'bytes_recv': psutil.net_io_counters().bytes_recv
            },
            'application': {
                'llm_status': self.check_llm_status(),
                'a2a_agents': self.check_a2a_agents(),
                'response_time': self.measure_response_time()
            }
        }
        
        self.metrics_history.append(metrics)
        if len(self.metrics_history) > 100:  # ìµœê·¼ 100ê°œë§Œ ìœ ì§€
            self.metrics_history.pop(0)
        
        return metrics
    
    def check_llm_status(self):
        """LLM ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸"""
        try:
            response = requests.get("http://localhost:11434/api/version", timeout=2)
            return "healthy" if response.status_code == 200 else "unhealthy"
        except:
            return "unreachable"
    
    def check_a2a_agents(self):
        """A2A ì—ì´ì „íŠ¸ ìƒíƒœ í™•ì¸"""
        healthy_count = 0
        total_count = 10  # 8306-8315
        
        for port in range(8306, 8316):
            try:
                response = requests.get(f"http://localhost:{port}/health", timeout=1)
                if response.status_code == 200:
                    healthy_count += 1
            except:
                pass
        
        return f"{healthy_count}/{total_count}"
    
    def measure_response_time(self):
        """ì‘ë‹µ ì‹œê°„ ì¸¡ì •"""
        try:
            start_time = time.time()
            response = requests.get("http://localhost:8000/health", timeout=5)
            end_time = time.time()
            
            if response.status_code == 200:
                return round((end_time - start_time) * 1000, 2)  # ms ë‹¨ìœ„
        except:
            pass
        return None
    
    def display_dashboard(self, metrics):
        """ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œ ì¶œë ¥"""
        import os
        os.system('clear' if os.name == 'posix' else 'cls')
        
        print("ğŸ–¥ï¸  Universal Engine ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ")
        print("=" * 60)
        print(f"ğŸ“… ì—…ë°ì´íŠ¸ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print()
        
        # ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­
        sys_metrics = metrics['system']
        print("ğŸ–¥ï¸  ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤:")
        print(f"   CPU ì‚¬ìš©ëŸ‰:    {sys_metrics['cpu_percent']:6.1f}% {'ğŸ”´' if sys_metrics['cpu_percent'] > 80 else 'ğŸŸ¢' if sys_metrics['cpu_percent'] < 50 else 'ğŸŸ¡'}")
        print(f"   ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {sys_metrics['memory_percent']:6.1f}% {'ğŸ”´' if sys_metrics['memory_percent'] > 80 else 'ğŸŸ¢' if sys_metrics['memory_percent'] < 70 else 'ğŸŸ¡'}")
        print(f"   ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰: {sys_metrics['disk_percent']:6.1f}% {'ğŸ”´' if sys_metrics['disk_percent'] > 90 else 'ğŸŸ¢' if sys_metrics['disk_percent'] < 70 else 'ğŸŸ¡'}")
        
        # ì• í”Œë¦¬ì¼€ì´ì…˜ ë©”íŠ¸ë¦­
        app_metrics = metrics['application']
        print("\nğŸš€ ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒíƒœ:")
        
        llm_status = app_metrics['llm_status']
        llm_icon = 'ğŸŸ¢' if llm_status == 'healthy' else 'ğŸ”´'
        print(f"   LLM ì„œë¹„ìŠ¤:    {llm_status:>12} {llm_icon}")
        
        a2a_status = app_metrics['a2a_agents']
        a2a_healthy = int(a2a_status.split('/')[0])
        a2a_total = int(a2a_status.split('/')[1])
        a2a_icon = 'ğŸŸ¢' if a2a_healthy == a2a_total else 'ğŸŸ¡' if a2a_healthy > a2a_total * 0.7 else 'ğŸ”´'
        print(f"   A2A ì—ì´ì „íŠ¸:  {a2a_status:>12} {a2a_icon}")
        
        response_time = app_metrics['response_time']
        if response_time:
            rt_icon = 'ğŸŸ¢' if response_time < 100 else 'ğŸŸ¡' if response_time < 500 else 'ğŸ”´'
            print(f"   ì‘ë‹µ ì‹œê°„:     {response_time:>9.1f}ms {rt_icon}")
        else:
            print(f"   ì‘ë‹µ ì‹œê°„:     {'N/A':>12} âšª")
        
        # ì•Œë¦¼ ë° ê¶Œì¥ì‚¬í•­
        alerts = []
        if sys_metrics['cpu_percent'] > 80:
            alerts.append("CPU ì‚¬ìš©ëŸ‰ì´ ë†’ìŠµë‹ˆë‹¤")
        if sys_metrics['memory_percent'] > 80:
            alerts.append("ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ë†’ìŠµë‹ˆë‹¤")
        if llm_status != 'healthy':
            alerts.append("LLM ì„œë¹„ìŠ¤ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤")
        if response_time and response_time > 1000:
            alerts.append("ì‘ë‹µ ì‹œê°„ì´ ëŠë¦½ë‹ˆë‹¤")
        
        if alerts:
            print("\nâš ï¸  ì•Œë¦¼:")
            for alert in alerts:
                print(f"   â€¢ {alert}")
        
        print(f"\nğŸ’¡ Press Ctrl+C to stop monitoring")
        print("-" * 60)
    
    def run_monitor(self, interval=5):
        """ëª¨ë‹ˆí„°ë§ ì‹¤í–‰"""
        try:
            while True:
                metrics = self.collect_metrics()
                self.display_dashboard(metrics)
                time.sleep(interval)
        except KeyboardInterrupt:
            print("\n\nëª¨ë‹ˆí„°ë§ì„ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤.")
            
            # ë©”íŠ¸ë¦­ íˆìŠ¤í† ë¦¬ ì €ì¥
            with open(f'metrics_history_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json', 'w') as f:
                json.dump(self.metrics_history, f, indent=2, ensure_ascii=False)
            print("ë©”íŠ¸ë¦­ íˆìŠ¤í† ë¦¬ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    monitor = PerformanceMonitor()
    monitor.run_monitor()
```

## ğŸ“ ì§€ì› ìš”ì²­

ë¬¸ì œê°€ í•´ê²°ë˜ì§€ ì•ŠëŠ” ê²½ìš° ë‹¤ìŒ ì •ë³´ë¥¼ í¬í•¨í•˜ì—¬ ì§€ì›ì„ ìš”ì²­í•˜ì„¸ìš”:

### ğŸ“‹ í•„ìˆ˜ ì •ë³´

1. **ì‹œìŠ¤í…œ í™˜ê²½**
   - OS ë° ë²„ì „
   - Python ë²„ì „
   - Universal Engine ë²„ì „

2. **ì˜¤ë¥˜ ì •ë³´**
   - ì •í™•í•œ ì˜¤ë¥˜ ë©”ì‹œì§€
   - ë°œìƒ ì‹œê°
   - ì¬í˜„ ë‹¨ê³„

3. **ë¡œê·¸ íŒŒì¼**
   ```bash
   # ìµœê·¼ ë¡œê·¸ ì¶”ì¶œ
   tail -100 /var/log/universal_engine.log > error_logs.txt
   ```

4. **ì‹œìŠ¤í…œ ìƒíƒœ**
   ```bash
   # ì§„ë‹¨ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
   python diagnostics.py > system_status.txt
   ```

### ğŸ“§ ì§€ì› ì±„ë„

- **GitHub Issues**: ë²„ê·¸ ë¦¬í¬íŠ¸ ë° ê¸°ëŠ¥ ìš”ì²­
- **ê¸°ìˆ  ë¬¸ì„œ**: [Universal Engine Documentation](./README.md)
- **ì»¤ë®¤ë‹ˆí‹° í¬ëŸ¼**: ì‚¬ìš©ì ê°„ ì •ë³´ ê³µìœ 

---

ì´ ë¬¸ì œ í•´ê²° ê°€ì´ë“œë¥¼ í†µí•´ ëŒ€ë¶€ë¶„ì˜ ì¼ë°˜ì ì¸ ë¬¸ì œë“¤ì„ í•´ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¶”ê°€ì ì¸ ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“ ì§€ ì§€ì›íŒ€ì— ë¬¸ì˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.