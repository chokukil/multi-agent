# ğŸ”§ CherryAI v2.0 API ì°¸ì¡° ë¬¸ì„œ

**ê°œë°œìë¥¼ ìœ„í•œ ì™„ì „í•œ ê¸°ìˆ  ë¬¸ì„œ**

## ğŸ“‹ ëª©ì°¨

- [ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜](#-ì‹œìŠ¤í…œ-ì•„í‚¤í…ì²˜)
- [A2A Protocol API](#-a2a-protocol-api)
- [Core Components](#-core-components)
- [Data Management](#-data-management)
- [Agent System](#-agent-system)
- [UI Components](#-ui-components)
- [Configuration](#-configuration)
- [Error Handling](#-error-handling)
- [Testing](#-testing)

## ğŸ—ï¸ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

### ì „ì²´ êµ¬ì¡°

```python
CherryAI_v2/
â”œâ”€â”€ core/                    # í•µì‹¬ ì‹œìŠ¤í…œ ì»´í¬ë„ŒíŠ¸
â”‚   â”œâ”€â”€ user_file_tracker.py     # Phase 1: íŒŒì¼ ì¶”ì  ì‹œìŠ¤í…œ
â”‚   â”œâ”€â”€ session_data_manager.py  # ì„¸ì…˜ ë°ì´í„° ê´€ë¦¬
â”‚   â”œâ”€â”€ multi_agent_orchestrator.py # Phase 3: ë©€í‹° ì—ì´ì „íŠ¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°
â”‚   â”œâ”€â”€ enhanced_langfuse_tracer.py # Phase 4: ê´€ì°°ì„± ì‹œìŠ¤í…œ
â”‚   â””â”€â”€ ...
â”œâ”€â”€ a2a_ds_servers/         # A2A í”„ë¡œí† ì½œ ì„œë²„ë“¤
â”œâ”€â”€ ui/                     # Streamlit UI ì»´í¬ë„ŒíŠ¸
â””â”€â”€ tests/                  # í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œ
```

### ë°ì´í„° í”Œë¡œìš°

```mermaid
graph TD
    A[User Upload] --> B[UserFileTracker]
    B --> C[SessionDataManager]
    C --> D[MultiAgentOrchestrator]
    D --> E[A2A Agents]
    E --> F[Result Processing]
    F --> G[UI Rendering]
    
    H[LangfuseTracer] --> I[Observability]
    D --> H
    E --> H
    F --> H
```

## ğŸ¤– A2A Protocol API

### Agent Card êµ¬ì¡°

ëª¨ë“  A2A ì—ì´ì „íŠ¸ëŠ” í‘œì¤€ Agent Cardë¥¼ ì œê³µí•©ë‹ˆë‹¤:

```json
{
  "agent_id": "orchestrator",
  "agent_name": "Data Science Orchestrator",
  "agent_description": "Central coordination for multi-agent data analysis",
  "version": "2.0.0",
  "skills": [
    "task_planning",
    "agent_coordination", 
    "workflow_management"
  ],
  "supported_formats": ["text", "data"],
  "endpoints": {
    "execute": "/.well-known/agent.json",
    "health": "/health"
  }
}
```

### A2A ë©”ì‹œì§€ êµ¬ì¡°

#### ìš”ì²­ ë©”ì‹œì§€
```python
from a2a.types import A2AMessage, TextPart

message = A2AMessage(
    message_id="msg_123",
    role="user",
    parts=[
        TextPart(text="Analyze this dataset and provide insights")
    ],
    metadata={
        "session_id": "session_abc",
        "user_context": {"emp_no": "EMP001"},
        "file_paths": ["/data/sample.csv"]
    }
)
```

#### ì‘ë‹µ ë©”ì‹œì§€
```python
from a2a.types import A2AMessage, TextPart, DataPart

response = A2AMessage(
    message_id="msg_124",
    role="assistant", 
    parts=[
        TextPart(text="Analysis completed. Key findings:"),
        DataPart(
            data=analysis_results,
            content_type="application/json"
        )
    ],
    metadata={
        "processing_time": 15.2,
        "agent_used": ["eda_tools", "visualization"],
        "confidence": 0.95
    }
)
```

### A2A ì„œë²„ í¬íŠ¸ êµ¬ì„±

| ì„œë²„ | í¬íŠ¸ | ì—”ë“œí¬ì¸íŠ¸ | ê¸°ëŠ¥ |
|------|------|------------|------|
| **Orchestrator** | 8100 | `/execute` | ì¤‘ì•™ ì¡°ì • |
| **Pandas Analyst** | 8200 | `/execute` | ë°ì´í„° ë¶„ì„ |
| **EDA Tools** | 8203 | `/execute` | íƒìƒ‰ì  ë¶„ì„ |
| **Data Visualization** | 8202 | `/execute` | ì‹œê°í™” |
| **SQL Analyst** | 8002 | `/execute` | SQL ë¶„ì„ |

### A2A í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš©ë²•

```python
from a2a.client import A2AClient
import asyncio

async def call_agent():
    client = A2AClient("http://localhost:8200")
    
    # Agent Card í™•ì¸
    agent_card = await client.get_agent_card()
    print(f"Agent: {agent_card.agent_name}")
    
    # ë¶„ì„ ìš”ì²­
    response = await client.execute(
        message="Analyze sales data and find trends",
        context={
            "session_id": "session_123",
            "file_path": "/data/sales.csv"
        }
    )
    
    return response

# ì‚¬ìš©
result = asyncio.run(call_agent())
```

## ğŸ”§ Core Components

### 1. UserFileTracker (Phase 1)

ì‚¬ìš©ì íŒŒì¼ì˜ ì „ì²´ ìƒëª…ì£¼ê¸°ë¥¼ ì¶”ì í•˜ê³  ê´€ë¦¬í•©ë‹ˆë‹¤.

#### í´ë˜ìŠ¤ êµ¬ì¡°
```python
from core.user_file_tracker import UserFileTracker

class UserFileTracker:
    def __init__(self):
        self.registered_files = {}
        self.session_files = {}
        self.access_history = []
    
    def register_uploaded_file(
        self, 
        session_id: str,
        file_path: str,
        original_name: str,
        data: Optional[pd.DataFrame] = None,
        user_context: Optional[str] = None
    ) -> str:
        """íŒŒì¼ ë“±ë¡ ë° ì¶”ì  ì‹œì‘"""
        pass
    
    def get_file_for_a2a_request(
        self,
        user_request: str,
        session_id: str,
        agent_name: str,
        context: Optional[Dict] = None
    ) -> Tuple[str, str]:
        """A2A ìš”ì²­ì— ìµœì í™”ëœ íŒŒì¼ ì„ íƒ"""
        pass
```

#### ì‚¬ìš© ì˜ˆì‹œ
```python
from core.user_file_tracker import get_user_file_tracker

# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
tracker = get_user_file_tracker()

# íŒŒì¼ ë“±ë¡
file_id = tracker.register_uploaded_file(
    session_id="session_123",
    file_path="/tmp/uploaded_sales.csv",
    original_name="sales_data.csv",
    data=dataframe,
    user_context="Q3 sales performance data"
)

# A2A ìš”ì²­ìš© íŒŒì¼ ì„ íƒ
file_path, reason = tracker.get_file_for_a2a_request(
    user_request="Show me monthly sales trends",
    session_id="session_123", 
    agent_name="pandas_analyst"
)

print(f"Selected file: {file_path}")
print(f"Reason: {reason}")
```

### 2. SessionDataManager

ì„¸ì…˜ë³„ ë°ì´í„° ìƒíƒœë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤.

#### API
```python
from core.session_data_manager import SessionDataManager

class SessionDataManager:
    def get_current_data(self, session_id: str) -> Optional[pd.DataFrame]:
        """í˜„ì¬ ì„¸ì…˜ì˜ í™œì„± ë°ì´í„° ë°˜í™˜"""
        pass
    
    def update_data_state(
        self, 
        session_id: str, 
        new_data: pd.DataFrame,
        source: str = "user_upload"
    ) -> bool:
        """ë°ì´í„° ìƒíƒœ ì—…ë°ì´íŠ¸"""
        pass
    
    def get_data_lineage(self, session_id: str) -> List[Dict]:
        """ë°ì´í„° ë³€í™˜ ì´ë ¥ ì¡°íšŒ"""
        pass
```

### 3. MultiAgentOrchestrator (Phase 3)

ì—¬ëŸ¬ A2A ì—ì´ì „íŠ¸ë¥¼ ì¡°ì •í•˜ê³  ê´€ë¦¬í•©ë‹ˆë‹¤.

#### í•µì‹¬ ë©”ì„œë“œ
```python
from core.multi_agent_orchestrator import MultiAgentOrchestrator

class MultiAgentOrchestrator:
    async def orchestrate_analysis(
        self,
        user_query: str,
        data: pd.DataFrame,
        session_id: str,
        context: Optional[Dict] = None
    ) -> OrchestrationResult:
        """ë©€í‹° ì—ì´ì „íŠ¸ ë¶„ì„ ì¡°ì •"""
        pass
    
    def register_agent(
        self,
        agent_name: str,
        capabilities: List[str],
        server_url: str,
        priority: int = 0
    ) -> bool:
        """ìƒˆ ì—ì´ì „íŠ¸ ë“±ë¡"""
        pass
    
    async def get_agent_status(self) -> Dict[str, AgentStatus]:
        """ëª¨ë“  ì—ì´ì „íŠ¸ ìƒíƒœ í™•ì¸"""
        pass
```

#### ì‚¬ìš© ì˜ˆì‹œ
```python
from core.multi_agent_orchestrator import get_multi_agent_orchestrator

# ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ê°€ì ¸ì˜¤ê¸°
orchestrator = get_multi_agent_orchestrator()

# ë¶„ì„ ì‹¤í–‰
result = await orchestrator.orchestrate_analysis(
    user_query="Analyze customer segmentation and create visualizations",
    data=customer_data,
    session_id="session_123",
    context={
        "priority": "high",
        "output_format": "interactive"
    }
)

# ê²°ê³¼ í™•ì¸
print(f"Analysis completed: {result.success}")
print(f"Agents used: {result.agents_used}")
print(f"Insights: {result.insights}")
```

### 4. EnhancedLangfuseTracer (Phase 4)

ì™„ì „í•œ ê´€ì°°ì„±ê³¼ ì¶”ì  ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.

#### íŠ¸ë ˆì´ì‹± API
```python
from core.enhanced_langfuse_tracer import EnhancedLangfuseTracer

class EnhancedLangfuseTracer:
    def start_span(
        self,
        name: str,
        level: TraceLevel,
        input_data: Optional[Dict] = None,
        metadata: Optional[Dict] = None
    ) -> str:
        """ìƒˆ ìŠ¤íŒ¬ ì‹œì‘"""
        pass
    
    def end_span(
        self,
        span_id: str,
        output_data: Optional[Dict] = None,
        success: bool = True
    ) -> None:
        """ìŠ¤íŒ¬ ì¢…ë£Œ"""
        pass
    
    def log_agent_interaction(
        self,
        agent_name: str,
        request_data: Dict,
        response_data: Dict,
        duration_ms: float
    ) -> None:
        """ì—ì´ì „íŠ¸ ìƒí˜¸ì‘ìš© ë¡œê¹…"""
        pass
```

#### ì‚¬ìš© ì˜ˆì‹œ
```python
from core.enhanced_langfuse_tracer import get_enhanced_tracer
from core.trace_context import TraceContext

tracer = get_enhanced_tracer()

# ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì‚¬ìš©
with TraceContext("Data Analysis Workflow", user_id="EMP001") as trace_id:
    # ë¶„ì„ ë‹¨ê³„ ì¶”ì 
    span_id = tracer.start_span(
        "Data Preprocessing",
        TraceLevel.COMPONENT,
        input_data={"rows": len(data), "columns": len(data.columns)}
    )
    
    # ë¶„ì„ ìˆ˜í–‰
    processed_data = preprocess_data(data)
    
    # ìŠ¤íŒ¬ ì¢…ë£Œ
    tracer.end_span(
        span_id,
        output_data={"processed_rows": len(processed_data)},
        success=True
    )
```

## ğŸ’¾ Data Management

### íŒŒì¼ ì²˜ë¦¬ ì‹œìŠ¤í…œ

#### ì§€ì› í˜•ì‹
```python
SUPPORTED_FORMATS = {
    "csv": {
        "extensions": [".csv"],
        "max_size": "100MB",
        "encoding": "auto-detect",
        "delimiter": "auto-detect"
    },
    "excel": {
        "extensions": [".xlsx", ".xls"],
        "max_size": "100MB", 
        "sheets": "multiple"
    },
    "json": {
        "extensions": [".json"],
        "max_size": "50MB",
        "structure": "nested"
    }
}
```

#### íŒŒì¼ ì—…ë¡œë“œ API
```python
from ui.file_upload_manager import FileUploadManager

class FileUploadManager:
    def process_uploaded_file(
        self,
        uploaded_file,
        session_id: str,
        file_type: Optional[str] = None
    ) -> Tuple[pd.DataFrame, Dict]:
        """ì—…ë¡œë“œëœ íŒŒì¼ ì²˜ë¦¬"""
        pass
    
    def validate_file_format(self, file) -> Tuple[bool, str]:
        """íŒŒì¼ í˜•ì‹ ìœ íš¨ì„± ê²€ì‚¬"""
        pass
    
    def get_file_metadata(self, file_path: str) -> Dict:
        """íŒŒì¼ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"""
        pass
```

### ë°ì´í„° ë³€í™˜ íŒŒì´í”„ë¼ì¸

```python
from core.data_pipeline import DataPipeline

class DataPipeline:
    def __init__(self):
        self.transformations = []
        self.validators = []
    
    def add_transformation(
        self, 
        transform_func: Callable,
        name: str,
        description: str
    ) -> None:
        """ë³€í™˜ í•¨ìˆ˜ ì¶”ê°€"""
        pass
    
    def execute_pipeline(
        self, 
        data: pd.DataFrame,
        session_id: str
    ) -> Tuple[pd.DataFrame, List[Dict]]:
        """íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        pass
```

## ğŸ¯ Agent System

### ì—ì´ì „íŠ¸ ì¸í„°í˜ì´ìŠ¤

ëª¨ë“  A2A ì—ì´ì „íŠ¸ëŠ” í‘œì¤€ ì¸í„°í˜ì´ìŠ¤ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤:

```python
from abc import ABC, abstractmethod
from a2a.server import AgentExecutor

class BaseA2AAgent(AgentExecutor):
    @abstractmethod
    async def execute(self, request_context) -> Dict:
        """A2A ìš”ì²­ ì²˜ë¦¬"""
        pass
    
    @abstractmethod
    async def cancel(self, task_id: str) -> bool:
        """ì‘ì—… ì·¨ì†Œ"""
        pass
    
    def get_capabilities(self) -> List[str]:
        """ì—ì´ì „íŠ¸ ì—­ëŸ‰ ë°˜í™˜"""
        pass
    
    def get_health_status(self) -> Dict:
        """í—¬ìŠ¤ ìƒíƒœ ë°˜í™˜"""
        pass
```

### ì»¤ìŠ¤í…€ ì—ì´ì „íŠ¸ êµ¬í˜„

```python
from a2a_ds_servers.base.base_a2a_agent import BaseA2AAgent

class CustomAnalysisAgent(BaseA2AAgent):
    def __init__(self):
        super().__init__(
            agent_name="Custom Analysis Agent",
            agent_description="Domain-specific analysis agent",
            skills=["custom_analysis", "domain_insights"]
        )
    
    async def execute(self, request_context) -> Dict:
        # A2A ìš”ì²­ íŒŒì‹±
        message = request_context.message
        user_query = message.parts[0].text
        
        # ë„ë©”ì¸ë³„ ë¶„ì„ ìˆ˜í–‰
        results = await self.perform_custom_analysis(user_query)
        
        # ê²°ê³¼ ë°˜í™˜
        return {
            "success": True,
            "results": results,
            "agent_info": self.get_agent_info()
        }
    
    async def perform_custom_analysis(self, query: str) -> Dict:
        """ì»¤ìŠ¤í…€ ë¶„ì„ ë¡œì§"""
        # êµ¬í˜„í•  ë¶„ì„ ë¡œì§
        pass
```

### ì—ì´ì „íŠ¸ ë“±ë¡

```python
# ì„œë²„ ì‹œì‘ ì‹œ ì—ì´ì „íŠ¸ ë“±ë¡
from core.multi_agent_orchestrator import get_multi_agent_orchestrator

orchestrator = get_multi_agent_orchestrator()

# ì»¤ìŠ¤í…€ ì—ì´ì „íŠ¸ ë“±ë¡
orchestrator.register_agent(
    agent_name="custom_analysis",
    capabilities=["domain_analysis", "specialized_insights"],
    server_url="http://localhost:9000",
    priority=5
)
```

## ğŸ¨ UI Components

### Streamlit ì»´í¬ë„ŒíŠ¸ ì‹œìŠ¤í…œ

#### ê¸°ë³¸ ì»´í¬ë„ŒíŠ¸
```python
from ui.components import StreamlitComponent

class StreamlitComponent:
    def __init__(self, component_id: str):
        self.component_id = component_id
        self.state = {}
    
    def render(self, **kwargs) -> Any:
        """ì»´í¬ë„ŒíŠ¸ ë Œë”ë§"""
        pass
    
    def update_state(self, new_state: Dict) -> None:
        """ìƒíƒœ ì—…ë°ì´íŠ¸"""
        pass
```

#### íŒŒì¼ ì—…ë¡œë“œ ì»´í¬ë„ŒíŠ¸
```python
from ui.file_upload_component import FileUploadComponent

class FileUploadComponent(StreamlitComponent):
    def render(self, 
               accepted_types: List[str] = None,
               max_size: int = 100
              ) -> Optional[pd.DataFrame]:
        """íŒŒì¼ ì—…ë¡œë“œ UI ë Œë”ë§"""
        
        uploaded_file = st.file_uploader(
            "ë°ì´í„° íŒŒì¼ ì—…ë¡œë“œ",
            type=accepted_types or ['csv', 'xlsx', 'json'],
            help=f"ìµœëŒ€ {max_size}MB íŒŒì¼ ì§€ì›"
        )
        
        if uploaded_file:
            return self.process_file(uploaded_file)
        return None
```

#### ê²°ê³¼ ë Œë”ë§ ì»´í¬ë„ŒíŠ¸
```python
from ui.result_renderer import ResultRenderer

class ResultRenderer:
    def render_analysis_result(
        self,
        result: Dict,
        session_id: str,
        interactive: bool = True
    ) -> None:
        """ë¶„ì„ ê²°ê³¼ ë Œë”ë§"""
        
        # ì½”ë“œ í‘œì‹œ
        if 'generated_code' in result:
            with st.expander("ğŸ” ìƒì„±ëœ ì½”ë“œ"):
                st.code(result['generated_code'], language='python')
        
        # ì‹œê°í™” í‘œì‹œ
        if 'visualizations' in result:
            for viz in result['visualizations']:
                st.plotly_chart(viz, use_container_width=True)
        
        # ì¸ì‚¬ì´íŠ¸ í‘œì‹œ
        if 'insights' in result:
            st.info(f"ğŸ’¡ ì£¼ìš” ì¸ì‚¬ì´íŠ¸: {result['insights']}")
```

### ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°

```python
from ui.streaming_handler import StreamingHandler

class StreamingHandler:
    def __init__(self):
        self.stream_container = st.empty()
        self.progress_bar = st.progress(0)
    
    async def handle_stream(self, stream_generator):
        """ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬"""
        async for chunk in stream_generator:
            if chunk.type == "progress":
                self.progress_bar.progress(chunk.value)
            elif chunk.type == "partial_result":
                self.stream_container.write(chunk.content)
            elif chunk.type == "final_result":
                self.render_final_result(chunk.content)
```

## âš™ï¸ Configuration

### í™˜ê²½ ì„¤ì •

#### .env íŒŒì¼ êµ¬ì¡°
```env
# Core API Keys
OPENAI_API_KEY=sk-your-openai-key
LANGFUSE_PUBLIC_KEY=pk-your-public-key
LANGFUSE_SECRET_KEY=sk-your-secret-key
LANGFUSE_HOST=https://your-langfuse-host

# User Configuration  
EMP_NO=EMP001

# LLM Settings
LLM_PROVIDER=OPENAI
LLM_MODEL=gpt-4o-mini
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=2000

# A2A Server Configuration
A2A_ORCHESTRATOR_PORT=8100
A2A_PANDAS_ANALYST_PORT=8200
A2A_EDA_TOOLS_PORT=8203
A2A_DATA_VIZ_PORT=8202

# System Settings
STREAMLIT_SERVER_PORT=8501
LOGGING_LEVEL=INFO
DEBUG_MODE=false
```

#### ì„¤ì • í´ë˜ìŠ¤
```python
from core.config import CherryAIConfig

class CherryAIConfig:
    def __init__(self):
        self.load_from_env()
    
    def load_from_env(self) -> None:
        """í™˜ê²½ ë³€ìˆ˜ì—ì„œ ì„¤ì • ë¡œë“œ"""
        self.openai_api_key = os.getenv("OPENAI_API_KEY")
        self.langfuse_public_key = os.getenv("LANGFUSE_PUBLIC_KEY")
        # ... ê¸°íƒ€ ì„¤ì •
    
    def validate_config(self) -> Tuple[bool, List[str]]:
        """ì„¤ì • ìœ íš¨ì„± ê²€ì‚¬"""
        errors = []
        if not self.openai_api_key:
            errors.append("OPENAI_API_KEY is required")
        # ... ê¸°íƒ€ ê²€ì¦
        return len(errors) == 0, errors
```

### ë™ì  ì„¤ì •

```python
from core.dynamic_config import DynamicConfigManager

class DynamicConfigManager:
    def update_agent_config(
        self,
        agent_name: str,
        new_config: Dict
    ) -> bool:
        """ì—ì´ì „íŠ¸ ì„¤ì • ë™ì  ì—…ë°ì´íŠ¸"""
        pass
    
    def get_current_config(self) -> Dict:
        """í˜„ì¬ ì‹œìŠ¤í…œ ì„¤ì • ë°˜í™˜"""
        pass
    
    def reload_config(self) -> bool:
        """ì„¤ì • ë‹¤ì‹œ ë¡œë“œ"""
        pass
```

## ğŸš¨ Error Handling

### ì—ëŸ¬ ê³„ì¸µ êµ¬ì¡°

```python
class CherryAIError(Exception):
    """ê¸°ë³¸ CherryAI ì˜ˆì™¸"""
    def __init__(self, message: str, error_code: str = None):
        self.message = message
        self.error_code = error_code
        super().__init__(message)

class FileProcessingError(CherryAIError):
    """íŒŒì¼ ì²˜ë¦¬ ê´€ë ¨ ì—ëŸ¬"""
    pass

class A2AAgentError(CherryAIError):
    """A2A ì—ì´ì „íŠ¸ ê´€ë ¨ ì—ëŸ¬"""
    pass

class DataAnalysisError(CherryAIError):
    """ë°ì´í„° ë¶„ì„ ê´€ë ¨ ì—ëŸ¬"""
    pass
```

### ì—ëŸ¬ í•¸ë“¤ëŸ¬

```python
from core.error_handler import ErrorHandler

class ErrorHandler:
    def __init__(self):
        self.error_callbacks = {}
    
    def handle_error(
        self,
        error: Exception,
        context: Dict
    ) -> Tuple[bool, str]:
        """ì—ëŸ¬ ì²˜ë¦¬ ë° ë³µêµ¬ ì‹œë„"""
        
        if isinstance(error, FileProcessingError):
            return self.handle_file_error(error, context)
        elif isinstance(error, A2AAgentError):
            return self.handle_agent_error(error, context)
        else:
            return self.handle_generic_error(error, context)
    
    def handle_file_error(self, error, context) -> Tuple[bool, str]:
        """íŒŒì¼ ì²˜ë¦¬ ì—ëŸ¬ í•¸ë“¤ë§"""
        # ìë™ ë³µêµ¬ ì‹œë„
        # ëŒ€ì•ˆ ì œì•ˆ
        pass
```

### ì¬ì‹œë„ ë©”ì»¤ë‹ˆì¦˜

```python
from core.retry_handler import RetryHandler

class RetryHandler:
    def __init__(self, max_retries: int = 3):
        self.max_retries = max_retries
    
    async def retry_with_backoff(
        self,
        func: Callable,
        *args,
        **kwargs
    ) -> Any:
        """ì§€ìˆ˜ ë°±ì˜¤í”„ë¥¼ ì‚¬ìš©í•œ ì¬ì‹œë„"""
        
        for attempt in range(self.max_retries):
            try:
                return await func(*args, **kwargs)
            except Exception as e:
                if attempt == self.max_retries - 1:
                    raise e
                
                wait_time = 2 ** attempt
                await asyncio.sleep(wait_time)
```

## ğŸ§ª Testing

### í…ŒìŠ¤íŠ¸ êµ¬ì¡°

```python
# ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
class TestUserFileTracker(unittest.TestCase):
    def setUp(self):
        self.tracker = UserFileTracker()
        self.test_session_id = "test_session_123"
    
    def test_file_registration(self):
        """íŒŒì¼ ë“±ë¡ í…ŒìŠ¤íŠ¸"""
        file_id = self.tracker.register_uploaded_file(
            session_id=self.test_session_id,
            file_path="/test/sample.csv",
            original_name="sample.csv"
        )
        self.assertIsNotNone(file_id)
    
    def test_a2a_file_selection(self):
        """A2A íŒŒì¼ ì„ íƒ í…ŒìŠ¤íŠ¸"""
        # í…ŒìŠ¤íŠ¸ êµ¬í˜„
        pass

# í†µí•© í…ŒìŠ¤íŠ¸
class TestA2AIntegration(unittest.TestCase):
    async def test_end_to_end_analysis(self):
        """ì „ì²´ ë¶„ì„ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸"""
        # E2E í…ŒìŠ¤íŠ¸ êµ¬í˜„
        pass
```

### ëª¨í‚¹ ë° í”½ìŠ¤ì²˜

```python
import pytest
from unittest.mock import Mock, AsyncMock

@pytest.fixture
def mock_langfuse_client():
    """Langfuse í´ë¼ì´ì–¸íŠ¸ ëª© ê°ì²´"""
    mock_client = Mock()
    mock_client.trace = AsyncMock()
    return mock_client

@pytest.fixture
def sample_dataframe():
    """í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ ë°ì´í„°í”„ë ˆì„"""
    return pd.DataFrame({
        'date': pd.date_range('2024-01-01', periods=100),
        'value': np.random.randn(100),
        'category': np.random.choice(['A', 'B', 'C'], 100)
    })
```

### ì„±ëŠ¥ í…ŒìŠ¤íŠ¸

```python
import time
import pytest

@pytest.mark.performance
class TestPerformance:
    def test_large_dataset_processing(self):
        """ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹ ì²˜ë¦¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        large_df = pd.DataFrame(np.random.randn(100000, 10))
        
        start_time = time.time()
        result = process_large_dataset(large_df)
        processing_time = time.time() - start_time
        
        assert processing_time < 30.0  # 30ì´ˆ ì´ë‚´
        assert result is not None
    
    @pytest.mark.asyncio
    async def test_concurrent_requests(self):
        """ë™ì‹œ ìš”ì²­ ì²˜ë¦¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        tasks = []
        for i in range(10):
            task = asyncio.create_task(
                make_analysis_request(f"test_query_{i}")
            )
            tasks.append(task)
        
        results = await asyncio.gather(*tasks)
        assert all(r.success for r in results)
```

## ğŸ“Š ëª¨ë‹ˆí„°ë§ ë° ë©”íŠ¸ë¦­

### ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­

```python
from core.metrics_collector import MetricsCollector

class MetricsCollector:
    def collect_system_metrics(self) -> Dict:
        """ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        return {
            "cpu_usage": psutil.cpu_percent(),
            "memory_usage": psutil.virtual_memory().percent,
            "disk_usage": psutil.disk_usage('/').percent,
            "active_sessions": len(self.get_active_sessions()),
            "agent_health": self.check_agent_health()
        }
    
    def collect_performance_metrics(self) -> Dict:
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        return {
            "avg_response_time": self.calculate_avg_response_time(),
            "request_count": self.get_request_count(),
            "error_rate": self.calculate_error_rate(),
            "throughput": self.calculate_throughput()
        }
```

### Langfuse ë©”íŠ¸ë¦­

```python
from core.langfuse_metrics import LangfuseMetrics

class LangfuseMetrics:
    def get_trace_statistics(self, time_range: str) -> Dict:
        """íŠ¸ë ˆì´ìŠ¤ í†µê³„ ì¡°íšŒ"""
        pass
    
    def get_agent_performance(self) -> Dict:
        """ì—ì´ì „íŠ¸ë³„ ì„±ëŠ¥ ë©”íŠ¸ë¦­"""
        pass
    
    def get_user_activity(self) -> Dict:
        """ì‚¬ìš©ì í™œë™ ë©”íŠ¸ë¦­"""
        pass
```

## ğŸ”Œ í™•ì¥ì„±

### í”ŒëŸ¬ê·¸ì¸ ì‹œìŠ¤í…œ

```python
from core.plugin_manager import PluginManager

class PluginManager:
    def __init__(self):
        self.plugins = {}
    
    def register_plugin(
        self,
        plugin_name: str,
        plugin_class: type,
        config: Dict = None
    ) -> bool:
        """í”ŒëŸ¬ê·¸ì¸ ë“±ë¡"""
        pass
    
    def load_plugin(self, plugin_name: str) -> Any:
        """í”ŒëŸ¬ê·¸ì¸ ë¡œë“œ"""
        pass
    
    def unload_plugin(self, plugin_name: str) -> bool:
        """í”ŒëŸ¬ê·¸ì¸ ì–¸ë¡œë“œ"""
        pass
```

### ì»¤ìŠ¤í…€ ë¶„ì„ ëª¨ë“ˆ

```python
from core.analysis_modules import AnalysisModule

class CustomAnalysisModule(AnalysisModule):
    def __init__(self):
        super().__init__(
            module_name="custom_analysis",
            description="Domain-specific analysis module"
        )
    
    def analyze(self, data: pd.DataFrame, params: Dict) -> Dict:
        """ì»¤ìŠ¤í…€ ë¶„ì„ ìˆ˜í–‰"""
        # ë¶„ì„ ë¡œì§ êµ¬í˜„
        pass
    
    def get_supported_data_types(self) -> List[str]:
        """ì§€ì›í•˜ëŠ” ë°ì´í„° íƒ€ì… ë°˜í™˜"""
        return ["tabular", "time_series", "categorical"]
```

---

## ğŸ“ ë²„ì „ ì •ë³´

### API ë²„ì „
- **CherryAI Core**: v2.0.0
- **A2A Protocol**: v0.2.9
- **Langfuse Integration**: v2.x
- **Streamlit UI**: v1.46+

### í˜¸í™˜ì„± ë§¤íŠ¸ë¦­ìŠ¤

| Component | Minimum Version | Recommended | Latest Tested |
|-----------|----------------|-------------|---------------|
| Python | 3.12.0 | 3.12.10 | 3.12.10 |
| NumPy | 2.0.0 | 2.1.3 | 2.1.3 |
| Pandas | 2.2.0 | 2.3.0 | 2.3.0 |
| Streamlit | 1.40.0 | 1.46.0 | 1.46.0 |
| A2A SDK | 0.2.9 | 0.2.9 | 0.2.9 |

---

**ğŸ’ CherryAI v2.0 API Reference** - *Building powerful data science applications with AI*

*For questions or contributions, please refer to our [GitHub repository](https://github.com/your-repo/cherryai)* 